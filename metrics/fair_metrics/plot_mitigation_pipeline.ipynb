{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Passing pipelines to mitigation techniques\n==========================================\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This notebook shows how to pass\n`sklearn.pipeline.Pipeline`{.interpreted-text role=\"class\"} to\nmitigation techniques from Fairlearn. Note that the notebook is not to\nbe used as an example for how to assess and mitigate fairness. It is\nmerely a demonstration of the technical aspects of passing\n`sklearn.pipeline.Pipeline`{.interpreted-text role=\"class\"}. For more\ninformation around proper fairness assessment and mitigation please\nrefer to the `user_guide`{.interpreted-text role=\"ref\"}.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import json\n\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.compose import make_column_selector as selector\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\n\nfrom fairlearn.datasets import fetch_adult\nfrom fairlearn.postprocessing import ThresholdOptimizer, plot_threshold_optimizer\nfrom fairlearn.reductions import DemographicParity, ExponentiatedGradient"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Below we load the \\\"Adult\\\" census dataset and split its features,\nsensitive features, and labels into train and test sets.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "data = fetch_adult()\nX_raw = data.data\ny = (data.target == \">50K\") * 1\nA = X_raw[\"sex\"]\n\n(X_train, X_test, y_train, y_test, A_train, A_test) = train_test_split(\n    X_raw, y, A, test_size=0.3, random_state=12345, stratify=y\n)\n\nX_train = X_train.reset_index(drop=True)\nX_test = X_test.reset_index(drop=True)\ny_train = y_train.reset_index(drop=True)\ny_test = y_test.reset_index(drop=True)\nA_train = A_train.reset_index(drop=True)\nA_test = A_test.reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To illustrate Fairlearn\\'s compatibility with\n`~sklearn.pipeline.Pipeline`{.interpreted-text role=\"class\"} we first\nneed to build our pipeline. In the following we assemble a pipeline by\ncombining preprocessing steps with an estimator. The preprocessing steps\ninclude imputing, scaling for numerical features and one-hot encoding\nfor categorical features.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "numeric_transformer = Pipeline(\n    steps=[\n        (\"impute\", SimpleImputer()),\n        (\"scaler\", StandardScaler()),\n    ]\n)\ncategorical_transformer = Pipeline(\n    [\n        (\"impute\", SimpleImputer(strategy=\"most_frequent\")),\n        (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\")),\n    ]\n)\npreprocessor = ColumnTransformer(\n    transformers=[\n        (\"num\", numeric_transformer, selector(dtype_exclude=\"category\")),\n        (\"cat\", categorical_transformer, selector(dtype_include=\"category\")),\n    ]\n)\n\npipeline = Pipeline(\n    steps=[\n        (\"preprocessor\", preprocessor),\n        (\n            \"classifier\",\n            LogisticRegression(solver=\"liblinear\", fit_intercept=True),\n        ),\n    ]\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Below we will pass the pipeline to some of our mitigation techniques,\nstarting with\n`fairlearn.postprocessing.ThresholdOptimizer`{.interpreted-text\nrole=\"class\"}:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "threshold_optimizer = ThresholdOptimizer(\n    estimator=pipeline,\n    constraints=\"demographic_parity\",\n    predict_method=\"predict_proba\",\n    prefit=False,\n)\nthreshold_optimizer.fit(X_train, y_train, sensitive_features=A_train)\nprint(threshold_optimizer.predict(X_test, sensitive_features=A_test))\nprint(\n    json.dumps(\n        threshold_optimizer.interpolated_thresholder_.interpolation_dict,\n        default=str,\n        indent=4,\n    )\n)\nplot_threshold_optimizer(threshold_optimizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Similarly,\n`fairlearn.reductions.ExponentiatedGradient`{.interpreted-text\nrole=\"class\"} works with pipelines. Since it requires the\n`sample_weight` parameter of the underlying estimator internally we need\nto provide it with the correct way of passing `sample_weight` to just\nthe `\"classifier\"` step using the step name followed by two underscores\nand `sample_weight`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "exponentiated_gradient = ExponentiatedGradient(\n    estimator=pipeline,\n    constraints=DemographicParity(),\n    sample_weight_name=\"classifier__sample_weight\",\n)\nexponentiated_gradient.fit(X_train, y_train, sensitive_features=A_train)\nprint(exponentiated_gradient.predict(X_test))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}