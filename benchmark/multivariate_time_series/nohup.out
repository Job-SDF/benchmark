True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           0                   Model:              PatchTST            

[1mData Loader[0m
  Data:               job_demand_r1       Root Path:          ../../dataset/demand/
  Data Path:          r1.parquet          Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        .cache/checkpoints  

[1mForecasting Task[0m
  Seq Len:            6                   Label Len:          1                   
  Pred Len:           3                   Seasonal Patterns:  Monthly             
  Inverse:            1                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             32690               Dec In:             32690               
  C Out:              32690               d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           2                   d FF:               2048                
  Moving Avg:         25                  Factor:             1                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              learned             Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        32                  Itr:                1                   
  Train Epochs:       20                  Batch Size:         1                   
  Patience:           3                   Learning Rate:      0.0001              
  Des:                test                Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1                 

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_break_bartlett_0_PatchTST_job_demand_r1_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 19
val 1
test 4
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:12,  1.47it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:12,  1.47it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:12,  1.47it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:03,  4.63it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:03,  4.63it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:03,  4.63it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01,  7.52it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01,  7.52it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01,  7.52it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 10.17it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:01<00:01, 10.17it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:01<00:01, 10.17it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:01<00:00, 12.33it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:01<00:00, 12.33it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:01<00:00, 12.33it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 14.17it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 14.17it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 14.17it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 15.59it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 15.59it/s]loss:0.05191777322461753:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 15.59it/s]loss:0.05191777322461753:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 16.62it/s]loss:0.25713460176402925:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 16.62it/s]loss:0.4170159672892399:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 16.62it/s] loss:0.4170159672892399:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 17.30it/s]loss:0.9462721409754359:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 17.30it/s]loss:1.084756197772712:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 17.30it/s] loss:1.084756197772712: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 17.76it/s]loss:1.084756197772712: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 11.43it/s]
Epoch: 1 cost time: 2.258903980255127
Epoch: 1, Steps: 19 | Train Loss: 0.1451104 Vali Loss: 3.8428137 Test Loss: 70.9770126
Validation loss decreased (inf --> 3.842814).  Saving model ...
Updating learning rate to 0.0001
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:00, 17.68it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:00, 17.68it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:00, 17.68it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 18.23it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 18.23it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 18.23it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:00, 18.73it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:00, 18.73it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:00, 18.73it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 19.01it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 19.01it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 19.01it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 19.16it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 19.16it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 19.16it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 19.14it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 19.14it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 19.14it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 19.18it/s]loss:0.4442068357589582:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 19.18it/s]loss:2.3243076344811278:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 19.18it/s]loss:2.3243076344811278:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 19.09it/s]loss:3.521880159452359:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 19.09it/s] loss:3.8939978433780267:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 19.09it/s]loss:3.8939978433780267:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:00<00:00, 18.97it/s]loss:3.54206737217016:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 18.97it/s]  loss:3.54206737217016: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 17.99it/s]
Epoch: 2 cost time: 1.573507308959961
Epoch: 2, Steps: 19 | Train Loss: 0.7224453 Vali Loss: 4.6659107 Test Loss: 88.1268234
EarlyStopping counter: 1 out of 3
Updating learning rate to 5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:00, 18.17it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:00, 18.17it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:00, 18.17it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 18.62it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 18.62it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 18.62it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:00, 18.80it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:00, 18.80it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:00, 18.80it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 19.05it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 19.05it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 19.05it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 19.17it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 19.17it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 19.17it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 19.22it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 19.22it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 19.22it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 19.16it/s]loss:0.09227221049078245:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 19.16it/s]loss:0.5622702036959024:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 19.16it/s] loss:0.5622702036959024:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 19.12it/s]loss:0.977187761630484:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 19.12it/s] loss:1.5480816064820373:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 19.12it/s]loss:1.5480816064820373:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:00<00:00, 19.07it/s]loss:1.3666812693607882:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:00<00:00, 19.07it/s]loss:1.3666812693607882: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 18.15it/s]
Epoch: 3 cost time: 1.5608243942260742
Epoch: 3, Steps: 19 | Train Loss: 0.2392891 Vali Loss: 4.8015308 Test Loss: 74.5480652
EarlyStopping counter: 2 out of 3
Updating learning rate to 2.5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:00, 18.77it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:00, 18.77it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:00, 18.77it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 18.83it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 18.83it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 18.83it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:00, 19.02it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:00, 19.02it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:00, 19.02it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 19.13it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 19.13it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 19.13it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 19.15it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 19.15it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 19.15it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 19.09it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 19.09it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 19.09it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 19.18it/s]loss:0.05286152395332155:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 19.18it/s]loss:0.23194468014813704:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 19.18it/s]loss:0.23194468014813704:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 19.10it/s]loss:0.45565442482077545:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 19.10it/s]loss:0.8559121189811051:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 19.10it/s] loss:0.8559121189811051:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:00<00:00, 18.99it/s]loss:1.198737767954177:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:00<00:00, 18.99it/s] loss:1.198737767954177: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 18.01it/s]
Epoch: 4 cost time: 1.570490837097168
Epoch: 4, Steps: 19 | Train Loss: 0.1471111 Vali Loss: 4.2505894 Test Loss: 75.1730652
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : long_term_forecast_break_bartlett_0_PatchTST_job_demand_r1_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 4
test shape: (4, 1, 3, 32690) (4, 1, 3, 32690)
test shape: (4, 3, 32690) (4, 3, 32690)
mse:72202.8203125, mae:20.193368911743164, dtw:-999
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           0                   Model:              PatchTST            

[1mData Loader[0m
  Data:               job_demand_r1       Root Path:          ../../dataset/demand/
  Data Path:          r1.parquet          Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        .cache/checkpoints  

[1mForecasting Task[0m
  Seq Len:            6                   Label Len:          1                   
  Pred Len:           3                   Seasonal Patterns:  Monthly             
  Inverse:            1                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             32690               Dec In:             32690               
  C Out:              32690               d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           2                   d FF:               2048                
  Moving Avg:         25                  Factor:             1                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              learned             Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        32                  Itr:                1                   
  Train Epochs:       20                  Batch Size:         1                   
  Patience:           3                   Learning Rate:      0.0001              
  Des:                test                Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1                 

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_break_parzen_0_PatchTST_job_demand_r1_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 19
val 1
test 4
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:11,  1.50it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:11,  1.50it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:11,  1.50it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:03,  4.72it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:03,  4.72it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:03,  4.72it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01,  7.66it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01,  7.66it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01,  7.66it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 10.26it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:01<00:01, 10.26it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:01<00:01, 10.26it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:01<00:00, 12.46it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:01<00:00, 12.46it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:01<00:00, 12.46it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 14.08it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 14.08it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 14.08it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 15.47it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 15.47it/s]loss:0.00023545475385313905:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 15.47it/s]loss:0.00023545475385313905:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 16.52it/s]loss:0.042171182508147095:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 16.52it/s]  loss:0.23437335795845718:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 16.52it/s] loss:0.23437335795845718:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 17.22it/s]loss:0.8454756513633835:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 17.22it/s] loss:1.0417109128116873:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 17.22it/s]loss:1.0417109128116873: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 17.70it/s]loss:1.0417109128116873: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 11.41it/s]
Epoch: 1 cost time: 2.1845543384552
Epoch: 1, Steps: 19 | Train Loss: 0.1138930 Vali Loss: 3.8705053 Test Loss: 71.4254379
Validation loss decreased (inf --> 3.870505).  Saving model ...
Updating learning rate to 0.0001
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:00, 18.10it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:00, 18.10it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:00, 18.10it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 18.55it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 18.55it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 18.55it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:00, 18.85it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:00, 18.85it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:00, 18.85it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 18.87it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 18.87it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 18.87it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 18.98it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 18.98it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 18.98it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 19.07it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 19.07it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 19.07it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 19.16it/s]loss:0.001844472760352881:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 19.16it/s]loss:0.3889886799802428:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 19.16it/s]  loss:0.3889886799802428:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 19.12it/s]loss:2.1440352263042946:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 19.12it/s]loss:4.64535380086601:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 19.12it/s]  loss:4.64535380086601:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:00<00:00, 19.08it/s]loss:4.6037695014585065:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 19.08it/s]loss:4.6037695014585065: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 18.07it/s]
Epoch: 2 cost time: 1.606942892074585
Epoch: 2, Steps: 19 | Train Loss: 0.6202101 Vali Loss: 5.8764429 Test Loss: 115.6464691
EarlyStopping counter: 1 out of 3
Updating learning rate to 5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 16.12it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 16.12it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 16.12it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 17.67it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 17.67it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 17.67it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:00, 18.36it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:00, 18.36it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:00, 18.36it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 18.74it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 18.74it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 18.74it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 18.95it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 18.95it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 18.95it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 19.05it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 19.05it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 19.05it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 18.99it/s]loss:0.00036071943890119703:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 18.99it/s]loss:0.07743152063219871:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 18.99it/s]   loss:0.07743152063219871:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 18.95it/s]loss:0.5596472008581983:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 18.95it/s] loss:1.4387027867582574:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 18.95it/s]loss:1.4387027867582574:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:00<00:00, 18.94it/s]loss:1.42615550545562:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 18.94it/s]  loss:1.42615550545562: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 17.78it/s]
Epoch: 3 cost time: 1.5853335857391357
Epoch: 3, Steps: 19 | Train Loss: 0.1843315 Vali Loss: 4.5809231 Test Loss: 67.1957016
EarlyStopping counter: 2 out of 3
Updating learning rate to 2.5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:00, 17.77it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:00, 17.77it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:00, 17.77it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 18.24it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 18.24it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 18.24it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:00, 18.70it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:00, 18.70it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:00, 18.70it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 18.89it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 18.89it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 18.89it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 19.03it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 19.03it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 19.03it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 19.08it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 19.08it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 19.08it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 19.14it/s]loss:0.00021981346396617263:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 19.14it/s]loss:0.03734865084992625:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 19.14it/s]   loss:0.03734865084992625:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 18.99it/s]loss:0.2481613848975578:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 18.99it/s] loss:0.770529977205235:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 18.99it/s] loss:0.770529977205235:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:00<00:00, 18.97it/s]loss:1.155843924925933:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 18.97it/s]loss:1.155843924925933: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 18.05it/s]
Epoch: 4 cost time: 1.605625867843628
Epoch: 4, Steps: 19 | Train Loss: 0.1164265 Vali Loss: 4.0521450 Test Loss: 69.7511444
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : long_term_forecast_break_parzen_0_PatchTST_job_demand_r1_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 4
test shape: (4, 1, 3, 32690) (4, 1, 3, 32690)
test shape: (4, 3, 32690) (4, 3, 32690)
mse:57354.56640625, mae:18.739816665649414, dtw:-999
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           0                   Model:              PatchTST            

[1mData Loader[0m
  Data:               job_demand_r1       Root Path:          ../../dataset/demand/
  Data Path:          r1.parquet          Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        .cache/checkpoints  

[1mForecasting Task[0m
  Seq Len:            6                   Label Len:          1                   
  Pred Len:           3                   Seasonal Patterns:  Monthly             
  Inverse:            1                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             32690               Dec In:             32690               
  C Out:              32690               d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           2                   d FF:               2048                
  Moving Avg:         25                  Factor:             1                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              learned             Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        32                  Itr:                1                   
  Train Epochs:       20                  Batch Size:         1                   
  Patience:           3                   Learning Rate:      0.0001              
  Des:                test                Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1                 

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_break_tukey-hanning_0_PatchTST_job_demand_r1_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 19
val 1
test 4
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:12,  1.46it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:12,  1.46it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:12,  1.46it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:03,  4.58it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:03,  4.58it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:03,  4.58it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01,  7.52it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01,  7.52it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:01<00:01,  7.52it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:01<00:01, 10.16it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:01<00:01, 10.16it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:01<00:01, 10.16it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:01<00:00, 12.36it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:01<00:00, 12.36it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:01<00:00, 12.36it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 14.15it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 14.15it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 14.15it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 15.57it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 15.57it/s]loss:0.006088725627076249:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 15.57it/s]loss:0.006088725627076249:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 16.59it/s]loss:0.16944375656558705:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 16.59it/s] loss:0.43509108204228075:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 16.59it/s]loss:0.43509108204228075:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 17.33it/s]loss:1.0256855889925678:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 17.33it/s] loss:1.0625336171065713:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 17.33it/s]loss:1.0625336171065713: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 17.86it/s]loss:1.0625336171065713: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 11.39it/s]
Epoch: 1 cost time: 2.2370665073394775
Epoch: 1, Steps: 19 | Train Loss: 0.1420444 Vali Loss: 3.8722711 Test Loss: 71.8165436
Validation loss decreased (inf --> 3.872271).  Saving model ...
Updating learning rate to 0.0001
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 16.33it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 16.33it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 16.33it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 17.16it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 17.16it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 17.16it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:00, 18.09it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:00, 18.09it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:00, 18.09it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 18.51it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 18.51it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 18.51it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 18.80it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 18.80it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 18.80it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 18.95it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 18.95it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 18.95it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 19.06it/s]loss:0.0502773420221695:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 19.06it/s]loss:1.5929325216004497:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 19.06it/s]loss:1.5929325216004497:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 19.00it/s]loss:3.8757151214749626:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 19.00it/s]loss:4.947704752207746:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 19.00it/s] loss:4.947704752207746:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:00<00:00, 18.99it/s]loss:4.0434091177543205:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 18.99it/s]loss:4.0434091177543205: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 17.66it/s]
Epoch: 2 cost time: 1.6136984825134277
Epoch: 2, Steps: 19 | Train Loss: 0.7636863 Vali Loss: 5.1410828 Test Loss: 99.7724838
EarlyStopping counter: 1 out of 3
Updating learning rate to 5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:00, 18.18it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:00, 18.18it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:00, 18.18it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 18.07it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 18.07it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 18.07it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:00, 18.44it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:00, 18.44it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:00, 18.44it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 18.59it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 18.59it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 18.59it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 18.59it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 18.59it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 18.59it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 18.78it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 18.78it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 18.78it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 18.93it/s]loss:0.010650132455275565:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 18.93it/s]loss:0.3511558590250754:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 18.93it/s]  loss:0.3511558590250754:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 18.88it/s]loss:1.0343224232651944:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 18.88it/s]loss:1.7781383641994628:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 18.88it/s]loss:1.7781383641994628:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:00<00:00, 18.90it/s]loss:1.390368627931601:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 18.90it/s] loss:1.390368627931601: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 17.86it/s]
Epoch: 3 cost time: 1.5955860614776611
Epoch: 3, Steps: 19 | Train Loss: 0.2402440 Vali Loss: 4.6978855 Test Loss: 71.0976105
EarlyStopping counter: 2 out of 3
Updating learning rate to 2.5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:00, 18.42it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:00, 18.42it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:00, 18.42it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 18.84it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 18.84it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 18.84it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:00, 18.87it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:00, 18.87it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:00, 18.87it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 18.90it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 18.90it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 18.90it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 18.97it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 18.97it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 18.97it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 19.04it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 19.04it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 19.04it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 19.08it/s]loss:0.005983774215717027:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 19.08it/s]loss:0.15112335693677878:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 19.08it/s] loss:0.15112335693677878:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 19.03it/s]loss:0.4641458510561171:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 19.03it/s] loss:0.944041942619909:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 19.03it/s] loss:0.944041942619909:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:00<00:00, 19.03it/s]loss:1.1860867774552912:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 19.03it/s]loss:1.1860867774552912: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 18.14it/s]
Epoch: 4 cost time: 1.5386180877685547
Epoch: 4, Steps: 19 | Train Loss: 0.1448096 Vali Loss: 4.1866121 Test Loss: 73.3470459
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : long_term_forecast_break_tukey-hanning_0_PatchTST_job_demand_r1_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 4
test shape: (4, 1, 3, 32690) (4, 1, 3, 32690)
test shape: (4, 3, 32690) (4, 3, 32690)
mse:68034.359375, mae:19.84754753112793, dtw:-999
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           0                   Model:              PatchTST            

[1mData Loader[0m
  Data:               job_demand_r1       Root Path:          ../../dataset/demand/
  Data Path:          r1.parquet          Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        .cache/checkpoints  

[1mForecasting Task[0m
  Seq Len:            6                   Label Len:          1                   
  Pred Len:           3                   Seasonal Patterns:  Monthly             
  Inverse:            1                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             32690               Dec In:             32690               
  C Out:              32690               d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           2                   d FF:               2048                
  Moving Avg:         25                  Factor:             1                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              learned             Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        32                  Itr:                1                   
  Train Epochs:       20                  Batch Size:         1                   
  Patience:           3                   Learning Rate:      0.0001              
  Des:                test                Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1                 

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_break_rayleigh_0_PatchTST_job_demand_r1_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 19
val 1
test 4
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.49067167017148056:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.49067167017148056:   5%|â–Œ         | 1/19 [00:00<00:12,  1.49it/s]loss:0.4674589186646568:   5%|â–Œ         | 1/19 [00:00<00:12,  1.49it/s] loss:0.5508567714245728:   5%|â–Œ         | 1/19 [00:00<00:12,  1.49it/s]loss:0.5508567714245728:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:03,  4.68it/s]loss:0.6936196218215559:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:03,  4.68it/s]loss:0.5712803395729796:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:03,  4.68it/s]loss:0.5712803395729796:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01,  7.60it/s]loss:0.6663116192966975:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01,  7.60it/s]loss:0.8948051084137336:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01,  7.60it/s]loss:0.8948051084137336:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 10.17it/s]loss:0.7720003104522905:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:01<00:01, 10.17it/s]loss:0.7828214755724423:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:01<00:01, 10.17it/s]loss:0.7828214755724423:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:01<00:00, 12.32it/s]loss:0.8104202628583748:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:01<00:00, 12.32it/s]loss:0.8825163930991146:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:01<00:00, 12.32it/s]loss:0.8825163930991146:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 13.98it/s]loss:0.8024590441692293:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 13.98it/s]loss:0.8173141037789313:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 13.98it/s]loss:0.8173141037789313:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 15.33it/s]loss:0.8685138059067967:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 15.33it/s]loss:0.8694575917212662:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 15.33it/s]loss:0.8694575917212662:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 16.33it/s]loss:0.8042972032020107:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 16.33it/s]loss:0.7729230603296833:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 16.33it/s]loss:0.7729230603296833:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 17.08it/s]loss:1.1673601967802896:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 17.08it/s]loss:1.2382545255547657:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 17.08it/s]loss:1.2382545255547657: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 17.60it/s]loss:1.2382545255547657: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 11.40it/s]
Epoch: 1 cost time: 2.252009153366089
Epoch: 1, Steps: 19 | Train Loss: 0.7854391 Vali Loss: 3.9098604 Test Loss: 69.0903854
Validation loss decreased (inf --> 3.909860).  Saving model ...
Updating learning rate to 0.0001
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.48514406400236426:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.4664680959560076:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.4664680959560076:  11%|â–ˆ         | 2/19 [00:00<00:00, 18.41it/s]loss:0.5763182643466503:  11%|â–ˆ         | 2/19 [00:00<00:00, 18.41it/s]loss:0.645648812261617:  11%|â–ˆ         | 2/19 [00:00<00:00, 18.41it/s] loss:0.645648812261617:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 18.63it/s]loss:0.6888587961878978:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 18.63it/s]loss:0.6692286618831368:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 18.63it/s]loss:0.6692286618831368:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:00, 18.74it/s]loss:0.762224737167009:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:00, 18.74it/s] loss:0.866135942702323:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:00, 18.74it/s]loss:0.866135942702323:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 18.78it/s]loss:0.7663054942947755:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 18.78it/s]loss:0.8629191305224594:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 18.78it/s]loss:0.8629191305224594:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 18.75it/s]loss:0.9122248175333438:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 18.75it/s]loss:0.8413177483190942:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 18.75it/s]loss:0.8413177483190942:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 18.77it/s]loss:0.9253494262227205:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 18.77it/s]loss:0.9050270581637956:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 18.77it/s]loss:0.9050270581637956:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 18.71it/s]loss:0.9456628614918565:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 18.71it/s]loss:0.9551963525553224:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 18.71it/s]loss:0.9551963525553224:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 18.73it/s]loss:0.8711689040987537:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 18.73it/s]loss:0.8538524721148787:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 18.73it/s]loss:0.8538524721148787:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:00<00:00, 18.78it/s]loss:0.8334864121270368:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 18.78it/s]loss:0.8334864121270368: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 17.85it/s]
Epoch: 2 cost time: 1.598656415939331
Epoch: 2, Steps: 19 | Train Loss: 0.7806599 Vali Loss: 3.9415746 Test Loss: 68.8403778
EarlyStopping counter: 1 out of 3
Updating learning rate to 5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.47098186991958224:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.44995196628701295:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.44995196628701295:  11%|â–ˆ         | 2/19 [00:00<00:00, 18.27it/s]loss:0.4224889725734064:  11%|â–ˆ         | 2/19 [00:00<00:00, 18.27it/s] loss:0.5461714332354676:  11%|â–ˆ         | 2/19 [00:00<00:00, 18.27it/s]loss:0.5461714332354676:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 18.23it/s]loss:0.6694229365789662:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 18.23it/s]loss:0.7836153819259029:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 18.23it/s]loss:0.7836153819259029:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:00, 18.34it/s]loss:0.594430686518292:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:00, 18.34it/s] loss:0.6292558534822931:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:00, 18.34it/s]loss:0.6292558534822931:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 18.54it/s]loss:0.803290556484211:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 18.54it/s] loss:0.6940859826047925:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 18.54it/s]loss:0.6940859826047925:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 18.66it/s]loss:0.9427054594988745:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 18.66it/s]loss:0.6940254848285203:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 18.66it/s]loss:0.6940254848285203:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 18.64it/s]loss:0.8250613981950842:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 18.64it/s]loss:0.8453995758958139:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 18.64it/s]loss:0.8453995758958139:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 18.72it/s]loss:0.8087556283452315:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 18.72it/s]loss:1.0054285554406228:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 18.72it/s]loss:1.0054285554406228:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 18.77it/s]loss:0.8699145649075631:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 18.77it/s]loss:0.9156620748607375:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 18.77it/s]loss:0.9156620748607375:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:00<00:00, 18.81it/s]loss:0.8340575586139001:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 18.81it/s]loss:0.8340575586139001: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 17.89it/s]
Epoch: 3 cost time: 1.6102464199066162
Epoch: 3, Steps: 19 | Train Loss: 0.7265635 Vali Loss: 3.9208663 Test Loss: 70.4582291
EarlyStopping counter: 2 out of 3
Updating learning rate to 2.5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.3780348298309859:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.4479371743225923:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.4479371743225923:  11%|â–ˆ         | 2/19 [00:00<00:00, 18.25it/s]loss:0.44139593915655084:  11%|â–ˆ         | 2/19 [00:00<00:00, 18.25it/s]loss:0.477568982972924:  11%|â–ˆ         | 2/19 [00:00<00:00, 18.25it/s]  loss:0.477568982972924:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 18.56it/s]loss:0.513846656886511:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 18.56it/s]loss:0.6757815865450364:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 18.56it/s]loss:0.6757815865450364:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:00, 18.65it/s]loss:0.6053744657215182:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:00, 18.65it/s]loss:0.675100085446248:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:00, 18.65it/s] loss:0.675100085446248:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 18.70it/s]loss:0.6273164849682457:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 18.70it/s]loss:0.8137642894553442:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 18.70it/s]loss:0.8137642894553442:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 18.62it/s]loss:0.673485464751931:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 18.62it/s] loss:0.7257394278086376:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 18.62it/s]loss:0.7257394278086376:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 18.59it/s]loss:0.9108697200345273:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 18.59it/s]loss:0.9728594971074863:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 18.59it/s]loss:0.9728594971074863:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 18.66it/s]loss:0.8585790982368039:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 18.66it/s]loss:0.728068453084488:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 18.66it/s] loss:0.728068453084488:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 18.75it/s]loss:0.8072897305105312:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 18.75it/s]loss:0.9628291779734489:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 18.75it/s]loss:0.9628291779734489:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:00<00:00, 18.77it/s]loss:1.0695509471133557:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 18.77it/s]loss:1.0695509471133557: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 17.82it/s]
Epoch: 4 cost time: 1.5932579040527344
Epoch: 4, Steps: 19 | Train Loss: 0.7034417 Vali Loss: 3.9143243 Test Loss: 70.3645706
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : long_term_forecast_break_rayleigh_0_PatchTST_job_demand_r1_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 4
test shape: (4, 1, 3, 32690) (4, 1, 3, 32690)
test shape: (4, 3, 32690) (4, 3, 32690)
mse:59522.29296875, mae:18.468584060668945, dtw:-999
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           0                   Model:              FiLM                

[1mData Loader[0m
  Data:               job_demand_r1       Root Path:          ../../dataset/demand/
  Data Path:          r1.parquet          Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        .cache/checkpoints  

[1mForecasting Task[0m
  Seq Len:            6                   Label Len:          1                   
  Pred Len:           3                   Seasonal Patterns:  Monthly             
  Inverse:            1                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             32690               Dec In:             32690               
  C Out:              32690               d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           2                   d FF:               2048                
  Moving Avg:         25                  Factor:             1                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              learned             Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        32                  Itr:                1                   
  Train Epochs:       20                  Batch Size:         1                   
  Patience:           3                   Learning Rate:      0.0001              
  Des:                test                Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1                 

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_break_bartlett_0_FiLM_job_demand_r1_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 19
val 1
test 4
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:10,  1.65it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:10,  1.65it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:10,  1.65it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:03,  4.37it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:03,  4.37it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:03,  4.37it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:02,  6.27it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:01<00:02,  6.27it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:01<00:02,  6.27it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:01<00:01,  7.60it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:01<00:01,  7.60it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:01<00:01,  7.60it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:01<00:01,  8.52it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:01<00:01,  8.52it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:01<00:01,  8.52it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00,  9.25it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00,  9.25it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00,  9.25it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00,  9.77it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00,  9.77it/s]loss:0.06466952073285631:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00,  9.77it/s]loss:0.06466952073285631:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.09it/s]loss:0.3634963432095523:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:02<00:00, 10.09it/s] loss:0.6132895093053291:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:02<00:00, 10.09it/s]loss:0.6132895093053291:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:02<00:00, 10.28it/s]loss:0.8439490741295815:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:02<00:00, 10.28it/s]loss:1.384911183528609:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:02<00:00, 10.28it/s] loss:1.384911183528609: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:02<00:00, 10.40it/s]loss:1.384911183528609: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:02<00:00,  8.17it/s]
Epoch: 1 cost time: 2.9307022094726562
Epoch: 1, Steps: 19 | Train Loss: 0.1721219 Vali Loss: 3.8822322 Test Loss: 69.4178619
Validation loss decreased (inf --> 3.882232).  Saving model ...
Updating learning rate to 0.0001
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:02,  8.79it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:02,  8.79it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01,  8.95it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01,  8.95it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01,  8.95it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01,  9.34it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01,  9.34it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01,  9.34it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 10.14it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 10.14it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 10.14it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:01, 10.51it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:01, 10.51it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:01, 10.51it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 10.68it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:00, 10.68it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:00, 10.68it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 10.76it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 10.76it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 10.76it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 10.35it/s]loss:0.058823444484872534:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 10.35it/s]loss:0.3564222509523932:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 10.35it/s]  loss:0.3564222509523932:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 10.44it/s]loss:0.614973136803005:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 10.44it/s] loss:0.8896734628856641:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 10.44it/s]loss:0.8896734628856641:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 10.49it/s]loss:1.103087018523562:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 10.49it/s] loss:1.103087018523562: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00,  9.94it/s]
Epoch: 2 cost time: 2.4952738285064697
Epoch: 2, Steps: 19 | Train Loss: 0.1591042 Vali Loss: 3.8815415 Test Loss: 69.5300598
Validation loss decreased (3.882232 --> 3.881541).  Saving model ...
Updating learning rate to 5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:02,  7.56it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:02,  7.56it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:02,  8.34it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:02,  8.34it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:02,  8.34it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01,  9.96it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01,  9.96it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01,  9.96it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 10.52it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 10.52it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 10.52it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:01, 10.13it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:01, 10.13it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:01, 10.13it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 10.38it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:00, 10.38it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:00, 10.38it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 10.53it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 10.53it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 10.53it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 10.61it/s]loss:0.052439162419503305:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 10.61it/s]loss:0.33310475868254785:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 10.61it/s] loss:0.33310475868254785:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 10.64it/s]loss:0.7222822264751637:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 10.64it/s] loss:0.8809096322840388:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 10.64it/s]loss:0.8809096322840388:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 10.66it/s]loss:1.2451651445683394:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 10.66it/s]loss:1.2451651445683394: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.02it/s]
Epoch: 3 cost time: 2.4948644638061523
Epoch: 3, Steps: 19 | Train Loss: 0.1702053 Vali Loss: 3.8814049 Test Loss: 69.5611267
Validation loss decreased (3.881541 --> 3.881405).  Saving model ...
Updating learning rate to 2.5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:02,  8.72it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:02,  8.72it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01,  9.37it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01,  9.37it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01,  9.21it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01,  9.21it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01,  9.21it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.23it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.23it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.23it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 10.53it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 10.53it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 10.53it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 10.70it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 10.70it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:01<00:00, 10.70it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 10.78it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 10.78it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 10.78it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.79it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.79it/s]loss:0.06562231709365282:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.79it/s]loss:0.06562231709365282:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.77it/s]loss:0.3627931912855652:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.77it/s] loss:0.6142637165548331:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.77it/s]loss:0.6142637165548331:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 10.72it/s]loss:0.9275441604259391:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 10.72it/s]loss:1.2443240582334198:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 10.72it/s]loss:1.2443240582334198: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.70it/s]loss:1.2443240582334198: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.10it/s]
Epoch: 4 cost time: 2.4882919788360596
Epoch: 4, Steps: 19 | Train Loss: 0.1691867 Vali Loss: 3.8812866 Test Loss: 69.5738831
Validation loss decreased (3.881405 --> 3.881287).  Saving model ...
Updating learning rate to 1.25e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:01,  9.28it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:01,  9.28it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:01,  9.28it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.44it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.44it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.44it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.75it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.75it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.75it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 10.84it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 10.84it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 10.84it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 10.40it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 10.40it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:01<00:00, 10.40it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 10.50it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 10.50it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 10.50it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.55it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.55it/s]loss:0.06421377443403692:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.55it/s]loss:0.06421377443403692:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.57it/s]loss:0.3625852493725765:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.57it/s] loss:0.6546599328432399:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.57it/s]loss:0.6546599328432399:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 10.44it/s]loss:0.8758056295937229:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 10.44it/s]loss:1.3775722597946731:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 10.44it/s]loss:1.3775722597946731: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.39it/s]loss:1.3775722597946731: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.15it/s]
Epoch: 5 cost time: 2.4351468086242676
Epoch: 5, Steps: 19 | Train Loss: 0.1755177 Vali Loss: 3.8810706 Test Loss: 69.5761566
Validation loss decreased (3.881287 --> 3.881071).  Saving model ...
Updating learning rate to 6.25e-06
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:02,  8.11it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:02,  8.11it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:02,  8.42it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:02,  8.42it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:02,  8.42it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01,  9.83it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01,  9.83it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01,  9.83it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 10.40it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 10.40it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 10.40it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:01, 10.66it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:01, 10.66it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:01, 10.66it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 10.76it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:00, 10.76it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:00, 10.76it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 10.77it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 10.77it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 10.77it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 10.75it/s]loss:0.057946711461061166:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 10.75it/s]loss:0.32750633432839826:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 10.75it/s] loss:0.32750633432839826:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 10.65it/s]loss:0.7214180263061635:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 10.65it/s] loss:0.9665123270892941:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 10.65it/s]loss:0.9665123270892941:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 10.63it/s]loss:1.2437579125219975:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 10.63it/s]loss:1.2437579125219975: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.04it/s]
Epoch: 6 cost time: 2.5570201873779297
Epoch: 6, Steps: 19 | Train Loss: 0.1745864 Vali Loss: 3.8809440 Test Loss: 69.5808411
Validation loss decreased (3.881071 --> 3.880944).  Saving model ...
Updating learning rate to 3.125e-06
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:02,  8.53it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:02,  8.53it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:02,  8.53it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.28it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.28it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.28it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.53it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.53it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.53it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 10.75it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 10.75it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 10.75it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 10.82it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 10.82it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:01<00:00, 10.82it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 10.82it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 10.82it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 10.82it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.78it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.78it/s]loss:0.0550122641509847:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.78it/s]loss:0.0550122641509847:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.75it/s]loss:0.3213005648862783:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.75it/s]loss:0.6003699979920806:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.75it/s]loss:0.6003699979920806:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 10.72it/s]loss:0.9475526065883997:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 10.72it/s]loss:1.1645613949041882:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 10.72it/s]loss:1.1645613949041882: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.70it/s]loss:1.1645613949041882: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.38it/s]
Epoch: 7 cost time: 2.318075180053711
Epoch: 7, Steps: 19 | Train Loss: 0.1625683 Vali Loss: 3.8808777 Test Loss: 69.5812073
Validation loss decreased (3.880944 --> 3.880878).  Saving model ...
Updating learning rate to 1.5625e-06
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:01,  9.56it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:01,  9.56it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:01,  9.56it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.74it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.74it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.74it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.99it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.99it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.99it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 11.02it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 11.02it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 11.02it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 11.01it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 11.01it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:01<00:00, 11.01it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 10.95it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 10.95it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 10.95it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.89it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.89it/s]loss:0.059484420659636786:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.89it/s]loss:0.059484420659636786:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.69it/s]loss:0.3726475499739841:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.69it/s]  loss:0.5762994940336782:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.69it/s]loss:0.5762994940336782:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 10.38it/s]loss:0.8567705705428393:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 10.38it/s]loss:1.2966160996937246:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 10.38it/s]loss:1.2966160996937246: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.51it/s]loss:1.2966160996937246: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.34it/s]
Epoch: 8 cost time: 2.347703695297241
Epoch: 8, Steps: 19 | Train Loss: 0.1664115 Vali Loss: 3.8808632 Test Loss: 69.5811310
Validation loss decreased (3.880878 --> 3.880863).  Saving model ...
Updating learning rate to 7.8125e-07
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:01,  9.49it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:01,  9.49it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:01,  9.49it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.32it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.32it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.32it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.32it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.32it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.32it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 10.59it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 10.59it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 10.59it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 10.74it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 10.74it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:01<00:00, 10.74it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 10.78it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 10.78it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 10.78it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.76it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.76it/s]loss:0.052352527361486614:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.76it/s]loss:0.052352527361486614:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.73it/s]loss:0.36234297954874173:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.73it/s] loss:0.600333607242645:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.73it/s]  loss:0.600333607242645:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 10.71it/s]loss:0.927056912180375:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 10.71it/s]loss:1.2965912677694025:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 10.71it/s]loss:1.2965912677694025: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.68it/s]loss:1.2965912677694025: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.26it/s]
Epoch: 9 cost time: 2.4124176502227783
Epoch: 9, Steps: 19 | Train Loss: 0.1704567 Vali Loss: 3.8808527 Test Loss: 69.5810089
Validation loss decreased (3.880863 --> 3.880853).  Saving model ...
Updating learning rate to 3.90625e-07
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:01,  9.57it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:01,  9.57it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:01,  9.57it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.71it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.71it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.71it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.88it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.88it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.88it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 10.95it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 10.95it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 10.95it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 10.93it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 10.93it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:01<00:00, 10.93it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 10.85it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 10.85it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 10.85it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.71it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.71it/s]loss:0.06559257493489523:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.71it/s]loss:0.06559257493489523:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.73it/s]loss:0.35689542897690807:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.73it/s]loss:0.6791592662268237:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.73it/s] loss:0.6791592662268237:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 10.74it/s]loss:0.9474903467886866:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 10.74it/s]loss:1.2625618135615932:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 10.74it/s]loss:1.2625618135615932: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.71it/s]loss:1.2625618135615932: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.45it/s]
Epoch: 10 cost time: 2.297987461090088
Epoch: 10, Steps: 19 | Train Loss: 0.1743000 Vali Loss: 3.8808472 Test Loss: 69.5808868
Validation loss decreased (3.880853 --> 3.880847).  Saving model ...
Updating learning rate to 1.953125e-07
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:01,  9.38it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:01,  9.38it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:01,  9.38it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.51it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.51it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.51it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.80it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.80it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.80it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 10.89it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 10.89it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 10.89it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 10.87it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 10.87it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:01<00:00, 10.87it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 10.81it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 10.81it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 10.81it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.76it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.76it/s]loss:0.05794022662042868:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.76it/s]loss:0.05794022662042868:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.71it/s]loss:0.33486791126962295:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.71it/s]loss:0.6003227734582105:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.71it/s] loss:0.6003227734582105:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 10.69it/s]loss:0.9662227687081331:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 10.69it/s]loss:1.2965697257207236:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 10.69it/s]loss:1.2965697257207236: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.68it/s]loss:1.2965697257207236: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.46it/s]
Epoch: 11 cost time: 2.3320395946502686
Epoch: 11, Steps: 19 | Train Loss: 0.1713644 Vali Loss: 3.8808441 Test Loss: 69.5809937
Validation loss decreased (3.880847 --> 3.880844).  Saving model ...
Updating learning rate to 9.765625e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:01,  9.45it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:01,  9.45it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:01,  9.45it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01,  9.99it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01,  9.99it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01,  9.99it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.50it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.50it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.50it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 10.71it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 10.71it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 10.71it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 10.76it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 10.76it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:01<00:00, 10.76it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 10.77it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 10.77it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 10.77it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.67it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.67it/s]loss:0.06038857378421256:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.67it/s]loss:0.06038857378421256:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.66it/s]loss:0.39343492205910163:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.66it/s]loss:0.7215117386010901:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.66it/s] loss:0.7215117386010901:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 10.64it/s]loss:0.9474836394932218:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 10.64it/s]loss:1.296566458111935:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 10.64it/s] loss:1.296566458111935: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.61it/s]loss:1.296566458111935: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.30it/s]
Epoch: 12 cost time: 2.334125280380249
Epoch: 12, Steps: 19 | Train Loss: 0.1799676 Vali Loss: 3.8808424 Test Loss: 69.5809784
Validation loss decreased (3.880844 --> 3.880842).  Saving model ...
Updating learning rate to 4.8828125e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:01,  9.42it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:01,  9.42it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:01,  9.42it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.53it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.53it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.53it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.72it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.72it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.72it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 10.77it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 10.77it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 10.77it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 10.71it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 10.71it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:01<00:00, 10.71it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 10.71it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 10.71it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 10.71it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.69it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.69it/s]loss:0.052351656842189495:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.69it/s]loss:0.052351656842189495:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.66it/s]loss:0.3934343979541108:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.66it/s]  loss:0.6003199448553768:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.66it/s]loss:0.6003199448553768:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 10.67it/s]loss:1.0265478207452403:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 10.67it/s]loss:1.2491152535817405:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 10.67it/s]loss:1.2491152535817405: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.66it/s]loss:1.2491152535817405: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.31it/s]
Epoch: 13 cost time: 2.363020658493042
Epoch: 13, Steps: 19 | Train Loss: 0.1748300 Vali Loss: 3.8808417 Test Loss: 69.5809937
Validation loss decreased (3.880842 --> 3.880842).  Saving model ...
Updating learning rate to 2.44140625e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:02,  8.98it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:02,  8.98it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:02,  8.98it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.48it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.48it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.48it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.76it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.76it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.76it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 10.83it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 10.83it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 10.83it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 10.84it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 10.84it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:01<00:00, 10.84it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 10.63it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 10.63it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 10.63it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.64it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.64it/s]loss:0.0554522320008218:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.64it/s]loss:0.0554522320008218:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.64it/s]loss:0.35530577951723635:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.64it/s]loss:0.7215100221181936:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.64it/s] loss:0.7215100221181936:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 10.63it/s]loss:0.9517058737666407:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 10.63it/s]loss:1.2318078155100307:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 10.63it/s]loss:1.2318078155100307: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.63it/s]loss:1.2318078155100307: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.36it/s]
Epoch: 14 cost time: 2.396819829940796
Epoch: 14, Steps: 19 | Train Loss: 0.1745148 Vali Loss: 3.8808415 Test Loss: 69.5810013
Validation loss decreased (3.880842 --> 3.880841).  Saving model ...
Updating learning rate to 1.220703125e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:01,  9.54it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:01,  9.54it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:01,  9.54it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.67it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.67it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.67it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.87it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.87it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.87it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 10.96it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 10.96it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 10.96it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 10.95it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 10.95it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:01<00:00, 10.95it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 10.89it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 10.89it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 10.89it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.82it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.82it/s]loss:0.06559179498320006:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.82it/s]loss:0.06559179498320006:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.80it/s]loss:0.3623305501256101:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.80it/s] loss:0.5758676323675209:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.80it/s]loss:0.5758676323675209:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 10.75it/s]loss:0.8872355029515364:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 10.75it/s]loss:1.1244823317771824:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 10.75it/s]loss:1.1244823317771824: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.69it/s]loss:1.1244823317771824: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.44it/s]
Epoch: 15 cost time: 2.3063204288482666
Epoch: 15, Steps: 19 | Train Loss: 0.1587109 Vali Loss: 3.8808415 Test Loss: 69.5810089
Validation loss decreased (3.880841 --> 3.880841).  Saving model ...
Updating learning rate to 6.103515625e-09
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:02,  8.98it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:02,  8.98it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:02,  8.98it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.51it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.51it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.51it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.78it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.78it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.78it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01,  9.98it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01,  9.98it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01,  9.98it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 10.30it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 10.30it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:01<00:00, 10.30it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 10.45it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 10.45it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 10.45it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.25it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.25it/s]loss:0.05794001320298599:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.25it/s]loss:0.05794001320298599:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.13it/s]loss:0.3623304896780144:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.13it/s] loss:0.6099743576343823:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.13it/s]loss:0.6099743576343823:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 10.20it/s]loss:1.0494686524270223:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 10.20it/s]loss:1.296563761023651:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 10.20it/s] loss:1.296563761023651: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.08it/s]loss:1.296563761023651: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00,  9.65it/s]
Epoch: 16 cost time: 2.4932684898376465
Epoch: 16, Steps: 19 | Train Loss: 0.1776988 Vali Loss: 3.8808415 Test Loss: 69.5810089
Validation loss decreased (3.880841 --> 3.880841).  Saving model ...
Updating learning rate to 3.0517578125e-09
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:01,  9.34it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:01,  9.34it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01,  9.54it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01,  9.54it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01,  9.54it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 10.48it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 10.48it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 10.48it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 10.73it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 10.73it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 10.73it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:01, 10.71it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:01, 10.71it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:01, 10.71it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 10.76it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:00, 10.76it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:00, 10.76it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 10.79it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 10.79it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 10.79it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 10.78it/s]loss:0.0617411285109027:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 10.78it/s]loss:0.32744706304125076:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 10.78it/s]loss:0.32744706304125076:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 10.77it/s]loss:0.6542972962621643:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 10.77it/s] loss:1.049157310085735:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 10.77it/s] loss:1.049157310085735:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 10.73it/s]loss:1.1244822102240015:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 10.73it/s]loss:1.1244822102240015: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.37it/s]
Epoch: 17 cost time: 2.3414430618286133
Epoch: 17, Steps: 19 | Train Loss: 0.1693224 Vali Loss: 3.8808415 Test Loss: 69.5810089
Validation loss decreased (3.880841 --> 3.880841).  Saving model ...
Updating learning rate to 1.52587890625e-09
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:03,  5.98it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:03,  5.98it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:02,  7.50it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:02,  7.50it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:02,  7.50it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01,  9.39it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01,  9.39it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01,  9.39it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 10.13it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 10.13it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 10.13it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:01, 10.47it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:01, 10.47it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:01<00:01, 10.47it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:00, 10.64it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:00, 10.64it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:00, 10.64it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 10.69it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 10.69it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 10.69it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 10.70it/s]loss:0.05470961108548192:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 10.70it/s]loss:0.3141095356310701:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 10.70it/s] loss:0.3141095356310701:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 10.66it/s]loss:0.6642725000385915:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 10.66it/s]loss:0.8567483244430679:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 10.66it/s]loss:0.8567483244430679:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 10.67it/s]loss:1.3042210911512837:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 10.67it/s]loss:1.3042210911512837: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00,  9.92it/s]
Epoch: 18 cost time: 2.5117266178131104
Epoch: 18, Steps: 19 | Train Loss: 0.1681085 Vali Loss: 3.8808415 Test Loss: 69.5810089
Validation loss decreased (3.880841 --> 3.880841).  Saving model ...
Updating learning rate to 7.62939453125e-10
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:02,  8.91it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:02,  8.91it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01,  9.34it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01,  9.34it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01,  9.34it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 10.45it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 10.45it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 10.45it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 10.71it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 10.71it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 10.71it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:01, 10.76it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:01, 10.76it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:01, 10.76it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 10.71it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:00, 10.71it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:00, 10.71it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 10.70it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 10.70it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 10.70it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 10.69it/s]loss:0.06174112752278069:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 10.69it/s]loss:0.3282576634004167:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 10.69it/s] loss:0.3282576634004167:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 10.64it/s]loss:0.7057497193657889:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 10.64it/s]loss:0.9936922491691308:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 10.64it/s]loss:0.9936922491691308:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 10.64it/s]loss:1.1644964423709658:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 10.64it/s]loss:1.1644964423709658: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.23it/s]
Epoch: 19 cost time: 2.310412645339966
Epoch: 19, Steps: 19 | Train Loss: 0.1712599 Vali Loss: 3.8808415 Test Loss: 69.5810089
Validation loss decreased (3.880841 --> 3.880841).  Saving model ...
Updating learning rate to 3.814697265625e-10
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:01,  9.61it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:01,  9.61it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:01,  9.61it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.64it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.64it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.64it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.76it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.76it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.76it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 10.83it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 10.83it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 10.83it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 10.83it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 10.83it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:01<00:00, 10.83it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 10.80it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 10.80it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 10.80it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.75it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.75it/s]loss:0.05457450905808819:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.75it/s]loss:0.05457450905808819:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.70it/s]loss:0.37044676278147365:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.70it/s]loss:0.5758674728417317:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.70it/s] loss:0.5758674728417317:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 10.68it/s]loss:1.0494685580960192:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 10.68it/s]loss:1.2681565186845185:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 10.68it/s]loss:1.2681565186845185: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.65it/s]loss:1.2681565186845185: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.37it/s]
Epoch: 20 cost time: 2.381397008895874
Epoch: 20, Steps: 19 | Train Loss: 0.1746586 Vali Loss: 3.8808415 Test Loss: 69.5810089
Validation loss decreased (3.880841 --> 3.880841).  Saving model ...
Updating learning rate to 1.9073486328125e-10
>>>>>>>testing : long_term_forecast_break_bartlett_0_FiLM_job_demand_r1_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 4
test shape: (4, 1, 3, 32690) (4, 1, 3, 32690)
test shape: (4, 3, 32690) (4, 3, 32690)
mse:44136.94921875, mae:19.315685272216797, dtw:-999
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           0                   Model:              FiLM                

[1mData Loader[0m
  Data:               job_demand_r1       Root Path:          ../../dataset/demand/
  Data Path:          r1.parquet          Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        .cache/checkpoints  

[1mForecasting Task[0m
  Seq Len:            6                   Label Len:          1                   
  Pred Len:           3                   Seasonal Patterns:  Monthly             
  Inverse:            1                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             32690               Dec In:             32690               
  C Out:              32690               d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           2                   d FF:               2048                
  Moving Avg:         25                  Factor:             1                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              learned             Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        32                  Itr:                1                   
  Train Epochs:       20                  Batch Size:         1                   
  Patience:           3                   Learning Rate:      0.0001              
  Des:                test                Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1                 

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_break_parzen_0_FiLM_job_demand_r1_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 19
val 1
test 4
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:10,  1.72it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:10,  1.72it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:05,  3.35it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:05,  3.35it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:05,  3.35it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:02,  5.88it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:02,  5.88it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:02,  5.88it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:01<00:01,  7.44it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:01<00:01,  7.44it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:01<00:01,  7.44it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:01<00:01,  8.42it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:01<00:01,  8.42it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:01<00:01,  8.42it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:00,  9.02it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:00,  9.02it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:00,  9.02it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00,  9.58it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00,  9.58it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00,  9.58it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00,  9.94it/s]loss:0.0002932858083122715:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00,  9.94it/s]loss:0.05934809891349831:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00,  9.94it/s]  loss:0.05934809891349831:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 10.18it/s]loss:0.3364170805381149:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:02<00:00, 10.18it/s] loss:0.8206629176382003:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:02<00:00, 10.18it/s]loss:0.8206629176382003:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:02<00:00, 10.30it/s]loss:1.385231438104128:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:02<00:00, 10.30it/s] loss:1.385231438104128: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:02<00:00,  8.17it/s]
Epoch: 1 cost time: 2.8615903854370117
Epoch: 1, Steps: 19 | Train Loss: 0.1369449 Vali Loss: 3.8824131 Test Loss: 69.4126511
Validation loss decreased (inf --> 3.882413).  Saving model ...
Updating learning rate to 0.0001
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:01,  9.37it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:01,  9.37it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01,  8.92it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01,  8.92it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01,  9.35it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01,  9.35it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01,  9.35it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.28it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.28it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.28it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 10.57it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 10.57it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 10.57it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 10.68it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 10.68it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:01<00:00, 10.68it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 10.54it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 10.54it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 10.54it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.61it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.61it/s]loss:0.00026684006753050654:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.61it/s]loss:0.00026684006753050654:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.65it/s]loss:0.05820752091959875:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.65it/s]   loss:0.3374438619753642:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.65it/s] loss:0.3374438619753642:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 10.62it/s]loss:0.8652576598554063:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 10.62it/s]loss:1.103535866864053:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 10.62it/s] loss:1.103535866864053: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.59it/s]loss:1.103535866864053: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.09it/s]
Epoch: 2 cost time: 2.4060187339782715
Epoch: 2, Steps: 19 | Train Loss: 0.1244585 Vali Loss: 3.8819160 Test Loss: 69.5130768
Validation loss decreased (3.882413 --> 3.881916).  Saving model ...
Updating learning rate to 5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:02,  8.03it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:02,  8.03it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:02,  8.44it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:02,  8.44it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01,  8.96it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01,  8.96it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01,  8.96it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.05it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.05it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.05it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 10.46it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 10.46it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 10.46it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 10.63it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 10.63it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:01<00:00, 10.63it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 10.47it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 10.47it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 10.47it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.59it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.59it/s]loss:0.00023789949895682108:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.59it/s]loss:0.00023789949895682108:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.64it/s]loss:0.05439915385567221:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.64it/s]   loss:0.3964806908925792:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.64it/s] loss:0.3964806908925792:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 10.63it/s]loss:0.8566748430706475:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 10.63it/s]loss:1.245902402929865:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 10.63it/s] loss:1.245902402929865: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.63it/s]loss:1.245902402929865: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.10it/s]
Epoch: 3 cost time: 2.51068377494812
Epoch: 3, Steps: 19 | Train Loss: 0.1344050 Vali Loss: 3.8818376 Test Loss: 69.5399323
Validation loss decreased (3.881916 --> 3.881838).  Saving model ...
Updating learning rate to 2.5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:02,  7.98it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:02,  7.98it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:02,  7.98it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.04it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.04it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.04it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.50it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.50it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.50it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 10.56it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 10.56it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 10.56it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 10.67it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 10.67it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:01<00:00, 10.67it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 10.72it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 10.72it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 10.72it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.74it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.74it/s]loss:0.0002978615309329168:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.74it/s]loss:0.0002978615309329168:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.64it/s]loss:0.05927966231000824:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.64it/s]  loss:0.3371288972832714:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.64it/s] loss:0.3371288972832714:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 10.68it/s]loss:0.9023325010653718:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 10.68it/s]loss:1.2451354074682182:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 10.68it/s]loss:1.2451354074682182: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.39it/s]loss:1.2451354074682182: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.15it/s]
Epoch: 4 cost time: 2.424095392227173
Epoch: 4, Steps: 19 | Train Loss: 0.1339039 Vali Loss: 3.8817856 Test Loss: 69.5503845
Validation loss decreased (3.881838 --> 3.881786).  Saving model ...
Updating learning rate to 1.25e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:01,  9.28it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:01,  9.28it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:01,  9.28it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.23it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.23it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.23it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.16it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.16it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.16it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 10.34it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 10.34it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 10.34it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 10.14it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 10.14it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:01<00:00, 10.14it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 10.43it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 10.43it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 10.43it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.58it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.58it/s]loss:0.0002916729621567338:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.58it/s]loss:0.0002916729621567338:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.66it/s]loss:0.0592626521331143:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.66it/s]   loss:0.35952584611191973:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.66it/s]loss:0.35952584611191973:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 10.55it/s]loss:0.8524757279154662:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 10.55it/s] loss:1.3788991297944915:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 10.55it/s]loss:1.3788991297944915: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.57it/s]loss:1.3788991297944915: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.12it/s]
Epoch: 5 cost time: 2.4446675777435303
Epoch: 5, Steps: 19 | Train Loss: 0.1394976 Vali Loss: 3.8816500 Test Loss: 69.5532837
Validation loss decreased (3.881786 --> 3.881650).  Saving model ...
Updating learning rate to 6.25e-06
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:02,  7.48it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:02,  7.48it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01,  8.56it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01,  8.56it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01,  9.00it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01,  9.00it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01,  9.00it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.08it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.08it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.08it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 10.51it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 10.51it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 10.51it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 10.68it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 10.68it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:01<00:00, 10.68it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 10.75it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 10.75it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 10.75it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.75it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.75it/s]loss:0.0002629328116873823:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.75it/s]loss:0.0002629328116873823:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.59it/s]loss:0.05349173528615266:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.59it/s]  loss:0.39611689631019875:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.59it/s]loss:0.39611689631019875:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 10.63it/s]loss:0.9409936007771234:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 10.63it/s] loss:1.2446057340800123:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 10.63it/s]loss:1.2446057340800123: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.63it/s]loss:1.2446057340800123: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.01it/s]
Epoch: 6 cost time: 2.506049394607544
Epoch: 6, Steps: 19 | Train Loss: 0.1387090 Vali Loss: 3.8815548 Test Loss: 69.5586853
Validation loss decreased (3.881650 --> 3.881555).  Saving model ...
Updating learning rate to 3.125e-06
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:01,  9.47it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:01,  9.47it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:01,  9.47it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01,  9.75it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01,  9.75it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01,  9.66it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01,  9.66it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01,  9.66it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 10.26it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 10.26it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 10.26it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:01, 10.55it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:01, 10.55it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:01, 10.55it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 10.65it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:00, 10.65it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:00, 10.65it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 10.71it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 10.71it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 10.71it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 10.72it/s]loss:0.0002494887289858243:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 10.72it/s]loss:0.052488945262919716:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 10.72it/s] loss:0.052488945262919716:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 10.57it/s]loss:0.3294684398507876:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 10.57it/s]  loss:0.9219969767832887:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 10.57it/s]loss:0.9219969767832887:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 10.55it/s]loss:1.1649769160376198:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 10.55it/s]loss:1.1649769160376198: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.05it/s]
Epoch: 7 cost time: 2.4790563583374023
Epoch: 7, Steps: 19 | Train Loss: 0.1299569 Vali Loss: 3.8814940 Test Loss: 69.5590591
Validation loss decreased (3.881555 --> 3.881494).  Saving model ...
Updating learning rate to 1.5625e-06
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:02,  8.64it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:02,  8.64it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01,  8.79it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01,  8.79it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01,  8.79it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 10.17it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 10.17it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 10.17it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 10.07it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 10.07it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01,  9.87it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01,  9.87it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01,  9.87it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 10.14it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 10.14it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:01<00:00, 10.14it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 10.42it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 10.42it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 10.42it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.58it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.58it/s]loss:0.00027009515949360895:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.58it/s]loss:0.00027009515949360895:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.64it/s]loss:0.06087769121466694:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.64it/s]   loss:0.3162771868759816:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.64it/s] loss:0.3162771868759816:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 10.67it/s]loss:0.8336052494394421:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 10.67it/s]loss:1.2974314962148832:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 10.67it/s]loss:1.2974314962148832: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.64it/s]loss:1.2974314962148832: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00,  9.97it/s]
Epoch: 8 cost time: 2.5423524379730225
Epoch: 8, Steps: 19 | Train Loss: 0.1320243 Vali Loss: 3.8814826 Test Loss: 69.5590439
Validation loss decreased (3.881494 --> 3.881483).  Saving model ...
Updating learning rate to 7.8125e-07
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:02,  8.16it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:02,  8.16it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01,  8.65it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01,  8.65it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01,  8.65it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01,  9.11it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01,  9.11it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01,  9.11it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01,  9.83it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01,  9.83it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01,  9.83it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:01, 10.09it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:01, 10.09it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:01<00:01, 10.09it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:00, 10.38it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:00, 10.38it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:00, 10.38it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 10.56it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 10.56it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 10.56it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 10.38it/s]loss:0.00023757994140474504:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 10.38it/s]loss:0.05923443332798167:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 10.38it/s]   loss:0.05923443332798167:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 10.52it/s]loss:0.3294529545095378:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 10.52it/s] loss:0.9019169021204252:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 10.52it/s]loss:0.9019169021204252:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 10.57it/s]loss:1.2974083006375665:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 10.57it/s]loss:1.2974083006375665: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00,  9.84it/s]
Epoch: 9 cost time: 2.7137229442596436
Epoch: 9, Steps: 19 | Train Loss: 0.1362237 Vali Loss: 3.8814747 Test Loss: 69.5588913
Validation loss decreased (3.881483 --> 3.881475).  Saving model ...
Updating learning rate to 3.90625e-07
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:02,  7.69it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:02,  7.69it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:02,  7.69it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01,  9.36it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01,  9.36it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01,  9.26it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01,  9.26it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01,  9.26it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 10.02it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 10.02it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 10.02it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:01, 10.23it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:01, 10.23it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:01, 10.23it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 10.50it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:00, 10.50it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:00, 10.50it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 10.58it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 10.58it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 10.58it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 10.67it/s]loss:0.0002977211446191134:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 10.67it/s]loss:0.05833900134094078:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 10.67it/s]  loss:0.05833900134094078:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 10.68it/s]loss:0.37278544495131677:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 10.68it/s]loss:0.9219400302638492:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 10.68it/s] loss:0.9219400302638492:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 10.64it/s]loss:1.264244361534357:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 10.64it/s] loss:1.264244361534357: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00,  9.90it/s]
Epoch: 10 cost time: 2.6622912883758545
Epoch: 10, Steps: 19 | Train Loss: 0.1377688 Vali Loss: 3.8814704 Test Loss: 69.5587921
Validation loss decreased (3.881475 --> 3.881470).  Saving model ...
Updating learning rate to 1.953125e-07
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:02,  8.67it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:02,  8.67it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:02,  8.38it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:02,  8.38it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:02,  8.38it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01,  9.49it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01,  9.49it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01,  9.49it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 10.19it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 10.19it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 10.19it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:01, 10.51it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:01, 10.51it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:01, 10.51it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 10.66it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:00, 10.66it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:00, 10.66it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 10.72it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 10.72it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 10.72it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 10.75it/s]loss:0.0002629078583706128:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 10.75it/s]loss:0.05470656202846393:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 10.75it/s]  loss:0.05470656202846393:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 10.73it/s]loss:0.3294483262924484:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 10.73it/s] loss:0.9407411539519015:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 10.73it/s]loss:0.9407411539519015:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 10.72it/s]loss:1.2973889104385434:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 10.72it/s]loss:1.2973889104385434: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.07it/s]
Epoch: 11 cost time: 2.536846876144409
Epoch: 11, Steps: 19 | Train Loss: 0.1380288 Vali Loss: 3.8814676 Test Loss: 69.5589218
Validation loss decreased (3.881470 --> 3.881468).  Saving model ...
Updating learning rate to 9.765625e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:02,  8.01it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:02,  8.01it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01,  8.64it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01,  8.64it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01,  8.64it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 10.08it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 10.08it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 10.08it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 10.55it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 10.55it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 10.55it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:01, 10.52it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:01, 10.52it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:01, 10.52it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 10.67it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:00, 10.67it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:00, 10.67it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 10.47it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 10.47it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 10.47it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 10.60it/s]loss:0.00027422699064689766:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 10.60it/s]loss:0.0642978830155291:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 10.60it/s]    loss:0.0642978830155291:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 10.46it/s]loss:0.39611504128451736:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 10.46it/s]loss:0.9219340717755669:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 10.46it/s] loss:0.9219340717755669:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 10.40it/s]loss:1.2973859077532648:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 10.40it/s]loss:1.2973859077532648: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00,  9.89it/s]
Epoch: 12 cost time: 2.7388527393341064
Epoch: 12, Steps: 19 | Train Loss: 0.1410530 Vali Loss: 3.8814657 Test Loss: 69.5588989
Validation loss decreased (3.881468 --> 3.881466).  Saving model ...
Updating learning rate to 4.8828125e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:02,  7.35it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:02,  7.35it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:02,  8.13it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:02,  8.13it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01,  8.60it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01,  8.60it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01,  8.60it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01,  9.61it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01,  9.61it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01,  9.60it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01,  9.60it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01,  9.60it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:01, 10.21it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:01, 10.21it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:01<00:01, 10.21it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:00, 10.50it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:00, 10.50it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:00, 10.50it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 10.64it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 10.64it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 10.64it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 10.75it/s]loss:0.00023757652222702722:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 10.75it/s]loss:0.06429783456240015:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 10.75it/s]   loss:0.06429783456240015:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 10.72it/s]loss:0.3294469070430508:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 10.72it/s] loss:0.9999130241089793:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 10.72it/s]loss:0.9999130241089793:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 10.65it/s]loss:1.2506268592995362:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 10.65it/s]loss:1.2506268592995362: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00,  9.77it/s]
Epoch: 13 cost time: 2.641899824142456
Epoch: 13, Steps: 19 | Train Loss: 0.1391854 Vali Loss: 3.8814652 Test Loss: 69.5588989
Validation loss decreased (3.881466 --> 3.881465).  Saving model ...
Updating learning rate to 2.44140625e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:02,  8.31it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:02,  8.31it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:02,  8.17it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:02,  8.17it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:02,  8.17it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01,  9.84it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01,  9.84it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01,  9.84it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 10.26it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 10.26it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 10.26it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:01, 10.55it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:01, 10.55it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:01, 10.55it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 10.52it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:00, 10.52it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:00, 10.52it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 10.66it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 10.66it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 10.66it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 10.71it/s]loss:0.00025157362270836165:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 10.71it/s]loss:0.05804911135373371:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 10.71it/s]   loss:0.05804911135373371:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 10.57it/s]loss:0.3961142976211636:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 10.57it/s] loss:0.9265243459592152:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 10.57it/s]loss:0.9265243459592152:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 10.66it/s]loss:1.232530516058923:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 10.66it/s] loss:1.232530516058923: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.03it/s]
Epoch: 14 cost time: 2.42870831489563
Epoch: 14, Steps: 19 | Train Loss: 0.1375510 Vali Loss: 3.8814647 Test Loss: 69.5589066
Validation loss decreased (3.881465 --> 3.881465).  Saving model ...
Updating learning rate to 1.220703125e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:02,  7.94it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:02,  7.94it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:02,  8.08it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:02,  8.08it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:02,  8.08it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01,  9.86it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01,  9.86it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01,  9.86it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 10.44it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 10.44it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 10.44it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:01, 10.69it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:01, 10.69it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:01, 10.69it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 10.82it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:00, 10.82it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:00, 10.82it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 10.87it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 10.87it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 10.87it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 10.82it/s]loss:0.0002977182729216465:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 10.82it/s]loss:0.05923290922743672:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 10.82it/s]  loss:0.05923290922743672:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 10.81it/s]loss:0.31609526397961374:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 10.81it/s]loss:0.8630231419569537:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 10.81it/s] loss:0.8630231419569537:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 10.76it/s]loss:1.125178113549215:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 10.76it/s] loss:1.125178113549215: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.13it/s]
Epoch: 15 cost time: 2.535592794418335
Epoch: 15, Steps: 19 | Train Loss: 0.1244120 Vali Loss: 3.8814647 Test Loss: 69.5589142
Validation loss decreased (3.881465 --> 3.881465).  Saving model ...
Updating learning rate to 6.103515625e-09
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:02,  8.08it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:02,  8.08it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:02,  8.12it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:02,  8.12it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:02,  8.12it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01,  9.81it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01,  9.81it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01,  9.81it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 10.42it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 10.42it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 10.42it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:01, 10.46it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:01, 10.46it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:01, 10.46it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 10.67it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:00, 10.67it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:00, 10.67it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 10.74it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 10.74it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 10.74it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 10.75it/s]loss:0.00026290700206892006:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 10.75it/s]loss:0.059232903737410164:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 10.75it/s]  loss:0.059232903737410164:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 10.74it/s]loss:0.33471861061690866:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 10.74it/s] loss:1.021322479148766:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 10.74it/s]  loss:1.021322479148766:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 10.70it/s]loss:1.2973834915211495:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 10.70it/s]loss:1.2973834915211495: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.07it/s]
Epoch: 16 cost time: 2.5600712299346924
Epoch: 16, Steps: 19 | Train Loss: 0.1427853 Vali Loss: 3.8814647 Test Loss: 69.5589142
Validation loss decreased (3.881465 --> 3.881465).  Saving model ...
Updating learning rate to 3.0517578125e-09
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:02,  8.62it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:02,  8.62it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:02,  8.17it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:02,  8.17it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:02,  8.17it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01,  9.71it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01,  9.71it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01,  9.71it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01,  9.62it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01,  9.62it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01,  9.62it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:01, 10.04it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:01, 10.04it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:01<00:01, 10.04it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:00, 10.29it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:00, 10.29it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:00, 10.29it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 10.41it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 10.41it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 10.41it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 10.43it/s]loss:0.00028018214525859413:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 10.43it/s]loss:0.0534840261986259:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 10.43it/s]    loss:0.0534840261986259:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 10.42it/s]loss:0.359346975246478:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 10.42it/s] loss:1.0211737250912105:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 10.42it/s]loss:1.0211737250912105:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 10.40it/s]loss:1.1251780225814778:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 10.40it/s]loss:1.1251780225814778: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00,  9.73it/s]
Epoch: 17 cost time: 2.7256979942321777
Epoch: 17, Steps: 19 | Train Loss: 0.1347086 Vali Loss: 3.8814647 Test Loss: 69.5589142
Validation loss decreased (3.881465 --> 3.881465).  Saving model ...
Updating learning rate to 1.52587890625e-09
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:02,  7.98it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:02,  7.98it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:02,  7.14it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:02,  7.14it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:02,  7.14it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01,  8.98it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01,  8.98it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01,  8.98it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01,  9.78it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01,  9.78it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01,  9.78it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:01, 10.20it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:01, 10.20it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:01<00:01, 10.20it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:00, 10.41it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:00, 10.41it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:00, 10.41it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 10.55it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 10.55it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 10.55it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 10.54it/s]loss:0.0002483818079137964:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 10.54it/s]loss:0.051316469242190174:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 10.54it/s] loss:0.051316469242190174:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 10.52it/s]loss:0.36485821472598984:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 10.52it/s] loss:0.8335866709550379:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 10.52it/s] loss:0.8335866709550379:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 10.46it/s]loss:1.3050277605382:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 10.46it/s]   loss:1.3050277605382: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00,  9.70it/s]
Epoch: 18 cost time: 2.6100051403045654
Epoch: 18, Steps: 19 | Train Loss: 0.1344757 Vali Loss: 3.8814647 Test Loss: 69.5589142
Validation loss decreased (3.881465 --> 3.881465).  Saving model ...
Updating learning rate to 7.62939453125e-10
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:02,  7.25it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:02,  7.25it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:02,  8.01it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:02,  8.01it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:02,  8.01it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01,  9.78it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01,  9.78it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01,  9.78it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 10.30it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 10.30it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 10.30it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:01, 10.61it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:01, 10.61it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:01, 10.61it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 10.68it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:00, 10.68it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:00, 10.68it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 10.75it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 10.75it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 10.75it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 10.76it/s]loss:0.0002801821436220948:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 10.76it/s]loss:0.05365047014718267:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 10.76it/s]  loss:0.05365047014718267:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 10.75it/s]loss:0.38780963082886905:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 10.75it/s]loss:0.9668281332850244:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 10.75it/s] loss:0.9668281332850244:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 10.73it/s]loss:1.1649112771668875:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 10.73it/s]loss:1.1649112771668875: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.08it/s]
Epoch: 19 cost time: 2.477682113647461
Epoch: 19, Steps: 19 | Train Loss: 0.1354463 Vali Loss: 3.8814647 Test Loss: 69.5589142
Validation loss decreased (3.881465 --> 3.881465).  Saving model ...
Updating learning rate to 3.814697265625e-10
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:02,  8.06it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:02,  8.06it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:02,  8.06it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:02,  8.06it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:02,  8.06it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01,  9.71it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01,  9.71it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01,  9.71it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 10.32it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 10.32it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 10.32it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:01, 10.60it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:01, 10.60it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:01, 10.60it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 10.72it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:00, 10.72it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:00, 10.72it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 10.57it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 10.57it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 10.57it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 10.67it/s]loss:0.00024761122829778276:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 10.67it/s]loss:0.06051934273265191:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 10.67it/s]   loss:0.06051934273265191:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 10.70it/s]loss:0.3160951943023084:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 10.70it/s] loss:1.0213223890805283:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 10.70it/s]loss:1.0213223890805283:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 10.68it/s]loss:1.2698052471019365:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 10.68it/s]loss:1.2698052471019365: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.06it/s]
Epoch: 20 cost time: 2.5947113037109375
Epoch: 20, Steps: 19 | Train Loss: 0.1404205 Vali Loss: 3.8814647 Test Loss: 69.5589142
Validation loss decreased (3.881465 --> 3.881465).  Saving model ...
Updating learning rate to 1.9073486328125e-10
>>>>>>>testing : long_term_forecast_break_parzen_0_FiLM_job_demand_r1_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 4
test shape: (4, 1, 3, 32690) (4, 1, 3, 32690)
test shape: (4, 3, 32690) (4, 3, 32690)
mse:44207.85546875, mae:19.326501846313477, dtw:-999
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           0                   Model:              FiLM                

[1mData Loader[0m
  Data:               job_demand_r1       Root Path:          ../../dataset/demand/
  Data Path:          r1.parquet          Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        .cache/checkpoints  

[1mForecasting Task[0m
  Seq Len:            6                   Label Len:          1                   
  Pred Len:           3                   Seasonal Patterns:  Monthly             
  Inverse:            1                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             32690               Dec In:             32690               
  C Out:              32690               d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           2                   d FF:               2048                
  Moving Avg:         25                  Factor:             1                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              learned             Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        32                  Itr:                1                   
  Train Epochs:       20                  Batch Size:         1                   
  Patience:           3                   Learning Rate:      0.0001              
  Des:                test                Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1                 

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_break_tukey-hanning_0_FiLM_job_demand_r1_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 19
val 1
test 4
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:10,  1.77it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:10,  1.77it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:10,  1.77it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:03,  4.60it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:03,  4.60it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:03,  4.60it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:02,  6.54it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:01<00:02,  6.54it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:01<00:02,  6.54it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:01<00:01,  7.88it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:01<00:01,  7.88it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:01<00:01,  7.88it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:01<00:01,  8.71it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:01<00:01,  8.71it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:01<00:01,  8.71it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00,  9.37it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00,  9.37it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00,  9.37it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00,  9.81it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00,  9.81it/s]loss:0.007584203707530675:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00,  9.81it/s]loss:0.007584203707530675:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.15it/s]loss:0.23950654928205897:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.15it/s] loss:0.6291615737373842:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:02<00:00, 10.15it/s] loss:0.6291615737373842:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:02<00:00, 10.32it/s]loss:0.9598626435554359:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:02<00:00, 10.32it/s]loss:1.385031423073161:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:02<00:00, 10.32it/s] loss:1.385031423073161: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:02<00:00, 10.46it/s]loss:1.385031423073161: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:02<00:00,  8.36it/s]
Epoch: 1 cost time: 2.95304274559021
Epoch: 1, Steps: 19 | Train Loss: 0.1695340 Vali Loss: 3.8823354 Test Loss: 69.4167404
Validation loss decreased (inf --> 3.882335).  Saving model ...
Updating learning rate to 0.0001
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 10.15it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 10.15it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 10.15it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 10.27it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 10.27it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 10.27it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 10.45it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 10.45it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 10.45it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:01, 10.65it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:01, 10.65it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:01, 10.65it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 10.60it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:00, 10.60it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:00, 10.60it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 10.58it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 10.58it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 10.58it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 10.62it/s]loss:0.006899127420791913:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 10.62it/s]loss:0.23486823101832238:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 10.62it/s] loss:0.23486823101832238:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 10.59it/s]loss:0.6309804001134738:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 10.59it/s] loss:1.0118699387489491:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 10.59it/s]loss:1.0118699387489491:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 10.64it/s]loss:1.103239991208241:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 10.64it/s] loss:1.103239991208241: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.22it/s]
Epoch: 2 cost time: 2.4425551891326904
Epoch: 2, Steps: 19 | Train Loss: 0.1572557 Vali Loss: 3.8817422 Test Loss: 69.5247955
Validation loss decreased (3.882335 --> 3.881742).  Saving model ...
Updating learning rate to 5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:02,  8.55it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:02,  8.55it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:02,  8.44it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:02,  8.44it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:02,  8.44it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01,  9.89it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01,  9.89it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01,  9.89it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01,  9.99it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01,  9.99it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01,  9.99it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:01, 10.16it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:01, 10.16it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:01, 10.16it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 10.47it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:00, 10.47it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:00, 10.47it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 10.49it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 10.49it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 10.49it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 10.19it/s]loss:0.0061506742060689614:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 10.19it/s]loss:0.21949364886903278:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 10.19it/s]  loss:0.21949364886903278:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 10.35it/s]loss:0.7411759852620906:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 10.35it/s] loss:1.001863641247976:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 10.35it/s] loss:1.001863641247976:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 10.47it/s]loss:1.2454585998034924:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 10.47it/s]loss:1.2454585998034924: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00,  9.86it/s]
Epoch: 3 cost time: 2.5662412643432617
Epoch: 3, Steps: 19 | Train Loss: 0.1691654 Vali Loss: 3.8816130 Test Loss: 69.5545807
Validation loss decreased (3.881742 --> 3.881613).  Saving model ...
Updating learning rate to 2.5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:02,  7.20it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:02,  7.20it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:02,  8.02it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:02,  8.02it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:02,  8.02it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01,  9.51it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01,  9.51it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01,  9.51it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 10.08it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 10.08it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 10.08it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:01, 10.48it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:01, 10.48it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:01, 10.48it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 10.70it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:00, 10.70it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:00, 10.70it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 10.80it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 10.80it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 10.80it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 10.81it/s]loss:0.007698165802431965:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 10.81it/s]loss:0.23913677798647784:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 10.81it/s] loss:0.23913677798647784:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 10.81it/s]loss:0.6302744907326576:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 10.81it/s] loss:1.0551198944427325:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 10.81it/s]loss:1.0551198944427325:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 10.81it/s]loss:1.2446565060325987:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 10.81it/s]loss:1.2446565060325987: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.02it/s]
Epoch: 4 cost time: 2.5473883152008057
Epoch: 4, Steps: 19 | Train Loss: 0.1672045 Vali Loss: 3.8815176 Test Loss: 69.5669250
Validation loss decreased (3.881613 --> 3.881518).  Saving model ...
Updating learning rate to 1.25e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:02,  7.55it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:02,  7.55it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:02,  7.55it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01,  9.93it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01,  9.93it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01,  9.93it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.53it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.53it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.53it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 10.76it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 10.76it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 10.76it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 10.84it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 10.84it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:01<00:00, 10.84it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 10.84it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 10.84it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 10.84it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.64it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.64it/s]loss:0.007535944540144409:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.64it/s]loss:0.007535944540144409:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.68it/s]loss:0.23902464194671352:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.68it/s] loss:0.6718943629252043:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.68it/s] loss:0.6718943629252043:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 10.66it/s]loss:0.9964619526261872:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 10.66it/s]loss:1.3780293794963212:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 10.66it/s]loss:1.3780293794963212: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.65it/s]loss:1.3780293794963212: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.24it/s]
Epoch: 5 cost time: 2.4523518085479736
Epoch: 5, Steps: 19 | Train Loss: 0.1733130 Vali Loss: 3.8813310 Test Loss: 69.5692596
Validation loss decreased (3.881518 --> 3.881331).  Saving model ...
Updating learning rate to 6.25e-06
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:02,  8.86it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:02,  8.86it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:02,  8.86it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.16it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.16it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.16it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.55it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.55it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.55it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 10.70it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 10.70it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 10.70it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 10.58it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 10.58it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:01<00:00, 10.58it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 10.65it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 10.65it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 10.65it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.68it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.68it/s]loss:0.00679716055524855:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.68it/s]loss:0.00679716055524855:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.66it/s]loss:0.2158385432290121:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.66it/s] loss:0.7403370160689431:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.66it/s]loss:0.7403370160689431:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 10.65it/s]loss:1.0998529437653477:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 10.65it/s]loss:1.244107769124:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 10.65it/s]    loss:1.244107769124: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.61it/s]loss:1.244107769124: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.22it/s]
Epoch: 6 cost time: 2.4093329906463623
Epoch: 6, Steps: 19 | Train Loss: 0.1740491 Vali Loss: 3.8812153 Test Loss: 69.5742340
Validation loss decreased (3.881331 --> 3.881215).  Saving model ...
Updating learning rate to 3.125e-06
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:01,  9.15it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:01,  9.15it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:01,  9.15it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.43it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.43it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.43it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.69it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.69it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.69it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 10.75it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 10.75it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 10.75it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 10.73it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 10.73it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:01<00:00, 10.73it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 10.71it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 10.71it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 10.71it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.67it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.67it/s]loss:0.006451168675327559:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.67it/s]loss:0.006451168675327559:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.60it/s]loss:0.2117547094471561:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.60it/s]  loss:0.616046009326241:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.60it/s] loss:0.616046009326241:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 10.59it/s]loss:1.0779703599290043:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 10.59it/s]loss:1.1646841694512087:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 10.59it/s]loss:1.1646841694512087: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.57it/s]loss:1.1646841694512087: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.27it/s]
Epoch: 7 cost time: 2.4078948497772217
Epoch: 7, Steps: 19 | Train Loss: 0.1619424 Vali Loss: 3.8811474 Test Loss: 69.5746765
Validation loss decreased (3.881215 --> 3.881147).  Saving model ...
Updating learning rate to 1.5625e-06
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:01,  9.42it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:01,  9.42it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:01,  9.42it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.53it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.53it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.53it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.65it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.65it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.65it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 10.69it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 10.69it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 10.69it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 10.71it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 10.71it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:01<00:00, 10.71it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 10.67it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 10.67it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 10.67it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.64it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.64it/s]loss:0.006979175545771051:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.64it/s]loss:0.006979175545771051:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.60it/s]loss:0.24559036257368175:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.60it/s] loss:0.5913174533990092:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.60it/s] loss:0.5913174533990092:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 10.61it/s]loss:0.9746597505692333:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 10.61it/s]loss:1.2969262333148068:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 10.61it/s]loss:1.2969262333148068: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.19it/s]loss:1.2969262333148068: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.19it/s]
Epoch: 8 cost time: 2.4216971397399902
Epoch: 8, Steps: 19 | Train Loss: 0.1639723 Vali Loss: 3.8811331 Test Loss: 69.5745850
Validation loss decreased (3.881147 --> 3.881133).  Saving model ...
Updating learning rate to 7.8125e-07
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:02,  8.12it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:02,  8.12it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:02,  8.12it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.09it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.09it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.09it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.60it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.60it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.60it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 10.76it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 10.76it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 10.76it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 10.83it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 10.83it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:01<00:00, 10.83it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 10.84it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 10.84it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 10.84it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.81it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.81it/s]loss:0.0061414493966814145:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.81it/s]loss:0.0061414493966814145:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.79it/s]loss:0.23887960271298173:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.79it/s]  loss:0.6160099987041655:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.79it/s] loss:0.6160099987041655:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 10.74it/s]loss:1.0545757526059027:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 10.74it/s]loss:1.2969029175445521:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 10.74it/s]loss:1.2969029175445521: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.70it/s]loss:1.2969029175445521: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.29it/s]
Epoch: 9 cost time: 2.348170280456543
Epoch: 9, Steps: 19 | Train Loss: 0.1690795 Vali Loss: 3.8811231 Test Loss: 69.5744705
Validation loss decreased (3.881133 --> 3.881123).  Saving model ...
Updating learning rate to 3.90625e-07
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:01,  9.42it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:01,  9.42it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:01,  9.42it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.25it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.25it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.25it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.66it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.66it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.66it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 10.81it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 10.81it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 10.81it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 10.81it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 10.81it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:01<00:00, 10.81it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 10.81it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 10.81it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 10.81it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.78it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.78it/s]loss:0.007694511422241383:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.78it/s]loss:0.007694511422241383:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.74it/s]loss:0.23525966949963048:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.74it/s] loss:0.696902673888504:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.74it/s]  loss:0.696902673888504:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 10.73it/s]loss:1.077899906891226:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 10.73it/s]loss:1.2631423528703767:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 10.73it/s]loss:1.2631423528703767: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.70it/s]loss:1.2631423528703767: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.32it/s]
Epoch: 10 cost time: 2.34873104095459
Epoch: 10, Steps: 19 | Train Loss: 0.1726789 Vali Loss: 3.8811181 Test Loss: 69.5743408
Validation loss decreased (3.881123 --> 3.881118).  Saving model ...
Updating learning rate to 1.953125e-07
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:01,  9.49it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:01,  9.49it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:01,  9.49it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.68it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.68it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.68it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.85it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.85it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.85it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 10.90it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 10.90it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 10.90it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 10.90it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 10.90it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:01<00:00, 10.90it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 10.89it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 10.89it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 10.89it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.85it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.85it/s]loss:0.0067964353302860684:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.85it/s]loss:0.0067964353302860684:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.79it/s]loss:0.2206870683909323:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.79it/s]   loss:0.6159991871282525:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.79it/s]loss:0.6159991871282525:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 10.74it/s]loss:1.0995216029143522:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 10.74it/s]loss:1.29688189843548:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 10.74it/s]  loss:1.29688189843548: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.69it/s]loss:1.29688189843548: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.45it/s]
Epoch: 11 cost time: 2.333672285079956
Epoch: 11, Steps: 19 | Train Loss: 0.1705203 Vali Loss: 3.8811152 Test Loss: 69.5744476
Validation loss decreased (3.881118 --> 3.881115).  Saving model ...
Updating learning rate to 9.765625e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:02,  8.63it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:02,  8.63it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:02,  8.63it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.21it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.21it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.21it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.54it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.54it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.54it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 10.72it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 10.72it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 10.72it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 10.79it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 10.79it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:01<00:00, 10.79it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 10.81it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 10.81it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 10.81it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.79it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.79it/s]loss:0.007086154601937932:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.79it/s]loss:0.007086154601937932:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.75it/s]loss:0.25931818632377823:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.75it/s] loss:0.7403817953506754:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.75it/s] loss:0.7403817953506754:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 10.72it/s]loss:1.077892238632726:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 10.72it/s] loss:1.2968786936942602:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 10.72it/s]loss:1.2968786936942602: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.70it/s]loss:1.2968786936942602: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.34it/s]
Epoch: 12 cost time: 2.407313585281372
Epoch: 12, Steps: 19 | Train Loss: 0.1779767 Vali Loss: 3.8811131 Test Loss: 69.5744324
Validation loss decreased (3.881115 --> 3.881113).  Saving model ...
Updating learning rate to 4.8828125e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:01,  9.32it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:01,  9.32it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:01,  9.32it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.12it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.12it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.12it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.46it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.46it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.46it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 10.55it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 10.55it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 10.55it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 10.70it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 10.70it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:01<00:00, 10.70it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 10.76it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 10.76it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 10.76it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.76it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.76it/s]loss:0.006141353249260424:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.76it/s]loss:0.006141353249260424:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.73it/s]loss:0.25931789536914335:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.73it/s] loss:0.6159962955751466:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.73it/s] loss:0.6159962955751466:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 10.67it/s]loss:1.1683791153513863:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 10.67it/s]loss:1.2496681860198033:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 10.67it/s]loss:1.2496681860198033: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.62it/s]loss:1.2496681860198033: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.29it/s]
Epoch: 13 cost time: 2.411090850830078
Epoch: 13, Steps: 19 | Train Loss: 0.1736580 Vali Loss: 3.8811123 Test Loss: 69.5744324
Validation loss decreased (3.881113 --> 3.881112).  Saving model ...
Updating learning rate to 2.44140625e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:02,  8.99it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:02,  8.99it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:02,  8.99it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.52it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.52it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.52it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.82it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.82it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.82it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 10.85it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 10.85it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 10.85it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 10.85it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 10.85it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:01<00:00, 10.85it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 10.81it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 10.81it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 10.81it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.60it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.60it/s]loss:0.006503927031351271:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.60it/s]loss:0.006503927031351271:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.65it/s]loss:0.23417463118427023:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.65it/s] loss:0.7403801546019306:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.65it/s] loss:0.7403801546019306:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 10.65it/s]loss:1.082868797239408:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 10.65it/s] loss:1.2320475591302198:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 10.65it/s]loss:1.2320475591302198: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.65it/s]loss:1.2320475591302198: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.31it/s]
Epoch: 14 cost time: 2.4818832874298096
Epoch: 14, Steps: 19 | Train Loss: 0.1734724 Vali Loss: 3.8811123 Test Loss: 69.5744476
Validation loss decreased (3.881112 --> 3.881112).  Saving model ...
Updating learning rate to 1.220703125e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:01,  9.51it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:01,  9.51it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:01,  9.51it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.63it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.63it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.63it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.88it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.88it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.88it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 10.90it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 10.90it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 10.90it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 10.88it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 10.88it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:01<00:00, 10.88it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 10.83it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 10.83it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 10.83it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.77it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.77it/s]loss:0.00769442626720011:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.77it/s]loss:0.00769442626720011:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.73it/s]loss:0.23887204372553197:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.73it/s]loss:0.5909381347499342:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.73it/s] loss:0.5909381347499342:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 10.68it/s]loss:1.0091740641041813:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 10.68it/s]loss:1.1247611821273233:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 10.68it/s]loss:1.1247611821273233: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.63it/s]loss:1.1247611821273233: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.37it/s]
Epoch: 15 cost time: 2.390713691711426
Epoch: 15, Steps: 19 | Train Loss: 0.1563916 Vali Loss: 3.8811123 Test Loss: 69.5744553
Validation loss decreased (3.881112 --> 3.881112).  Saving model ...
Updating learning rate to 6.103515625e-09
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:02,  8.60it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:02,  8.60it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:02,  8.60it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.07it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.07it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.07it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.54it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.54it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.54it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 10.73it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 10.73it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 10.73it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 10.80it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 10.80it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:01<00:00, 10.80it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 10.75it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 10.75it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 10.75it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.63it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.63it/s]loss:0.006796411359627579:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.63it/s]loss:0.006796411359627579:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.65it/s]loss:0.2388720139072527:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.65it/s]  loss:0.6258264127033193:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.65it/s]loss:0.6258264127033193:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 10.64it/s]loss:1.1938966358471161:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 10.64it/s]loss:1.2968761283902797:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 10.64it/s]loss:1.2968761283902797: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.61it/s]loss:1.2968761283902797: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.24it/s]
Epoch: 16 cost time: 2.5098423957824707
Epoch: 16, Steps: 19 | Train Loss: 0.1769615 Vali Loss: 3.8811123 Test Loss: 69.5744553
Validation loss decreased (3.881112 --> 3.881112).  Saving model ...
Updating learning rate to 3.0517578125e-09
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:02,  7.96it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:02,  7.96it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:02,  7.96it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.07it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.07it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.07it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.58it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.58it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.58it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 10.59it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 10.59it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 10.59it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 10.75it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 10.75it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:01<00:00, 10.75it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 10.81it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 10.81it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 10.81it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.83it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.83it/s]loss:0.0072425170431598945:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.83it/s]loss:0.0072425170431598945:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.83it/s]loss:0.21580186132524654:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.83it/s]  loss:0.6715268195773135:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.83it/s] loss:0.6715268195773135:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 10.82it/s]loss:1.1936221730303:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 10.82it/s]   loss:1.1247610785456226:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 10.82it/s]loss:1.1247610785456226: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.75it/s]loss:1.1247610785456226: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.38it/s]
Epoch: 17 cost time: 2.4456911087036133
Epoch: 17, Steps: 19 | Train Loss: 0.1691029 Vali Loss: 3.8811123 Test Loss: 69.5744553
Validation loss decreased (3.881112 --> 3.881112).  Saving model ...
Updating learning rate to 1.52587890625e-09
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:01,  9.42it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:01,  9.42it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:01,  9.42it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.70it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.70it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.70it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.68it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.68it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.68it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 10.83it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 10.83it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 10.83it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 10.91it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 10.91it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:01<00:00, 10.91it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 10.91it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 10.91it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 10.91it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.88it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.88it/s]loss:0.0064187281789620885:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.88it/s]loss:0.0064187281789620885:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.70it/s]loss:0.2070233044257736:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.70it/s]   loss:0.6818485234187258:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.70it/s]loss:0.6818485234187258:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 10.61it/s]loss:0.9746346161808623:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 10.61it/s]loss:1.3045186271148472:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 10.61it/s]loss:1.3045186271148472: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.61it/s]loss:1.3045186271148472: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.37it/s]
Epoch: 18 cost time: 2.3389666080474854
Epoch: 18, Steps: 19 | Train Loss: 0.1670760 Vali Loss: 3.8811123 Test Loss: 69.5744629
Validation loss decreased (3.881112 --> 3.881112).  Saving model ...
Updating learning rate to 7.62939453125e-10
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:02,  8.89it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:02,  8.89it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:02,  8.89it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.36it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.36it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.36it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.68it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.68it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.68it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 10.75it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 10.75it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 10.75it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 10.77it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 10.77it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:01<00:00, 10.77it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 10.71it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 10.71it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 10.71it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.69it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.69it/s]loss:0.007242516976435684:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.69it/s]loss:0.007242516976435684:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.64it/s]loss:0.21637380229154432:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.64it/s] loss:0.7245535056393929:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.64it/s] loss:0.7245535056393929:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 10.60it/s]loss:1.1303992115928005:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 10.60it/s]loss:1.1646205531966471:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 10.60it/s]loss:1.1646205531966471: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.59it/s]loss:1.1646205531966471: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.27it/s]
Epoch: 19 cost time: 2.5004563331604004
Epoch: 19, Steps: 19 | Train Loss: 0.1706942 Vali Loss: 3.8811123 Test Loss: 69.5744629
Validation loss decreased (3.881112 --> 3.881112).  Saving model ...
Updating learning rate to 3.814697265625e-10
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 10.92it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 10.92it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 10.92it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 10.96it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 10.96it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 10.96it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 10.90it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 10.90it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 10.90it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:01, 10.84it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:01, 10.84it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:01, 10.84it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 10.78it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:00, 10.78it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:00, 10.78it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 10.70it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 10.70it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 10.70it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 10.68it/s]loss:0.006401761320636299:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 10.68it/s]loss:0.244143527536645:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 10.68it/s]   loss:0.244143527536645:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 10.68it/s]loss:0.5909379721692347:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 10.68it/s]loss:1.1938965169957632:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 10.68it/s]loss:1.1938965169957632:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 10.65it/s]loss:1.2688739019519353:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 10.65it/s]loss:1.2688739019519353: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.39it/s]
Epoch: 20 cost time: 2.4037017822265625
Epoch: 20, Steps: 19 | Train Loss: 0.1739081 Vali Loss: 3.8811123 Test Loss: 69.5744629
Validation loss decreased (3.881112 --> 3.881112).  Saving model ...
Updating learning rate to 1.9073486328125e-10
>>>>>>>testing : long_term_forecast_break_tukey-hanning_0_FiLM_job_demand_r1_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 4
test shape: (4, 1, 3, 32690) (4, 1, 3, 32690)
test shape: (4, 3, 32690) (4, 3, 32690)
mse:44165.8046875, mae:19.320405960083008, dtw:-999
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           0                   Model:              FiLM                

[1mData Loader[0m
  Data:               job_demand_r1       Root Path:          ../../dataset/demand/
  Data Path:          r1.parquet          Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        .cache/checkpoints  

[1mForecasting Task[0m
  Seq Len:            6                   Label Len:          1                   
  Pred Len:           3                   Seasonal Patterns:  Monthly             
  Inverse:            1                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             32690               Dec In:             32690               
  C Out:              32690               d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           2                   d FF:               2048                
  Moving Avg:         25                  Factor:             1                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              learned             Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        32                  Itr:                1                   
  Train Epochs:       20                  Batch Size:         1                   
  Patience:           3                   Learning Rate:      0.0001              
  Des:                test                Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1                 

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_break_rayleigh_0_FiLM_job_demand_r1_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 19
val 1
test 4
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.5102367466920505:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5102367466920505:   5%|â–Œ         | 1/19 [00:00<00:10,  1.79it/s]loss:0.5708876029274293:   5%|â–Œ         | 1/19 [00:00<00:10,  1.79it/s]loss:0.6094395083213995:   5%|â–Œ         | 1/19 [00:00<00:10,  1.79it/s]loss:0.6094395083213995:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:03,  4.62it/s]loss:0.705052240608512:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:03,  4.62it/s] loss:0.7713757565388751:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:03,  4.62it/s]loss:0.7713757565388751:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:02,  6.58it/s]loss:0.819748602725447:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:01<00:02,  6.58it/s] loss:0.850841091337532:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:01<00:02,  6.58it/s]loss:0.850841091337532:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:01<00:01,  7.91it/s]loss:0.9654737032994126:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:01<00:01,  7.91it/s]loss:0.988377711526569:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:01<00:01,  7.91it/s] loss:0.988377711526569:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:01<00:01,  8.80it/s]loss:1.13026022484463:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:01<00:01,  8.80it/s] loss:0.9860152222796823:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:01<00:01,  8.80it/s]loss:0.9860152222796823:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00,  9.40it/s]loss:0.9965501464771757:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00,  9.40it/s]loss:1.0082344037994426:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00,  9.40it/s]loss:1.0082344037994426:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00,  9.73it/s]loss:1.2195226744266567:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00,  9.73it/s]loss:1.2966327545133354:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00,  9.73it/s]loss:1.2966327545133354:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00,  9.96it/s]loss:1.2384911286099005:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00,  9.96it/s]loss:1.156808590212059:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:02<00:00,  9.96it/s] loss:1.156808590212059:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:02<00:00, 10.11it/s]loss:1.1015641930146616:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:02<00:00, 10.11it/s]loss:1.380786276876458:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:02<00:00, 10.11it/s] loss:1.380786276876458: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:02<00:00, 10.35it/s]loss:1.380786276876458: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:02<00:00,  8.33it/s]
Epoch: 1 cost time: 2.815680503845215
Epoch: 1, Steps: 19 | Train Loss: 0.9634894 Vali Loss: 3.8797803 Test Loss: 69.4408646
Validation loss decreased (inf --> 3.879780).  Saving model ...
Updating learning rate to 0.0001
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.5141260609897582:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5141260609897582:   5%|â–Œ         | 1/19 [00:00<00:02,  8.66it/s]loss:0.6138123508288296:   5%|â–Œ         | 1/19 [00:00<00:02,  8.66it/s]loss:0.6138123508288296:  11%|â–ˆ         | 2/19 [00:00<00:01,  9.23it/s]loss:0.6831233755400602:  11%|â–ˆ         | 2/19 [00:00<00:01,  9.23it/s]loss:0.7420328084580647:  11%|â–ˆ         | 2/19 [00:00<00:01,  9.23it/s]loss:0.7420328084580647:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 10.07it/s]loss:0.8445439021522357:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 10.07it/s]loss:0.7482051463329895:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 10.07it/s]loss:0.7482051463329895:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 10.54it/s]loss:0.7840717661967648:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 10.54it/s]loss:0.8129397597477787:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 10.54it/s]loss:0.8129397597477787:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:01, 10.31it/s]loss:1.0720417691933157:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:01, 10.31it/s]loss:0.9915061922055461:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:01, 10.31it/s]loss:0.9915061922055461:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 10.57it/s]loss:1.1422679327483873:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:00, 10.57it/s]loss:1.1029137523272938:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:00, 10.57it/s]loss:1.1029137523272938:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 10.69it/s]loss:1.04502403442307:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 10.69it/s]  loss:1.183769457318707:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 10.69it/s]loss:1.183769457318707:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 10.74it/s]loss:1.1803555691976546:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 10.74it/s]loss:1.2149430554362097:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 10.74it/s]loss:1.2149430554362097:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 10.54it/s]loss:1.1566007541326857:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 10.54it/s]loss:1.1617718846815435:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 10.54it/s]loss:1.1617718846815435:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 10.22it/s]loss:1.0982875097040725:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 10.22it/s]loss:1.0982875097040725: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00,  9.97it/s]
Epoch: 2 cost time: 2.5901975631713867
Epoch: 2, Steps: 19 | Train Loss: 0.9522283 Vali Loss: 3.8773632 Test Loss: 69.5704498
Validation loss decreased (3.879780 --> 3.877363).  Saving model ...
Updating learning rate to 5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.49896466679955537:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.49896466679955537:   5%|â–Œ         | 1/19 [00:00<00:02,  8.39it/s]loss:0.6304718094871763:   5%|â–Œ         | 1/19 [00:00<00:02,  8.39it/s] loss:0.6304718094871763:  11%|â–ˆ         | 2/19 [00:00<00:01,  8.79it/s]loss:0.6622369270247567:  11%|â–ˆ         | 2/19 [00:00<00:01,  8.79it/s]loss:0.6901951108243194:  11%|â–ˆ         | 2/19 [00:00<00:01,  8.79it/s]loss:0.6901951108243194:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01,  9.82it/s]loss:0.6722247480602506:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01,  9.82it/s]loss:0.873775971149722:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01,  9.82it/s] loss:0.873775971149722:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 10.31it/s]loss:0.9566736547102657:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 10.31it/s]loss:0.8418894509476719:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 10.31it/s]loss:0.8418894509476719:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:01, 10.60it/s]loss:0.9784538675337432:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:01, 10.60it/s]loss:0.9299627281796244:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:01, 10.60it/s]loss:0.9299627281796244:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 10.63it/s]loss:1.044612931785592:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:00, 10.63it/s] loss:1.0972851797167722:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:00, 10.63it/s]loss:1.0972851797167722:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 10.69it/s]loss:1.0661201078154905:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 10.69it/s]loss:1.2108715194553905:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 10.69it/s]loss:1.2108715194553905:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 10.71it/s]loss:1.0535173763826733:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 10.71it/s]loss:1.1371309234580822:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 10.71it/s]loss:1.1371309234580822:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 10.70it/s]loss:1.3567888996264081:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 10.70it/s]loss:1.1500204586380627:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 10.70it/s]loss:1.1500204586380627:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 10.68it/s]loss:1.2391990067702523:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 10.68it/s]loss:1.2391990067702523: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.14it/s]
Epoch: 3 cost time: 2.57144832611084
Epoch: 3, Steps: 19 | Train Loss: 0.9521261 Vali Loss: 3.8764036 Test Loss: 69.6173706
Validation loss decreased (3.877363 --> 3.876404).  Saving model ...
Updating learning rate to 2.5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.5729924919302128:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5729924919302128:   5%|â–Œ         | 1/19 [00:00<00:02,  8.78it/s]loss:0.5317315714078185:   5%|â–Œ         | 1/19 [00:00<00:02,  8.78it/s]loss:0.5778682787984397:   5%|â–Œ         | 1/19 [00:00<00:02,  8.78it/s]loss:0.5778682787984397:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01,  9.91it/s]loss:0.6476838171144103:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01,  9.91it/s]loss:0.7499932094000383:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01,  9.91it/s]loss:0.7499932094000383:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.43it/s]loss:0.8208565704048463:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.43it/s]loss:0.8636346728381848:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.43it/s]loss:0.8636346728381848:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 10.65it/s]loss:0.8278107894758231:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 10.65it/s]loss:1.009731957679173:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 10.65it/s] loss:1.009731957679173:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 10.70it/s]loss:1.1172501306014628:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 10.70it/s]loss:0.9901859901586038:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:01<00:00, 10.70it/s]loss:0.9901859901586038:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 10.71it/s]loss:1.1750462376597055:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 10.71it/s]loss:1.0529608371438437:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 10.71it/s]loss:1.0529608371438437:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.57it/s]loss:1.0686309322528427:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.57it/s]loss:1.3152648900884703:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.57it/s]loss:1.3152648900884703:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.49it/s]loss:1.226146750645815:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.49it/s] loss:1.1535694427394423:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.49it/s]loss:1.1535694427394423:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 10.52it/s]loss:1.2057469376156074:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 10.52it/s]loss:1.2379602135472014:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 10.52it/s]loss:1.2379602135472014: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.49it/s]loss:1.2379602135472014: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.23it/s]
Epoch: 4 cost time: 2.405646562576294
Epoch: 4, Steps: 19 | Train Loss: 0.9550035 Vali Loss: 3.8760967 Test Loss: 69.6425476
Validation loss decreased (3.876404 --> 3.876097).  Saving model ...
Updating learning rate to 1.25e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.5724053928939444:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5724053928939444:   5%|â–Œ         | 1/19 [00:00<00:01,  9.59it/s]loss:0.5521735132002245:   5%|â–Œ         | 1/19 [00:00<00:01,  9.59it/s]loss:0.5521735132002245:  11%|â–ˆ         | 2/19 [00:00<00:01,  9.56it/s]loss:0.6142810770578573:  11%|â–ˆ         | 2/19 [00:00<00:01,  9.56it/s]loss:0.6562985329906275:  11%|â–ˆ         | 2/19 [00:00<00:01,  9.56it/s]loss:0.6562985329906275:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01,  9.86it/s]loss:0.7664278299987967:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01,  9.86it/s]loss:0.7920839438920647:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01,  9.86it/s]loss:0.7920839438920647:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 10.40it/s]loss:0.9536459907357621:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 10.40it/s]loss:0.9037794079128089:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 10.40it/s]loss:0.9037794079128089:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:01, 10.56it/s]loss:0.8528512663666404:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:01, 10.56it/s]loss:1.0582132831935642:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:01, 10.56it/s]loss:1.0582132831935642:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 10.63it/s]loss:1.0546469947617214:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:00, 10.63it/s]loss:1.0274848582390612:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:00, 10.63it/s]loss:1.0274848582390612:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 10.71it/s]loss:0.9996263562576466:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 10.71it/s]loss:1.0518609357702111:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 10.71it/s]loss:1.0518609357702111:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 10.73it/s]loss:1.2744326732287885:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 10.73it/s]loss:1.2253629865343316:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 10.73it/s]loss:1.2253629865343316:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 10.24it/s]loss:1.2235596394893191:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 10.24it/s]loss:1.1319069327192033:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 10.24it/s]loss:1.1319069327192033:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 10.33it/s]loss:1.3679275281353975:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 10.33it/s]loss:1.3679275281353975: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.03it/s]
Epoch: 5 cost time: 2.4520630836486816
Epoch: 5, Steps: 19 | Train Loss: 0.9515247 Vali Loss: 3.8759003 Test Loss: 69.6522064
Validation loss decreased (3.876097 --> 3.875900).  Saving model ...
Updating learning rate to 6.25e-06
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.5122986412135265:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5122986412135265:   5%|â–Œ         | 1/19 [00:00<00:02,  8.12it/s]loss:0.5309279203423698:   5%|â–Œ         | 1/19 [00:00<00:02,  8.12it/s]loss:0.5309279203423698:  11%|â–ˆ         | 2/19 [00:00<00:01,  8.92it/s]loss:0.6122835216148806:  11%|â–ˆ         | 2/19 [00:00<00:01,  8.92it/s]loss:0.6122835216148806:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01,  8.92it/s]loss:0.6238151560545961:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01,  8.92it/s]loss:0.6238151560545961:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01,  9.31it/s]loss:0.6858498407030895:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01,  9.31it/s]loss:0.8194612831109399:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01,  9.31it/s]loss:0.8194612831109399:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01,  9.94it/s]loss:0.8972303608802027:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01,  9.94it/s]loss:0.9572790650493522:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01,  9.94it/s]loss:0.9572790650493522:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:01, 10.39it/s]loss:0.9521292525090402:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:01, 10.39it/s]loss:0.9510649501554334:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:01, 10.39it/s]loss:0.9510649501554334:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 10.61it/s]loss:1.1641580545599657:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:00, 10.61it/s]loss:1.1728762958198944:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:00, 10.61it/s]loss:1.1728762958198944:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 10.55it/s]loss:1.0367710696776973:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 10.55it/s]loss:1.160501528850554:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 10.55it/s] loss:1.160501528850554:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 10.44it/s]loss:1.1606610062781688:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 10.44it/s]loss:1.1114992652424376:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 10.44it/s]loss:1.1114992652424376:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 10.10it/s]loss:1.3539403799105958:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 10.10it/s]loss:1.249573989375457:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 10.10it/s] loss:1.249573989375457:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 10.26it/s]loss:1.2370871922812092:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 10.26it/s]loss:1.2370871922812092: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00,  9.73it/s]
Epoch: 6 cost time: 2.5518927574157715
Epoch: 6, Steps: 19 | Train Loss: 0.9573373 Vali Loss: 3.8757904 Test Loss: 69.6596832
Validation loss decreased (3.875900 --> 3.875790).  Saving model ...
Updating learning rate to 3.125e-06
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.5373678272355911:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5373678272355911:   5%|â–Œ         | 1/19 [00:00<00:02,  7.75it/s]loss:0.5315006814094033:   5%|â–Œ         | 1/19 [00:00<00:02,  7.75it/s]loss:0.5315006814094033:  11%|â–ˆ         | 2/19 [00:00<00:02,  7.16it/s]loss:0.5980535050884854:  11%|â–ˆ         | 2/19 [00:00<00:02,  7.16it/s]loss:0.5980535050884854:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01,  8.08it/s]loss:0.7137100276432669:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01,  8.08it/s]loss:0.7876984172533875:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01,  8.08it/s]loss:0.7876984172533875:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01,  9.61it/s]loss:0.8011276569864926:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01,  9.61it/s]loss:0.8123605527028039:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01,  9.61it/s]loss:0.8123605527028039:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 10.24it/s]loss:0.9571309257769959:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 10.24it/s]loss:1.0649348555868323:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 10.24it/s]loss:1.0649348555868323:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 10.53it/s]loss:1.1154694484120298:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:01<00:00, 10.53it/s]loss:1.0524424353892186:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:01<00:00, 10.53it/s]loss:1.0524424353892186:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 10.52it/s]loss:1.1057370862173177:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 10.52it/s]loss:0.9990629184230256:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 10.52it/s]loss:0.9990629184230256:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.66it/s]loss:1.2449001203609913:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.66it/s]loss:1.1063235869183803:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.66it/s]loss:1.1063235869183803:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.67it/s]loss:1.0944352520834295:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.67it/s]loss:1.125359575043672:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.67it/s] loss:1.125359575043672:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 10.55it/s]loss:1.2338673219254868:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 10.55it/s]loss:1.1609664262076806:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 10.55it/s]loss:1.1609664262076806: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.64it/s]loss:1.1609664262076806: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00,  9.92it/s]
Epoch: 7 cost time: 2.457279682159424
Epoch: 7, Steps: 19 | Train Loss: 0.9496026 Vali Loss: 3.8757279 Test Loss: 69.6628418
Validation loss decreased (3.875790 --> 3.875728).  Saving model ...
Updating learning rate to 1.5625e-06
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.5122351090125481:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5122351090125481:   5%|â–Œ         | 1/19 [00:00<00:02,  8.44it/s]loss:0.5636869404242894:   5%|â–Œ         | 1/19 [00:00<00:02,  8.44it/s]loss:0.5636869404242894:  11%|â–ˆ         | 2/19 [00:00<00:01,  8.63it/s]loss:0.7201340795911417:  11%|â–ˆ         | 2/19 [00:00<00:01,  8.63it/s]loss:0.7201340795911417:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01,  9.06it/s]loss:0.7549988286052371:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01,  9.06it/s]loss:0.7672614428241022:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01,  9.06it/s]loss:0.7672614428241022:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.18it/s]loss:0.819064573267272:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.18it/s] loss:0.9538998578512656:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.18it/s]loss:0.9538998578512656:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 10.58it/s]loss:0.8077380413572622:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 10.58it/s]loss:0.9633019398544922:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 10.58it/s]loss:0.9633019398544922:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 10.73it/s]loss:0.9261020682841106:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 10.73it/s]loss:1.0292254010071207:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:01<00:00, 10.73it/s]loss:1.0292254010071207:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 10.81it/s]loss:1.030047209951368:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 10.81it/s] loss:1.0387982684818717:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 10.81it/s]loss:1.0387982684818717:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.80it/s]loss:1.1481416531388975:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.80it/s]loss:1.1864248335560157:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.80it/s]loss:1.1864248335560157:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.78it/s]loss:1.2662915907032861:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.78it/s]loss:1.083659283867007:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.78it/s] loss:1.083659283867007:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 10.40it/s]loss:1.1164868865368953:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 10.40it/s]loss:1.285582054754264:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 10.40it/s] loss:1.285582054754264: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.54it/s]loss:1.285582054754264: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.02it/s]
Epoch: 8 cost time: 2.4569714069366455
Epoch: 8, Steps: 19 | Train Loss: 0.9459516 Vali Loss: 3.8757033 Test Loss: 69.6643372
Validation loss decreased (3.875728 --> 3.875703).  Saving model ...
Updating learning rate to 7.8125e-07
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.5164393217723602:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5164393217723602:   5%|â–Œ         | 1/19 [00:00<00:02,  7.79it/s]loss:0.5934048264497065:   5%|â–Œ         | 1/19 [00:00<00:02,  7.79it/s]loss:0.5934048264497065:  11%|â–ˆ         | 2/19 [00:00<00:01,  8.83it/s]loss:0.6589162790059444:  11%|â–ˆ         | 2/19 [00:00<00:01,  8.83it/s]loss:0.6589162790059444:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01,  9.27it/s]loss:0.7047395637029127:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01,  9.27it/s]loss:0.7053904318802436:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01,  9.27it/s]loss:0.7053904318802436:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.22it/s]loss:0.8950376027522522:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.22it/s]loss:0.7808898800648536:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.22it/s]loss:0.7808898800648536:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 10.51it/s]loss:0.9124722802845239:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 10.51it/s]loss:0.9067192404649542:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 10.51it/s]loss:0.9067192404649542:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 10.60it/s]loss:1.0820444848638453:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 10.60it/s]loss:0.9662457678580557:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:01<00:00, 10.60it/s]loss:0.9662457678580557:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 10.57it/s]loss:0.9683368717917358:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 10.57it/s]loss:1.249497325493107:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 10.57it/s] loss:1.249497325493107:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.66it/s]loss:1.2166115506116444:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.66it/s]loss:1.0501329610302264:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.66it/s]loss:1.0501329610302264:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.64it/s]loss:1.224458118132068:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.64it/s] loss:1.1252835259916276:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.64it/s]loss:1.1252835259916276:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 10.15it/s]loss:1.204736634340825:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 10.15it/s] loss:1.285542539017156:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 10.15it/s]loss:1.285542539017156: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.08it/s]loss:1.285542539017156: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00,  9.89it/s]
Epoch: 9 cost time: 2.5377418994903564
Epoch: 9, Steps: 19 | Train Loss: 0.9498368 Vali Loss: 3.8756921 Test Loss: 69.6650314
Validation loss decreased (3.875703 --> 3.875692).  Saving model ...
Updating learning rate to 3.90625e-07
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.5372767084154256:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5372767084154256:   5%|â–Œ         | 1/19 [00:00<00:02,  8.30it/s]loss:0.5652787367764965:   5%|â–Œ         | 1/19 [00:00<00:02,  8.30it/s]loss:0.5652787367764965:  11%|â–ˆ         | 2/19 [00:00<00:01,  8.99it/s]loss:0.5901763195870796:  11%|â–ˆ         | 2/19 [00:00<00:01,  8.99it/s]loss:0.5901763195870796:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01,  9.27it/s]loss:0.7135405646896805:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01,  9.27it/s]loss:0.6695864931896741:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01,  9.27it/s]loss:0.6695864931896741:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.24it/s]loss:0.8683266043830424:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.24it/s]loss:0.8099206941055291:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.24it/s]loss:0.8099206941055291:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 10.32it/s]loss:0.8508533248077786:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 10.32it/s]loss:0.8851699612872541:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 10.32it/s]loss:0.8851699612872541:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 10.52it/s]loss:0.9980900658974016:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 10.52it/s]loss:1.1035759533829188:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:01<00:00, 10.52it/s]loss:1.1035759533829188:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 10.32it/s]loss:1.0031352837301224:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 10.32it/s]loss:1.2494711421712867:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 10.32it/s]loss:1.2494711421712867:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.47it/s]loss:1.0281998861291866:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.47it/s]loss:1.3120271420903724:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.47it/s]loss:1.3120271420903724:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.56it/s]loss:1.2072646718002702:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.56it/s]loss:1.2727329220557326:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.56it/s]loss:1.2727329220557326:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 10.59it/s]loss:1.2337279184927823:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 10.59it/s]loss:1.2495558657620327:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 10.59it/s]loss:1.2495558657620327: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.59it/s]loss:1.2495558657620327: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.03it/s]
Epoch: 10 cost time: 2.4478836059570312
Epoch: 10, Steps: 19 | Train Loss: 0.9551532 Vali Loss: 3.8756855 Test Loss: 69.6652679
Validation loss decreased (3.875692 --> 3.875685).  Saving model ...
Updating learning rate to 1.953125e-07
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.5436657932254563:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5436657932254563:   5%|â–Œ         | 1/19 [00:00<00:01,  9.26it/s]loss:0.5434372638012107:   5%|â–Œ         | 1/19 [00:00<00:01,  9.26it/s]loss:0.5434372638012107:  11%|â–ˆ         | 2/19 [00:00<00:01,  8.88it/s]loss:0.6071241370895815:  11%|â–ˆ         | 2/19 [00:00<00:01,  8.88it/s]loss:0.7548701534189054:  11%|â–ˆ         | 2/19 [00:00<00:01,  8.88it/s]loss:0.7548701534189054:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 10.25it/s]loss:0.8375386138492993:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 10.25it/s]loss:0.7173468764649555:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 10.25it/s]loss:0.7173468764649555:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 10.32it/s]loss:0.9527181869814508:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 10.32it/s]loss:0.9233771673885202:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 10.32it/s]loss:0.9233771673885202:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:01, 10.40it/s]loss:1.0085845159430717:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:01, 10.40it/s]loss:0.9259963966798893:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:01, 10.40it/s]loss:0.9259963966798893:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 10.58it/s]loss:0.9892300227295262:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:00, 10.58it/s]loss:0.9669475543060776:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:00, 10.58it/s]loss:0.9669475543060776:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 10.65it/s]loss:1.128447803634137:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 10.65it/s] loss:1.161873423766838:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 10.65it/s]loss:1.161873423766838:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 10.68it/s]loss:1.1603723876212497:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 10.68it/s]loss:1.1383159570548766:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 10.68it/s]loss:1.1383159570548766:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 10.68it/s]loss:1.1252620947839882:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 10.68it/s]loss:1.2491506200731877:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 10.68it/s]loss:1.2491506200731877:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 10.66it/s]loss:1.285510913587716:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 10.66it/s] loss:1.285510913587716: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.14it/s]
Epoch: 11 cost time: 2.4667322635650635
Epoch: 11, Steps: 19 | Train Loss: 0.9484089 Vali Loss: 3.8756828 Test Loss: 69.6655273
Validation loss decreased (3.875685 --> 3.875683).  Saving model ...
Updating learning rate to 9.765625e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.5043974047113146:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5043974047113146:   5%|â–Œ         | 1/19 [00:00<00:02,  8.60it/s]loss:0.5590447414632742:   5%|â–Œ         | 1/19 [00:00<00:02,  8.60it/s]loss:0.5590447414632742:  11%|â–ˆ         | 2/19 [00:00<00:01,  8.88it/s]loss:0.6138826016178246:  11%|â–ˆ         | 2/19 [00:00<00:01,  8.88it/s]loss:0.6138826016178246:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01,  9.27it/s]loss:0.6963316738027382:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01,  9.27it/s]loss:0.6695725228051068:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01,  9.27it/s]loss:0.6695725228051068:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.19it/s]loss:0.7915505640227614:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.19it/s]loss:0.7915505640227614:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 10.13it/s]loss:0.7636080354593988:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 10.13it/s]loss:0.9569961626062298:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 10.13it/s]loss:0.9569961626062298:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:01, 10.53it/s]loss:1.031771376652061:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:01, 10.53it/s] loss:0.9282202059573444:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:01, 10.53it/s]loss:0.9282202059573444:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 10.36it/s]loss:1.0647853863761794:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:00, 10.36it/s]loss:0.9902033626584689:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:00, 10.36it/s]loss:0.9902033626584689:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 10.56it/s]loss:1.1284387687223858:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 10.56it/s]loss:1.09053409094263:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 10.56it/s]  loss:1.09053409094263:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 10.63it/s]loss:1.2031698163877231:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 10.63it/s]loss:1.336698494551918:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 10.63it/s] loss:1.336698494551918:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 10.64it/s]loss:1.3519579465548448:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 10.64it/s]loss:1.2337133487911525:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 10.64it/s]loss:1.2337133487911525:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 10.66it/s]loss:1.285506295449036:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 10.66it/s] loss:1.285506295449036: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.02it/s]
Epoch: 12 cost time: 2.5336759090423584
Epoch: 12, Steps: 19 | Train Loss: 0.9579149 Vali Loss: 3.8756816 Test Loss: 69.6655960
Validation loss decreased (3.875683 --> 3.875682).  Saving model ...
Updating learning rate to 4.8828125e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.5179099634192335:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5179099634192335:   5%|â–Œ         | 1/19 [00:00<00:02,  7.33it/s]loss:0.5434343158113681:   5%|â–Œ         | 1/19 [00:00<00:02,  7.33it/s]loss:0.5434343158113681:  11%|â–ˆ         | 2/19 [00:00<00:01,  8.54it/s]loss:0.6588693338787062:  11%|â–ˆ         | 2/19 [00:00<00:01,  8.54it/s]loss:0.7378919004098434:  11%|â–ˆ         | 2/19 [00:00<00:01,  8.54it/s]loss:0.7378919004098434:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 10.03it/s]loss:0.7111773108856352:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 10.03it/s]loss:0.7111773108856352:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01,  9.85it/s]loss:0.8425282732331797:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01,  9.85it/s]loss:0.7636065009989852:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01,  9.85it/s]loss:0.7636065009989852:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 10.39it/s]loss:0.8508434445756113:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 10.39it/s]loss:0.8830292796955177:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 10.39it/s]loss:0.8830292796955177:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 10.62it/s]loss:1.0100776927795303:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 10.62it/s]loss:1.0671128687617282:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:01<00:00, 10.62it/s]loss:1.0671128687617282:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 10.70it/s]loss:1.0811951647468458:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 10.70it/s]loss:1.1037742344345176:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 10.70it/s]loss:1.1037742344345176:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.53it/s]loss:1.282808051256512:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.53it/s] loss:1.0500941712062175:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.53it/s]loss:1.0500941712062175:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.49it/s]loss:1.3366947325879481:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.49it/s]loss:1.1252569012255544:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.49it/s]loss:1.1252569012255544:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 10.56it/s]loss:1.3215034770775766:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 10.56it/s]loss:1.2347023365337624:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 10.56it/s]loss:1.2347023365337624: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.45it/s]loss:1.2347023365337624: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00,  9.96it/s]
Epoch: 13 cost time: 2.541347026824951
Epoch: 13, Steps: 19 | Train Loss: 0.9538163 Vali Loss: 3.8756807 Test Loss: 69.6656342
Validation loss decreased (3.875682 --> 3.875681).  Saving model ...
Updating learning rate to 2.44140625e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.5558636442973378:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5558636442973378:   5%|â–Œ         | 1/19 [00:00<00:02,  7.34it/s]loss:0.6637826167233802:   5%|â–Œ         | 1/19 [00:00<00:02,  7.34it/s]loss:0.6071206223893578:   5%|â–Œ         | 1/19 [00:00<00:02,  7.34it/s]loss:0.6071206223893578:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01,  9.16it/s]loss:0.6881384501452528:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01,  9.16it/s]loss:0.7875333188291305:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01,  9.16it/s]loss:0.7875333188291305:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01,  9.94it/s]loss:0.848776695312549:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01,  9.94it/s] loss:0.7636057176230024:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01,  9.94it/s]loss:0.7636057176230024:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 10.38it/s]loss:0.839886176414891:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 10.38it/s] loss:0.9066894587931573:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 10.38it/s]loss:0.9066894587931573:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 10.05it/s]loss:0.9140706380162265:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:01<00:00, 10.05it/s]loss:0.9661859203474626:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:01<00:00, 10.05it/s]loss:0.9661859203474626:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 10.19it/s]loss:0.9669377978845128:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 10.19it/s]loss:1.1444857628028131:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 10.19it/s]loss:1.1444857628028131:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.43it/s]loss:1.2445433081118285:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.43it/s]loss:1.1153467190065602:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.43it/s]loss:1.1153467190065602:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.58it/s]loss:1.2092810165516121:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.58it/s]loss:1.351952941152426:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.58it/s] loss:1.351952941152426:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 10.24it/s]loss:1.2316180867111666:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 10.24it/s]loss:1.2220940471333166:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 10.24it/s]loss:1.2220940471333166: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.41it/s]loss:1.2220940471333166: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00,  9.93it/s]
Epoch: 14 cost time: 2.5105526447296143
Epoch: 14, Steps: 19 | Train Loss: 0.9488375 Vali Loss: 3.8756807 Test Loss: 69.6656570
Validation loss decreased (3.875681 --> 3.875681).  Saving model ...
Updating learning rate to 1.220703125e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.5761084719073783:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5761084719073783:   5%|â–Œ         | 1/19 [00:00<00:01,  9.40it/s]loss:0.6005110869219283:   5%|â–Œ         | 1/19 [00:00<00:01,  9.40it/s]loss:0.6005110869219283:  11%|â–ˆ         | 2/19 [00:00<00:01,  8.86it/s]loss:0.607120610626759:  11%|â–ˆ         | 2/19 [00:00<00:01,  8.86it/s] loss:0.64603628882528:  11%|â–ˆ         | 2/19 [00:00<00:01,  8.86it/s] loss:0.64603628882528:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01,  9.65it/s]loss:0.7132269836165369:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01,  9.65it/s]loss:0.8425265985045277:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01,  9.65it/s]loss:0.8425265985045277:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01,  9.84it/s]loss:0.7929547259878316:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01,  9.84it/s]loss:0.7929547259878316:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01,  9.63it/s]loss:0.8087996269439797:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01,  9.63it/s]loss:0.9405734091909059:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01,  9.63it/s]loss:0.9405734091909059:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:01,  9.86it/s]loss:1.081953018180996:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:01<00:01,  9.86it/s] loss:1.1649740705378495:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:01<00:01,  9.86it/s]loss:1.1649740705378495:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00,  9.98it/s]loss:1.0811935779549957:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00,  9.98it/s]loss:1.1284311799099702:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00,  9.98it/s]loss:1.1284311799099702:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.30it/s]loss:1.1738239072407495:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.30it/s]loss:1.3119961577398764:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.30it/s]loss:1.3119961577398764:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00,  9.80it/s]loss:1.2244048509012044:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00,  9.80it/s]loss:1.0820726162255492:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00,  9.80it/s]loss:1.0820726162255492:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 10.18it/s]loss:1.1579660581021167:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 10.18it/s]loss:1.119242853135431:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 10.18it/s] loss:1.119242853135431: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.18it/s]loss:1.119242853135431: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00,  9.64it/s]
Epoch: 15 cost time: 2.6971752643585205
Epoch: 15, Steps: 19 | Train Loss: 0.9502061 Vali Loss: 3.8756807 Test Loss: 69.6656723
Validation loss decreased (3.875681 --> 3.875681).  Saving model ...
Updating learning rate to 6.103515625e-09
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.5893513957012261:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5893513957012261:   5%|â–Œ         | 1/19 [00:00<00:01,  9.41it/s]loss:0.6287890771792916:   5%|â–Œ         | 1/19 [00:00<00:01,  9.41it/s]loss:0.6287890771792916:  11%|â–ˆ         | 2/19 [00:00<00:01,  9.31it/s]loss:0.6138800348190824:  11%|â–ˆ         | 2/19 [00:00<00:01,  9.31it/s]loss:0.6138800348190824:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01,  9.28it/s]loss:0.6236261207519533:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01,  9.28it/s]loss:0.6695684828252292:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01,  9.28it/s]loss:0.6695684828252292:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01,  9.78it/s]loss:0.8092300829810001:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01,  9.78it/s]loss:0.8092300829810001:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01,  9.69it/s]loss:0.9537998875297817:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01,  9.69it/s]loss:0.8378634235008386:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01,  9.69it/s]loss:0.8378634235008386:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:01,  9.81it/s]loss:0.9632190291264099:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:01,  9.81it/s]loss:0.9632190291264099:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:01,  9.61it/s]loss:0.9282174876724352:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:01<00:01,  9.61it/s]loss:0.9282174876724352:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:00,  9.52it/s]loss:1.0413994327613294:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:00,  9.52it/s]loss:1.1054653669763082:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:00,  9.52it/s]loss:1.1054653669763082:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00,  9.78it/s]loss:1.022910890157079:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00,  9.78it/s] loss:1.0816332034615581:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00,  9.78it/s]loss:1.0816332034615581:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 10.22it/s]loss:1.160364596291385:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 10.22it/s] loss:1.2244045712153282:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 10.22it/s]loss:1.2244045712153282:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 10.41it/s]loss:1.1493137048798159:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 10.41it/s]loss:1.3621298268781177:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 10.41it/s]loss:1.3621298268781177:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00,  9.84it/s]loss:1.2855024795827648:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00,  9.84it/s]loss:1.2855024795827648: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00,  9.46it/s]loss:1.2855024795827648: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:02<00:00,  9.40it/s]
Epoch: 16 cost time: 2.844860553741455
Epoch: 16, Steps: 19 | Train Loss: 0.9500352 Vali Loss: 3.8756800 Test Loss: 69.6656799
Validation loss decreased (3.875681 --> 3.875680).  Saving model ...
Updating learning rate to 3.0517578125e-09
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.5570805842623664:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5570805842623664:   5%|â–Œ         | 1/19 [00:00<00:02,  8.76it/s]loss:0.5505154169696858:   5%|â–Œ         | 1/19 [00:00<00:02,  8.76it/s]loss:0.5505154169696858:  11%|â–ˆ         | 2/19 [00:00<00:02,  8.28it/s]loss:0.607120562617489:  11%|â–ˆ         | 2/19 [00:00<00:02,  8.28it/s] loss:0.7780608807326123:  11%|â–ˆ         | 2/19 [00:00<00:02,  8.28it/s]loss:0.7780608807326123:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01,  9.73it/s]loss:0.7654941411216214:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01,  9.73it/s]loss:0.7654941411216214:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01,  8.69it/s]loss:0.7630315848180125:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01,  8.69it/s]loss:0.8526256783286779:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01,  8.69it/s]loss:0.8526256783286779:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01,  9.64it/s]loss:0.9569927545464588:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01,  9.64it/s]loss:0.9569927545464588:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:01,  9.65it/s]loss:0.9632189433735837:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:01,  9.65it/s]loss:0.8938615608468022:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:01<00:01,  9.65it/s]loss:0.8938615608468022:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:00,  9.63it/s]loss:0.9313482621640649:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:00,  9.63it/s]loss:1.0684769447141547:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:00,  9.63it/s]loss:1.0684769447141547:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 10.02it/s]loss:1.0609502267286686:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 10.02it/s]loss:1.2445411758253884:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 10.02it/s]loss:1.2445411758253884:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 10.25it/s]loss:1.235097144342279:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 10.25it/s] loss:1.1112780539207623:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 10.25it/s]loss:1.1112780539207623:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00,  9.93it/s]loss:1.2224141431484372:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00,  9.93it/s]loss:1.363695732805297:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00,  9.93it/s] loss:1.363695732805297:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 10.19it/s]loss:1.119242763480357:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 10.19it/s]loss:1.119242763480357: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00,  9.54it/s]
Epoch: 17 cost time: 2.7199747562408447
Epoch: 17, Steps: 19 | Train Loss: 0.9497393 Vali Loss: 3.8756800 Test Loss: 69.6656799
Validation loss decreased (3.875680 --> 3.875680).  Saving model ...
Updating learning rate to 1.52587890625e-09
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.6074711610335346:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6074711610335346:   5%|â–Œ         | 1/19 [00:00<00:02,  8.35it/s]loss:0.62415883885031:   5%|â–Œ         | 1/19 [00:00<00:02,  8.35it/s]  loss:0.62415883885031:  11%|â–ˆ         | 2/19 [00:00<00:01,  8.89it/s]loss:0.5771203784697054:  11%|â–ˆ         | 2/19 [00:00<00:01,  8.89it/s]loss:0.5771203784697054:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01,  9.18it/s]loss:0.6963278289326313:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01,  9.18it/s]loss:0.6963278289326313:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01,  9.24it/s]loss:0.7111761870667882:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01,  9.24it/s]loss:0.7111761870667882:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01,  9.32it/s]loss:0.7915471714485756:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01,  9.32it/s]loss:0.7929546425789822:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01,  9.32it/s]loss:0.7929546425789822:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01,  9.88it/s]loss:0.9124040635799232:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01,  9.88it/s]loss:0.9066888921760555:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01,  9.88it/s]loss:0.9066888921760555:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 10.18it/s]loss:1.1164996134212246:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:01<00:00, 10.18it/s]loss:1.128926109428714:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:01<00:00, 10.18it/s] loss:1.128926109428714:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00,  9.79it/s]loss:1.0186437420038283:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00,  9.79it/s]loss:1.0186437420038283:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00,  9.25it/s]loss:1.1419829676338773:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00,  9.25it/s]loss:1.1419829676338773:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00,  9.29it/s]loss:1.1618637632493325:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00,  9.29it/s]loss:1.0893699795937366:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00,  9.29it/s]loss:1.0893699795937366:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00,  9.62it/s]loss:1.0686305030808354:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00,  9.62it/s]loss:1.2398055541338835:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00,  9.62it/s]loss:1.2398055541338835:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 10.12it/s]loss:1.1164481427035027:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 10.12it/s]loss:1.2950386201762565:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 10.12it/s]loss:1.2950386201762565: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.39it/s]loss:1.2950386201762565: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:02<00:00,  9.47it/s]
Epoch: 18 cost time: 2.67041277885437
Epoch: 18, Steps: 19 | Train Loss: 0.9472136 Vali Loss: 3.8756800 Test Loss: 69.6656799
Validation loss decreased (3.875680 --> 3.875680).  Saving model ...
Updating learning rate to 7.62939453125e-10
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.5179089058714791:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5179089058714791:   5%|â–Œ         | 1/19 [00:00<00:02,  7.12it/s]loss:0.5863925574555173:   5%|â–Œ         | 1/19 [00:00<00:02,  7.12it/s]loss:0.5863925574555173:  11%|â–ˆ         | 2/19 [00:00<00:02,  7.73it/s]loss:0.5901682213518898:  11%|â–ˆ         | 2/19 [00:00<00:02,  7.73it/s]loss:0.6963278106878618:  11%|â–ˆ         | 2/19 [00:00<00:02,  7.73it/s]loss:0.6963278106878618:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01,  8.84it/s]loss:0.7654940532794539:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01,  8.84it/s]loss:0.7449119419853752:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01,  8.84it/s]loss:0.7449119419853752:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01,  9.68it/s]loss:0.862884348279248:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01,  9.68it/s] loss:0.9124040154753639:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01,  9.68it/s]loss:0.9124040154753639:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:01, 10.00it/s]loss:0.9752655679573459:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:01, 10.00it/s]loss:0.9752655679573459:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:01,  9.93it/s]loss:0.8925952103564669:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:01<00:01,  9.93it/s]loss:0.8925952103564669:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:00,  9.91it/s]loss:1.1649735856690804:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:00,  9.91it/s]loss:1.1649735856690804:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00,  9.59it/s]loss:1.208100602352619:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00,  9.59it/s] loss:1.208100602352619:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00,  9.36it/s]loss:1.052293517799056:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00,  9.36it/s]loss:1.0281854669151744:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00,  9.36it/s]loss:1.0281854669151744:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 10.00it/s]loss:1.2350970784435829:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 10.00it/s]loss:1.1086016999453625:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 10.00it/s]loss:1.1086016999453625:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 10.15it/s]loss:1.3116249073367992:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 10.15it/s]loss:1.2918050588409826:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 10.15it/s]loss:1.2918050588409826:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 10.44it/s]loss:1.160864401493877:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 10.44it/s] loss:1.160864401493877: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:02<00:00,  9.48it/s]
Epoch: 19 cost time: 2.7095553874969482
Epoch: 19, Steps: 19 | Train Loss: 0.9529421 Vali Loss: 3.8756800 Test Loss: 69.6656799
Validation loss decreased (3.875680 --> 3.875680).  Saving model ...
Updating learning rate to 3.814697265625e-10
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.6081695348776961:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6081695348776961:   5%|â–Œ         | 1/19 [00:00<00:02,  8.33it/s]loss:0.5652676628232549:   5%|â–Œ         | 1/19 [00:00<00:02,  8.33it/s]loss:0.5652676628232549:  11%|â–ˆ         | 2/19 [00:00<00:01,  8.58it/s]loss:0.5771203585657295:  11%|â–ˆ         | 2/19 [00:00<00:01,  8.58it/s]loss:0.7035105460359149:  11%|â–ˆ         | 2/19 [00:00<00:01,  8.58it/s]loss:0.7035105460359149:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 10.02it/s]loss:0.7111761710855603:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 10.02it/s]loss:0.8009676273323345:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 10.02it/s]loss:0.8009676273323345:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 10.48it/s]loss:0.8032992895356289:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 10.48it/s]loss:0.92336205759656:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 10.48it/s]  loss:0.92336205759656:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:01, 10.07it/s]loss:0.9632188637698912:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:01, 10.07it/s]loss:1.0819519125436672:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:01, 10.07it/s]loss:1.0819519125436672:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 10.31it/s]loss:0.9537557517060837:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:00, 10.31it/s]loss:1.145728303416967:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:00, 10.31it/s] loss:1.145728303416967:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00,  9.69it/s]loss:1.0362407183423168:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00,  9.69it/s]loss:1.0362407183423168:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00,  9.71it/s]loss:1.1345478104393316:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00,  9.71it/s]loss:1.1345478104393316:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00,  9.73it/s]loss:1.0919998386336398:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00,  9.73it/s]loss:1.0919998386336398:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00,  9.58it/s]loss:1.2569014959848943:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00,  9.58it/s]loss:1.2569014959848943:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00,  9.47it/s]loss:1.0820721774277073:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00,  9.47it/s]loss:1.362129597074337:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00,  9.47it/s] loss:1.362129597074337:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00,  9.95it/s]loss:1.2522657532594077:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00,  9.95it/s]loss:1.2522657532594077: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00,  9.57it/s]
Epoch: 20 cost time: 2.6439108848571777
Epoch: 20, Steps: 19 | Train Loss: 0.9501940 Vali Loss: 3.8756800 Test Loss: 69.6656799
Validation loss decreased (3.875680 --> 3.875680).  Saving model ...
Updating learning rate to 1.9073486328125e-10
>>>>>>>testing : long_term_forecast_break_rayleigh_0_FiLM_job_demand_r1_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 4
test shape: (4, 1, 3, 32690) (4, 1, 3, 32690)
test shape: (4, 3, 32690) (4, 3, 32690)
mse:43506.62890625, mae:19.198305130004883, dtw:-999
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           0                   Model:              Koopa               

[1mData Loader[0m
  Data:               job_demand_r1       Root Path:          ../../dataset/demand/
  Data Path:          r1.parquet          Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        .cache/checkpoints  

[1mForecasting Task[0m
  Seq Len:            6                   Label Len:          1                   
  Pred Len:           3                   Seasonal Patterns:  Monthly             
  Inverse:            1                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             32690               Dec In:             32690               
  C Out:              32690               d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           2                   d FF:               2048                
  Moving Avg:         25                  Factor:             1                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              learned             Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        32                  Itr:                1                   
  Train Epochs:       20                  Batch Size:         1                   
  Patience:           3                   Learning Rate:      0.0001              
  Des:                test                Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1                 

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
train 19
>>>>>>>start training : long_term_forecast_break_bartlett_0_Koopa_job_demand_r1_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 19
val 1
test 4
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.57it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.57it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.57it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:02,  7.11it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:02,  7.11it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:02,  7.11it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:02,  7.11it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 12.87it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 12.87it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 12.87it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 12.87it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 12.87it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 12.87it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 12.87it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 25.64it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 25.64it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 25.64it/s]loss:0.04877207233650796:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 25.64it/s]loss:0.27325722409960457:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 25.64it/s]loss:0.5259939410030975:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 25.64it/s] loss:0.8280117216009788:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 25.64it/s]loss:0.9457603085483374:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 25.64it/s]loss:0.9457603085483374: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 22.26it/s]
Epoch: 1 cost time: 1.3199634552001953
Epoch: 1, Steps: 19 | Train Loss: 0.1379892 Vali Loss: 3.9896505 Test Loss: 68.1518021
Validation loss decreased (inf --> 3.989650).  Saving model ...
Updating learning rate to 0.0001
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 69.53it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 69.53it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 69.53it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 69.53it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 69.53it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 69.53it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 69.53it/s]loss:0.04537753015826243:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 69.53it/s]loss:0.04537753015826243:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 67.20it/s]loss:0.26572539427926906:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 67.20it/s]loss:0.5561886288182301:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 67.20it/s] loss:0.8489001983900019:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 67.20it/s]loss:1.149978508096081:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 67.20it/s] loss:1.149978508096081: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 57.64it/s]
Epoch: 2 cost time: 0.902484655380249
Epoch: 2, Steps: 19 | Train Loss: 0.1508511 Vali Loss: 4.0517888 Test Loss: 75.1646042
EarlyStopping counter: 1 out of 3
Updating learning rate to 5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 99.94it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 99.94it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 99.94it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 99.94it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 99.94it/s]loss:0.04777276546378157:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 99.94it/s]loss:0.26784630870018356:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 99.94it/s]loss:0.46572323366674034:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 99.94it/s]loss:0.6721507406357372:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 99.94it/s] loss:1.041382428232277:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 99.94it/s] loss:1.041382428232277: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 84.23it/s]
Epoch: 3 cost time: 0.7592430114746094
Epoch: 3, Steps: 19 | Train Loss: 0.1313092 Vali Loss: 4.0240073 Test Loss: 70.0247498
EarlyStopping counter: 2 out of 3
Updating learning rate to 2.5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 90.39it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 90.39it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 90.39it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 90.39it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 90.39it/s]loss:0.04167473803271587:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 90.39it/s]loss:0.2983520594958032:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 90.39it/s] loss:0.4579866323302571:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 90.39it/s]loss:0.6102412791295714:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 90.39it/s]loss:0.9031713873147288:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 90.39it/s]loss:0.9031713873147288: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 70.99it/s]
Epoch: 4 cost time: 0.8089606761932373
Epoch: 4, Steps: 19 | Train Loss: 0.1216540 Vali Loss: 4.0115418 Test Loss: 69.2953491
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : long_term_forecast_break_bartlett_0_Koopa_job_demand_r1_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 4
test shape: (4, 1, 3, 32690) (4, 1, 3, 32690)
test shape: (4, 3, 32690) (4, 3, 32690)
mse:67221.78125, mae:19.95947265625, dtw:-999
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           0                   Model:              Koopa               

[1mData Loader[0m
  Data:               job_demand_r1       Root Path:          ../../dataset/demand/
  Data Path:          r1.parquet          Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        .cache/checkpoints  

[1mForecasting Task[0m
  Seq Len:            6                   Label Len:          1                   
  Pred Len:           3                   Seasonal Patterns:  Monthly             
  Inverse:            1                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             32690               Dec In:             32690               
  C Out:              32690               d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           2                   d FF:               2048                
  Moving Avg:         25                  Factor:             1                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              learned             Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        32                  Itr:                1                   
  Train Epochs:       20                  Batch Size:         1                   
  Patience:           3                   Learning Rate:      0.0001              
  Des:                test                Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1                 

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
train 19
>>>>>>>start training : long_term_forecast_break_parzen_0_Koopa_job_demand_r1_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 19
val 1
test 4
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.77it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.77it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.77it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.77it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.77it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.77it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.77it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.77it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.77it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 24.51it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 24.51it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 24.51it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 24.51it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 24.51it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 24.51it/s]loss:0.0002211885366735039:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 24.51it/s]loss:0.04451667395226285:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 24.51it/s]  loss:0.28890710087167537:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 24.51it/s]loss:0.28890710087167537:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 38.81it/s]loss:0.8050496462894415:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 38.81it/s] loss:1.045354073652451:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 38.81it/s] loss:1.045354073652451: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 29.47it/s]
Epoch: 1 cost time: 1.0847773551940918
Epoch: 1, Steps: 19 | Train Loss: 0.1149499 Vali Loss: 3.9828191 Test Loss: 68.1432343
Validation loss decreased (inf --> 3.982819).  Saving model ...
Updating learning rate to 0.0001
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 94.62it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 94.62it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 94.62it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 94.62it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 94.62it/s]loss:0.00018330662197500554:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 94.62it/s]loss:0.04820336837812667:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 94.62it/s]   loss:0.3121864760573373:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 94.62it/s] loss:0.7733481714336676:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 94.62it/s]loss:1.0057028394747896:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 94.62it/s]loss:1.0057028394747896: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 67.73it/s]
Epoch: 2 cost time: 0.8437759876251221
Epoch: 2, Steps: 19 | Train Loss: 0.1126118 Vali Loss: 3.9633131 Test Loss: 69.3131714
Validation loss decreased (3.982819 --> 3.963313).  Saving model ...
Updating learning rate to 5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 77.66it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 77.66it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 77.66it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 77.66it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 77.66it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 77.66it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 77.66it/s]loss:0.00022999881759405575:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 77.66it/s]loss:0.04293323349655087:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 77.66it/s]   loss:0.04293323349655087:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 71.62it/s]loss:0.2510217460392621:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 71.62it/s] loss:0.7187318997189773:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 71.62it/s]loss:1.0114299136223708:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 71.62it/s]loss:1.0114299136223708: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 58.20it/s]
Epoch: 3 cost time: 0.8851706981658936
Epoch: 3, Steps: 19 | Train Loss: 0.1065446 Vali Loss: 3.9704006 Test Loss: 69.0668030
EarlyStopping counter: 1 out of 3
Updating learning rate to 2.5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 74.20it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 74.20it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 74.20it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 74.20it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 74.20it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 74.20it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 74.20it/s]loss:0.00020027747708834743:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 74.20it/s]loss:0.04830504301117515:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 74.20it/s]   loss:0.2672539003135495:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 74.20it/s] loss:0.2672539003135495:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 80.33it/s]loss:0.599353064185796:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 80.33it/s] loss:1.0116152098022329:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 80.33it/s]loss:1.0116152098022329: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 69.69it/s]
Epoch: 4 cost time: 0.7710332870483398
Epoch: 4, Steps: 19 | Train Loss: 0.1014067 Vali Loss: 3.9776351 Test Loss: 69.1206512
EarlyStopping counter: 2 out of 3
Updating learning rate to 1.25e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 99.70it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 99.70it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 99.70it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 99.70it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 99.70it/s]loss:0.00019392503160142044:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 99.70it/s]loss:0.04288989220795378:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 99.70it/s]   loss:0.2665662012025349:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 99.70it/s] loss:0.8159157999667088:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 99.70it/s]loss:0.9153353890221846:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 99.70it/s]loss:0.9153353890221846: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 87.21it/s]
Epoch: 5 cost time: 0.799170732498169
Epoch: 5, Steps: 19 | Train Loss: 0.1074159 Vali Loss: 3.9834101 Test Loss: 69.2706909
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : long_term_forecast_break_parzen_0_Koopa_job_demand_r1_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 4
test shape: (4, 1, 3, 32690) (4, 1, 3, 32690)
test shape: (4, 3, 32690) (4, 3, 32690)
mse:67957.7578125, mae:20.01369857788086, dtw:-999
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           0                   Model:              Koopa               

[1mData Loader[0m
  Data:               job_demand_r1       Root Path:          ../../dataset/demand/
  Data Path:          r1.parquet          Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        .cache/checkpoints  

[1mForecasting Task[0m
  Seq Len:            6                   Label Len:          1                   
  Pred Len:           3                   Seasonal Patterns:  Monthly             
  Inverse:            1                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             32690               Dec In:             32690               
  C Out:              32690               d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           2                   d FF:               2048                
  Moving Avg:         25                  Factor:             1                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              learned             Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        32                  Itr:                1                   
  Train Epochs:       20                  Batch Size:         1                   
  Patience:           3                   Learning Rate:      0.0001              
  Des:                test                Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1                 

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
train 19
>>>>>>>start training : long_term_forecast_break_tukey-hanning_0_Koopa_job_demand_r1_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 19
val 1
test 4
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.61it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.61it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.61it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.61it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.61it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.61it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.61it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.61it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.61it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.61it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 26.11it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 26.11it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 26.11it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 26.11it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 26.11it/s]loss:0.0057198093885140865:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 26.11it/s]loss:0.1800587777716229:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 26.11it/s]   loss:0.5398232504526765:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 26.11it/s]loss:0.9411739003163037:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 26.11it/s]loss:0.9411739003163037:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:00<00:00, 40.78it/s]loss:0.9875312927081205:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:00<00:00, 40.78it/s]loss:0.9875312927081205: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 29.65it/s]
Epoch: 1 cost time: 1.104419469833374
Epoch: 1, Steps: 19 | Train Loss: 0.1397004 Vali Loss: 3.9875758 Test Loss: 67.2753601
Validation loss decreased (inf --> 3.987576).  Saving model ...
Updating learning rate to 0.0001
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 70.82it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 70.82it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 70.82it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 70.82it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 70.82it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 70.82it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 70.82it/s]loss:0.00481722239771427:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 70.82it/s]loss:0.20133368854277953:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 70.82it/s]loss:0.20133368854277953:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 51.20it/s]loss:0.5683877926446012:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 51.20it/s] loss:0.9394310334576959:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 51.20it/s]loss:1.0592965878731726:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 51.20it/s]loss:1.0592965878731726: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 46.97it/s]
Epoch: 2 cost time: 1.016610860824585
Epoch: 2, Steps: 19 | Train Loss: 0.1459614 Vali Loss: 4.0083485 Test Loss: 70.1824417
EarlyStopping counter: 1 out of 3
Updating learning rate to 5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 78.70it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 78.70it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 78.70it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 78.70it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 78.70it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 78.70it/s]loss:0.006114898897125548:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 78.70it/s]loss:0.1757658576356275:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 78.70it/s]  loss:0.4642276238467439:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 78.70it/s]loss:0.4642276238467439:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 70.65it/s]loss:0.8699011261456624:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 70.65it/s]loss:1.0241372391709047:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 70.65it/s]loss:1.0241372391709047: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 59.79it/s]
Epoch: 3 cost time: 0.8712289333343506
Epoch: 3, Steps: 19 | Train Loss: 0.1336919 Vali Loss: 3.9845502 Test Loss: 70.0677185
Validation loss decreased (3.987576 --> 3.984550).  Saving model ...
Updating learning rate to 2.5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 87.39it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 87.39it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 87.39it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 87.39it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 87.39it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 87.39it/s]loss:0.0053194081160001265:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 87.39it/s]loss:0.2128447576777944:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 87.39it/s]   loss:0.5337454933312692:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 87.39it/s]loss:0.7015012797037617:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 87.39it/s]loss:0.7015012797037617:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:00<00:00, 80.36it/s]loss:1.000819236205388:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:00<00:00, 80.36it/s] loss:1.000819236205388: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 67.87it/s]
Epoch: 4 cost time: 0.8959972858428955
Epoch: 4, Steps: 19 | Train Loss: 0.1291700 Vali Loss: 3.9889269 Test Loss: 70.0557404
EarlyStopping counter: 1 out of 3
Updating learning rate to 1.25e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 99.65it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 99.65it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 99.65it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 99.65it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 99.65it/s]loss:0.004915011588594518:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 99.65it/s]loss:0.18025826769405434:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 99.65it/s] loss:0.5075997950640472:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 99.65it/s] loss:0.9418852133566431:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 99.65it/s]loss:0.9536035110310045:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 99.65it/s]loss:0.9536035110310045: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 86.27it/s]
Epoch: 5 cost time: 0.7759602069854736
Epoch: 5, Steps: 19 | Train Loss: 0.1362243 Vali Loss: 3.9967568 Test Loss: 70.3843155
EarlyStopping counter: 2 out of 3
Updating learning rate to 6.25e-06
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 97.31it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 97.31it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 97.31it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 97.31it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 97.31it/s]loss:0.004715427370207529:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 97.31it/s]loss:0.1790686044266618:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 97.31it/s]  loss:0.46959270038922923:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 97.31it/s]loss:0.9061969611938867:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 97.31it/s] loss:1.1077126626145366:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 97.31it/s]loss:1.1077126626145366: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 86.04it/s]
Epoch: 6 cost time: 0.7641656398773193
Epoch: 6, Steps: 19 | Train Loss: 0.1403835 Vali Loss: 4.0046310 Test Loss: 70.4453278
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : long_term_forecast_break_tukey-hanning_0_Koopa_job_demand_r1_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 4
test shape: (4, 1, 3, 32690) (4, 1, 3, 32690)
test shape: (4, 3, 32690) (4, 3, 32690)
mse:68270.5078125, mae:20.14854621887207, dtw:-999
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           0                   Model:              Koopa               

[1mData Loader[0m
  Data:               job_demand_r1       Root Path:          ../../dataset/demand/
  Data Path:          r1.parquet          Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        .cache/checkpoints  

[1mForecasting Task[0m
  Seq Len:            6                   Label Len:          1                   
  Pred Len:           3                   Seasonal Patterns:  Monthly             
  Inverse:            1                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             32690               Dec In:             32690               
  C Out:              32690               d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           2                   d FF:               2048                
  Moving Avg:         25                  Factor:             1                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              learned             Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        32                  Itr:                1                   
  Train Epochs:       20                  Batch Size:         1                   
  Patience:           3                   Learning Rate:      0.0001              
  Des:                test                Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1                 

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
train 19
>>>>>>>start training : long_term_forecast_break_rayleigh_0_Koopa_job_demand_r1_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 19
val 1
test 4
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.3903621258729879:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.3903621258729879:   5%|â–Œ         | 1/19 [00:00<00:06,  2.83it/s]loss:0.4227197200258012:   5%|â–Œ         | 1/19 [00:00<00:06,  2.83it/s]loss:0.5145740921565718:   5%|â–Œ         | 1/19 [00:00<00:06,  2.83it/s]loss:0.5169212805745336:   5%|â–Œ         | 1/19 [00:00<00:06,  2.83it/s]loss:0.5685646131200636:   5%|â–Œ         | 1/19 [00:00<00:06,  2.83it/s]loss:0.5755532529397109:   5%|â–Œ         | 1/19 [00:00<00:06,  2.83it/s]loss:0.6030584159663522:   5%|â–Œ         | 1/19 [00:00<00:06,  2.83it/s]loss:0.6416001271534868:   5%|â–Œ         | 1/19 [00:00<00:06,  2.83it/s]loss:0.7102782009808963:   5%|â–Œ         | 1/19 [00:00<00:06,  2.83it/s]loss:0.7102782009808963:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 24.51it/s]loss:0.9201566959929472:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 24.51it/s]loss:0.739058763650166:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 24.51it/s] loss:0.9611884864626847:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 24.51it/s]loss:0.7674104117781184:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 24.51it/s]loss:0.7554119339433305:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 24.51it/s]loss:0.9946625160417765:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 24.51it/s]loss:0.9404812643806644:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 24.51it/s]loss:0.9404812643806644:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 37.55it/s]loss:1.0003124112167006:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 37.55it/s]loss:1.1498428430426302:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 37.55it/s]loss:0.9564601222783036:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 37.55it/s]loss:0.9564601222783036: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 29.35it/s]
Epoch: 1 cost time: 1.1077446937561035
Epoch: 1, Steps: 19 | Train Loss: 0.7436114 Vali Loss: 4.0261221 Test Loss: 69.9009323
Validation loss decreased (inf --> 4.026122).  Saving model ...
Updating learning rate to 0.0001
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.4490830166330117:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.41979498752808275:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5136554031747202:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.6280887607255604:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5829148913655959:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5661554871036126:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.777894664749004:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.777894664749004:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 63.26it/s]loss:0.7884330906986524:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 63.26it/s]loss:0.7333184833080861:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 63.26it/s]loss:0.8255873790841946:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 63.26it/s]loss:0.7151719317370931:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 63.26it/s]loss:0.7659399190216304:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 63.26it/s]loss:0.9927639637791725:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 63.26it/s]loss:0.9112556458434494:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 63.26it/s]loss:0.9112556458434494:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 60.36it/s]loss:0.753342531395492:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 60.36it/s] loss:0.9078092385537408:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 60.36it/s]loss:1.0603682848393101:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 60.36it/s]loss:0.9817618677446835:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 60.36it/s]loss:0.9754007041021945:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 60.36it/s]loss:0.9754007041021945: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 51.35it/s]
Epoch: 2 cost time: 0.941291093826294
Epoch: 2, Steps: 19 | Train Loss: 0.7551969 Vali Loss: 4.0325828 Test Loss: 70.1040649
EarlyStopping counter: 1 out of 3
Updating learning rate to 5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.38791181986739237:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.4588211889836256:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.5015460118968909:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.44069088118765926:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5138874251798095:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.6596692142343173:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5875285441320931:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6833229696632568:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7406075827483656:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7406075827483656:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 89.66it/s]loss:0.7480769510440345:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 89.66it/s]loss:0.9232987104398975:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 89.66it/s]loss:0.9299620487543345:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 89.66it/s]loss:0.7873002903492253:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 89.66it/s]loss:1.0469336785591166:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 89.66it/s]loss:0.9438337973608092:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 89.66it/s]loss:0.8406087700271265:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 89.66it/s]loss:0.8077175441884274:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 89.66it/s]loss:0.8863690026255905:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 89.66it/s]loss:1.0117923144126353:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 89.66it/s]loss:1.0117923144126353: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 90.03it/s]loss:1.0117923144126353: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 75.75it/s]
Epoch: 3 cost time: 0.8095195293426514
Epoch: 3, Steps: 19 | Train Loss: 0.7315726 Vali Loss: 4.0307536 Test Loss: 70.2990417
EarlyStopping counter: 2 out of 3
Updating learning rate to 2.5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.4103771244198741:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5405355621935835:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.4422613623625197:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6165858815539904:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5781464417351928:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5650674865823415:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7306361682989997:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.743451680553457:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.743451680553457:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 73.13it/s]loss:0.7324630017560542:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 73.13it/s]loss:0.7392289197400803:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 73.13it/s]loss:0.6947973723248518:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 73.13it/s]loss:0.8540062607050103:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 73.13it/s]loss:0.7732338547511145:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 73.13it/s]loss:0.800989835004852:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 73.13it/s] loss:0.8455793218798314:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 73.13it/s]loss:0.9818176773584399:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 73.13it/s]loss:0.9818176773584399:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 66.92it/s]loss:0.8367702147673312:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 66.92it/s]loss:0.7728884266605821:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 66.92it/s]loss:0.9324911319215582:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 66.92it/s]loss:0.9324911319215582: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 56.59it/s]
Epoch: 4 cost time: 0.903395414352417
Epoch: 4, Steps: 19 | Train Loss: 0.7153330 Vali Loss: 4.0292687 Test Loss: 70.2997360
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : long_term_forecast_break_rayleigh_0_Koopa_job_demand_r1_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 4
test shape: (4, 1, 3, 32690) (4, 1, 3, 32690)
test shape: (4, 3, 32690) (4, 3, 32690)
mse:70468.4453125, mae:20.108495712280273, dtw:-999
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           0                   Model:              DLinear             

[1mData Loader[0m
  Data:               job_demand_r1       Root Path:          ../../dataset/demand/
  Data Path:          r1.parquet          Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        .cache/checkpoints  

[1mForecasting Task[0m
  Seq Len:            6                   Label Len:          1                   
  Pred Len:           3                   Seasonal Patterns:  Monthly             
  Inverse:            1                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             32690               Dec In:             32690               
  C Out:              32690               d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           2                   d FF:               2048                
  Moving Avg:         25                  Factor:             1                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              learned             Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        32                  Itr:                1                   
  Train Epochs:       20                  Batch Size:         1                   
  Patience:           3                   Learning Rate:      0.0001              
  Des:                test                Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1                 

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_break_bartlett_0_DLinear_job_demand_r1_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 19
val 1
test 4
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.21it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.21it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.21it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.21it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.21it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.21it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.21it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.21it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.21it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.21it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.21it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.21it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.21it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.21it/s]loss:0.043563421701756116:   5%|â–Œ         | 1/19 [00:00<00:08,  2.21it/s]loss:0.2836301620479067:   5%|â–Œ         | 1/19 [00:00<00:08,  2.21it/s]  loss:0.4613383113585295:   5%|â–Œ         | 1/19 [00:00<00:08,  2.21it/s]loss:0.8232267471735155:   5%|â–Œ         | 1/19 [00:00<00:08,  2.21it/s]loss:1.003903518274142:   5%|â–Œ         | 1/19 [00:00<00:08,  2.21it/s] loss:1.003903518274142: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 35.68it/s]
Epoch: 1 cost time: 1.059574842453003
Epoch: 1, Steps: 19 | Train Loss: 0.1376664 Vali Loss: 3.9375165 Test Loss: 69.5440598
Validation loss decreased (inf --> 3.937516).  Saving model ...
Updating learning rate to 0.0001
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.05133818452400414:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.2557673342446381:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.518707192064042:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.6737840734219622:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.0574708716481056:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.0574708716481056: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 249.34it/s]
Epoch: 2 cost time: 0.544579029083252
Epoch: 2, Steps: 19 | Train Loss: 0.1345825 Vali Loss: 3.9356868 Test Loss: 69.5556488
Validation loss decreased (3.937516 --> 3.935687).  Saving model ...
Updating learning rate to 5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.04266560335894116:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.2603277354380457:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.5533463530655883:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.762301610955391:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.9749983109943938:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9749983109943938: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 252.76it/s]
Epoch: 3 cost time: 0.5710783004760742
Epoch: 3, Steps: 19 | Train Loss: 0.1365073 Vali Loss: 3.9349821 Test Loss: 69.5716019
Validation loss decreased (3.935687 --> 3.934982).  Saving model ...
Updating learning rate to 2.5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.05165175754108127:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.2552674903449785:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.46237854768963316:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7009440195593446:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.871188651561204:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.871188651561204: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 237.88it/s]
Epoch: 4 cost time: 0.5739142894744873
Epoch: 4, Steps: 19 | Train Loss: 0.1232332 Vali Loss: 3.9346595 Test Loss: 69.5801849
Validation loss decreased (3.934982 --> 3.934659).  Saving model ...
Updating learning rate to 1.25e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.041527833443683354:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.2627968867609987:   0%|          | 0/19 [00:00<?, ?it/s]  loss:0.458569641971689:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.6195779568959402:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9883444186529622:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9883444186529622: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 239.89it/s]
Epoch: 5 cost time: 0.5475690364837646
Epoch: 5, Steps: 19 | Train Loss: 0.1247798 Vali Loss: 3.9344919 Test Loss: 69.5804977
Validation loss decreased (3.934659 --> 3.934492).  Saving model ...
Updating learning rate to 6.25e-06
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.04260372153142418:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.2551140049963438:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.4621340042397272:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6668527013325769:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9059457675745429:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9059457675745429: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 240.89it/s]
Epoch: 6 cost time: 0.5605733394622803
Epoch: 6, Steps: 19 | Train Loss: 0.1227711 Vali Loss: 3.9344056 Test Loss: 69.5818634
Validation loss decreased (3.934492 --> 3.934406).  Saving model ...
Updating learning rate to 3.125e-06
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.05025375426374121:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.2588145569176718:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.49865853638550434:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.742058325784227:   0%|          | 0/19 [00:00<?, ?it/s]  loss:0.9195819033300807:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9195819033300807: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 218.45it/s]
Epoch: 7 cost time: 0.5533483028411865
Epoch: 7, Steps: 19 | Train Loss: 0.1299667 Vali Loss: 3.9343555 Test Loss: 69.5823669
Validation loss decreased (3.934406 --> 3.934355).  Saving model ...
Updating learning rate to 1.5625e-06
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.04705369820134752:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.2587995505490986:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.46207100434679155:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6932595937511326:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.8718231922462027:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8718231922462027: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 213.30it/s]
Epoch: 8 cost time: 0.5588700771331787
Epoch: 8, Steps: 19 | Train Loss: 0.1227898 Vali Loss: 3.9343307 Test Loss: 69.5826950
Validation loss decreased (3.934355 --> 3.934331).  Saving model ...
Updating learning rate to 7.8125e-07
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.038708411779231365:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.24908762644945132:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.5175822423900044:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.666726489947885:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.9519328699888151:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9519328699888151: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 269.06it/s]
Epoch: 9 cost time: 0.5575215816497803
Epoch: 9, Steps: 19 | Train Loss: 0.1275809 Vali Loss: 3.9343238 Test Loss: 69.5828934
Validation loss decreased (3.934331 --> 3.934324).  Saving model ...
Updating learning rate to 3.90625e-07
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.050251112440539994:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.23224731576365343:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.45836878320503993:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6815219412295345:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.905760991891746:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.905760991891746: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 238.02it/s]
Epoch: 10 cost time: 0.5554006099700928
Epoch: 10, Steps: 19 | Train Loss: 0.1225342 Vali Loss: 3.9343190 Test Loss: 69.5829773
Validation loss decreased (3.934324 --> 3.934319).  Saving model ...
Updating learning rate to 1.953125e-07
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.04532959230853771:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.24875371240597313:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.46854337581526395:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7135071820289468:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.8128589094225404:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8128589094225404: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 257.46it/s]
Epoch: 11 cost time: 0.5397098064422607
Epoch: 11, Steps: 19 | Train Loss: 0.1204733 Vali Loss: 3.9343162 Test Loss: 69.5830002
Validation loss decreased (3.934319 --> 3.934316).  Saving model ...
Updating learning rate to 9.765625e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.04230461870131097:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.2490830246000605:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.5175746219484016:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6932317816464824:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.892722426780661:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.892722426780661: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 240.81it/s]
Epoch: 12 cost time: 0.5005285739898682
Epoch: 12, Steps: 19 | Train Loss: 0.1260482 Vali Loss: 3.9343145 Test Loss: 69.5830231
Validation loss decreased (3.934316 --> 3.934314).  Saving model ...
Updating learning rate to 4.8828125e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.04459407317685328:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.3096094460704345:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.46761592954098413:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7005932493000069:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.999386480912481:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.999386480912481: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 251.01it/s]
Epoch: 13 cost time: 0.5725457668304443
Epoch: 13, Steps: 19 | Train Loss: 0.1327263 Vali Loss: 3.9343143 Test Loss: 69.5830231
Validation loss decreased (3.934314 --> 3.934314).  Saving model ...
Updating learning rate to 2.44140625e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.04378705901667641:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.248752547685243:   0%|          | 0/19 [00:00<?, ?it/s]  loss:0.46534993267443625:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7420056525674971:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.9364749484231014:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9364749484231014: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 221.53it/s]
Epoch: 14 cost time: 0.581942081451416
Epoch: 14, Steps: 19 | Train Loss: 0.1282300 Vali Loss: 3.9343135 Test Loss: 69.5830231
Validation loss decreased (3.934314 --> 3.934314).  Saving model ...
Updating learning rate to 1.220703125e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.04200471806625822:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.25556774429776574:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.4986234484611741:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.6642202021701722:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8927205606058941:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8927205606058941: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 222.54it/s]
Epoch: 15 cost time: 0.5732386112213135
Epoch: 15, Steps: 19 | Train Loss: 0.1238493 Vali Loss: 3.9343135 Test Loss: 69.5830307
Validation loss decreased (3.934314 --> 3.934314).  Saving model ...
Updating learning rate to 6.103515625e-09
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.04251050113658206:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.23224418961344928:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.46854084033476523:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6900949304199392:   0%|          | 0/19 [00:00<?, ?it/s] loss:1.0756361532127998:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.0756361532127998: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 249.91it/s]
Epoch: 16 cost time: 0.5501720905303955
Epoch: 16, Steps: 19 | Train Loss: 0.1320540 Vali Loss: 3.9343135 Test Loss: 69.5830307
Validation loss decreased (3.934314 --> 3.934314).  Saving model ...
Updating learning rate to 3.0517578125e-09
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.041458750911765756:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.25506300467607723:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.5175737860429087:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.6815139449744119:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9098648818689448:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9098648818689448: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 220.15it/s]
Epoch: 17 cost time: 0.5466699600219727
Epoch: 17, Steps: 19 | Train Loss: 0.1266039 Vali Loss: 3.9343135 Test Loss: 69.5830307
Validation loss decreased (3.934314 --> 3.934314).  Saving model ...
Updating learning rate to 1.52587890625e-09
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.04332689914060248:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.25001597389924013:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5527584362377198:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.825624124560088:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.8927205158227141:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8927205158227141: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 247.80it/s]
Epoch: 18 cost time: 0.5482194423675537
Epoch: 18, Steps: 19 | Train Loss: 0.1349708 Vali Loss: 3.9343135 Test Loss: 69.5830307
Validation loss decreased (3.934314 --> 3.934314).  Saving model ...
Updating learning rate to 7.62939453125e-10
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.044594039794545036:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.25556772859682325:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.4765958899472648:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.6633400144350953:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9738822315062641:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9738822315062641: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 244.90it/s]
Epoch: 19 cost time: 0.6075592041015625
Epoch: 19, Steps: 19 | Train Loss: 0.1270516 Vali Loss: 3.9343135 Test Loss: 69.5830307
Validation loss decreased (3.934314 --> 3.934314).  Saving model ...
Updating learning rate to 3.814697265625e-10
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.04200471570546676:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.2487525054131606:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.4653498255120136:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7614368239603787:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9519174497789735:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9519174497789735: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 219.48it/s]
Epoch: 20 cost time: 0.5578594207763672
Epoch: 20, Steps: 19 | Train Loss: 0.1299716 Vali Loss: 3.9343135 Test Loss: 69.5830307
Validation loss decreased (3.934314 --> 3.934314).  Saving model ...
Updating learning rate to 1.9073486328125e-10
>>>>>>>testing : long_term_forecast_break_bartlett_0_DLinear_job_demand_r1_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 4
test shape: (4, 1, 3, 32690) (4, 1, 3, 32690)
test shape: (4, 3, 32690) (4, 3, 32690)
mse:62161.64453125, mae:19.311838150024414, dtw:-999
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           0                   Model:              DLinear             

[1mData Loader[0m
  Data:               job_demand_r1       Root Path:          ../../dataset/demand/
  Data Path:          r1.parquet          Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        .cache/checkpoints  

[1mForecasting Task[0m
  Seq Len:            6                   Label Len:          1                   
  Pred Len:           3                   Seasonal Patterns:  Monthly             
  Inverse:            1                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             32690               Dec In:             32690               
  C Out:              32690               d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           2                   d FF:               2048                
  Moving Avg:         25                  Factor:             1                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              learned             Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        32                  Itr:                1                   
  Train Epochs:       20                  Batch Size:         1                   
  Patience:           3                   Learning Rate:      0.0001              
  Des:                test                Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1                 

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_break_parzen_0_DLinear_job_demand_r1_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 19
val 1
test 4
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.25it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.25it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.25it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.25it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.25it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.25it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.25it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.25it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.25it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.25it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.25it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.25it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.25it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.25it/s]loss:0.00019756653832995834:   5%|â–Œ         | 1/19 [00:00<00:08,  2.25it/s]loss:0.04630688249672208:   5%|â–Œ         | 1/19 [00:00<00:08,  2.25it/s]   loss:0.25307314066878117:   5%|â–Œ         | 1/19 [00:00<00:08,  2.25it/s]loss:0.8005194099312516:   5%|â–Œ         | 1/19 [00:00<00:08,  2.25it/s] loss:1.0039774649669964:   5%|â–Œ         | 1/19 [00:00<00:08,  2.25it/s]loss:1.0039774649669964: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 35.77it/s]
Epoch: 1 cost time: 1.065924882888794
Epoch: 1, Steps: 19 | Train Loss: 0.1107408 Vali Loss: 3.9375880 Test Loss: 69.5426254
Validation loss decreased (inf --> 3.937588).  Saving model ...
Updating learning rate to 0.0001
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.00023287714709998344:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.04176664301844732:   0%|          | 0/19 [00:00<?, ?it/s]   loss:0.2846097947503146:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.6553635013763772:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.0577456348737289:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.0577456348737289: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 238.35it/s]
Epoch: 2 cost time: 0.5305066108703613
Epoch: 2, Steps: 19 | Train Loss: 0.1073536 Vali Loss: 3.9360170 Test Loss: 69.5528488
Validation loss decreased (3.937588 --> 3.936017).  Saving model ...
Updating learning rate to 5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.00019359694855256671:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.042521892413519585:   0%|          | 0/19 [00:00<?, ?it/s]  loss:0.30362881531595115:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.7415804918527031:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.9754639650895364:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9754639650895364: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 193.33it/s]
Epoch: 3 cost time: 0.5986545085906982
Epoch: 3, Steps: 19 | Train Loss: 0.1085994 Vali Loss: 3.9354217 Test Loss: 69.5691376
Validation loss decreased (3.936017 --> 3.935422).  Saving model ...
Updating learning rate to 2.5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.00023445003598188607:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.04170098019219133:   0%|          | 0/19 [00:00<?, ?it/s]   loss:0.25377582784261327:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6819149177959674:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.8716169447776388:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8716169447776388: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 238.90it/s]
Epoch: 4 cost time: 0.5858066082000732
Epoch: 4, Steps: 19 | Train Loss: 0.0973286 Vali Loss: 3.9351375 Test Loss: 69.5768890
Validation loss decreased (3.935422 --> 3.935138).  Saving model ...
Updating learning rate to 1.25e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.00018843380192771293:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.04292834318808381:   0%|          | 0/19 [00:00<?, ?it/s]   loss:0.25174558762361915:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6028946540587625:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.988898655262352:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.988898655262352: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 250.37it/s]
Epoch: 5 cost time: 0.5921518802642822
Epoch: 5, Steps: 19 | Train Loss: 0.0992977 Vali Loss: 3.9349945 Test Loss: 69.5770874
Validation loss decreased (3.935138 --> 3.934994).  Saving model ...
Updating learning rate to 6.25e-06
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.00019336246365418965:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.04168015672689637:   0%|          | 0/19 [00:00<?, ?it/s]   loss:0.253663469916589:   0%|          | 0/19 [00:00<?, ?it/s]  loss:0.6489588058877153:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9067678001933256:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9067678001933256: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 178.53it/s]
Epoch: 6 cost time: 0.5753281116485596
Epoch: 6, Steps: 19 | Train Loss: 0.0974349 Vali Loss: 3.9349196 Test Loss: 69.5784836
Validation loss decreased (3.934994 --> 3.934920).  Saving model ...
Updating learning rate to 3.125e-06
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.00022801308968368667:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.04229408986432788:   0%|          | 0/19 [00:00<?, ?it/s]   loss:0.27369792652572206:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7219880713321197:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.9200989107367886:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9200989107367886: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 224.90it/s]
Epoch: 7 cost time: 0.6205055713653564
Epoch: 7, Steps: 19 | Train Loss: 0.1030688 Vali Loss: 3.9348755 Test Loss: 69.5790176
Validation loss decreased (3.934920 --> 3.934875).  Saving model ...
Updating learning rate to 1.5625e-06
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.00021351997341578546:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.04229211632645571:   0%|          | 0/19 [00:00<?, ?it/s]   loss:0.25363427614122325:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6745579912690793:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.8723177362313225:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8723177362313225: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 246.97it/s]
Epoch: 8 cost time: 0.5562500953674316
Epoch: 8, Steps: 19 | Train Loss: 0.0970008 Vali Loss: 3.9348552 Test Loss: 69.5793152
Validation loss decreased (3.934875 --> 3.934855).  Saving model ...
Updating learning rate to 7.8125e-07
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.000175684467276653:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0406904712802634:   0%|          | 0/19 [00:00<?, ?it/s]  loss:0.28408458339312187:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6488504918230861:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.95250121584216:   0%|          | 0/19 [00:00<?, ?it/s]  loss:0.95250121584216: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 253.40it/s]
Epoch: 9 cost time: 0.5457150936126709
Epoch: 9, Steps: 19 | Train Loss: 0.1013843 Vali Loss: 3.9348502 Test Loss: 69.5795059
Validation loss decreased (3.934855 --> 3.934850).  Saving model ...
Updating learning rate to 3.90625e-07
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.00022800265860971748:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.03794740815783603:   0%|          | 0/19 [00:00<?, ?it/s]   loss:0.25165021159847245:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6632157785470596:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.9066070389195473:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9066070389195473: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 249.47it/s]
Epoch: 10 cost time: 0.5809175968170166
Epoch: 10, Steps: 19 | Train Loss: 0.0978762 Vali Loss: 3.9348457 Test Loss: 69.5795593
Validation loss decreased (3.934850 --> 3.934846).  Saving model ...
Updating learning rate to 1.953125e-07
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.00020569933308607462:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.04063623089828486:   0%|          | 0/19 [00:00<?, ?it/s]   loss:0.25722303329877244:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6942053549070243:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.8134921467967561:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8134921467967561: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 243.98it/s]
Epoch: 11 cost time: 0.5469045639038086
Epoch: 11, Steps: 19 | Train Loss: 0.0950401 Vali Loss: 3.9348428 Test Loss: 69.5795898
Validation loss decreased (3.934846 --> 3.934843).  Saving model ...
Updating learning rate to 9.765625e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0001919761185462618:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.04068985546309886:   0%|          | 0/19 [00:00<?, ?it/s]  loss:0.28408092754676656:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6745344219432151:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.8933718442394921:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8933718442394921: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 245.06it/s]
Epoch: 12 cost time: 0.5481271743774414
Epoch: 12, Steps: 19 | Train Loss: 0.0996247 Vali Loss: 3.9348412 Test Loss: 69.5796051
Validation loss decreased (3.934843 --> 3.934841).  Saving model ...
Updating learning rate to 4.8828125e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.00020236222543292584:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.05059990766230355:   0%|          | 0/19 [00:00<?, ?it/s]   loss:0.2566957846129537:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.6816200874918668:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.0000009436937223:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.0000009436937223: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 225.79it/s]
Epoch: 13 cost time: 0.5642776489257812
Epoch: 13, Steps: 19 | Train Loss: 0.1046905 Vali Loss: 3.9348409 Test Loss: 69.5796127
Validation loss decreased (3.934841 --> 3.934841).  Saving model ...
Updating learning rate to 2.44140625e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.00019869402543268706:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.040636073287715624:   0%|          | 0/19 [00:00<?, ?it/s]  loss:0.2554238381316937:   0%|          | 0/19 [00:00<?, ?it/s]  loss:0.7219436039862235:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9370378554499799:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9370378554499799: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 241.68it/s]
Epoch: 14 cost time: 0.5372965335845947
Epoch: 14, Steps: 19 | Train Loss: 0.1029074 Vali Loss: 3.9348404 Test Loss: 69.5796127
Validation loss decreased (3.934841 --> 3.934840).  Saving model ...
Updating learning rate to 1.220703125e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0001906241236507799:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0417586812045503:   0%|          | 0/19 [00:00<?, ?it/s]   loss:0.2736820155293035:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6462331330244365:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8933702568893801:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8933702568893801: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 246.54it/s]
Epoch: 15 cost time: 0.5425400733947754
Epoch: 15, Steps: 19 | Train Loss: 0.0976439 Vali Loss: 3.9348404 Test Loss: 69.5796127
Validation loss decreased (3.934840 --> 3.934840).  Saving model ...
Updating learning rate to 6.103515625e-09
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.00019293169679946253:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.03794698573441959:   0%|          | 0/19 [00:00<?, ?it/s]   loss:0.25722186588776697:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.671651157814282:   0%|          | 0/19 [00:00<?, ?it/s]  loss:1.0762627088151953:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.0762627088151953: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 230.72it/s]
Epoch: 16 cost time: 0.5353775024414062
Epoch: 16, Steps: 19 | Train Loss: 0.1075408 Vali Loss: 3.9348404 Test Loss: 69.5796127
Validation loss decreased (3.934840 --> 3.934840).  Saving model ...
Updating learning rate to 3.0517578125e-09
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.00018812995701580044:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.04167324641697824:   0%|          | 0/19 [00:00<?, ?it/s]   loss:0.2840805601869675:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.6632090252552996:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.910487237754402:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.910487237754402: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 216.17it/s]
Epoch: 17 cost time: 0.5953400135040283
Epoch: 17, Steps: 19 | Train Loss: 0.0999810 Vali Loss: 3.9348404 Test Loss: 69.5796127
Validation loss decreased (3.934840 --> 3.934840).  Saving model ...
Updating learning rate to 1.52587890625e-09
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.00019662827725234653:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.04085368133758796:   0%|          | 0/19 [00:00<?, ?it/s]   loss:0.303355791186262:   0%|          | 0/19 [00:00<?, ?it/s]  loss:0.8036241622612774:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8933702201556845:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8933702201556845: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 206.53it/s]
Epoch: 18 cost time: 0.5611586570739746
Epoch: 18, Steps: 19 | Train Loss: 0.1074421 Vali Loss: 3.9348404 Test Loss: 69.5796127
Validation loss decreased (3.934840 --> 3.934840).  Saving model ...
Updating learning rate to 7.62939453125e-10
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.00020236211481554033:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.041758679336463135:   0%|          | 0/19 [00:00<?, ?it/s]  loss:0.26161392289211427:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.6453798177032518:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.9744816629029356:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9744816629029356: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 225.65it/s]
Epoch: 19 cost time: 0.5563418865203857
Epoch: 19, Steps: 19 | Train Loss: 0.1012335 Vali Loss: 3.9348404 Test Loss: 69.5796127
Validation loss decreased (3.934840 --> 3.934840).  Saving model ...
Updating learning rate to 3.814697265625e-10
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.00019062411609728787:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0406360707255217:   0%|          | 0/19 [00:00<?, ?it/s]    loss:0.25542380793112734:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7408490454484211:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.9524874354703216:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9524874354703216: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 253.57it/s]
Epoch: 20 cost time: 0.5595202445983887
Epoch: 20, Steps: 19 | Train Loss: 0.1047151 Vali Loss: 3.9348404 Test Loss: 69.5796127
Validation loss decreased (3.934840 --> 3.934840).  Saving model ...
Updating learning rate to 1.9073486328125e-10
>>>>>>>testing : long_term_forecast_break_parzen_0_DLinear_job_demand_r1_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 4
test shape: (4, 1, 3, 32690) (4, 1, 3, 32690)
test shape: (4, 3, 32690) (4, 3, 32690)
mse:62103.5078125, mae:19.31105613708496, dtw:-999
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           0                   Model:              DLinear             

[1mData Loader[0m
  Data:               job_demand_r1       Root Path:          ../../dataset/demand/
  Data Path:          r1.parquet          Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        .cache/checkpoints  

[1mForecasting Task[0m
  Seq Len:            6                   Label Len:          1                   
  Pred Len:           3                   Seasonal Patterns:  Monthly             
  Inverse:            1                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             32690               Dec In:             32690               
  C Out:              32690               d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           2                   d FF:               2048                
  Moving Avg:         25                  Factor:             1                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              learned             Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        32                  Itr:                1                   
  Train Epochs:       20                  Batch Size:         1                   
  Patience:           3                   Learning Rate:      0.0001              
  Des:                test                Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1                 

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_break_tukey-hanning_0_DLinear_job_demand_r1_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 19
val 1
test 4
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.04it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.04it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.04it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.04it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.04it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.04it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.04it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.04it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.04it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.04it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.04it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.04it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.04it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.04it/s]loss:0.005108957985756642:   5%|â–Œ         | 1/19 [00:00<00:08,  2.04it/s]loss:0.18688187787535182:   5%|â–Œ         | 1/19 [00:00<00:08,  2.04it/s] loss:0.4732884495681293:   5%|â–Œ         | 1/19 [00:00<00:08,  2.04it/s] loss:0.9362929294201847:   5%|â–Œ         | 1/19 [00:00<00:08,  2.04it/s]loss:1.003941121747561:   5%|â–Œ         | 1/19 [00:00<00:08,  2.04it/s] loss:1.003941121747561: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 31.50it/s]
Epoch: 1 cost time: 1.1565933227539062
Epoch: 1, Steps: 19 | Train Loss: 0.1371323 Vali Loss: 3.9375389 Test Loss: 69.5431366
Validation loss decreased (inf --> 3.937539).  Saving model ...
Updating learning rate to 0.0001
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0060212894551593095:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.1685378673619637:   0%|          | 0/19 [00:00<?, ?it/s]   loss:0.5321897216018052:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7664049613988507:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.0575699728343348:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.0575699728343348: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 245.04it/s]
Epoch: 2 cost time: 0.5998859405517578
Epoch: 2, Steps: 19 | Train Loss: 0.1331960 Vali Loss: 3.9357774 Test Loss: 69.5534668
Validation loss decreased (3.937539 --> 3.935777).  Saving model ...
Updating learning rate to 5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0050046576251201085:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.17155942899913446:   0%|          | 0/19 [00:00<?, ?it/s]  loss:0.5677371119400461:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.8671282333928351:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9751782558617443:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9751782558617443: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 241.58it/s]
Epoch: 3 cost time: 0.5631463527679443
Epoch: 3, Steps: 19 | Train Loss: 0.1361372 Vali Loss: 3.9350941 Test Loss: 69.5687256
Validation loss decreased (3.935777 --> 3.935094).  Saving model ...
Updating learning rate to 2.5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.006059383641692237:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.16822860385554925:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.47444609181853575:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7973365045016368:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.8713455895192215:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8713455895192215: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 237.92it/s]
Epoch: 4 cost time: 0.5836212635040283
Epoch: 4, Steps: 19 | Train Loss: 0.1219693 Vali Loss: 3.9347796 Test Loss: 69.5769806
Validation loss decreased (3.935094 --> 3.934780).  Saving model ...
Updating learning rate to 1.25e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0048712656808321516:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.17318725573981392:   0%|          | 0/19 [00:00<?, ?it/s]  loss:0.4705789877725303:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.7048619432640001:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9885429637170914:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9885429637170914: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 240.68it/s]
Epoch: 5 cost time: 0.6552221775054932
Epoch: 5, Steps: 19 | Train Loss: 0.1232654 Vali Loss: 3.9346168 Test Loss: 69.5772400
Validation loss decreased (3.934780 --> 3.934617).  Saving model ...
Updating learning rate to 6.25e-06
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.004997820536741904:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.16813289428591183:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.4742077279125979:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.7586572815598454:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9062321678422918:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9062321678422918: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 198.32it/s]
Epoch: 6 cost time: 0.594257116317749
Epoch: 6, Steps: 19 | Train Loss: 0.1216962 Vali Loss: 3.9345345 Test Loss: 69.5785980
Validation loss decreased (3.934617 --> 3.934535).  Saving model ...
Updating learning rate to 3.125e-06
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.005894530348099781:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.1705855075125179:   0%|          | 0/19 [00:00<?, ?it/s]  loss:0.5116707356507788:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8441464691304774:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9197624629892046:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9197624629892046: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 239.37it/s]
Epoch: 7 cost time: 0.530911922454834
Epoch: 7, Steps: 19 | Train Loss: 0.1290558 Vali Loss: 3.9344866 Test Loss: 69.5790787
Validation loss decreased (3.934535 --> 3.934487).  Saving model ...
Updating learning rate to 1.5625e-06
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.005519438038011984:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.17057624229577129:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.4741461255922867:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.7886607523962501:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8720185141446529:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8720185141446529: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 229.87it/s]
Epoch: 8 cost time: 0.5712730884552002
Epoch: 8, Steps: 19 | Train Loss: 0.1216274 Vali Loss: 3.9344633 Test Loss: 69.5793915
Validation loss decreased (3.934487 --> 3.934463).  Saving model ...
Updating learning rate to 7.8125e-07
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.004540960610660963:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.16415890704520905:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.5310882290286042:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.7585190452897432:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9521359761766981:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9521359761766981: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 226.65it/s]
Epoch: 9 cost time: 0.5759680271148682
Epoch: 9, Steps: 19 | Train Loss: 0.1268654 Vali Loss: 3.9344575 Test Loss: 69.5795746
Validation loss decreased (3.934463 --> 3.934458).  Saving model ...
Updating learning rate to 3.90625e-07
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.005894235302909926:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.1530727475359358:   0%|          | 0/19 [00:00<?, ?it/s]  loss:0.4703802859091198:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7753320656648134:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9060557497248398:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9060557497248398: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 216.97it/s]
Epoch: 10 cost time: 0.5794754028320312
Epoch: 10, Steps: 19 | Train Loss: 0.1216176 Vali Loss: 3.9344525 Test Loss: 69.5796432
Validation loss decreased (3.934458 --> 3.934453).  Saving model ...
Updating learning rate to 1.953125e-07
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.005317223637511349:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.16393578563735536:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.4808093532491671:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.8116509578145199:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8131071339938701:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8131071339938701: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 234.24it/s]
Epoch: 11 cost time: 0.5873153209686279
Epoch: 11, Steps: 19 | Train Loss: 0.1197274 Vali Loss: 3.9344490 Test Loss: 69.5796661
Validation loss decreased (3.934453 --> 3.934449).  Saving model ...
Updating learning rate to 9.765625e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.004962477971811473:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.16415606223488052:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.5310806006488294:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.7886303594719017:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8929446359797248:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8929446359797248: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 229.90it/s]
Epoch: 12 cost time: 0.5692059993743896
Epoch: 12, Steps: 19 | Train Loss: 0.1253565 Vali Loss: 3.9344480 Test Loss: 69.5796890
Validation loss decreased (3.934449 --> 3.934448).  Saving model ...
Updating learning rate to 4.8828125e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.005230914163032814:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.204073203519687:   0%|          | 0/19 [00:00<?, ?it/s]   loss:0.479836660380383:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7969538611845063:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9996057441666201:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9996057441666201: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 219.27it/s]
Epoch: 13 cost time: 0.5823626518249512
Epoch: 13, Steps: 19 | Train Loss: 0.1308263 Vali Loss: 3.9344471 Test Loss: 69.5796967
Validation loss decreased (3.934448 --> 3.934447).  Saving model ...
Updating learning rate to 2.44140625e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0051362066115128325:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.16393507216351472:   0%|          | 0/19 [00:00<?, ?it/s]  loss:0.477503094735854:   0%|          | 0/19 [00:00<?, ?it/s]  loss:0.8440887124517301:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9366693071433043:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9366693071433043: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 248.64it/s]
Epoch: 14 cost time: 0.575791597366333
Epoch: 14, Steps: 19 | Train Loss: 0.1277543 Vali Loss: 3.9344468 Test Loss: 69.5796967
Validation loss decreased (3.934447 --> 3.934447).  Saving model ...
Updating learning rate to 1.220703125e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.004927386851267189:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.16844108384741283:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.5116365773533186:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.7555983950551548:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8929428710004605:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8929428710004605: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 194.60it/s]
Epoch: 15 cost time: 0.5878801345825195
Epoch: 15, Steps: 19 | Train Loss: 0.1228182 Vali Loss: 3.9344468 Test Loss: 69.5796967
Validation loss decreased (3.934447 --> 3.934447).  Saving model ...
Updating learning rate to 6.103515625e-09
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.004986716849657748:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.15307081028942093:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.4808068784819176:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.7851112604391896:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.0758699475902578:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.0758699475902578: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 214.88it/s]
Epoch: 16 cost time: 0.5887775421142578
Epoch: 16, Steps: 19 | Train Loss: 0.1315708 Vali Loss: 3.9344468 Test Loss: 69.5796967
Validation loss decreased (3.934447 --> 3.934447).  Saving model ...
Updating learning rate to 3.0517578125e-09
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.00486313277329598:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.16810104142230145:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5310797841127671:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.7753232733315191:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9101041683206408:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9101041683206408: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 247.70it/s]
Epoch: 17 cost time: 0.609208345413208
Epoch: 17, Steps: 19 | Train Loss: 0.1257617 Vali Loss: 3.9344468 Test Loss: 69.5796967
Validation loss decreased (3.934447 --> 3.934447).  Saving model ...
Updating learning rate to 1.52587890625e-09
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 136.29it/s]loss:0.0050825558047393835:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 136.29it/s]loss:0.16478620078626943:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 136.29it/s]  loss:0.567156573478868:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 136.29it/s]  loss:0.9393345268851042:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 136.29it/s]loss:0.8929428262784816:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 136.29it/s]loss:0.8929428262784816: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 121.31it/s]
Epoch: 18 cost time: 0.631197452545166
Epoch: 18, Steps: 19 | Train Loss: 0.1352265 Vali Loss: 3.9344468 Test Loss: 69.5796967
Validation loss decreased (3.934447 --> 3.934447).  Saving model ...
Updating learning rate to 7.62939453125e-10
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.005230910559868984:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.1684410741409681:   0%|          | 0/19 [00:00<?, ?it/s]  loss:0.4890581686877883:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7545823449075828:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9741065042196667:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9741065042196667: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 232.21it/s]
Epoch: 19 cost time: 0.5770106315612793
Epoch: 19, Steps: 19 | Train Loss: 0.1258642 Vali Loss: 3.9344468 Test Loss: 69.5796967
Validation loss decreased (3.934447 --> 3.934447).  Saving model ...
Updating learning rate to 3.814697265625e-10
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.00492738659580922:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.16393505169298977:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.4775029980961407:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.8661837795710776:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9521210207894559:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9521210207894559: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 217.95it/s]
Epoch: 20 cost time: 0.6048543453216553
Epoch: 20, Steps: 19 | Train Loss: 0.1297195 Vali Loss: 3.9344468 Test Loss: 69.5796967
Validation loss decreased (3.934447 --> 3.934447).  Saving model ...
Updating learning rate to 1.9073486328125e-10
>>>>>>>testing : long_term_forecast_break_tukey-hanning_0_DLinear_job_demand_r1_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 4
test shape: (4, 1, 3, 32690) (4, 1, 3, 32690)
test shape: (4, 3, 32690) (4, 3, 32690)
mse:62136.1953125, mae:19.31125831604004, dtw:-999
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           0                   Model:              DLinear             

[1mData Loader[0m
  Data:               job_demand_r1       Root Path:          ../../dataset/demand/
  Data Path:          r1.parquet          Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        .cache/checkpoints  

[1mForecasting Task[0m
  Seq Len:            6                   Label Len:          1                   
  Pred Len:           3                   Seasonal Patterns:  Monthly             
  Inverse:            1                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             32690               Dec In:             32690               
  C Out:              32690               d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           2                   d FF:               2048                
  Moving Avg:         25                  Factor:             1                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              learned             Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        32                  Itr:                1                   
  Train Epochs:       20                  Batch Size:         1                   
  Patience:           3                   Learning Rate:      0.0001              
  Des:                test                Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1                 

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_break_rayleigh_0_DLinear_job_demand_r1_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 19
val 1
test 4
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.388859306347417:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.388859306347417:   5%|â–Œ         | 1/19 [00:00<00:07,  2.43it/s]loss:0.45676644662501864:   5%|â–Œ         | 1/19 [00:00<00:07,  2.43it/s]loss:0.5586709822969722:   5%|â–Œ         | 1/19 [00:00<00:07,  2.43it/s] loss:0.5444615155879058:   5%|â–Œ         | 1/19 [00:00<00:07,  2.43it/s]loss:0.535889814837452:   5%|â–Œ         | 1/19 [00:00<00:07,  2.43it/s] loss:0.5846901352759579:   5%|â–Œ         | 1/19 [00:00<00:07,  2.43it/s]loss:0.7606603248149216:   5%|â–Œ         | 1/19 [00:00<00:07,  2.43it/s]loss:0.6725554017633397:   5%|â–Œ         | 1/19 [00:00<00:07,  2.43it/s]loss:0.6351165161823403:   5%|â–Œ         | 1/19 [00:00<00:07,  2.43it/s]loss:0.7979896237640188:   5%|â–Œ         | 1/19 [00:00<00:07,  2.43it/s]loss:0.7627409345101674:   5%|â–Œ         | 1/19 [00:00<00:07,  2.43it/s]loss:0.8154341650152509:   5%|â–Œ         | 1/19 [00:00<00:07,  2.43it/s]loss:0.8197015027560339:   5%|â–Œ         | 1/19 [00:00<00:07,  2.43it/s]loss:0.8300549774829341:   5%|â–Œ         | 1/19 [00:00<00:07,  2.43it/s]loss:0.8756851652977654:   5%|â–Œ         | 1/19 [00:00<00:07,  2.43it/s]loss:0.9677830343848914:   5%|â–Œ         | 1/19 [00:00<00:07,  2.43it/s]loss:0.8676914655025879:   5%|â–Œ         | 1/19 [00:00<00:07,  2.43it/s]loss:1.074453032882356:   5%|â–Œ         | 1/19 [00:00<00:07,  2.43it/s] loss:1.0005517512173108:   5%|â–Œ         | 1/19 [00:00<00:07,  2.43it/s]loss:1.0005517512173108: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 37.53it/s]
Epoch: 1 cost time: 1.0373363494873047
Epoch: 1, Steps: 19 | Train Loss: 0.7341977 Vali Loss: 3.9351485 Test Loss: 69.5815430
Validation loss decreased (inf --> 3.935148).  Saving model ...
Updating learning rate to 0.0001
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.4168809827952845:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.43437971536908854:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.4594005491340915:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.5422188249209972:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5570162007736427:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5930634779910721:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6411426932561911:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6557086925901016:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6315491719494766:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7944307827657042:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7437284315212889:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7681751701719521:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9117905968987791:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.0145045985420178:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.0312979211567537:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8696743516269678:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9758144463713363:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8763876903445889:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.0525665917838831:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.0525665917838831: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 212.51it/s]
Epoch: 2 cost time: 0.5398862361907959
Epoch: 2, Steps: 19 | Train Loss: 0.7352490 Vali Loss: 3.9319625 Test Loss: 69.6227036
Validation loss decreased (3.935148 --> 3.931962).  Saving model ...
Updating learning rate to 5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.38709943289015303:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.42146272615249963:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.4920047859761027:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.6135042478373988:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5417266227175426:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.529392166143431:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.6277579585036974:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7003163580705095:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6832400492558257:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7247769786082404:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7377944926593722:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8099525885686856:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9785935121458594:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9241119312963236:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8534125476176236:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8839414290535401:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.0404592733111002:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9916369399969536:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9685447293464102:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9685447293464102: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 230.32it/s]
Epoch: 3 cost time: 0.5248548984527588
Epoch: 3, Steps: 19 | Train Loss: 0.7320910 Vali Loss: 3.9304237 Test Loss: 69.6411438
Validation loss decreased (3.931962 --> 3.930424).  Saving model ...
Updating learning rate to 2.5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.4673625318094506:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.4825382403318636:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5105764266287864:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5056174878148868:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.49374179275098423:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5920407857004972:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.6050481527919477:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7903673265213725:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7653328703522748:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7327991583315798:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8061591663509904:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7661398215313862:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8061926648220636:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8744463531412459:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.0303654949321452:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8658245030690837:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.866607042397259:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.911714237600759:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8642129967090457:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8642129967090457: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 266.64it/s]
Epoch: 4 cost time: 0.5890674591064453
Epoch: 4, Steps: 19 | Train Loss: 0.7230046 Vali Loss: 3.9296796 Test Loss: 69.6538620
Validation loss decreased (3.930424 --> 3.929680).  Saving model ...
Updating learning rate to 1.25e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.44167502308204726:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.42490041603149653:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.467349053899113:   0%|          | 0/19 [00:00<?, ?it/s]  loss:0.5387329381651667:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5401055075019958:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.687875127282983:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.6747961743777505:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6623376534375021:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6892794490463805:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7055762345035094:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9106108280478675:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.823031533453903:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.9791554681734762:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8475270462001232:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8313792154341856:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8932496563715059:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8572225559434267:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8026390989457268:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9817225810769531:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9817225810769531: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 220.13it/s]
Epoch: 5 cost time: 0.5595746040344238
Epoch: 5, Steps: 19 | Train Loss: 0.7241666 Vali Loss: 3.9293034 Test Loss: 69.6574554
Validation loss decreased (3.929680 --> 3.929303).  Saving model ...
Updating learning rate to 6.25e-06
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.4367152323966726:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.45158456826068855:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5532374044483841:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.5532374044483841:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:00, 23.82it/s]loss:0.6102038588910058:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:00, 23.82it/s]loss:0.552559482085985:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:00, 23.82it/s] loss:0.567007201803297:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:00, 23.82it/s]loss:0.637265361155039:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:00, 23.82it/s]loss:0.5944885785581256:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:00, 23.82it/s]loss:0.7359847970774295:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:00, 23.82it/s]loss:0.7359847970774295:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 42.60it/s]loss:0.719603785512526:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 42.60it/s] loss:0.8455150948179546:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 42.60it/s]loss:0.8552672660079725:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 42.60it/s]loss:0.7892538147343083:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 42.60it/s]loss:1.003463408149234:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 42.60it/s] loss:0.8508570031158611:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 42.60it/s]loss:0.8648574161136983:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 42.60it/s]loss:0.8657449448558328:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 42.60it/s]loss:0.863286027777156:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 42.60it/s] loss:0.863286027777156:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:00<00:00, 62.81it/s]loss:0.8955512266428083:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:00<00:00, 62.81it/s]loss:0.8955512266428083: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 50.87it/s]
Epoch: 6 cost time: 0.8460268974304199
Epoch: 6, Steps: 19 | Train Loss: 0.7206551 Vali Loss: 3.9291234 Test Loss: 69.6602402
Validation loss decreased (3.929303 --> 3.929123).  Saving model ...
Updating learning rate to 3.125e-06
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.4136576130320016:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.4816979825471669:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.4560810022736231:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.49199330453862045:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5301520602672732:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.5271272513177141:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.614622956272551:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.6535604402867742:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7022362570300975:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8015108877692229:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9121903149135235:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7735238298007111:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8092000217483575:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.0033033437767056:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.0078100835280226:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8754758520064716:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9353919215443495:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9640956744179713:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9131693089367504:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9131693089367504: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 231.33it/s]
Epoch: 7 cost time: 0.6080114841461182
Epoch: 7, Steps: 19 | Train Loss: 0.7298316 Vali Loss: 3.9290354 Test Loss: 69.6613846
Validation loss decreased (3.929123 --> 3.929035).  Saving model ...
Updating learning rate to 1.5625e-06
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.4202895802149135:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.518534338043086:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.4552498535639274:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5018995993046431:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6557111633997996:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5795872169603249:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6176695715849382:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6393704613302044:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8168719390889219:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.789297413080436:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.7922570033748301:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8078536836584561:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7349238863849704:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9318325876713088:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9428339920173434:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8753730864869135:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8655239063957123:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8993008297735086:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8648043520022637:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8648043520022637: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 232.99it/s]
Epoch: 8 cost time: 0.5564193725585938
Epoch: 8, Steps: 19 | Train Loss: 0.7215360 Vali Loss: 3.9289856 Test Loss: 69.6620483
Validation loss decreased (3.929035 --> 3.928986).  Saving model ...
Updating learning rate to 7.8125e-07
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.4062038473259054:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.4191768062991676:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.4662670943264886:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.49810825830901645:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6076658976397654:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.580207146858078:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.6246018559734605:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7891345627622459:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7526449822232958:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7193346911750423:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7682313428680007:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9279107665338351:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9780949931423347:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8733500220706343:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7725577411691162:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8455402731999824:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9715080246936415:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8629759369487527:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9446882419534133:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9446882419534133: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 253.66it/s]
Epoch: 9 cost time: 0.5464630126953125
Epoch: 9, Steps: 19 | Train Loss: 0.7267475 Vali Loss: 3.9289634 Test Loss: 69.6624146
Validation loss decreased (3.928986 --> 3.928963).  Saving model ...
Updating learning rate to 3.90625e-07
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.39182154643835154:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.4377165931557809:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.5642985889496762:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.49273190352752677:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.592037630125001:   0%|          | 0/19 [00:00<?, ?it/s]  loss:0.5729416389630052:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6590824494480775:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.789114946303457:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.7642066477289341:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7221395832435733:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7356519884333307:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8224748828885109:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9064996680009836:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8577537187884697:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.00768765610679:   0%|          | 0/19 [00:00<?, ?it/s]  loss:0.7861745988955424:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8565072755394397:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.883009612219577:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.883009612219577:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:00<00:00, 143.07it/s]loss:0.8952122886190595:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:00<00:00, 143.07it/s]loss:0.8952122886190595: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 107.47it/s]
Epoch: 10 cost time: 0.6582045555114746
Epoch: 10, Steps: 19 | Train Loss: 0.7230033 Vali Loss: 3.9289525 Test Loss: 69.6625824
Validation loss decreased (3.928963 --> 3.928952).  Saving model ...
Updating learning rate to 1.953125e-07
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.4412381285357554:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5196004870789376:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.4814543629679007:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5018432299185639:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5416969533923219:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5908441454273101:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6845950457476557:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.661529842966897:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.81681046922985:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.7892268842512123:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.737195402656063:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.944728923736969:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7903277668206052:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8211991566756774:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9076264652481617:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8440772627598464:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8764020049008177:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9273255324310906:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8040524412740644:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8040524412740644: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 234.30it/s]
Epoch: 11 cost time: 0.5462729930877686
Epoch: 11, Steps: 19 | Train Loss: 0.7200934 Vali Loss: 3.9289465 Test Loss: 69.6626663
Validation loss decreased (3.928952 --> 3.928946).  Saving model ...
Updating learning rate to 9.765625e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.3982371302535507:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.41915545350634636:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.4239702349467449:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.609748746539126:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.6425229152473888:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5729288096477781:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6370217902981131:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6980769881255603:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7724560907875365:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7592280090808002:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7371891762381156:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7831468357680719:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9759316607228904:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9078206872110672:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8462183562779997:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8455114571591885:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9714789078094661:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8992324013921993:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.884210507503066:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.884210507503066: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 187.31it/s]
Epoch: 12 cost time: 0.595829963684082
Epoch: 12, Steps: 19 | Train Loss: 0.7254782 Vali Loss: 3.9289439 Test Loss: 69.6627045
Validation loss decreased (3.928946 --> 3.928944).  Saving model ...
Updating learning rate to 4.8828125e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.3918096379683308:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5184745834788455:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.46093546521114737:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5043737215495515:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.5787245587569307:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5908371327399959:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.603557251027532:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.6615204494274904:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.75260811589691:   0%|          | 0/19 [00:00<?, ?it/s]  loss:0.8565383853559873:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7356373066689803:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8681095706594161:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.790321282804332:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.7553316799182652:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8931895571413202:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.0463250206346248:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8754106673757357:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9107786111211348:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9918492286561446:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9918492286561446: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 203.34it/s]
Epoch: 13 cost time: 0.5689277648925781
Epoch: 13, Steps: 19 | Train Loss: 0.7255964 Vali Loss: 3.9289424 Test Loss: 69.6627274
Validation loss decreased (3.928944 --> 3.928942).  Saving model ...
Updating learning rate to 2.44140625e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.42023968417495744:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5195892056849659:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.5630616915330812:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5100653426254647:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.4925794871285249:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5795154907142063:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6919894158058754:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6459717511516038:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7020736507328564:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7065107219393434:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8937248028965863:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8681084689601025:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7903202564117988:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8315691729832734:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8772561110289461:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8440700841869876:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8719856548429881:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9639530069465921:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9296399697121712:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9296399697121712: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 234.50it/s]
Epoch: 14 cost time: 0.5555622577667236
Epoch: 14, Steps: 19 | Train Loss: 0.7211697 Vali Loss: 3.9289420 Test Loss: 69.6627350
Validation loss decreased (3.928942 --> 3.928942).  Saving model ...
Updating learning rate to 1.220703125e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.39823312062057004:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5195883433895772:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.4901920552763126:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5506185605962208:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5299789461318438:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5772483339034934:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7317194872330983:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6379341429037217:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7724518546574927:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7362260394842308:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6851613127065146:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8681078177472986:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9759271895789013:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8577377092635827:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8398761938882549:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8655051695065648:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9352592428400373:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8625880204026621:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8842066855503601:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8842066855503601: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 198.78it/s]
Epoch: 15 cost time: 0.5684502124786377
Epoch: 15, Steps: 19 | Train Loss: 0.7220295 Vali Loss: 3.9289410 Test Loss: 69.6627502
Validation loss decreased (3.928942 --> 3.928941).  Saving model ...
Updating learning rate to 6.103515625e-09
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.38484343670065435:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5195878910656754:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.48144797610744944:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5590929266902087:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.5297669114834876:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5908350088474813:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6144773267412398:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.732944036974094:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.7357009030777055:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8565364397469225:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7449032150331758:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8224574881401028:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7889750252308309:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9078160610331095:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.849536404072554:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.7861549510503555:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.876391717556373:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.8929554498124881:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.0678342067966617:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.0678342067966617: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 93.67it/s]
Epoch: 16 cost time: 0.7100338935852051
Epoch: 16, Steps: 19 | Train Loss: 0.7232767 Vali Loss: 3.9289410 Test Loss: 69.6627502
Validation loss decreased (3.928941 --> 3.928941).  Saving model ...
Updating learning rate to 3.0517578125e-09
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.39823277263036017:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.518472904758054:   0%|          | 0/19 [00:00<?, ?it/s]  loss:0.49811135220802993:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6097420294066904:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.6425193000389642:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6092914902306235:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6035546505251957:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7141134017366773:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.711089408085662:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.7139081364205346:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6851610454014012:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8774933189834752:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7903193729379457:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8273865762004051:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8294266414418882:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8645341341785934:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9714751431669008:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8829893592796195:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9014790492651723:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9014790492651723: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 150.28it/s]
Epoch: 17 cost time: 0.5800268650054932
Epoch: 17, Steps: 19 | Train Loss: 0.7183842 Vali Loss: 3.9289410 Test Loss: 69.6627502
Validation loss decreased (3.928941 --> 3.928941).  Saving model ...
Updating learning rate to 1.52587890625e-09
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.4298953336772917:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.41915243859545503:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5229936580409849:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.4581304251914224:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5484174058600133:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6998652133136316:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6144773257893792:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7251044268889903:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6734657462885913:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7456812035389545:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8049850035294942:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7831413081531803:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7989147876808265:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.873315410962747:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.8661315503052797:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8458453915728283:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.0383589896571535:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.0674585983876117:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8842066378501303:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8842066378501303: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 240.87it/s]
Epoch: 18 cost time: 0.5162441730499268
Epoch: 18, Steps: 19 | Train Loss: 0.7262916 Vali Loss: 3.9289410 Test Loss: 69.6627502
Validation loss decreased (3.928941 --> 3.928941).  Saving model ...
Updating learning rate to 7.62939453125e-10
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.4750346569594915:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.42763585625266265:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.4239662767454201:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.5100642434478603:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5416883239376521:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.598423182869961:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.6098751665472197:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7907927781412066:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6737348197787099:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8100284226240649:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8361564034743622:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8357450880168829:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9585261561246192:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8123547565592532:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8931877327296466:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8655049983788305:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8925091834308371:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.861120691208968:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.966365152584245:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.966365152584245: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 224.64it/s]
Epoch: 19 cost time: 0.569739580154419
Epoch: 19, Steps: 19 | Train Loss: 0.7254060 Vali Loss: 3.9289410 Test Loss: 69.6627502
Validation loss decreased (3.928941 --> 3.928941).  Saving model ...
Updating learning rate to 3.814697265625e-10
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.4365119191454709:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.451374235463999:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.47202723506507505:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5506182663609805:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.5422966355199468:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5795145602193708:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7466047726026066:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7890958239881386:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6737348197787099:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7362257543566353:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8937238641887992:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8077868040546822:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7348408286430027:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8123547565592532:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8398760246311922:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8440693590800266:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8719848329008588:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9893709495811646:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.94465865249342:   0%|          | 0/19 [00:00<?, ?it/s]  loss:0.94465865249342: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 219.75it/s]
Epoch: 20 cost time: 0.537287712097168
Epoch: 20, Steps: 19 | Train Loss: 0.7219300 Vali Loss: 3.9289410 Test Loss: 69.6627502
Validation loss decreased (3.928941 --> 3.928941).  Saving model ...
Updating learning rate to 1.9073486328125e-10
>>>>>>>testing : long_term_forecast_break_rayleigh_0_DLinear_job_demand_r1_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 4
test shape: (4, 1, 3, 32690) (4, 1, 3, 32690)
test shape: (4, 3, 32690) (4, 3, 32690)
mse:63126.5, mae:19.337631225585938, dtw:-999
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           0                   Model:              SegRNN              

[1mData Loader[0m
  Data:               job_demand_r1       Root Path:          ../../dataset/demand/
  Data Path:          r1.parquet          Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        .cache/checkpoints  

[1mForecasting Task[0m
  Seq Len:            6                   Label Len:          1                   
  Pred Len:           3                   Seasonal Patterns:  Monthly             
  Inverse:            1                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             32690               Dec In:             32690               
  C Out:              32690               d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           2                   d FF:               2048                
  Moving Avg:         25                  Factor:             1                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              learned             Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        32                  Itr:                1                   
  Train Epochs:       20                  Batch Size:         1                   
  Patience:           3                   Learning Rate:      0.0001              
  Des:                test                Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1                 

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_break_bartlett_0_SegRNN_job_demand_r1_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 19
val 1
test 4
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:09,  1.96it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:09,  1.96it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:09,  1.96it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:09,  1.96it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:09,  1.96it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.13it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.13it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.13it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.13it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.13it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 17.02it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 17.02it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 17.02it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 17.02it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 17.02it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 17.02it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 23.87it/s]loss:0.06545458692904349:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 23.87it/s]loss:0.4301518582688772:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 23.87it/s] loss:0.7734199564099455:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 23.87it/s]loss:1.0817273120353887:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 23.87it/s]loss:1.3567817606461183:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 23.87it/s]loss:1.3567817606461183: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 28.89it/s]loss:1.3567817606461183: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 18.81it/s]
Epoch: 1 cost time: 1.545121192932129
Epoch: 1, Steps: 19 | Train Loss: 0.1951334 Vali Loss: 4.2737179 Test Loss: 80.1817551
Validation loss decreased (inf --> 4.273718).  Saving model ...
Updating learning rate to 0.0001
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:00, 27.76it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:00, 27.76it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:00, 27.76it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:00, 27.76it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:00, 27.76it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 33.63it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 33.63it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 33.63it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 33.63it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 33.63it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 36.18it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 36.18it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 36.18it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 36.18it/s]loss:0.05524787893415768:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 36.18it/s]loss:0.05524787893415768:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 37.62it/s]loss:0.3714204154477357:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 37.62it/s] loss:0.6960743844128837:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 37.62it/s]loss:0.9323007771307833:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 37.62it/s]loss:1.281654237921313:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 37.62it/s] loss:1.281654237921313: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 38.24it/s]loss:1.281654237921313: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 33.54it/s]
Epoch: 2 cost time: 1.0416648387908936
Epoch: 2, Steps: 19 | Train Loss: 0.1756157 Vali Loss: 3.9779477 Test Loss: 79.7648239
Validation loss decreased (4.273718 --> 3.977948).  Saving model ...
Updating learning rate to 5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 36.35it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 36.35it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 36.35it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 36.35it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 36.35it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 37.65it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 37.65it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 37.65it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 37.65it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 37.65it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 37.65it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 38.86it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 38.86it/s]loss:0.044518552853410866:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 38.86it/s]loss:0.3233730279111957:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 38.86it/s]  loss:0.5310687799640883:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 38.86it/s]loss:0.7168907961633059:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 38.86it/s]loss:0.7168907961633059:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:00<00:00, 39.54it/s]loss:1.103787408487554:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:00<00:00, 39.54it/s] loss:1.103787408487554: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 35.63it/s]
Epoch: 3 cost time: 1.004638671875
Epoch: 3, Steps: 19 | Train Loss: 0.1431389 Vali Loss: 3.9284816 Test Loss: 79.6412201
Validation loss decreased (3.977948 --> 3.928482).  Saving model ...
Updating learning rate to 2.5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 38.98it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 38.98it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 38.98it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 38.98it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 38.98it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 38.97it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 38.97it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 38.97it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 38.97it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 38.97it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 38.97it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 39.57it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 39.57it/s]loss:0.04984519739430422:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 39.57it/s]loss:0.3080795771364313:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 39.57it/s] loss:0.6006022536429013:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 39.57it/s]loss:0.757233664333455:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 39.57it/s] loss:0.757233664333455:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:00<00:00, 40.17it/s]loss:1.0791289679738703:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:00<00:00, 40.17it/s]loss:1.0791289679738703: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 36.36it/s]
Epoch: 4 cost time: 0.9772601127624512
Epoch: 4, Steps: 19 | Train Loss: 0.1470995 Vali Loss: 3.8987184 Test Loss: 79.5702744
Validation loss decreased (3.928482 --> 3.898718).  Saving model ...
Updating learning rate to 1.25e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 33.92it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 33.92it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 33.92it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 33.92it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 33.92it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 36.65it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 36.65it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 36.65it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 36.65it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 36.65it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 37.64it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 37.64it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 37.64it/s]loss:0.045039145269998755:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 37.64it/s]loss:0.28897623370349107:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 37.64it/s] loss:0.4979569384214839:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 37.64it/s] loss:0.4979569384214839:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 38.73it/s]loss:0.7875196722256957:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 38.73it/s]loss:1.0758614201145111:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 38.73it/s]loss:1.0758614201145111: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 35.13it/s]
Epoch: 5 cost time: 1.0387475490570068
Epoch: 5, Steps: 19 | Train Loss: 0.1418607 Vali Loss: 3.8697729 Test Loss: 79.5317612
Validation loss decreased (3.898718 --> 3.869773).  Saving model ...
Updating learning rate to 6.25e-06
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 37.31it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 37.31it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 37.31it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 37.31it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 37.31it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 38.68it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 38.68it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 38.68it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 38.68it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 38.68it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 39.18it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 39.18it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 39.18it/s]loss:0.04122285169007048:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 39.18it/s]loss:0.2866557660133385:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 39.18it/s] loss:0.2866557660133385:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 39.39it/s]loss:0.4900663319841747:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 39.39it/s]loss:0.6730177761883158:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 39.39it/s]loss:1.0247041837182997:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 39.39it/s]loss:1.0247041837182997: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 35.02it/s]
Epoch: 6 cost time: 1.0871522426605225
Epoch: 6, Steps: 19 | Train Loss: 0.1324035 Vali Loss: 3.8615034 Test Loss: 79.5185547
Validation loss decreased (3.869773 --> 3.861503).  Saving model ...
Updating learning rate to 3.125e-06
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:00, 29.41it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:00, 29.41it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:00, 29.41it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:00, 29.41it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:00, 29.41it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 34.78it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 34.78it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 34.78it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 34.78it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 34.78it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 37.06it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 37.06it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 37.06it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 37.06it/s]loss:0.04768060647433461:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 37.06it/s]loss:0.26969304551575035:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 37.06it/s]loss:0.26969304551575035:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 38.52it/s]loss:0.4886590323942943:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 38.52it/s] loss:0.7073700012763868:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 38.52it/s]loss:0.879917311625206:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 38.52it/s] loss:0.879917311625206: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 34.45it/s]
Epoch: 7 cost time: 1.0657801628112793
Epoch: 7, Steps: 19 | Train Loss: 0.1259642 Vali Loss: 3.8594935 Test Loss: 79.5128555
Validation loss decreased (3.861503 --> 3.859493).  Saving model ...
Updating learning rate to 1.5625e-06
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 32.04it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 32.04it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 32.04it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 32.04it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 32.04it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 35.86it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 35.86it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 35.86it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 35.86it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 35.86it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 37.64it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 37.64it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 37.64it/s]loss:0.04432602000407684:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 37.64it/s]loss:0.29144786654398774:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 37.64it/s]loss:0.4842679876010118:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 37.64it/s] loss:0.4842679876010118:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 38.66it/s]loss:0.7639355911513873:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 38.66it/s]loss:1.000364680443388:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 38.66it/s] loss:1.000364680443388: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 34.37it/s]
Epoch: 8 cost time: 1.074126958847046
Epoch: 8, Steps: 19 | Train Loss: 0.1360180 Vali Loss: 3.8591154 Test Loss: 79.5105438
Validation loss decreased (3.859493 --> 3.859115).  Saving model ...
Updating learning rate to 7.8125e-07
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 37.09it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 37.09it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 37.09it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 37.09it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 37.09it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 38.10it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 38.10it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 38.10it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 38.10it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 38.10it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 38.10it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 39.38it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 39.38it/s]loss:0.0431244227735653:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 39.38it/s]loss:0.30842920915493555:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 39.38it/s]loss:0.4520818445891586:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 39.38it/s] loss:0.6513214313507525:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 39.38it/s]loss:0.6513214313507525:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:00<00:00, 40.04it/s]loss:0.9610875070747089:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:00<00:00, 40.04it/s]loss:0.9610875070747089: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 36.19it/s]
Epoch: 9 cost time: 1.050384759902954
Epoch: 9, Steps: 19 | Train Loss: 0.1271602 Vali Loss: 3.8580675 Test Loss: 79.5088959
Validation loss decreased (3.859115 --> 3.858068).  Saving model ...
Updating learning rate to 3.90625e-07
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 38.24it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 38.24it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 38.24it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 38.24it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 38.24it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 38.19it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 38.19it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 38.19it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 38.19it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 38.19it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 38.59it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 38.59it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 38.59it/s]loss:0.04984674383956184:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 38.59it/s]loss:0.2861145642624695:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 38.59it/s] loss:0.45143416962559535:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 38.59it/s]loss:0.45143416962559535:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 39.42it/s]loss:0.7080847879492705:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 39.42it/s] loss:0.8545075977377853:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 39.42it/s]loss:0.8545075977377853: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 36.05it/s]
Epoch: 10 cost time: 1.0468940734863281
Epoch: 10, Steps: 19 | Train Loss: 0.1236836 Vali Loss: 3.8580334 Test Loss: 79.5082550
Validation loss decreased (3.858068 --> 3.858033).  Saving model ...
Updating learning rate to 1.953125e-07
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 36.97it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 36.97it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 36.97it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 36.97it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 36.97it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 37.99it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 37.99it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 37.99it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 37.99it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 37.99it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 37.99it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 39.34it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 39.34it/s]loss:0.04726924916324401:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 39.34it/s]loss:0.26804792831499835:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 39.34it/s]loss:0.4870807222973227:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 39.34it/s] loss:0.6923431171367428:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 39.34it/s]loss:0.6923431171367428:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:00<00:00, 39.88it/s]loss:0.8530375980335112:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:00<00:00, 39.88it/s]loss:0.8530375980335112: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 35.77it/s]
Epoch: 11 cost time: 1.0701313018798828
Epoch: 11, Steps: 19 | Train Loss: 0.1235673 Vali Loss: 3.8581333 Test Loss: 79.5079727
EarlyStopping counter: 1 out of 3
Updating learning rate to 9.765625e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 32.93it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 32.93it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 32.93it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 32.93it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 32.93it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 36.12it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 36.12it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 36.12it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 36.12it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 36.12it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 37.63it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 37.63it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 37.63it/s]loss:0.049869221302274704:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 37.63it/s]loss:0.2844996664147466:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 37.63it/s]  loss:0.4835806843811731:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 37.63it/s]loss:0.4835806843811731:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 38.88it/s]loss:0.7143269699458364:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 38.88it/s]loss:0.8950589635902965:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 38.88it/s]loss:0.8950589635902965: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 34.85it/s]
Epoch: 12 cost time: 0.9934000968933105
Epoch: 12, Steps: 19 | Train Loss: 0.1277545 Vali Loss: 3.8582397 Test Loss: 79.5078583
EarlyStopping counter: 2 out of 3
Updating learning rate to 4.8828125e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 38.60it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 38.60it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 38.60it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 38.60it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 38.60it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 38.60it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 39.63it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 39.63it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 39.63it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 39.63it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 39.63it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 39.63it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 40.35it/s]loss:0.04240753664851247:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 40.35it/s]loss:0.2556798689655343:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 40.35it/s] loss:0.5026322411765376:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 40.35it/s]loss:0.7629821925031195:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 40.35it/s]loss:0.9231706777968999:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 40.35it/s]loss:0.9231706777968999: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 40.40it/s]loss:0.9231706777968999: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 36.71it/s]
Epoch: 13 cost time: 1.0171897411346436
Epoch: 13, Steps: 19 | Train Loss: 0.1308880 Vali Loss: 3.8582740 Test Loss: 79.5078049
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : long_term_forecast_break_bartlett_0_SegRNN_job_demand_r1_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 4
test shape: (4, 1, 3, 32690) (4, 1, 3, 32690)
test shape: (4, 3, 32690) (4, 3, 32690)
mse:42433.69921875, mae:18.15831756591797, dtw:-999
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           0                   Model:              SegRNN              

[1mData Loader[0m
  Data:               job_demand_r1       Root Path:          ../../dataset/demand/
  Data Path:          r1.parquet          Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        .cache/checkpoints  

[1mForecasting Task[0m
  Seq Len:            6                   Label Len:          1                   
  Pred Len:           3                   Seasonal Patterns:  Monthly             
  Inverse:            1                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             32690               Dec In:             32690               
  C Out:              32690               d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           2                   d FF:               2048                
  Moving Avg:         25                  Factor:             1                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              learned             Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        32                  Itr:                1                   
  Train Epochs:       20                  Batch Size:         1                   
  Patience:           3                   Learning Rate:      0.0001              
  Des:                test                Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1                 

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_break_parzen_0_SegRNN_job_demand_r1_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 19
val 1
test 4
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.15it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.15it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.15it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.15it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.15it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.92it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.92it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.92it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.92it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.92it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 18.09it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 18.09it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 18.09it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 18.09it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 18.09it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 23.72it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 23.72it/s]loss:0.0002968461992246849:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 23.72it/s]loss:0.07043057926393247:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 23.72it/s]  loss:0.4270097383651011:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 23.72it/s] loss:1.0531850762909392:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 23.72it/s]loss:1.0531850762909392:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:00<00:00, 29.08it/s]loss:1.3572585477293995:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:00<00:00, 29.08it/s]loss:1.3572585477293995: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 19.88it/s]
Epoch: 1 cost time: 1.4927968978881836
Epoch: 1, Steps: 19 | Train Loss: 0.1530621 Vali Loss: 4.3022408 Test Loss: 80.2105484
Validation loss decreased (inf --> 4.302241).  Saving model ...
Updating learning rate to 0.0001
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 38.24it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 38.24it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 38.24it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 38.24it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 38.24it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 38.55it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 38.55it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 38.55it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 38.55it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 38.55it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 38.79it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 38.79it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 38.79it/s]loss:0.00027373196440397534:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 38.79it/s]loss:0.06777840869928237:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 38.79it/s]   loss:0.4322724031139928:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 38.79it/s] loss:0.4322724031139928:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 39.35it/s]loss:0.9790422452024693:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 39.35it/s]loss:1.4573001361294273:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 39.35it/s]loss:1.4573001361294273: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 35.52it/s]
Epoch: 2 cost time: 1.0058972835540771
Epoch: 2, Steps: 19 | Train Loss: 0.1545614 Vali Loss: 4.0755820 Test Loss: 79.8780060
Validation loss decreased (4.302241 --> 4.075582).  Saving model ...
Updating learning rate to 5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 37.56it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 37.56it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 37.56it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 37.56it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 37.56it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 38.39it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 38.39it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 38.39it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 38.39it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 38.39it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 38.90it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 38.90it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 38.90it/s]loss:0.00021060914850735683:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 38.90it/s]loss:0.052409434724892935:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 38.90it/s]  loss:0.29913058819505217:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 38.90it/s] loss:0.29913058819505217:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 39.53it/s]loss:0.7485864963064668:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 39.53it/s] loss:1.130370508523525:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 39.53it/s] loss:1.130370508523525: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 35.91it/s]
Epoch: 3 cost time: 1.066725730895996
Epoch: 3, Steps: 19 | Train Loss: 0.1174057 Vali Loss: 3.9326444 Test Loss: 79.6916656
Validation loss decreased (4.075582 --> 3.932644).  Saving model ...
Updating learning rate to 2.5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 36.91it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 36.91it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 36.91it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 36.91it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 36.91it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 37.93it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 37.93it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 37.93it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 37.93it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 37.93it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 37.93it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 39.17it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 39.17it/s]loss:0.000230934511404838:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 39.17it/s]loss:0.05111139987178727:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 39.17it/s] loss:0.3297503013194329:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 39.17it/s] loss:0.3297503013194329:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 39.31it/s]loss:0.7668679594701111:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 39.31it/s]loss:1.1032884008882373:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 39.31it/s]loss:1.1032884008882373: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 35.27it/s]
Epoch: 4 cost time: 1.0601458549499512
Epoch: 4, Steps: 19 | Train Loss: 0.1184868 Vali Loss: 3.9158223 Test Loss: 79.6366043
Validation loss decreased (3.932644 --> 3.915822).  Saving model ...
Updating learning rate to 1.25e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 36.28it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 36.28it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 36.28it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 36.28it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 36.28it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 37.89it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 37.89it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 37.89it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 37.89it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 37.89it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 38.72it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 38.72it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 38.72it/s]loss:0.0002126108641244382:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 38.72it/s]loss:0.047899023356476673:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 38.72it/s] loss:0.047899023356476673:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 38.89it/s]loss:0.2857359834547607:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 38.89it/s]  loss:0.7904823922866953:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 38.89it/s]loss:1.109022614262385:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 38.89it/s] loss:1.109022614262385: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 35.51it/s]
Epoch: 5 cost time: 1.078387975692749
Epoch: 5, Steps: 19 | Train Loss: 0.1175449 Vali Loss: 3.8947496 Test Loss: 79.6034775
Validation loss decreased (3.915822 --> 3.894750).  Saving model ...
Updating learning rate to 6.25e-06
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 32.39it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 32.39it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 32.39it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 32.39it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 32.39it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 35.86it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 35.86it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 35.86it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 35.86it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 35.86it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 35.86it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 38.39it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 38.39it/s]loss:0.00019200789581065177:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 38.39it/s]loss:0.04873394926608878:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 38.39it/s]   loss:0.2787756504868963:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 38.39it/s] loss:0.6753695811107147:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 38.39it/s]loss:0.6753695811107147:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:00<00:00, 39.37it/s]loss:1.0582436926107712:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:00<00:00, 39.37it/s]loss:1.0582436926107712: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 35.40it/s]
Epoch: 6 cost time: 1.0672683715820312
Epoch: 6, Steps: 19 | Train Loss: 0.1084903 Vali Loss: 3.8862238 Test Loss: 79.5904541
Validation loss decreased (3.894750 --> 3.886224).  Saving model ...
Updating learning rate to 3.125e-06
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 38.80it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 38.80it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 38.80it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 38.80it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 38.80it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 38.16it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 38.16it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 38.16it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 38.16it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 38.16it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 38.56it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 38.56it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 38.56it/s]loss:0.00022437272224417232:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 38.56it/s]loss:0.04607470556806527:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 38.56it/s]   loss:0.2779534623313491:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 38.56it/s] loss:0.2779534623313491:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 39.15it/s]loss:0.7165518728255215:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 39.15it/s]loss:0.9079951219055316:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 39.15it/s]loss:0.9079951219055316: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 35.55it/s]
Epoch: 7 cost time: 1.0733120441436768
Epoch: 7, Steps: 19 | Train Loss: 0.1025684 Vali Loss: 3.8833899 Test Loss: 79.5842590
Validation loss decreased (3.886224 --> 3.883390).  Saving model ...
Updating learning rate to 1.5625e-06
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 36.72it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 36.72it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 36.72it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 36.72it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 36.72it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 37.03it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 37.03it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 37.03it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 37.03it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 37.03it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 38.29it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 38.29it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 38.29it/s]loss:0.00020844275039331265:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 38.29it/s]loss:0.04911925443368574:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 38.29it/s]   loss:0.27686994661055997:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 38.29it/s]loss:0.27686994661055997:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 38.96it/s]loss:0.7539520645322361:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 38.96it/s] loss:1.0376407669399406:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 38.96it/s]loss:1.0376407669399406: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 35.32it/s]
Epoch: 8 cost time: 1.0538568496704102
Epoch: 8, Steps: 19 | Train Loss: 0.1114627 Vali Loss: 3.8824108 Test Loss: 79.5815659
Validation loss decreased (3.883390 --> 3.882411).  Saving model ...
Updating learning rate to 7.8125e-07
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 38.24it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 38.24it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 38.24it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 38.24it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 38.24it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 38.25it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 38.25it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 38.25it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 38.25it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 38.25it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 38.84it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 38.84it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 38.84it/s]loss:0.00020254542600363348:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 38.84it/s]loss:0.05158932315752239:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 38.84it/s]   loss:0.2545763556501387:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 38.84it/s] loss:0.2545763556501387:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 39.82it/s]loss:0.6651907033914497:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 39.82it/s]loss:1.0032900093457695:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 39.82it/s]loss:1.0032900093457695: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 36.00it/s]
Epoch: 9 cost time: 1.0663037300109863
Epoch: 9, Steps: 19 | Train Loss: 0.1039394 Vali Loss: 3.8813558 Test Loss: 79.5798645
Validation loss decreased (3.882411 --> 3.881356).  Saving model ...
Updating learning rate to 3.90625e-07
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 36.90it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 36.90it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 36.90it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 36.90it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 36.90it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 38.13it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 38.13it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 38.13it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 38.13it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 38.13it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 38.81it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 38.81it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 38.81it/s]loss:0.0002330954174353512:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 38.81it/s]loss:0.04741311667028656:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 38.81it/s]  loss:0.04741311667028656:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 39.15it/s]loss:0.2542535858682125:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 39.15it/s] loss:0.7138848787776138:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 39.15it/s]loss:0.8972509147640314:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 39.15it/s]loss:0.8972509147640314: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 35.80it/s]
Epoch: 10 cost time: 1.0537621974945068
Epoch: 10, Steps: 19 | Train Loss: 0.1006861 Vali Loss: 3.8811817 Test Loss: 79.5790787
Validation loss decreased (3.881356 --> 3.881182).  Saving model ...
Updating learning rate to 1.953125e-07
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 38.87it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 38.87it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 38.87it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 38.87it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 38.87it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 38.20it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 38.20it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 38.20it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 38.20it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 38.20it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 38.50it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 38.50it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 38.50it/s]loss:0.00022188227320329724:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 38.50it/s]loss:0.04582604392175646:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 38.50it/s]   loss:0.2770100874556861:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 38.50it/s] loss:0.2770100874556861:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 39.18it/s]loss:0.6990571298067724:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 39.18it/s]loss:0.8956961826428244:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 39.18it/s]loss:0.8956961826428244: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 35.47it/s]
Epoch: 11 cost time: 1.1073448657989502
Epoch: 11, Steps: 19 | Train Loss: 0.1009374 Vali Loss: 3.8811643 Test Loss: 79.5787354
Validation loss decreased (3.881182 --> 3.881164).  Saving model ...
Updating learning rate to 9.765625e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 36.34it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 36.34it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 36.34it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 36.34it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 36.34it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 36.84it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 36.84it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 36.84it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 36.84it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 36.84it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 34.47it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 34.47it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 34.47it/s]loss:0.0002331788436232826:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 34.47it/s]loss:0.048367860155842234:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 34.47it/s] loss:0.048367860155842234:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 36.21it/s]loss:0.27640836944983854:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 36.21it/s] loss:0.7274007669539798:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 36.21it/s] loss:0.9321401595002801:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 36.21it/s]loss:0.9321401595002801: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 33.58it/s]
Epoch: 12 cost time: 1.1279053688049316
Epoch: 12, Steps: 19 | Train Loss: 0.1044500 Vali Loss: 3.8811882 Test Loss: 79.5785828
EarlyStopping counter: 1 out of 3
Updating learning rate to 4.8828125e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 34.83it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 34.83it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 34.83it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 34.83it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 34.83it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 36.87it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 36.87it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 36.87it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 36.87it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 36.87it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 38.17it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 38.17it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 38.17it/s]loss:0.0001995045135021032:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 38.17it/s]loss:0.04347423736182974:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 38.17it/s]  loss:0.2877106116299707:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 38.17it/s] loss:0.2877106116299707:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 38.93it/s]loss:0.7529393971850016:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 38.93it/s]loss:0.9620188745549:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 38.93it/s]   loss:0.9620188745549: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 34.88it/s]
Epoch: 13 cost time: 1.0816593170166016
Epoch: 13, Steps: 19 | Train Loss: 0.1077022 Vali Loss: 3.8811860 Test Loss: 79.5785141
EarlyStopping counter: 2 out of 3
Updating learning rate to 2.44140625e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 38.33it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 38.33it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 38.33it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 38.33it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 38.33it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 38.33it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 39.55it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 39.55it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 39.55it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 39.55it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 39.55it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 39.55it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 40.30it/s]loss:0.00020773021704190004:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 40.30it/s]loss:0.048011379730435795:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 40.30it/s]  loss:0.2541330289911069:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 40.30it/s]  loss:0.6934164132294963:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 40.30it/s]loss:0.9229550451692295:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 40.30it/s]loss:0.9229550451692295: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 40.55it/s]loss:0.9229550451692295: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 36.82it/s]
Epoch: 14 cost time: 1.021333932876587
Epoch: 14, Steps: 19 | Train Loss: 0.1009855 Vali Loss: 3.8811729 Test Loss: 79.5784760
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : long_term_forecast_break_parzen_0_SegRNN_job_demand_r1_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 4
test shape: (4, 1, 3, 32690) (4, 1, 3, 32690)
test shape: (4, 3, 32690) (4, 3, 32690)
mse:40474.39453125, mae:18.06130599975586, dtw:-999
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           0                   Model:              SegRNN              

[1mData Loader[0m
  Data:               job_demand_r1       Root Path:          ../../dataset/demand/
  Data Path:          r1.parquet          Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        .cache/checkpoints  

[1mForecasting Task[0m
  Seq Len:            6                   Label Len:          1                   
  Pred Len:           3                   Seasonal Patterns:  Monthly             
  Inverse:            1                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             32690               Dec In:             32690               
  C Out:              32690               d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           2                   d FF:               2048                
  Moving Avg:         25                  Factor:             1                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              learned             Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        32                  Itr:                1                   
  Train Epochs:       20                  Batch Size:         1                   
  Patience:           3                   Learning Rate:      0.0001              
  Des:                test                Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1                 

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_break_tukey-hanning_0_SegRNN_job_demand_r1_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 19
val 1
test 4
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.14it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.14it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.14it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.14it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.14it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.45it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.45it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.45it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.45it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.45it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 17.41it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 17.41it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 17.41it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 17.41it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 17.41it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 17.41it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 24.26it/s]loss:0.007676273385615589:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 24.26it/s]loss:0.2834762250208813:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 24.26it/s]  loss:0.7953761993480342:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 24.26it/s]loss:1.2314567664302019:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 24.26it/s]loss:1.3571029673186068:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 24.26it/s]loss:1.3571029673186068: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 29.19it/s]loss:1.3571029673186068: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 19.35it/s]
Epoch: 1 cost time: 1.471766710281372
Epoch: 1, Steps: 19 | Train Loss: 0.1934257 Vali Loss: 4.2843161 Test Loss: 80.1926346
Validation loss decreased (inf --> 4.284316).  Saving model ...
Updating learning rate to 0.0001
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 35.70it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 35.70it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 35.70it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 35.70it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 35.70it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 37.29it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 37.29it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 37.29it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 37.29it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 37.29it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 37.71it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 37.71it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 37.71it/s]loss:0.006672287279230002:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 37.71it/s]loss:0.2550763115604853:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 37.71it/s]  loss:0.2550763115604853:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 38.53it/s]loss:0.7465310928992908:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 38.53it/s]loss:1.0880043081767965:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 38.53it/s]loss:1.33742495538389:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 38.53it/s]  loss:1.33742495538389: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 35.17it/s]
Epoch: 2 cost time: 1.0923795700073242
Epoch: 2, Steps: 19 | Train Loss: 0.1807215 Vali Loss: 4.0054479 Test Loss: 79.7988205
Validation loss decreased (4.284316 --> 4.005448).  Saving model ...
Updating learning rate to 5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 36.74it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 36.74it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 36.74it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 36.74it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 36.74it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 37.88it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 37.88it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 37.88it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 37.88it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 37.88it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 38.11it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 38.11it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 38.11it/s]loss:0.005276241261954451:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 38.11it/s]loss:0.2121587383528172:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 38.11it/s]  loss:0.2121587383528172:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 37.78it/s]loss:0.548075036544677:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 37.78it/s] loss:0.8332449543103195:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 37.78it/s]loss:1.1121614868632506:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 37.78it/s]loss:1.1121614868632506: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 34.86it/s]
Epoch: 3 cost time: 1.0565016269683838
Epoch: 3, Steps: 19 | Train Loss: 0.1426798 Vali Loss: 3.9277959 Test Loss: 79.6565704
Validation loss decreased (4.005448 --> 3.927796).  Saving model ...
Updating learning rate to 2.5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 37.04it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 37.04it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 37.04it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 37.04it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 37.04it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 37.74it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 37.74it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 37.74it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 37.74it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 37.74it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 38.29it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 38.29it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 38.29it/s]loss:0.005893788176691532:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 38.29it/s]loss:0.20471939876571602:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 38.29it/s] loss:0.6197888585990668:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 38.29it/s] loss:0.6197888585990668:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 39.01it/s]loss:0.8722863341733166:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 39.01it/s]loss:1.0924729187238407:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 39.01it/s]loss:1.0924729187238407: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 35.71it/s]
Epoch: 4 cost time: 1.0864410400390625
Epoch: 4, Steps: 19 | Train Loss: 0.1471138 Vali Loss: 3.9054751 Test Loss: 79.5937500
Validation loss decreased (3.927796 --> 3.905475).  Saving model ...
Updating learning rate to 1.25e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 37.63it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 37.63it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 37.63it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 37.63it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 37.63it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 38.66it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 38.66it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 38.66it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 38.66it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 38.66it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 39.02it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 39.02it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 39.02it/s]loss:0.005332305069607062:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 39.02it/s]loss:0.19180971752988432:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 39.02it/s] loss:0.19180971752988432:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 39.37it/s]loss:0.5150735934125473:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 39.37it/s] loss:0.907072694827758:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 39.37it/s] loss:1.0881229237550252:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 39.37it/s]loss:1.0881229237550252: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 35.98it/s]
Epoch: 5 cost time: 1.0341975688934326
Epoch: 5, Steps: 19 | Train Loss: 0.1424953 Vali Loss: 3.8789637 Test Loss: 79.5557632
Validation loss decreased (3.905475 --> 3.878964).  Saving model ...
Updating learning rate to 6.25e-06
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 32.95it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 32.95it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 32.95it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 32.95it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 32.95it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 35.78it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 35.78it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 35.78it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 35.78it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 35.78it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 37.22it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 37.22it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 37.22it/s]loss:0.004878221521111966:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 37.22it/s]loss:0.19125985880197963:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 37.22it/s] loss:0.19125985880197963:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 38.26it/s]loss:0.5083535455408297:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 38.26it/s] loss:0.7724244337184141:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 38.26it/s]loss:1.037316969902423:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 38.26it/s] loss:1.037316969902423: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 34.69it/s]
Epoch: 6 cost time: 1.0537874698638916
Epoch: 6, Steps: 19 | Train Loss: 0.1323281 Vali Loss: 3.8703585 Test Loss: 79.5423508
Validation loss decreased (3.878964 --> 3.870358).  Saving model ...
Updating learning rate to 3.125e-06
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 37.24it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 37.24it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 37.24it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 37.24it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 37.24it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 37.68it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 37.68it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 37.68it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 37.68it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 37.68it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 37.68it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 38.77it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 38.77it/s]loss:0.00568313058803277:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 38.77it/s]loss:0.1792091828412975:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 38.77it/s] loss:0.5068147223035118:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 38.77it/s]loss:0.5068147223035118:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 38.86it/s]loss:0.8126608706025513:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 38.86it/s]loss:0.8877791252426711:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 38.86it/s]loss:0.8877791252426711: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 35.40it/s]
Epoch: 7 cost time: 1.0203931331634521
Epoch: 7, Steps: 19 | Train Loss: 0.1259025 Vali Loss: 3.8679183 Test Loss: 79.5362091
Validation loss decreased (3.870358 --> 3.867918).  Saving model ...
Updating learning rate to 1.5625e-06
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 37.13it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 37.13it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 37.13it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 37.13it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 37.13it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 37.13it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 39.38it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 39.38it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 39.38it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 39.38it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 39.38it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 39.38it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 40.25it/s]loss:0.005255560016496457:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 40.25it/s]loss:0.19433082962908074:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 40.25it/s] loss:0.5019451491104626:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 40.25it/s] loss:0.8745796428387616:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 40.25it/s]loss:1.0164036389475701:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 40.25it/s]loss:1.0164036389475701: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 40.32it/s]loss:1.0164036389475701: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 36.51it/s]
Epoch: 8 cost time: 0.9950697422027588
Epoch: 8, Steps: 19 | Train Loss: 0.1364481 Vali Loss: 3.8672903 Test Loss: 79.5335236
Validation loss decreased (3.867918 --> 3.867290).  Saving model ...
Updating learning rate to 7.8125e-07
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 37.06it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 37.06it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 37.06it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 37.06it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 37.06it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 38.12it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 38.12it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 38.12it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 38.12it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 38.12it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 38.59it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 38.59it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 38.59it/s]loss:0.005097706112018619:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 38.59it/s]loss:0.20534494244054524:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 38.59it/s] loss:0.20534494244054524:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 39.00it/s]loss:0.467883258992713:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 39.00it/s]  loss:0.74920060094021:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 39.00it/s] loss:0.9730874106191177:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 39.00it/s]loss:0.9730874106191177: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 35.61it/s]
Epoch: 9 cost time: 1.091153860092163
Epoch: 9, Steps: 19 | Train Loss: 0.1263481 Vali Loss: 3.8661835 Test Loss: 79.5317307
Validation loss decreased (3.867290 --> 3.866184).  Saving model ...
Updating learning rate to 3.90625e-07
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 39.03it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 39.03it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 39.03it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 39.03it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 39.03it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 39.03it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 40.30it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 40.30it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 40.30it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 40.30it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 40.30it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 40.30it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 40.33it/s]loss:0.005912495212717108:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 40.33it/s]loss:0.18975022550496615:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 40.33it/s] loss:0.4672191824166942:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 40.33it/s] loss:0.8141164541920887:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 40.33it/s]loss:0.8641519731179931:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 40.33it/s]loss:0.8641519731179931: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 40.24it/s]loss:0.8641519731179931: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 36.54it/s]
Epoch: 10 cost time: 1.0133838653564453
Epoch: 10, Steps: 19 | Train Loss: 0.1232184 Vali Loss: 3.8661160 Test Loss: 79.5309372
Validation loss decreased (3.866184 --> 3.866116).  Saving model ...
Updating learning rate to 1.953125e-07
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 36.89it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 36.89it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 36.89it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 36.89it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 36.89it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 37.85it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 37.85it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 37.85it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 37.85it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 37.85it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 34.62it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 34.62it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 34.62it/s]loss:0.005608090630657398:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 34.62it/s]loss:0.17821359614475868:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 34.62it/s] loss:0.5051404090275357:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 34.62it/s] loss:0.5051404090275357:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 37.03it/s]loss:0.7958153640816987:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 37.03it/s]loss:0.8626933688734084:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 37.03it/s]loss:0.8626933688734084: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 34.22it/s]
Epoch: 11 cost time: 1.089289665222168
Epoch: 11, Steps: 19 | Train Loss: 0.1235511 Vali Loss: 3.8661699 Test Loss: 79.5306015
EarlyStopping counter: 1 out of 3
Updating learning rate to 9.765625e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 38.81it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 38.81it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 38.81it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 38.81it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 38.81it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 38.81it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 39.57it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 39.57it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 39.57it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 39.57it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 39.57it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 39.61it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 39.61it/s]loss:0.00591502890676637:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 39.61it/s]loss:0.18981983838565056:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 39.61it/s]loss:0.501200149815228:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 39.61it/s]  loss:0.501200149815228:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 39.74it/s]loss:0.8198256670219691:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 39.74it/s]loss:0.9038042619253875:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 39.74it/s]loss:0.9038042619253875: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 35.75it/s]
Epoch: 12 cost time: 1.0684421062469482
Epoch: 12, Steps: 19 | Train Loss: 0.1273982 Vali Loss: 3.8662503 Test Loss: 79.5304642
EarlyStopping counter: 2 out of 3
Updating learning rate to 4.8828125e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 32.35it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 32.35it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 32.35it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 32.35it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 32.35it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 32.35it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 36.91it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 36.91it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 36.91it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 36.91it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 36.91it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 38.10it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 38.10it/s]loss:0.005030969237127969:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 38.10it/s]loss:0.170113219679035:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 38.10it/s]   loss:0.522024043527252:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 38.10it/s]loss:0.8733768327409375:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 38.10it/s]loss:0.8733768327409375:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:00<00:00, 39.01it/s]loss:0.9326963458967505:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:00<00:00, 39.01it/s]loss:0.9326963458967505: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 35.00it/s]
Epoch: 13 cost time: 1.056351900100708
Epoch: 13, Steps: 19 | Train Loss: 0.1317495 Vali Loss: 3.8662739 Test Loss: 79.5303955
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : long_term_forecast_break_tukey-hanning_0_SegRNN_job_demand_r1_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 4
test shape: (4, 1, 3, 32690) (4, 1, 3, 32690)
test shape: (4, 3, 32690) (4, 3, 32690)
mse:41857.1796875, mae:18.119653701782227, dtw:-999
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           0                   Model:              SegRNN              

[1mData Loader[0m
  Data:               job_demand_r1       Root Path:          ../../dataset/demand/
  Data Path:          r1.parquet          Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        .cache/checkpoints  

[1mForecasting Task[0m
  Seq Len:            6                   Label Len:          1                   
  Pred Len:           3                   Seasonal Patterns:  Monthly             
  Inverse:            1                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             32690               Dec In:             32690               
  C Out:              32690               d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           2                   d FF:               2048                
  Moving Avg:         25                  Factor:             1                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              learned             Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        32                  Itr:                1                   
  Train Epochs:       20                  Batch Size:         1                   
  Patience:           3                   Learning Rate:      0.0001              
  Des:                test                Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1                 

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_break_rayleigh_0_SegRNN_job_demand_r1_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 19
val 1
test 4
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.6515532669453971:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6515532669453971:   5%|â–Œ         | 1/19 [00:00<00:08,  2.11it/s]loss:0.610861139595596:   5%|â–Œ         | 1/19 [00:00<00:08,  2.11it/s] loss:0.5813822984657537:   5%|â–Œ         | 1/19 [00:00<00:08,  2.11it/s]loss:0.7306478669942823:   5%|â–Œ         | 1/19 [00:00<00:08,  2.11it/s]loss:0.6989274077000779:   5%|â–Œ         | 1/19 [00:00<00:08,  2.11it/s]loss:0.6989274077000779:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.79it/s]loss:0.812142976651107:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.79it/s] loss:0.7892942541493223:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.79it/s]loss:0.8196916308111648:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.79it/s]loss:1.0938774451476638:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.79it/s]loss:1.0938774451476638:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 17.91it/s]loss:0.9644700866168672:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 17.91it/s]loss:0.8305491342075946:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 17.91it/s]loss:0.9953099370303842:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 17.91it/s]loss:0.9526443583952242:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 17.91it/s]loss:1.0480365168773478:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 17.91it/s]loss:1.0480365168773478:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 24.71it/s]loss:1.0495874423331324:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 24.71it/s]loss:0.9161519765049002:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 24.71it/s]loss:1.04068104901369:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 24.71it/s]  loss:1.0449535655738034:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 24.71it/s]loss:1.1062550570282295:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 24.71it/s]loss:1.1062550570282295: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 29.42it/s]loss:1.1062550570282295: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 19.67it/s]
Epoch: 1 cost time: 1.5152685642242432
Epoch: 1, Steps: 19 | Train Loss: 0.8808957 Vali Loss: 3.8484881 Test Loss: 79.4733047
Validation loss decreased (inf --> 3.848488).  Saving model ...
Updating learning rate to 0.0001
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.414538322614169:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.4843044326390987:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.4896536113276773:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5373998716670529:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5373998716670529:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 36.63it/s]loss:0.5601366232927492:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 36.63it/s]loss:0.6573756106354944:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 36.63it/s]loss:0.624327951054243:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 36.63it/s] loss:0.6523501769861748:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 36.63it/s]loss:0.6523501769861748:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 37.51it/s]loss:0.6462740714682984:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 37.51it/s]loss:0.7612952199136218:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 37.51it/s]loss:0.777905631403564:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 37.51it/s] loss:0.8414727672347028:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 37.51it/s]loss:0.8414727672347028:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 37.73it/s]loss:0.777257046698219:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 37.73it/s] loss:0.7500524726776612:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 37.73it/s]loss:0.8182794303943224:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 37.73it/s]loss:0.8724688436411314:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 37.73it/s]loss:0.8724688436411314:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 38.53it/s]loss:0.9468106648374416:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 38.53it/s]loss:1.0131184301207508:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 38.53it/s]loss:0.8700024160307586:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 38.53it/s]loss:0.8700024160307586: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 35.13it/s]
Epoch: 2 cost time: 1.046238899230957
Epoch: 2, Steps: 19 | Train Loss: 0.7102644 Vali Loss: 3.9777238 Test Loss: 79.3393097
EarlyStopping counter: 1 out of 3
Updating learning rate to 5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.4041413037912149:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.42048770897703375:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.42048770897703375:  11%|â–ˆ         | 2/19 [00:00<00:01, 14.12it/s]loss:0.4219020284430593:  11%|â–ˆ         | 2/19 [00:00<00:01, 14.12it/s] loss:0.5289423817485069:  11%|â–ˆ         | 2/19 [00:00<00:01, 14.12it/s]loss:0.5289423817485069:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 16.24it/s]loss:0.4960308158244662:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 16.24it/s]loss:0.6216909075299616:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 16.24it/s]loss:0.5739228019572673:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 16.24it/s]loss:0.5739228019572673:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 19.59it/s]loss:0.6902168109517648:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 19.59it/s]loss:0.6589084437347673:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 19.59it/s]loss:0.6681972607347085:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 19.59it/s]loss:0.8909532674093739:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 19.59it/s]loss:0.8909532674093739:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 25.85it/s]loss:0.7633889545393258:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 25.85it/s]loss:0.7438547972117016:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 25.85it/s]loss:0.9570193550716845:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 25.85it/s]loss:0.768888453239676:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 25.85it/s] loss:0.768888453239676:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 30.36it/s]loss:0.9194306978539336:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 30.36it/s]loss:0.843158707087618:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 30.36it/s] loss:0.7494096451635556:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 30.36it/s]loss:0.8901369016861324:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 30.36it/s]loss:0.8901369016861324: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 25.83it/s]
Epoch: 3 cost time: 1.2822511196136475
Epoch: 3, Steps: 19 | Train Loss: 0.6847727 Vali Loss: 3.8861289 Test Loss: 79.3187408
EarlyStopping counter: 2 out of 3
Updating learning rate to 2.5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.36641086635045655:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.39478144264070225:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.44133407002198743:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.55500927417162:   0%|          | 0/19 [00:00<?, ?it/s]   loss:0.55500927417162:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 32.18it/s]loss:0.5406865483745577:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 32.18it/s]loss:0.5120195242087259:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 32.18it/s]loss:0.7004155601785177:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 32.18it/s]loss:0.5906954809640212:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 32.18it/s]loss:0.5906954809640212:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 33.92it/s]loss:0.5758635315789579:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 33.92it/s]loss:0.6588543887128465:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 33.92it/s]loss:0.7143838949922925:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 33.92it/s]loss:0.7543899029510238:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 33.92it/s]loss:0.7543899029510238:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 32.17it/s]loss:0.780249089001571:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 32.17it/s] loss:0.7614978318948341:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 32.17it/s]loss:0.8825230531497973:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 32.17it/s]loss:0.9171289790043061:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 32.17it/s]loss:0.9952545577397578:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 32.17it/s]loss:0.9952545577397578:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 35.09it/s]loss:0.883961853395397:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 35.09it/s] loss:0.94311109274133:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 35.09it/s] loss:0.94311109274133: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 31.86it/s]
Epoch: 4 cost time: 1.0824077129364014
Epoch: 4, Steps: 19 | Train Loss: 0.6825564 Vali Loss: 3.8998346 Test Loss: 79.3215027
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : long_term_forecast_break_rayleigh_0_SegRNN_job_demand_r1_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 4
test shape: (4, 1, 3, 32690) (4, 1, 3, 32690)
test shape: (4, 3, 32690) (4, 3, 32690)
mse:54604.22265625, mae:19.164371490478516, dtw:-999
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           0                   Model:              PatchTST            

[1mData Loader[0m
  Data:               job_demand_region   Root Path:          ../../dataset/demand/
  Data Path:          region.parquet      Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        .cache/checkpoints  

[1mForecasting Task[0m
  Seq Len:            6                   Label Len:          1                   
  Pred Len:           3                   Seasonal Patterns:  Monthly             
  Inverse:            1                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             16345               Dec In:             16345               
  C Out:              16345               d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           2                   d FF:               2048                
  Moving Avg:         25                  Factor:             1                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              learned             Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        32                  Itr:                1                   
  Train Epochs:       20                  Batch Size:         1                   
  Patience:           3                   Learning Rate:      0.0001              
  Des:                test                Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1                 

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_break_bartlett_0_PatchTST_job_demand_region_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 19
val 1
test 4
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:11,  1.54it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:11,  1.54it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:11,  1.54it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:11,  1.54it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:11,  1.54it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01,  8.37it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01,  8.37it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01,  8.37it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01,  8.37it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01,  8.37it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 14.65it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 14.65it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 14.65it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 14.65it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 14.65it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 20.09it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 20.09it/s]loss:0.05491556429749821:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 20.09it/s]loss:0.333543433528445:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 20.09it/s]  loss:0.460987652981866:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 20.09it/s]loss:0.460987652981866:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 24.57it/s]loss:1.274707761362962:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 24.57it/s]loss:1.386522459249759:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 24.57it/s]loss:1.386522459249759: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 16.36it/s]
Epoch: 1 cost time: 1.6635644435882568
Epoch: 1, Steps: 19 | Train Loss: 0.1847725 Vali Loss: 3.0454724 Test Loss: 40.5788269
Validation loss decreased (inf --> 3.045472).  Saving model ...
Updating learning rate to 0.0001
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 36.46it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 36.46it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 36.46it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 36.46it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 36.46it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 36.88it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 36.88it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 36.88it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 36.88it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 36.88it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 37.27it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 37.27it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 37.27it/s]loss:0.5314476107817155:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 37.27it/s]loss:2.768333407574399:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 37.27it/s] loss:2.768333407574399:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 37.32it/s]loss:4.090034304133355:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 37.32it/s]loss:4.839625560835678:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 37.32it/s]loss:5.050446673597532:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 37.32it/s]loss:5.050446673597532: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 33.99it/s]
Epoch: 2 cost time: 1.1334223747253418
Epoch: 2, Steps: 19 | Train Loss: 0.9094678 Vali Loss: 4.5151486 Test Loss: 43.4582367
EarlyStopping counter: 1 out of 3
Updating learning rate to 5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 37.11it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 37.11it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 37.11it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 37.11it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 37.11it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 36.58it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 36.58it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 36.58it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 36.58it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 36.58it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 37.17it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 37.17it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 37.17it/s]loss:0.10760952564534469:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 37.17it/s]loss:0.5862458582757457:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 37.17it/s] loss:0.5862458582757457:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 36.81it/s]loss:1.0199655535666112:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 36.81it/s]loss:1.8679559494324793:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 36.81it/s]loss:1.3906103269755077:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 36.81it/s]loss:1.3906103269755077: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 34.02it/s]
Epoch: 3 cost time: 1.066084623336792
Epoch: 3, Steps: 19 | Train Loss: 0.2617046 Vali Loss: 4.1577177 Test Loss: 43.1308670
EarlyStopping counter: 2 out of 3
Updating learning rate to 2.5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:00, 29.58it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:00, 29.58it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:00, 29.58it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:00, 29.58it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:00, 23.42it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:00, 23.42it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:00, 23.42it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:00, 23.42it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:00, 23.42it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 29.91it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 29.91it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 29.91it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 29.91it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 29.91it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 28.61it/s]loss:0.06472325130856325:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 28.61it/s]loss:0.25363418939089:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 28.61it/s]   loss:0.5012279041214386:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 28.61it/s]loss:0.9839821724125866:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 28.61it/s]loss:0.9839821724125866:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:00<00:00, 31.55it/s]loss:1.6691919902370862:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:00<00:00, 31.55it/s]loss:1.6691919902370862: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 28.17it/s]
Epoch: 4 cost time: 1.1744120121002197
Epoch: 4, Steps: 19 | Train Loss: 0.1827768 Vali Loss: 3.6719289 Test Loss: 45.5801659
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : long_term_forecast_break_bartlett_0_PatchTST_job_demand_region_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 4
test shape: (4, 1, 3, 16345) (4, 1, 3, 16345)
test shape: (4, 3, 16345) (4, 3, 16345)
mse:57469.87109375, mae:36.85396194458008, dtw:-999
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           0                   Model:              PatchTST            

[1mData Loader[0m
  Data:               job_demand_region   Root Path:          ../../dataset/demand/
  Data Path:          region.parquet      Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        .cache/checkpoints  

[1mForecasting Task[0m
  Seq Len:            6                   Label Len:          1                   
  Pred Len:           3                   Seasonal Patterns:  Monthly             
  Inverse:            1                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             16345               Dec In:             16345               
  C Out:              16345               d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           2                   d FF:               2048                
  Moving Avg:         25                  Factor:             1                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              learned             Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        32                  Itr:                1                   
  Train Epochs:       20                  Batch Size:         1                   
  Patience:           3                   Learning Rate:      0.0001              
  Des:                test                Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1                 

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_break_parzen_0_PatchTST_job_demand_region_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 19
val 1
test 4
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:11,  1.57it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:11,  1.57it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:11,  1.57it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:11,  1.57it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:11,  1.57it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01,  8.47it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01,  8.47it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01,  8.47it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01,  8.47it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01,  8.47it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 14.63it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 14.63it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 14.63it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 14.63it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 14.63it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 20.05it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 20.05it/s]loss:0.0002490501782199448:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 20.05it/s]loss:0.05460308491168505:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 20.05it/s]  loss:0.26022554354587357:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 20.05it/s]loss:0.26022554354587357:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 24.53it/s]loss:1.1103814969103645:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 24.53it/s] loss:1.2599527307288019:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 24.53it/s]loss:1.2599527307288019: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 16.40it/s]
Epoch: 1 cost time: 1.7106127738952637
Epoch: 1, Steps: 19 | Train Loss: 0.1413375 Vali Loss: 3.0783675 Test Loss: 39.9482651
Validation loss decreased (inf --> 3.078367).  Saving model ...
Updating learning rate to 0.0001
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 36.29it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 36.29it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 36.29it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 36.29it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 36.29it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 36.81it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 36.81it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 36.81it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 36.81it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 36.81it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 37.86it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 37.86it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 37.86it/s]loss:0.0026113809262378338:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 37.86it/s]loss:0.5277142018433084:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 37.86it/s]   loss:0.5277142018433084:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 38.16it/s]loss:2.925123162627827:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 38.16it/s] loss:6.616591060979812:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 38.16it/s]loss:7.764984191295041:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 38.16it/s]loss:7.764984191295041: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 34.71it/s]
Epoch: 2 cost time: 1.040405035018921
Epoch: 2, Steps: 19 | Train Loss: 0.9387907 Vali Loss: 7.1443963 Test Loss: 56.2730675
EarlyStopping counter: 1 out of 3
Updating learning rate to 5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 36.79it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 36.79it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 36.79it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 36.79it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 36.79it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 36.98it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 36.98it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 36.98it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 36.98it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 36.98it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 37.13it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 37.13it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 37.13it/s]loss:0.0004439024743969671:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 37.13it/s]loss:0.09029913469713845:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 37.13it/s]  loss:0.09029913469713845:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 37.43it/s]loss:0.5415571575416377:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 37.43it/s] loss:1.7609508926201354:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 37.43it/s]loss:1.5975946733027564:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 37.43it/s]loss:1.5975946733027564: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 33.92it/s]
Epoch: 3 cost time: 1.094186782836914
Epoch: 3, Steps: 19 | Train Loss: 0.2100445 Vali Loss: 3.7169006 Test Loss: 36.8000450
EarlyStopping counter: 2 out of 3
Updating learning rate to 2.5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 37.18it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 37.18it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 37.18it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 37.18it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 37.18it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 38.23it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 38.23it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 38.23it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 38.23it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 38.23it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 38.68it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 38.68it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 38.68it/s]loss:0.0002756645052298286:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 38.68it/s]loss:0.04592372376837672:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 38.68it/s]  loss:0.04592372376837672:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 38.75it/s]loss:0.28345873599041754:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 38.75it/s]loss:0.9256655214294238:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 38.75it/s] loss:1.5886334389482428:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 38.75it/s]loss:1.5886334389482428: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 34.77it/s]
Epoch: 4 cost time: 1.0855743885040283
Epoch: 4, Steps: 19 | Train Loss: 0.1496820 Vali Loss: 3.3336837 Test Loss: 40.3349686
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : long_term_forecast_break_parzen_0_PatchTST_job_demand_region_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 4
test shape: (4, 1, 3, 16345) (4, 1, 3, 16345)
test shape: (4, 3, 16345) (4, 3, 16345)
mse:39831.97265625, mae:32.965274810791016, dtw:-999
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           0                   Model:              PatchTST            

[1mData Loader[0m
  Data:               job_demand_region   Root Path:          ../../dataset/demand/
  Data Path:          region.parquet      Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        .cache/checkpoints  

[1mForecasting Task[0m
  Seq Len:            6                   Label Len:          1                   
  Pred Len:           3                   Seasonal Patterns:  Monthly             
  Inverse:            1                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             16345               Dec In:             16345               
  C Out:              16345               d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           2                   d FF:               2048                
  Moving Avg:         25                  Factor:             1                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              learned             Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        32                  Itr:                1                   
  Train Epochs:       20                  Batch Size:         1                   
  Patience:           3                   Learning Rate:      0.0001              
  Des:                test                Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1                 

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_break_tukey-hanning_0_PatchTST_job_demand_region_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 19
val 1
test 4
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:14,  1.25it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:14,  1.25it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:14,  1.25it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:14,  1.25it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:14,  1.25it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01,  7.04it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01,  7.04it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01,  7.04it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01,  7.04it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:01<00:01,  7.04it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:01<00:00, 12.70it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:01<00:00, 12.70it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:01<00:00, 12.70it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:01<00:00, 12.70it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:01<00:00, 12.70it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 17.98it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 17.98it/s]loss:0.006440295546130754:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 17.98it/s]loss:0.2197801964125164:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 17.98it/s]  loss:0.48170946767145606:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 17.98it/s]loss:0.48170946767145606:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 22.41it/s]loss:1.3741671598435974:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 22.41it/s] loss:1.3265340535351127:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 22.41it/s]loss:1.3265340535351127: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 14.42it/s]
Epoch: 1 cost time: 1.9208793640136719
Epoch: 1, Steps: 19 | Train Loss: 0.1794016 Vali Loss: 3.0650756 Test Loss: 40.6494522
Validation loss decreased (inf --> 3.065076).  Saving model ...
Updating learning rate to 0.0001
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 36.47it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 36.47it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 36.47it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 36.47it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 36.47it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 37.67it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 37.67it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 37.67it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 37.67it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 37.67it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 37.53it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 37.53it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 37.53it/s]loss:0.06509855380001728:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 37.53it/s]loss:2.005310313746332:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 37.53it/s]  loss:2.005310313746332:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 37.47it/s]loss:4.853408546205415:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 37.47it/s]loss:6.545692690164557:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 37.47it/s]loss:6.258175708000954:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 37.47it/s]loss:6.258175708000954: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 33.92it/s]
Epoch: 2 cost time: 1.079169750213623
Epoch: 2, Steps: 19 | Train Loss: 1.0382993 Vali Loss: 5.5123744 Test Loss: 48.8965187
EarlyStopping counter: 1 out of 3
Updating learning rate to 5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 35.66it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 35.66it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 35.66it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 35.66it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 35.66it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 35.52it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 35.52it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 35.52it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 35.52it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 35.52it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 36.50it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 36.50it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 36.50it/s]loss:0.012375723208583074:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 36.50it/s]loss:0.3591458068983894:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 36.50it/s]  loss:0.3591458068983894:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 36.94it/s]loss:1.0292559821381073:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 36.94it/s]loss:2.098236156709397:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 36.94it/s] loss:1.4363487673455348:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 36.94it/s]loss:1.4363487673455348: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 33.32it/s]
Epoch: 3 cost time: 1.0879452228546143
Epoch: 3, Steps: 19 | Train Loss: 0.2597559 Vali Loss: 3.8799474 Test Loss: 40.3115311
EarlyStopping counter: 2 out of 3
Updating learning rate to 2.5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 35.79it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 35.79it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 35.79it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 35.79it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 35.79it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 36.69it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 36.69it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 36.69it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 36.69it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 36.69it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 37.25it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 37.25it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 37.25it/s]loss:0.007234506735314381:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 37.25it/s]loss:0.16784045349988103:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 37.25it/s] loss:0.16784045349988103:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 37.50it/s]loss:0.5197053797658227:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 37.50it/s] loss:1.0763317997040605:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 37.50it/s]loss:1.639231509546604:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 37.50it/s] loss:1.639231509546604: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 33.83it/s]
Epoch: 4 cost time: 1.0734171867370605
Epoch: 4, Steps: 19 | Train Loss: 0.1794918 Vali Loss: 3.5413032 Test Loss: 43.7358704
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : long_term_forecast_break_tukey-hanning_0_PatchTST_job_demand_region_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 4
test shape: (4, 1, 3, 16345) (4, 1, 3, 16345)
test shape: (4, 3, 16345) (4, 3, 16345)
mse:51799.29296875, mae:35.55461502075195, dtw:-999
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           0                   Model:              PatchTST            

[1mData Loader[0m
  Data:               job_demand_region   Root Path:          ../../dataset/demand/
  Data Path:          region.parquet      Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        .cache/checkpoints  

[1mForecasting Task[0m
  Seq Len:            6                   Label Len:          1                   
  Pred Len:           3                   Seasonal Patterns:  Monthly             
  Inverse:            1                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             16345               Dec In:             16345               
  C Out:              16345               d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           2                   d FF:               2048                
  Moving Avg:         25                  Factor:             1                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              learned             Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        32                  Itr:                1                   
  Train Epochs:       20                  Batch Size:         1                   
  Patience:           3                   Learning Rate:      0.0001              
  Des:                test                Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1                 

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_break_rayleigh_0_PatchTST_job_demand_region_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 19
val 1
test 4
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.5801081184651863:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5801081184651863:   5%|â–Œ         | 1/19 [00:00<00:10,  1.69it/s]loss:0.6107643347160181:   5%|â–Œ         | 1/19 [00:00<00:10,  1.69it/s]loss:0.6003637023547604:   5%|â–Œ         | 1/19 [00:00<00:10,  1.69it/s]loss:0.8865374792303451:   5%|â–Œ         | 1/19 [00:00<00:10,  1.69it/s]loss:0.7199236646273497:   5%|â–Œ         | 1/19 [00:00<00:10,  1.69it/s]loss:0.7199236646273497:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01,  9.01it/s]loss:0.829911796264221:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01,  9.01it/s] loss:1.0264281912657056:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01,  9.01it/s]loss:1.0325043552706268:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01,  9.01it/s]loss:1.0085269024486487:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01,  9.01it/s]loss:1.0085269024486487:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 15.38it/s]loss:0.9274747738839327:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 15.38it/s]loss:1.020319972557611:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 15.38it/s] loss:1.0687523600208038:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 15.38it/s]loss:1.0687523600208038:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 18.30it/s]loss:1.0261461303371584:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 18.30it/s]loss:1.0442732862636845:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 18.30it/s]loss:1.0218643091635993:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 18.30it/s]loss:1.16068905303411:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 18.30it/s]  loss:1.16068905303411:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 22.81it/s]loss:0.8388863372268651:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 22.81it/s]loss:1.5350714494285753:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 22.81it/s]loss:1.6258470156182938:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 22.81it/s]loss:1.6258470156182938: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 16.52it/s]
Epoch: 1 cost time: 1.682554006576538
Epoch: 1, Steps: 19 | Train Loss: 0.9770733 Vali Loss: 3.2645168 Test Loss: 39.8917618
Validation loss decreased (inf --> 3.264517).  Saving model ...
Updating learning rate to 0.0001
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.6162693198559897:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5515613261905398:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7488773295952663:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9015113396791955:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9015113396791955:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 33.87it/s]loss:0.8070480539820764:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 33.87it/s]loss:0.7871396310752731:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 33.87it/s]loss:0.9058767794761085:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 33.87it/s]loss:1.072559514422876:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 33.87it/s] loss:1.072559514422876:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 35.12it/s]loss:0.9335894893010404:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 35.12it/s]loss:1.0351044533126068:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 35.12it/s]loss:1.140899627499921:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 35.12it/s] loss:0.9852692258710962:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 35.12it/s]loss:0.9852692258710962:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 36.03it/s]loss:1.2475873171779053:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 36.03it/s]loss:1.0909275876408608:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 36.03it/s]loss:1.118888887528533:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 36.03it/s] loss:1.0679282736006923:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 36.03it/s]loss:1.0679282736006923:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 36.54it/s]loss:1.0241112868148183:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 36.54it/s]loss:0.9863851860527553:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 36.54it/s]loss:1.0940406451230318:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 36.54it/s]loss:1.0940406451230318: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 33.25it/s]
Epoch: 2 cost time: 1.1276772022247314
Epoch: 2, Steps: 19 | Train Loss: 0.9534513 Vali Loss: 3.2631609 Test Loss: 43.8109131
Validation loss decreased (3.264517 --> 3.263161).  Saving model ...
Updating learning rate to 5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.5376050925625946:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5785728431645972:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.564468991788413:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.6427184766398623:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6427184766398623:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 34.38it/s]loss:0.7544634185219284:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 34.38it/s]loss:0.9337913812624368:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 34.38it/s]loss:0.7381258573847125:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 34.38it/s]loss:0.6692658527695808:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 34.38it/s]loss:0.6692658527695808:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 34.90it/s]loss:0.937061485473737:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 34.90it/s] loss:0.7884723565229194:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 34.90it/s]loss:1.2544810883742465:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 34.90it/s]loss:0.8077013752555163:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 34.90it/s]loss:0.8077013752555163:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 35.89it/s]loss:1.0158061223865196:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 35.89it/s]loss:1.1336145591598599:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 35.89it/s]loss:0.8636244688948749:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 35.89it/s]loss:1.1506224052074154:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 35.89it/s]loss:1.1506224052074154:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 36.35it/s]loss:1.06857898504909:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 36.35it/s]  loss:1.0635683654492023:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 36.35it/s]loss:0.9183496008635524:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 36.35it/s]loss:0.9183496008635524: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 33.04it/s]
Epoch: 3 cost time: 1.0984258651733398
Epoch: 3, Steps: 19 | Train Loss: 0.8642575 Vali Loss: 3.1268663 Test Loss: 41.8479652
Validation loss decreased (3.263161 --> 3.126866).  Saving model ...
Updating learning rate to 2.5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.4201684678442698:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5217030853412105:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5648010676156829:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5175069422446532:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5175069422446532:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 35.78it/s]loss:0.6229140628630815:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 35.78it/s]loss:0.7893858412289912:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 35.78it/s]loss:0.7334736286003929:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 35.78it/s]loss:0.8550569286021699:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 35.78it/s]loss:0.8550569286021699:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 36.29it/s]loss:0.8186997783259868:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 36.29it/s]loss:0.9299067910000379:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 36.29it/s]loss:0.9113044872446528:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 36.29it/s]loss:0.7932654223772405:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 36.29it/s]loss:0.7932654223772405:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 36.80it/s]loss:1.1354392939551516:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 36.80it/s]loss:1.232801087788377:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 36.80it/s] loss:1.0537656685970749:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 36.80it/s]loss:0.8389835721416009:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 36.80it/s]loss:0.8389835721416009:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 32.31it/s]loss:0.902398524537062:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 32.31it/s] loss:1.1384957209126332:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 32.31it/s]loss:1.4200148392770346:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 32.31it/s]loss:1.4200148392770346: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 31.26it/s]
Epoch: 4 cost time: 1.1433451175689697
Epoch: 4, Steps: 19 | Train Loss: 0.8526361 Vali Loss: 3.1649992 Test Loss: 42.3876762
EarlyStopping counter: 1 out of 3
Updating learning rate to 1.25e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.4864987336733567:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5748263890798592:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.46161906736458364:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5211923037820043:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.5211923037820043:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 35.84it/s]loss:0.5603760615601726:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 35.84it/s]loss:0.6227295428555176:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 35.84it/s]loss:0.7451103178617251:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 35.84it/s]loss:0.8485216182218389:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 35.84it/s]loss:0.8485216182218389:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 36.77it/s]loss:0.8280935352145042:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 36.77it/s]loss:0.7529918609975251:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 36.77it/s]loss:0.919728607196462:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 36.77it/s] loss:0.9989216372659782:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 36.77it/s]loss:0.9989216372659782:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 36.99it/s]loss:1.197852683974617:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 36.99it/s] loss:1.28598049233821:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 36.99it/s] loss:0.9970865896351837:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 36.99it/s]loss:1.0556495928716843:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 36.99it/s]loss:1.0556495928716843:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 37.23it/s]loss:1.089677711909733:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 37.23it/s] loss:1.1376710696279522:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 37.23it/s]loss:1.1034817352108508:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 37.23it/s]loss:1.1034817352108508: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 34.01it/s]
Epoch: 5 cost time: 1.0634188652038574
Epoch: 5, Steps: 19 | Train Loss: 0.8520005 Vali Loss: 3.1436188 Test Loss: 42.2141342
EarlyStopping counter: 2 out of 3
Updating learning rate to 6.25e-06
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.6118155539372511:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.49487367595255566:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.49487367595255566:  11%|â–ˆ         | 2/19 [00:00<00:01, 12.30it/s]loss:0.4644767703573064:  11%|â–ˆ         | 2/19 [00:00<00:01, 12.30it/s] loss:0.6557971143205406:  11%|â–ˆ         | 2/19 [00:00<00:01, 12.30it/s]loss:0.6557971143205406:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 11.43it/s]loss:0.5632371311190855:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 11.43it/s]loss:0.7026145529770925:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 11.43it/s]loss:0.769769139744588:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 11.43it/s] loss:0.821419806632912:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 11.43it/s]loss:0.821419806632912:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 19.95it/s]loss:0.8345324684741583:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 19.95it/s]loss:0.7464966400126931:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 19.95it/s]loss:1.0018342753584217:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 19.95it/s]loss:0.7956933087576717:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 19.95it/s]loss:0.7956933087576717:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 25.16it/s]loss:0.8642004069197486:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 25.16it/s]loss:0.9795117005957938:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 25.16it/s]loss:1.0840074598039433:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 25.16it/s]loss:1.2638646950854662:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 25.16it/s]loss:1.2638646950854662:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 29.11it/s]loss:1.07023801155922:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 29.11it/s]  loss:1.109080992176959:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 29.11it/s]loss:1.14188015616136:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 29.11it/s] loss:1.14188015616136: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 22.21it/s]
Epoch: 6 cost time: 1.4311659336090088
Epoch: 6, Steps: 19 | Train Loss: 0.8408076 Vali Loss: 3.1480460 Test Loss: 41.9727707
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : long_term_forecast_break_rayleigh_0_PatchTST_job_demand_region_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 4
test shape: (4, 1, 3, 16345) (4, 1, 3, 16345)
test shape: (4, 3, 16345) (4, 3, 16345)
mse:45802.98828125, mae:33.33481216430664, dtw:-999
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           0                   Model:              FiLM                

[1mData Loader[0m
  Data:               job_demand_region   Root Path:          ../../dataset/demand/
  Data Path:          region.parquet      Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        .cache/checkpoints  

[1mForecasting Task[0m
  Seq Len:            6                   Label Len:          1                   
  Pred Len:           3                   Seasonal Patterns:  Monthly             
  Inverse:            1                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             16345               Dec In:             16345               
  C Out:              16345               d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           2                   d FF:               2048                
  Moving Avg:         25                  Factor:             1                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              learned             Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        32                  Itr:                1                   
  Train Epochs:       20                  Batch Size:         1                   
  Patience:           3                   Learning Rate:      0.0001              
  Des:                test                Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1                 

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_break_bartlett_0_FiLM_job_demand_region_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 19
val 1
test 4
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:09,  1.88it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:09,  1.88it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:09,  1.88it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:09,  1.88it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:02,  7.21it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:02,  7.21it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:02,  7.21it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:02,  7.21it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 11.22it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 11.22it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 11.22it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 11.22it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 14.22it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 14.22it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:00, 14.22it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:00, 14.22it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 16.37it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 16.37it/s]loss:0.07925305067353651:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 16.37it/s]loss:0.42460240847360936:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 16.37it/s]loss:0.42460240847360936:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 18.03it/s]loss:0.6734062536551121:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 18.03it/s] loss:0.9072532271160775:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 18.03it/s]loss:1.7832358097128476:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 18.03it/s]loss:1.7832358097128476: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 19.27it/s]loss:1.7832358097128476: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 13.63it/s]
Epoch: 1 cost time: 1.9225411415100098
Epoch: 1, Steps: 19 | Train Loss: 0.2035658 Vali Loss: 3.0623088 Test Loss: 39.4095230
Validation loss decreased (inf --> 3.062309).  Saving model ...
Updating learning rate to 0.0001
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 14.95it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 14.95it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 14.95it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 14.95it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 18.78it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 18.78it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 18.78it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 18.78it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 20.37it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 20.37it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 20.37it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 20.37it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 20.85it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 20.85it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 20.85it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 20.85it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.38it/s]loss:0.06322313134865079:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.38it/s]loss:0.41315647543522865:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.38it/s]loss:0.6934709166923463:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.38it/s] loss:0.6934709166923463:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 21.50it/s]loss:0.9766005439947762:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 21.50it/s]loss:1.185132186335888:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 21.50it/s] loss:1.185132186335888: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 19.60it/s]
Epoch: 2 cost time: 1.5061800479888916
Epoch: 2, Steps: 19 | Train Loss: 0.1753465 Vali Loss: 3.0613005 Test Loss: 39.4267197
Validation loss decreased (3.062309 --> 3.061301).  Saving model ...
Updating learning rate to 5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:00, 21.12it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:00, 21.12it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:00, 21.12it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:00, 21.12it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:00, 19.74it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:00, 19.74it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:00, 19.74it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:00, 19.74it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 20.55it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 20.55it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 20.55it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 20.55it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 21.31it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 21.31it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 21.31it/s]loss:0.05654509230271538:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 21.31it/s]loss:0.05654509230271538:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 21.83it/s]loss:0.3655224215115544:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 21.83it/s] loss:0.9302151108357594:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 21.83it/s]loss:0.9678177004748388:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 21.83it/s]loss:0.9678177004748388:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:00<00:00, 21.99it/s]loss:1.4428082580336254:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:00<00:00, 21.99it/s]loss:1.4428082580336254: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 20.35it/s]
Epoch: 3 cost time: 1.484722375869751
Epoch: 3, Steps: 19 | Train Loss: 0.1980478 Vali Loss: 3.0610633 Test Loss: 39.4321861
Validation loss decreased (3.061301 --> 3.061063).  Saving model ...
Updating learning rate to 2.5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 16.20it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 16.20it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 16.20it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 17.05it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 17.05it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 17.05it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 17.05it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 19.34it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 19.34it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 19.34it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 19.34it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 20.31it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 20.31it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 20.31it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 20.31it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 21.07it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 21.07it/s]loss:0.08452104321870774:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 21.07it/s]loss:0.42435731011481725:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 21.07it/s]loss:0.42435731011481725:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 21.07it/s]loss:0.6932436662979911:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 21.07it/s] loss:1.0022163927124985:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 21.07it/s]loss:1.441607060850694:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 21.07it/s] loss:1.441607060850694: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 21.39it/s]loss:1.441607060850694: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 19.14it/s]
Epoch: 4 cost time: 1.5880019664764404
Epoch: 4, Steps: 19 | Train Loss: 0.1918919 Vali Loss: 3.0609145 Test Loss: 39.4321785
Validation loss decreased (3.061063 --> 3.060915).  Saving model ...
Updating learning rate to 1.25e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 15.38it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 15.38it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 15.38it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 15.38it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 19.09it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 19.09it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 19.09it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 19.09it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 20.36it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 20.36it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 20.36it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 20.36it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 20.64it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 20.64it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 20.64it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 20.64it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 20.65it/s]loss:0.07867500996716074:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 20.65it/s]loss:0.4240937476005943:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 20.65it/s] loss:0.742402063947135:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 20.65it/s] loss:0.742402063947135:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 20.74it/s]loss:0.9610728231619801:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 20.74it/s]loss:1.7743929738678828:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 20.74it/s]loss:1.7743929738678828: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 19.34it/s]
Epoch: 5 cost time: 1.5287234783172607
Epoch: 5, Steps: 19 | Train Loss: 0.2095072 Vali Loss: 3.0606680 Test Loss: 39.4308395
Validation loss decreased (3.060915 --> 3.060668).  Saving model ...
Updating learning rate to 6.25e-06
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 14.87it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 14.87it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 14.87it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 14.87it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 18.95it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 18.95it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 18.95it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 18.95it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 20.78it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 20.78it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 20.78it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 20.78it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.44it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.44it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.44it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.44it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.19it/s]loss:0.06261359269374206:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.19it/s]loss:0.3629409039919652:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.19it/s] loss:0.9291955423669421:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.19it/s]loss:0.9291955423669421:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 21.63it/s]loss:1.130358266799522:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 21.63it/s] loss:1.440904896929742:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 21.63it/s]loss:1.440904896929742: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 19.91it/s]
Epoch: 6 cost time: 1.5309784412384033
Epoch: 6, Steps: 19 | Train Loss: 0.2066323 Vali Loss: 3.0605085 Test Loss: 39.4307899
Validation loss decreased (3.060668 --> 3.060508).  Saving model ...
Updating learning rate to 3.125e-06
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 12.93it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 12.93it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 12.93it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 15.63it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 15.63it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 15.63it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 15.63it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 18.62it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 18.62it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 18.62it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 18.62it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 20.10it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 20.10it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 20.10it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 20.10it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 20.97it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 20.97it/s]loss:0.06044847341142301:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 20.97it/s]loss:0.3563119707332814:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 20.97it/s] loss:0.3563119707332814:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 21.35it/s]loss:0.6653476820782359:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 21.35it/s]loss:1.097746332787393:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 21.35it/s] loss:1.277685890549509:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 21.35it/s]loss:1.277685890549509: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 21.54it/s]loss:1.277685890549509: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 19.22it/s]
Epoch: 7 cost time: 1.558335304260254
Epoch: 7, Steps: 19 | Train Loss: 0.1819758 Vali Loss: 3.0604377 Test Loss: 39.4307518
Validation loss decreased (3.060508 --> 3.060438).  Saving model ...
Updating learning rate to 1.5625e-06
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 15.66it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 15.66it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 15.66it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 15.66it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 19.13it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 19.13it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 19.13it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 19.13it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 20.34it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 20.34it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 20.34it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 20.34it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.29it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.29it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.29it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.29it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.59it/s]loss:0.0674537919087867:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.59it/s]loss:0.4533255861442983:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.59it/s]loss:0.6214301422286491:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.59it/s]loss:0.6214301422286491:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 21.67it/s]loss:0.9501408697671555:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 21.67it/s]loss:1.6402561458643814:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 21.67it/s]loss:1.6402561458643814: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 19.73it/s]
Epoch: 8 cost time: 1.4920883178710938
Epoch: 8, Steps: 19 | Train Loss: 0.1964530 Vali Loss: 3.0604250 Test Loss: 39.4307556
Validation loss decreased (3.060438 --> 3.060425).  Saving model ...
Updating learning rate to 7.8125e-07
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 15.12it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 15.12it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 15.12it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 15.12it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 18.44it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 18.44it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 18.44it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 18.44it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 20.21it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 20.21it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 20.21it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 20.21it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 20.82it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 20.82it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 20.82it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 20.82it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.33it/s]loss:0.056214302450856374:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.33it/s]loss:0.4237583313575286:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.33it/s]  loss:0.665315685853615:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.33it/s] loss:0.665315685853615:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 21.48it/s]loss:1.0017256941569883:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 21.48it/s]loss:1.640217671238703:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 21.48it/s] loss:1.640217671238703: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 19.59it/s]
Epoch: 9 cost time: 1.5484309196472168
Epoch: 9, Steps: 19 | Train Loss: 0.1993280 Vali Loss: 3.0604115 Test Loss: 39.4307289
Validation loss decreased (3.060425 --> 3.060411).  Saving model ...
Updating learning rate to 3.90625e-07
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 13.46it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 13.46it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 13.46it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 16.49it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 16.49it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 16.49it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 16.49it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 19.50it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 19.50it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 19.50it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 19.50it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 20.74it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 20.74it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 20.74it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 20.74it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 20.09it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 20.09it/s]loss:0.08642554419715001:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 20.09it/s]loss:0.40470713036853867:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 20.09it/s]loss:0.40470713036853867:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 20.97it/s]loss:0.8591510179646339:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 20.97it/s] loss:1.0976664434183043:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 20.97it/s]loss:1.4744541469203145:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 20.97it/s]loss:1.4744541469203145: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 21.27it/s]loss:1.4744541469203145: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 19.09it/s]
Epoch: 10 cost time: 1.5958225727081299
Epoch: 10, Steps: 19 | Train Loss: 0.2064423 Vali Loss: 3.0604045 Test Loss: 39.4306870
Validation loss decreased (3.060411 --> 3.060405).  Saving model ...
Updating learning rate to 1.953125e-07
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 16.12it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 16.12it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 16.12it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 17.65it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 17.65it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 17.65it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 17.65it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 20.14it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 20.14it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 20.14it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 20.14it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 20.64it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 20.64it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 20.64it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 20.64it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 20.96it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 20.96it/s]loss:0.0626069537167897:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 20.96it/s]loss:0.3779723418330175:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 20.96it/s]loss:0.3779723418330175:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 20.55it/s]loss:0.6653058957415412:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 20.55it/s]loss:1.129987445587124:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 20.55it/s] loss:1.640185580671714:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 20.55it/s]loss:1.640185580671714: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 21.11it/s]loss:1.640185580671714: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 19.13it/s]
Epoch: 11 cost time: 1.5597727298736572
Epoch: 11, Steps: 19 | Train Loss: 0.2040031 Vali Loss: 3.0604007 Test Loss: 39.4306679
Validation loss decreased (3.060405 --> 3.060401).  Saving model ...
Updating learning rate to 9.765625e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 15.38it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 15.38it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 15.38it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 15.38it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 19.28it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 19.28it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 19.28it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 19.28it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 20.64it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 20.64it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 20.64it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 20.64it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.20it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.20it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.20it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.20it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.51it/s]loss:0.07062368774094756:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.51it/s]loss:0.506741370279059:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.51it/s]  loss:0.9506705794227718:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.51it/s]loss:0.9506705794227718:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 21.55it/s]loss:1.0976578825565808:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 21.55it/s]loss:1.6401805643147298:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 21.55it/s]loss:1.6401805643147298: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 19.72it/s]
Epoch: 12 cost time: 1.4925644397735596
Epoch: 12, Steps: 19 | Train Loss: 0.2245197 Vali Loss: 3.0603986 Test Loss: 39.4306564
Validation loss decreased (3.060401 --> 3.060399).  Saving model ...
Updating learning rate to 4.8828125e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 13.79it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 13.79it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 13.79it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 13.79it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 18.23it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 18.23it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 18.23it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 18.23it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 19.26it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 19.26it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 19.26it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 19.26it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 20.47it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 20.47it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 20.47it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 20.47it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.02it/s]loss:0.056213282311217014:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.02it/s]loss:0.5067405756416735:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.02it/s]  loss:0.6653032521448904:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.02it/s]loss:0.6653032521448904:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 21.01it/s]loss:1.2575721182978672:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 21.01it/s]loss:1.416449794577774:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 21.01it/s] loss:1.416449794577774: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 19.09it/s]
Epoch: 13 cost time: 1.5847642421722412
Epoch: 13, Steps: 19 | Train Loss: 0.2053831 Vali Loss: 3.0603976 Test Loss: 39.4306488
Validation loss decreased (3.060399 --> 3.060398).  Saving model ...
Updating learning rate to 2.44140625e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:00, 17.10it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:00, 17.10it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:00, 17.10it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 17.71it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 17.71it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 17.71it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 17.71it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 20.04it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 20.04it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 20.04it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 20.04it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 20.55it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 20.55it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 20.55it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 20.55it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 20.07it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 20.07it/s]loss:0.06083819846828275:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 20.07it/s]loss:0.41162091561535313:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 20.07it/s]loss:0.41162091561535313:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 20.60it/s]loss:0.950667932394913:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 20.60it/s]  loss:1.079198576159053:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 20.60it/s]loss:1.3238947247525585:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 20.60it/s]loss:1.3238947247525585: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 20.76it/s]loss:1.3238947247525585: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 18.96it/s]
Epoch: 14 cost time: 1.5526187419891357
Epoch: 14, Steps: 19 | Train Loss: 0.2013800 Vali Loss: 3.0603969 Test Loss: 39.4306412
Validation loss decreased (3.060398 --> 3.060397).  Saving model ...
Updating learning rate to 1.220703125e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 15.39it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 15.39it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 15.39it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 16.70it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 16.70it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 16.70it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 16.70it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 18.95it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 18.95it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 18.95it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 18.95it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 20.09it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 20.09it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 20.09it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 20.09it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 20.26it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 20.26it/s]loss:0.08642431986812474:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 20.26it/s]loss:0.42374069305451156:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 20.26it/s]loss:0.42374069305451156:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 20.57it/s]loss:0.6183453154416666:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 20.57it/s] loss:0.9734108693889156:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 20.57it/s]loss:1.2470299730939787:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 20.57it/s]loss:1.2470299730939787: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 20.39it/s]loss:1.2470299730939787: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 18.65it/s]
Epoch: 15 cost time: 1.6353027820587158
Epoch: 15, Steps: 19 | Train Loss: 0.1762606 Vali Loss: 3.0603969 Test Loss: 39.4306412
Validation loss decreased (3.060397 --> 3.060397).  Saving model ...
Updating learning rate to 6.103515625e-09
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 15.26it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 15.26it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 15.26it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 15.26it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 18.72it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 18.72it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 18.72it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 18.72it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 20.07it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 20.07it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 20.07it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 20.07it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 20.76it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 20.76it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 20.76it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 20.76it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 20.85it/s]loss:0.0626067217756633:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 20.85it/s]loss:0.4237406328200865:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 20.85it/s]loss:0.6692198943442921:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 20.85it/s]loss:0.6692198943442921:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 21.03it/s]loss:1.3827890027312293:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 21.03it/s]loss:1.6401762463239136:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 21.03it/s]loss:1.6401762463239136: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 19.35it/s]
Epoch: 16 cost time: 1.5230822563171387
Epoch: 16, Steps: 19 | Train Loss: 0.2199228 Vali Loss: 3.0603969 Test Loss: 39.4306412
Validation loss decreased (3.060397 --> 3.060397).  Saving model ...
Updating learning rate to 3.0517578125e-09
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 15.11it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 15.11it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 15.11it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 15.11it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 19.55it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 19.55it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 19.55it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 19.55it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 20.91it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 20.91it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 20.91it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 20.91it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.41it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.41it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.41it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.41it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 18.71it/s]loss:0.07810362582066162:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 18.71it/s]loss:0.3628925202033205:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 18.71it/s] loss:0.741948371226463:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 18.71it/s] loss:0.741948371226463:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 19.46it/s]loss:1.3513067895668285:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 19.46it/s]loss:1.2470298726781248:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 19.46it/s]loss:1.2470298726781248: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 18.66it/s]
Epoch: 17 cost time: 1.599931240081787
Epoch: 17, Steps: 19 | Train Loss: 0.1990148 Vali Loss: 3.0603969 Test Loss: 39.4306412
Validation loss decreased (3.060397 --> 3.060397).  Saving model ...
Updating learning rate to 1.52587890625e-09
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 13.53it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 13.53it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 13.53it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 16.10it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 16.10it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 16.10it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 16.10it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 18.99it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 18.99it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 18.99it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 18.99it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 15.73it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 15.73it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 15.73it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 15.73it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 17.74it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 17.74it/s]loss:0.060032558017540795:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 17.74it/s]loss:0.33727915854469726:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 17.74it/s] loss:0.33727915854469726:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 19.15it/s]loss:0.776857727924467:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 19.15it/s]  loss:0.9501179777891898:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 19.15it/s]loss:1.5865780572324102:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 19.15it/s]loss:1.5865780572324102: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 20.07it/s]loss:1.5865780572324102: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 17.38it/s]
Epoch: 18 cost time: 1.6493587493896484
Epoch: 18, Steps: 19 | Train Loss: 0.1953087 Vali Loss: 3.0603969 Test Loss: 39.4306412
Validation loss decreased (3.060397 --> 3.060397).  Saving model ...
Updating learning rate to 7.62939453125e-10
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 16.22it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 16.22it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 16.22it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 11.62it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 11.62it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 11.62it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 12.67it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 12.67it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 12.67it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 14.49it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 14.49it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 14.49it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 14.49it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 16.99it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 16.99it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 16.99it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 16.99it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 18.39it/s]loss:0.07810362333235686:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 18.39it/s]loss:0.360195341496473:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 18.39it/s]  loss:0.8645779391807423:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 18.39it/s]loss:0.8645779391807423:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 19.27it/s]loss:1.2088213600925877:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 19.27it/s]loss:1.277601549918969:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 19.27it/s] loss:1.277601549918969: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 16.41it/s]
Epoch: 19 cost time: 1.726905345916748
Epoch: 19, Steps: 19 | Train Loss: 0.1994368 Vali Loss: 3.0603969 Test Loss: 39.4306412
Validation loss decreased (3.060397 --> 3.060397).  Saving model ...
Updating learning rate to 3.814697265625e-10
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 13.45it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 13.45it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 13.45it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 13.45it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 18.68it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 18.68it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 18.68it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 18.68it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 20.24it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 20.24it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 20.24it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 20.24it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 20.79it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 20.79it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 20.79it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 20.79it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.34it/s]loss:0.060482085617792614:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.34it/s]loss:0.4686217349116793:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.34it/s]  loss:0.618345111298457:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.34it/s] loss:0.618345111298457:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 18.82it/s]loss:1.3827888295130895:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 18.82it/s]loss:1.4830919228429513:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 18.82it/s]loss:1.4830919228429513: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 18.36it/s]
Epoch: 20 cost time: 1.5640621185302734
Epoch: 20, Steps: 19 | Train Loss: 0.2112279 Vali Loss: 3.0603969 Test Loss: 39.4306412
Validation loss decreased (3.060397 --> 3.060397).  Saving model ...
Updating learning rate to 1.9073486328125e-10
>>>>>>>testing : long_term_forecast_break_bartlett_0_FiLM_job_demand_region_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 4
test shape: (4, 1, 3, 16345) (4, 1, 3, 16345)
test shape: (4, 3, 16345) (4, 3, 16345)
mse:35634.08203125, mae:34.467811584472656, dtw:-999
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           0                   Model:              FiLM                

[1mData Loader[0m
  Data:               job_demand_region   Root Path:          ../../dataset/demand/
  Data Path:          region.parquet      Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        .cache/checkpoints  

[1mForecasting Task[0m
  Seq Len:            6                   Label Len:          1                   
  Pred Len:           3                   Seasonal Patterns:  Monthly             
  Inverse:            1                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             16345               Dec In:             16345               
  C Out:              16345               d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           2                   d FF:               2048                
  Moving Avg:         25                  Factor:             1                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              learned             Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        32                  Itr:                1                   
  Train Epochs:       20                  Batch Size:         1                   
  Patience:           3                   Learning Rate:      0.0001              
  Des:                test                Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1                 

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_break_parzen_0_FiLM_job_demand_region_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 19
val 1
test 4
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:09,  1.90it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:09,  1.90it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:09,  1.90it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:09,  1.90it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:02,  7.27it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:02,  7.27it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:02,  7.27it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:02,  7.27it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 11.34it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 11.34it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 11.34it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 11.34it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 14.29it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 14.29it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:00, 14.29it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:00, 14.29it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 16.51it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 16.51it/s]loss:0.0003594242660931336:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 16.51it/s]loss:0.06932413754565332:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 16.51it/s]  loss:0.06932413754565332:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 18.15it/s]loss:0.3693954011205533:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 18.15it/s] loss:0.8822229228236489:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 18.15it/s]loss:1.7836621163871105:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 18.15it/s]loss:1.7836621163871105: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 19.24it/s]loss:1.7836621163871105: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 13.66it/s]
Epoch: 1 cost time: 1.909980058670044
Epoch: 1, Steps: 19 | Train Loss: 0.1634192 Vali Loss: 3.0625210 Test Loss: 39.4097099
Validation loss decreased (inf --> 3.062521).  Saving model ...
Updating learning rate to 0.0001
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 16.86it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 16.86it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 16.86it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 16.86it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 20.33it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 20.33it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 20.33it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 20.33it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 20.80it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 20.80it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 20.80it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 20.80it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 20.81it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 20.81it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 20.81it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 20.81it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.27it/s]loss:0.0002868034781295921:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.27it/s]loss:0.06747344698415839:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.27it/s]  loss:0.3804883740744552:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.27it/s] loss:0.3804883740744552:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 21.54it/s]loss:0.9498626607768882:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 21.54it/s]loss:1.1857057487392155:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 21.54it/s]loss:1.1857057487392155: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 19.82it/s]
Epoch: 2 cost time: 1.4971718788146973
Epoch: 2, Steps: 19 | Train Loss: 0.1359904 Vali Loss: 3.0617497 Test Loss: 39.4274826
Validation loss decreased (3.062521 --> 3.061750).  Saving model ...
Updating learning rate to 5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:00, 19.00it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:00, 19.00it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:00, 19.00it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:00, 19.00it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 21.29it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 21.29it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 21.29it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 21.29it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 21.93it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 21.93it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 21.93it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 21.93it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.49it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.49it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.49it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.49it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.00it/s]loss:0.0002565681268576223:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.00it/s]loss:0.05969674829520414:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.00it/s]  loss:0.5105569189510969:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.00it/s] loss:0.5105569189510969:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 21.31it/s]loss:0.9411405458327903:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 21.31it/s]loss:1.4437517280017953:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 21.31it/s]loss:1.4437517280017953: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 20.17it/s]
Epoch: 3 cost time: 1.4678475856781006
Epoch: 3, Steps: 19 | Train Loss: 0.1555475 Vali Loss: 3.0616150 Test Loss: 39.4337616
Validation loss decreased (3.061750 --> 3.061615).  Saving model ...
Updating learning rate to 2.5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:00, 17.17it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:00, 17.17it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:00, 17.17it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:00, 17.17it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 20.64it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 20.64it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 20.64it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 20.64it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 21.67it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 21.67it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 21.67it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 21.67it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 22.03it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 22.03it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 22.03it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 22.03it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 22.15it/s]loss:0.00038360352851060935:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 22.15it/s]loss:0.06935696355830069:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 22.15it/s]   loss:0.38043193600203684:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 22.15it/s]loss:0.38043193600203684:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 22.09it/s]loss:0.9749554910497628:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 22.09it/s] loss:1.4426289669263304:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 22.09it/s]loss:1.4426289669263304: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 20.38it/s]
Epoch: 4 cost time: 1.4400603771209717
Epoch: 4, Steps: 19 | Train Loss: 0.1509346 Vali Loss: 3.0615604 Test Loss: 39.4335594
Validation loss decreased (3.061615 --> 3.061560).  Saving model ...
Updating learning rate to 1.25e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:00, 17.45it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:00, 17.45it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:00, 17.45it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:00, 17.45it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 20.47it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 20.47it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 20.47it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 20.47it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 21.35it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 21.35it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 21.35it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 21.35it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.66it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.66it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.66it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.66it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.78it/s]loss:0.000357476581791588:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.78it/s]loss:0.06934100336190378:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.78it/s] loss:0.40773302618592566:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.78it/s]loss:0.40773302618592566:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 21.66it/s]loss:0.9355951918353733:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 21.66it/s] loss:1.7759554647441433:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 21.66it/s]loss:1.7759554647441433: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 20.23it/s]
Epoch: 5 cost time: 1.4477460384368896
Epoch: 5, Steps: 19 | Train Loss: 0.1678412 Vali Loss: 3.0614133 Test Loss: 39.4326401
Validation loss decreased (3.061560 --> 3.061413).  Saving model ...
Updating learning rate to 6.25e-06
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 16.11it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 16.11it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 16.11it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 16.11it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 20.17it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 20.17it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 20.17it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 20.17it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 20.58it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 20.58it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 20.58it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 20.58it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.17it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.17it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.17it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.17it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.46it/s]loss:0.0002841019206722328:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.46it/s]loss:0.05928158625306128:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.46it/s]  loss:0.5101625779521706:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.46it/s] loss:0.5101625779521706:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 21.70it/s]loss:1.1009653255334015:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 21.70it/s]loss:1.44193537713203:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 21.70it/s]  loss:1.44193537713203: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 20.05it/s]
Epoch: 6 cost time: 1.4205613136291504
Epoch: 6, Steps: 19 | Train Loss: 0.1638226 Vali Loss: 3.0612900 Test Loss: 39.4327888
Validation loss decreased (3.061413 --> 3.061290).  Saving model ...
Updating learning rate to 3.125e-06
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 16.90it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 16.90it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 16.90it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 16.90it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 20.65it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 20.65it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 20.65it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 20.65it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 21.44it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 21.44it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 21.44it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 21.44it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.75it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.75it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.75it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.75it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.66it/s]loss:0.0002740988636545645:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.66it/s]loss:0.05820438673340802:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.66it/s]  loss:0.36513848187280806:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.66it/s]loss:0.36513848187280806:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 21.69it/s]loss:1.0681740182833164:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 21.69it/s] loss:1.2781448974906218:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 21.69it/s]loss:1.2781448974906218: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 20.24it/s]
Epoch: 7 cost time: 1.4780590534210205
Epoch: 7, Steps: 19 | Train Loss: 0.1457861 Vali Loss: 3.0612235 Test Loss: 39.4326935
Validation loss decreased (3.061290 --> 3.061224).  Saving model ...
Updating learning rate to 1.5625e-06
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 15.75it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 15.75it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 15.75it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 15.75it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 19.64it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 19.64it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 19.64it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 19.64it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 20.88it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 20.88it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 20.88it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 20.88it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.52it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.52it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.52it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.52it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.73it/s]loss:0.00030629904301720845:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.73it/s]loss:0.07406225630750654:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.73it/s]   loss:0.3411364846158001:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.73it/s] loss:0.3411364846158001:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 21.77it/s]loss:0.9243815617147719:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 21.77it/s]loss:1.6415991119466724:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 21.77it/s]loss:1.6415991119466724: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 20.03it/s]
Epoch: 8 cost time: 1.4495885372161865
Epoch: 8, Steps: 19 | Train Loss: 0.1569203 Vali Loss: 3.0612140 Test Loss: 39.4326859
Validation loss decreased (3.061224 --> 3.061214).  Saving model ...
Updating learning rate to 7.8125e-07
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 14.96it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 14.96it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 14.96it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 14.96it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 19.40it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 19.40it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 19.40it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 19.40it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 20.73it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 20.73it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 20.73it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 20.73it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.13it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.13it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.13it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.13it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.48it/s]loss:0.00025512302073819567:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.48it/s]loss:0.06930272407936032:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.48it/s]   loss:0.36512502928013457:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.48it/s]loss:0.36512502928013457:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 21.45it/s]loss:0.9745350105707106:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 21.45it/s] loss:1.6415635346870436:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 21.45it/s]loss:1.6415635346870436: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 19.74it/s]
Epoch: 9 cost time: 1.4732863903045654
Epoch: 9, Steps: 19 | Train Loss: 0.1605674 Vali Loss: 3.0612030 Test Loss: 39.4326553
Validation loss decreased (3.061214 --> 3.061203).  Saving model ...
Updating learning rate to 3.90625e-07
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:00, 17.32it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:00, 17.32it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:00, 17.32it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:00, 17.32it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 20.76it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 20.76it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 20.76it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 20.76it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 21.73it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 21.73it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 21.73it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 21.73it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 22.00it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 22.00it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 22.00it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 22.00it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 22.03it/s]loss:0.00039229098772803066:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 22.03it/s]loss:0.06615838013229049:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 22.03it/s]   loss:0.4716714333760433:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 22.03it/s] loss:0.4716714333760433:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 22.14it/s]loss:1.06809839952912:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 22.14it/s]  loss:1.4763834724939284:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 22.14it/s]loss:1.4763834724939284: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 20.62it/s]
Epoch: 10 cost time: 1.4025752544403076
Epoch: 10, Steps: 19 | Train Loss: 0.1622476 Vali Loss: 3.0611980 Test Loss: 39.4326172
Validation loss decreased (3.061203 --> 3.061198).  Saving model ...
Updating learning rate to 1.953125e-07
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 16.66it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 16.66it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 16.66it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 16.66it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 20.38it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 20.38it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 20.38it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 20.38it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 21.26it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 21.26it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 21.26it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 21.26it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.59it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.59it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.59it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.59it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.84it/s]loss:0.00028407594634616057:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.84it/s]loss:0.06174373463180468:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.84it/s]   loss:0.365120937025838:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.84it/s]  loss:0.365120937025838:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 21.73it/s]loss:1.1006395453323974:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 21.73it/s]loss:1.6415351353970495:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 21.73it/s]loss:1.6415351353970495: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 20.04it/s]
Epoch: 11 cost time: 1.4470314979553223
Epoch: 11, Steps: 19 | Train Loss: 0.1668065 Vali Loss: 3.0611942 Test Loss: 39.4326096
Validation loss decreased (3.061198 --> 3.061194).  Saving model ...
Updating learning rate to 9.765625e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 12.68it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 12.68it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 12.68it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 12.68it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 17.62it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 17.62it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 17.62it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 17.62it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 19.77it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 19.77it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 19.77it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 19.77it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 20.77it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 20.77it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 20.77it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 20.77it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.30it/s]loss:0.000320836962123339:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.30it/s]loss:0.0828088357921083:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.30it/s]  loss:0.5219384251051756:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.30it/s]loss:0.5219384251051756:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 21.51it/s]loss:1.0680909100404747:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 21.51it/s]loss:1.6415303664669167:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 21.51it/s]loss:1.6415303664669167: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 19.39it/s]
Epoch: 12 cost time: 1.5497207641601562
Epoch: 12, Steps: 19 | Train Loss: 0.1744573 Vali Loss: 3.0611920 Test Loss: 39.4325943
Validation loss decreased (3.061194 --> 3.061192).  Saving model ...
Updating learning rate to 4.8828125e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:00, 17.25it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:00, 17.25it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:00, 17.25it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:00, 17.25it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 20.68it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 20.68it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 20.68it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 20.68it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 21.74it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 21.74it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 21.74it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 21.74it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.99it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.99it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.99it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.99it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.91it/s]loss:0.00025511897166950655:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.91it/s]loss:0.08280875677967069:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.91it/s]   loss:0.3651196073028376:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.91it/s] loss:0.3651196073028376:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 21.86it/s]loss:1.2253982982176703:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 21.86it/s]loss:1.4182492728510057:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 21.86it/s]loss:1.4182492728510057: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 20.15it/s]
Epoch: 13 cost time: 1.478032112121582
Epoch: 13, Steps: 19 | Train Loss: 0.1627280 Vali Loss: 3.0611911 Test Loss: 39.4325905
Validation loss decreased (3.061192 --> 3.061191).  Saving model ...
Updating learning rate to 2.44140625e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 15.03it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 15.03it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 15.03it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 15.03it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 19.42it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 19.42it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 19.42it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 19.42it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 20.81it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 20.81it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 20.81it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 20.81it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.53it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.53it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.53it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.53it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.81it/s]loss:0.0002760085835501477:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.81it/s]loss:0.0672517803298935:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.81it/s]   loss:0.5219372296756402:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.81it/s]loss:0.5219372296756402:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 21.88it/s]loss:1.0507069334695067:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 21.88it/s]loss:1.3246226799638392:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 21.88it/s]loss:1.3246226799638392: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 20.11it/s]
Epoch: 14 cost time: 1.4802377223968506
Epoch: 14, Steps: 19 | Train Loss: 0.1560418 Vali Loss: 3.0611904 Test Loss: 39.4325829
Validation loss decreased (3.061191 --> 3.061190).  Saving model ...
Updating learning rate to 1.220703125e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 15.20it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 15.20it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 15.20it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 15.20it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 18.94it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 18.94it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 18.94it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 18.94it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 20.61it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 20.61it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 20.61it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 20.61it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.20it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.20it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.20it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.20it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.62it/s]loss:0.0003922863812104135:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.62it/s]loss:0.06930058662491774:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.62it/s]  loss:0.3394353958031328:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.62it/s] loss:0.3394353958031328:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 21.68it/s]loss:0.9468471968565577:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 21.68it/s]loss:1.2477074879679328:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 21.68it/s]loss:1.2477074879679328: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 19.63it/s]
Epoch: 15 cost time: 1.5279643535614014
Epoch: 15, Steps: 19 | Train Loss: 0.1370359 Vali Loss: 3.0611904 Test Loss: 39.4325829
Validation loss decreased (3.061190 --> 3.061190).  Saving model ...
Updating learning rate to 6.103515625e-09
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:00, 17.60it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:00, 17.60it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:00, 17.60it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:00, 17.60it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 20.89it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 20.89it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 20.89it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 20.89it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 21.65it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 21.65it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 21.65it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 21.65it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.56it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.56it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.56it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.56it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.65it/s]loss:0.0002840749879493973:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.65it/s]loss:0.06930058430208776:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.65it/s]  loss:0.3672292779147035:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.65it/s] loss:0.3672292779147035:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 21.48it/s]loss:1.3457383367574909:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 21.48it/s]loss:1.6415264007459056:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 21.48it/s]loss:1.6415264007459056: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 19.86it/s]
Epoch: 16 cost time: 1.505722999572754
Epoch: 16, Steps: 19 | Train Loss: 0.1802147 Vali Loss: 3.0611904 Test Loss: 39.4325790
Validation loss decreased (3.061190 --> 3.061190).  Saving model ...
Updating learning rate to 3.0517578125e-09
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 17.00it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 17.00it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 17.00it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 17.00it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 20.58it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 20.58it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 20.58it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 20.58it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 21.29it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 21.29it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 21.29it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 21.29it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.60it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.60it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.60it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.60it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.82it/s]loss:0.0003545030336796737:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.82it/s]loss:0.0592753102520708:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.82it/s]   loss:0.4075104175785854:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.82it/s]loss:0.4075104175785854:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 20.57it/s]loss:1.315162963543897:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 20.57it/s] loss:1.2477074146328009:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 20.57it/s]loss:1.2477074146328009: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 19.74it/s]
Epoch: 17 cost time: 1.476370096206665
Epoch: 17, Steps: 19 | Train Loss: 0.1594742 Vali Loss: 3.0611904 Test Loss: 39.4325790
Validation loss decreased (3.061190 --> 3.061190).  Saving model ...
Updating learning rate to 1.52587890625e-09
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 14.30it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 14.30it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 14.30it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 14.30it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 19.18it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 19.18it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 19.18it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 19.18it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 20.60it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 20.60it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 20.60it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 20.60it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.06it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.06it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.06it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.06it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.43it/s]loss:0.0002725861082495674:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.43it/s]loss:0.055105619859385634:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.43it/s] loss:0.42687232084500365:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.43it/s] loss:0.42687232084500365:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 19.31it/s]loss:0.9243624221079326:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 19.31it/s] loss:1.587658751862262:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 19.31it/s] loss:1.587658751862262: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 18.77it/s]
Epoch: 18 cost time: 1.5612568855285645
Epoch: 18, Steps: 19 | Train Loss: 0.1575932 Vali Loss: 3.0611904 Test Loss: 39.4325790
Validation loss decreased (3.061190 --> 3.061190).  Saving model ...
Updating learning rate to 7.62939453125e-10
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 16.67it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 16.67it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 16.67it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 16.67it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 20.26it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 20.26it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 20.26it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 20.26it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 19.60it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 19.60it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 19.60it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 19.60it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 20.51it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 20.51it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 20.51it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 20.51it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 20.96it/s]loss:0.0003545030245715508:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 20.96it/s]loss:0.058878598549158556:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 20.96it/s] loss:0.47526231138709046:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 20.96it/s] loss:0.47526231138709046:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 20.83it/s]loss:1.1762149393255:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 20.83it/s]    loss:1.2780571857120147:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 20.83it/s]loss:1.2780571857120147: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 19.50it/s]
Epoch: 19 cost time: 1.50223708152771
Epoch: 19, Steps: 19 | Train Loss: 0.1573036 Vali Loss: 3.0611904 Test Loss: 39.4325790
Validation loss decreased (3.061190 --> 3.061190).  Saving model ...
Updating learning rate to 3.814697265625e-10
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 15.84it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 15.84it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 15.84it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 15.84it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 19.99it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 19.99it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 19.99it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 19.99it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 21.12it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 21.12it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 21.12it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 21.12it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.47it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.47it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.47it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.47it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.55it/s]loss:0.00027442273063294165:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.55it/s]loss:0.07657265278125444:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.55it/s]   loss:0.3394353074717279:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.55it/s] loss:0.3394353074717279:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 21.44it/s]loss:1.3457381751268023:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 21.44it/s]loss:1.485631097807927:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 21.44it/s] loss:1.485631097807927: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 19.90it/s]
Epoch: 20 cost time: 1.5645513534545898
Epoch: 20, Steps: 19 | Train Loss: 0.1709290 Vali Loss: 3.0611904 Test Loss: 39.4325790
Validation loss decreased (3.061190 --> 3.061190).  Saving model ...
Updating learning rate to 1.9073486328125e-10
>>>>>>>testing : long_term_forecast_break_parzen_0_FiLM_job_demand_region_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 4
test shape: (4, 1, 3, 16345) (4, 1, 3, 16345)
test shape: (4, 3, 16345) (4, 3, 16345)
mse:35663.359375, mae:34.482322692871094, dtw:-999
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           0                   Model:              FiLM                

[1mData Loader[0m
  Data:               job_demand_region   Root Path:          ../../dataset/demand/
  Data Path:          region.parquet      Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        .cache/checkpoints  

[1mForecasting Task[0m
  Seq Len:            6                   Label Len:          1                   
  Pred Len:           3                   Seasonal Patterns:  Monthly             
  Inverse:            1                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             16345               Dec In:             16345               
  C Out:              16345               d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           2                   d FF:               2048                
  Moving Avg:         25                  Factor:             1                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              learned             Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        32                  Itr:                1                   
  Train Epochs:       20                  Batch Size:         1                   
  Patience:           3                   Learning Rate:      0.0001              
  Des:                test                Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1                 

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_break_tukey-hanning_0_FiLM_job_demand_region_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 19
val 1
test 4
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:09,  1.87it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:09,  1.87it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:09,  1.87it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:09,  1.87it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:02,  7.13it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:02,  7.13it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:02,  7.13it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:02,  7.13it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 11.23it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 11.23it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 11.23it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 11.23it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 14.13it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 14.13it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:00, 14.13it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:00, 14.13it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 16.43it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 16.43it/s]loss:0.009294506499194895:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 16.43it/s]loss:0.27976826903703844:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 16.43it/s] loss:0.27976826903703844:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 18.02it/s]loss:0.6908329949690576:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 18.02it/s] loss:1.0318602725944634:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 18.02it/s]loss:1.7834118704033461:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 18.02it/s]loss:1.7834118704033461: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 19.01it/s]loss:1.7834118704033461: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 13.53it/s]
Epoch: 1 cost time: 1.9263427257537842
Epoch: 1, Steps: 19 | Train Loss: 0.1997457 Vali Loss: 3.0624468 Test Loss: 39.4097214
Validation loss decreased (inf --> 3.062447).  Saving model ...
Updating learning rate to 0.0001
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:00, 17.51it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:00, 17.51it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:00, 17.51it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 18.68it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 18.68it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 18.68it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 18.68it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 20.90it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 20.90it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 20.90it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 20.90it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 21.75it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 21.75it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 21.75it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 21.75it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 21.81it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 21.81it/s]loss:0.007415060041326868:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 21.81it/s]loss:0.2722468577080292:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 21.81it/s]  loss:0.2722468577080292:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 21.87it/s]loss:0.7115346654309244:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 21.87it/s]loss:1.110713198910881:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 21.87it/s] loss:1.185309013879953:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 21.87it/s]loss:1.185309013879953: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 21.81it/s]loss:1.185309013879953: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 19.90it/s]
Epoch: 2 cost time: 1.5020782947540283
Epoch: 2, Steps: 19 | Train Loss: 0.1730115 Vali Loss: 3.0615723 Test Loss: 39.4277878
Validation loss decreased (3.062447 --> 3.061572).  Saving model ...
Updating learning rate to 5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 16.62it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 16.62it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 16.62it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 16.62it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 20.41it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 20.41it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 20.41it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 20.41it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 21.55it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 21.55it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 21.55it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 21.55it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 22.00it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 22.00it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 22.00it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 22.00it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 22.10it/s]loss:0.006633127711444287:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 22.10it/s]loss:0.2408509256750132:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 22.10it/s]  loss:0.9545629430552522:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 22.10it/s]loss:0.9545629430552522:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 22.06it/s]loss:1.1006589837588554:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 22.06it/s]loss:1.4431684082154839:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 22.06it/s]loss:1.4431684082154839: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 20.28it/s]
Epoch: 3 cost time: 1.579244613647461
Epoch: 3, Steps: 19 | Train Loss: 0.1971513 Vali Loss: 3.0613554 Test Loss: 39.4332886
Validation loss decreased (3.061572 --> 3.061355).  Saving model ...
Updating learning rate to 2.5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 16.06it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 16.06it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 16.06it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 16.06it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 20.13it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 20.13it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 20.13it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 20.13it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 21.21it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 21.21it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 21.21it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 21.21it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.69it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.69it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.69it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.69it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 22.03it/s]loss:0.009915331326886587:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 22.03it/s]loss:0.2797592815506173:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 22.03it/s]  loss:0.7113083228051262:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 22.03it/s]loss:0.7113083228051262:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 22.19it/s]loss:1.1400585664886576:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 22.19it/s]loss:1.4420160737257948:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 22.19it/s]loss:1.4420160737257948: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 20.21it/s]
Epoch: 4 cost time: 1.4244298934936523
Epoch: 4, Steps: 19 | Train Loss: 0.1885820 Vali Loss: 3.0612361 Test Loss: 39.4331818
Validation loss decreased (3.061355 --> 3.061236).  Saving model ...
Updating learning rate to 1.25e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 14.96it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 14.96it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 14.96it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 14.96it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 17.98it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 17.98it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 17.98it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 17.98it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 19.55it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 19.55it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 19.55it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 19.55it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 20.69it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 20.69it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 20.69it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 20.69it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.28it/s]loss:0.009235014259011645:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.28it/s]loss:0.27962304570527596:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.28it/s] loss:0.7620009095918306:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.28it/s] loss:0.7620009095918306:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 21.51it/s]loss:1.0936110341479635:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 21.51it/s]loss:1.7750399725833423:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 21.51it/s]loss:1.7750399725833423: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 19.57it/s]
Epoch: 5 cost time: 1.5343687534332275
Epoch: 5, Steps: 19 | Train Loss: 0.2062900 Vali Loss: 3.0610240 Test Loss: 39.4318352
Validation loss decreased (3.061236 --> 3.061024).  Saving model ...
Updating learning rate to 6.25e-06
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 16.19it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 16.19it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 16.19it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 16.19it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 19.46it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 19.46it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 19.46it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 19.46it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 21.23it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 21.23it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 21.23it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 21.23it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.70it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.70it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.70it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.70it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.85it/s]loss:0.00734455167656006:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.85it/s]loss:0.23918419440001337:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.85it/s]loss:0.9535960962322546:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.85it/s] loss:0.9535960962322546:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 21.91it/s]loss:1.2865583635778153:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 21.91it/s]loss:1.441322645916384:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 21.91it/s] loss:1.441322645916384: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 19.96it/s]
Epoch: 6 cost time: 1.48252534866333
Epoch: 6, Steps: 19 | Train Loss: 0.2067372 Vali Loss: 3.0608742 Test Loss: 39.4317932
Validation loss decreased (3.061024 --> 3.060874).  Saving model ...
Updating learning rate to 3.125e-06
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:00, 17.25it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:00, 17.25it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:00, 17.25it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:00, 17.25it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 20.83it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 20.83it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 20.83it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 20.83it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 21.28it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 21.28it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 21.28it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 21.28it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.93it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.93it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.93it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.93it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 22.33it/s]loss:0.007088222046985907:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 22.33it/s]loss:0.23482314616429598:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 22.33it/s] loss:0.6826988063424342:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 22.33it/s] loss:0.6826988063424342:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 22.39it/s]loss:1.2488472257876277:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 22.39it/s]loss:1.2777923256221881:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 22.39it/s]loss:1.2777923256221881: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 20.71it/s]
Epoch: 7 cost time: 1.4455571174621582
Epoch: 7, Steps: 19 | Train Loss: 0.1816447 Vali Loss: 3.0608015 Test Loss: 39.4317474
Validation loss decreased (3.060874 --> 3.060802).  Saving model ...
Updating learning rate to 1.5625e-06
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 16.09it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 16.09it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 16.09it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 16.09it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 19.98it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 19.98it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 19.98it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 19.98it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 20.43it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 20.43it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 20.43it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 20.43it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.26it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.26it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.26it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.26it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.65it/s]loss:0.007914764328351778:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.65it/s]loss:0.298774863349662:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.65it/s]   loss:0.6377313873874356:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.65it/s]loss:0.6377313873874356:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 21.67it/s]loss:1.080849105373033:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 21.67it/s] loss:1.6408057322841065:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 21.67it/s]loss:1.6408057322841065: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 20.05it/s]
Epoch: 8 cost time: 1.4679603576660156
Epoch: 8, Steps: 19 | Train Loss: 0.1929514 Vali Loss: 3.0607886 Test Loss: 39.4317474
Validation loss decreased (3.060802 --> 3.060789).  Saving model ...
Updating learning rate to 7.8125e-07
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 16.92it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 16.92it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 16.92it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 16.92it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 20.24it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 20.24it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 20.24it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 20.24it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 21.28it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 21.28it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 21.28it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 21.28it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.49it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.49it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.49it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.49it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.49it/s]loss:0.006594704425091708:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.49it/s]loss:0.27942212447661235:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.49it/s] loss:0.6826671857519407:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.49it/s] loss:0.6826671857519407:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 20.04it/s]loss:1.1395089674145373:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 20.04it/s]loss:1.6407693457677441:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 20.04it/s]loss:1.6407693457677441: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 19.32it/s]
Epoch: 9 cost time: 1.498852252960205
Epoch: 9, Steps: 19 | Train Loss: 0.1973138 Vali Loss: 3.0607760 Test Loss: 39.4317284
Validation loss decreased (3.060789 --> 3.060776).  Saving model ...
Updating learning rate to 3.90625e-07
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 16.58it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 16.58it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 16.58it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 16.58it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 20.22it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 20.22it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 20.22it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 20.22it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 21.36it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 21.36it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 21.36it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 21.36it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.79it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.79it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.79it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.79it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.75it/s]loss:0.010138930176010015:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.75it/s]loss:0.26679537462432074:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.75it/s] loss:0.8816815763504837:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.75it/s] loss:0.8816815763504837:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 21.64it/s]loss:1.2487564172699626:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 21.64it/s]loss:1.475233807809567:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 21.64it/s] loss:1.475233807809567: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 20.17it/s]
Epoch: 10 cost time: 1.48325777053833
Epoch: 10, Steps: 19 | Train Loss: 0.2043477 Vali Loss: 3.0607698 Test Loss: 39.4316864
Validation loss decreased (3.060776 --> 3.060770).  Saving model ...
Updating learning rate to 1.953125e-07
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:00, 17.36it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:00, 17.36it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:00, 17.36it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:00, 17.36it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 20.31it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 20.31it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 20.31it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 20.31it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 21.25it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 21.25it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 21.25it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 21.25it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.62it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.62it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.62it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.62it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 22.11it/s]loss:0.007343805666608667:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 22.11it/s]loss:0.2490952004660264:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 22.11it/s]  loss:0.6826574982145054:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 22.11it/s]loss:0.6826574982145054:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 22.18it/s]loss:1.2861273945804659:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 22.18it/s]loss:1.6407385436741224:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 22.18it/s]loss:1.6407385436741224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 20.34it/s]
Epoch: 11 cost time: 1.5313234329223633
Epoch: 11, Steps: 19 | Train Loss: 0.2034717 Vali Loss: 3.0607660 Test Loss: 39.4316711
Validation loss decreased (3.060770 --> 3.060766).  Saving model ...
Updating learning rate to 9.765625e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:00, 17.26it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:00, 17.26it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:00, 17.26it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:00, 17.26it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 19.91it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 19.91it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 19.91it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 19.91it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 20.44it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 20.44it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 20.44it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 20.44it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.17it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.17it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.17it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.17it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.26it/s]loss:0.00828876996412538:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.26it/s]loss:0.33401076521857453:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.26it/s]loss:0.9755871902289255:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.26it/s] loss:0.9755871902289255:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 21.54it/s]loss:1.2487467366054494:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 21.54it/s]loss:1.6407335941857835:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 21.54it/s]loss:1.6407335941857835: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 19.76it/s]
Epoch: 12 cost time: 1.7098126411437988
Epoch: 12, Steps: 19 | Train Loss: 0.2214404 Vali Loss: 3.0607634 Test Loss: 39.4316597
Validation loss decreased (3.060766 --> 3.060763).  Saving model ...
Updating learning rate to 4.8828125e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:00, 17.18it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:00, 17.18it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:00, 17.18it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:00, 17.18it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 19.64it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 19.64it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 19.64it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 19.64it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 21.17it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 21.17it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 21.17it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 21.17it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.70it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.70it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.70it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.70it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.57it/s]loss:0.006594591501155705:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.57it/s]loss:0.334010292839577:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.57it/s]   loss:0.682654768796203:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.57it/s]loss:0.682654768796203:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 21.69it/s]loss:1.431641089361256:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 21.69it/s]loss:1.4171777868814883:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 21.69it/s]loss:1.4171777868814883: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 19.90it/s]
Epoch: 13 cost time: 1.5503020286560059
Epoch: 13, Steps: 19 | Train Loss: 0.2037936 Vali Loss: 3.0607626 Test Loss: 39.4316521
Validation loss decreased (3.060763 --> 3.060763).  Saving model ...
Updating learning rate to 2.44140625e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 16.53it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 16.53it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 16.53it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 16.53it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 20.47it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 20.47it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 20.47it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 20.47it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 21.43it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 21.43it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 21.43it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 21.43it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.76it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.76it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.76it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.76it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.94it/s]loss:0.007135482505000057:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.94it/s]loss:0.2712930708961177:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.94it/s]  loss:0.9755845335861295:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.94it/s]loss:0.9755845335861295:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 21.96it/s]loss:1.2280198986196966:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 21.96it/s]loss:1.3241388307030053:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 21.96it/s]loss:1.3241388307030053: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 20.11it/s]
Epoch: 14 cost time: 1.5282189846038818
Epoch: 14, Steps: 19 | Train Loss: 0.2003248 Vali Loss: 3.0607622 Test Loss: 39.4316483
Validation loss decreased (3.060763 --> 3.060762).  Saving model ...
Updating learning rate to 1.220703125e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:00, 19.61it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:00, 19.61it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:00, 19.61it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:00, 19.61it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 20.95it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 20.95it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 20.95it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 20.95it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 19.84it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 19.84it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 19.84it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 19.84it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 19.97it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 19.97it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 19.97it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 19.97it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 20.47it/s]loss:0.010138795313802506:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 20.47it/s]loss:0.2794115754300289:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 20.47it/s]  loss:0.6345498303038015:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 20.47it/s]loss:0.6345498303038015:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 20.50it/s]loss:1.1071685332080234:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 20.50it/s]loss:1.2473069649966635:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 20.50it/s]loss:1.2473069649966635: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 19.32it/s]
Epoch: 15 cost time: 1.5031075477600098
Epoch: 15, Steps: 19 | Train Loss: 0.1725566 Vali Loss: 3.0607617 Test Loss: 39.4316444
Validation loss decreased (3.060762 --> 3.060762).  Saving model ...
Updating learning rate to 6.103515625e-09
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 16.62it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 16.62it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 16.62it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 16.62it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 19.84it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 19.84it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 19.84it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 19.84it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 20.79it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 20.79it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 20.79it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 20.79it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 20.85it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 20.85it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 20.85it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 20.85it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 20.85it/s]loss:0.00734377882424577:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 20.85it/s]loss:0.2794115510941197:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 20.85it/s] loss:0.6865964052029552:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 20.85it/s]loss:0.6865964052029552:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 20.95it/s]loss:1.573174269345281:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 20.95it/s] loss:1.640729290145123:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 20.95it/s]loss:1.640729290145123: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 19.66it/s]
Epoch: 16 cost time: 1.4965438842773438
Epoch: 16, Steps: 19 | Train Loss: 0.2203819 Vali Loss: 3.0607617 Test Loss: 39.4316483
Validation loss decreased (3.060762 --> 3.060762).  Saving model ...
Updating learning rate to 3.0517578125e-09
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:00, 17.67it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:00, 17.67it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:00, 17.67it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 18.73it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 18.73it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 18.73it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 18.73it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 20.45it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 20.45it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 20.45it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 20.45it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 21.23it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 21.23it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 21.23it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 21.23it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 21.41it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 21.41it/s]loss:0.009162794686601654:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 21.41it/s]loss:0.23915433108795994:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 21.41it/s] loss:0.23915433108795994:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 21.59it/s]loss:0.7615402711907917:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 21.59it/s] loss:1.5374260827908208:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 21.59it/s]loss:1.2473068805109944:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 21.59it/s]loss:1.2473068805109944: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 21.58it/s]loss:1.2473068805109944: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 19.82it/s]
Epoch: 17 cost time: 1.5754292011260986
Epoch: 17, Steps: 19 | Train Loss: 0.1997153 Vali Loss: 3.0607617 Test Loss: 39.4316483
Validation loss decreased (3.060762 --> 3.060762).  Saving model ...
Updating learning rate to 1.52587890625e-09
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:00, 17.09it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:00, 17.09it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:00, 17.09it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:00, 17.09it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 19.97it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 19.97it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 19.97it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 19.97it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 21.29it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 21.29it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 21.29it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 21.29it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.44it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.44it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.44it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.44it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.77it/s]loss:0.007044099093301726:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.77it/s]loss:0.2223017754037867:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.77it/s]  loss:0.7975666401079442:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.77it/s]loss:0.7975666401079442:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 21.72it/s]loss:1.080823737205879:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 21.72it/s] loss:1.5870165894396964:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 21.72it/s]loss:1.5870165894396964: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 20.03it/s]
Epoch: 18 cost time: 1.493257999420166
Epoch: 18, Steps: 19 | Train Loss: 0.1944607 Vali Loss: 3.0607617 Test Loss: 39.4316483
Validation loss decreased (3.060762 --> 3.060762).  Saving model ...
Updating learning rate to 7.62939453125e-10
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 16.37it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 16.37it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 16.37it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 18.14it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 18.14it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 18.14it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 18.14it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 20.42it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 20.42it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 20.42it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 20.42it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 21.20it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 21.20it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 21.20it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 21.20it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 21.60it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 21.60it/s]loss:0.00916279441503317:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 21.60it/s]loss:0.23745490571095426:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 21.60it/s]loss:0.23745490571095426:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 21.82it/s]loss:0.8878110517365795:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 21.82it/s] loss:1.37519101714529:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 21.82it/s]  loss:1.2777093864119051:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 21.82it/s]loss:1.2777093864119051: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 21.93it/s]loss:1.2777093864119051: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 20.16it/s]
Epoch: 19 cost time: 1.4479405879974365
Epoch: 19, Steps: 19 | Train Loss: 0.1993331 Vali Loss: 3.0607617 Test Loss: 39.4316483
Validation loss decreased (3.060762 --> 3.060762).  Saving model ...
Updating learning rate to 3.814697265625e-10
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 15.24it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 15.24it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 15.24it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 15.24it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 18.94it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 18.94it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 18.94it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 18.94it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 20.35it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 20.35it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 20.35it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 20.35it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.37it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.37it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.37it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.37it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.78it/s]loss:0.007094512353955389:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.78it/s]loss:0.30887562296196813:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.78it/s] loss:0.6345496211655023:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.78it/s] loss:0.6345496211655023:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 21.93it/s]loss:1.5731740677408066:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 21.93it/s]loss:1.4842174611583514:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 21.93it/s]loss:1.4842174611583514: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 20.02it/s]
Epoch: 20 cost time: 1.4186100959777832
Epoch: 20, Steps: 19 | Train Loss: 0.2109427 Vali Loss: 3.0607617 Test Loss: 39.4316444
Validation loss decreased (3.060762 --> 3.060762).  Saving model ...
Updating learning rate to 1.9073486328125e-10
>>>>>>>testing : long_term_forecast_break_tukey-hanning_0_FiLM_job_demand_region_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 4
test shape: (4, 1, 3, 16345) (4, 1, 3, 16345)
test shape: (4, 3, 16345) (4, 3, 16345)
mse:35649.10546875, mae:34.47460174560547, dtw:-999
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           0                   Model:              FiLM                

[1mData Loader[0m
  Data:               job_demand_region   Root Path:          ../../dataset/demand/
  Data Path:          region.parquet      Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        .cache/checkpoints  

[1mForecasting Task[0m
  Seq Len:            6                   Label Len:          1                   
  Pred Len:           3                   Seasonal Patterns:  Monthly             
  Inverse:            1                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             16345               Dec In:             16345               
  C Out:              16345               d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           2                   d FF:               2048                
  Moving Avg:         25                  Factor:             1                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              learned             Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        32                  Itr:                1                   
  Train Epochs:       20                  Batch Size:         1                   
  Patience:           3                   Learning Rate:      0.0001              
  Des:                test                Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1                 

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_break_rayleigh_0_FiLM_job_demand_region_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 19
val 1
test 4
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.5651873353195662:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5651873353195662:   5%|â–Œ         | 1/19 [00:00<00:09,  1.91it/s]loss:0.6426643483617817:   5%|â–Œ         | 1/19 [00:00<00:09,  1.91it/s]loss:0.6690752516832822:   5%|â–Œ         | 1/19 [00:00<00:09,  1.91it/s]loss:0.7575447827107027:   5%|â–Œ         | 1/19 [00:00<00:09,  1.91it/s]loss:0.7575447827107027:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:02,  7.26it/s]loss:0.8755149666051804:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:02,  7.26it/s]loss:0.95077499931122:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:02,  7.26it/s]  loss:0.9192334586007556:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:02,  7.26it/s]loss:0.9192334586007556:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 11.27it/s]loss:1.1751926495652996:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 11.27it/s]loss:1.156146475017894:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 11.27it/s] loss:1.489223882471012:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 11.27it/s]loss:1.489223882471012:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 14.25it/s]loss:1.0826366412782522:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 14.25it/s]loss:1.1049035513910854:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:00, 14.25it/s]loss:1.0863985885859557:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:00, 14.25it/s]loss:1.0863985885859557:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 16.43it/s]loss:1.542703560603711:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 16.43it/s] loss:1.5874668249225166:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 16.43it/s]loss:1.4472474411950091:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 16.43it/s]loss:1.4472474411950091:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 18.15it/s]loss:1.2701313627826056:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 18.15it/s]loss:1.183912202893355:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 18.15it/s] loss:1.7791937719062443:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 18.15it/s]loss:1.7791937719062443: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 19.41it/s]loss:1.7791937719062443: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 13.72it/s]
Epoch: 1 cost time: 1.9121270179748535
Epoch: 1, Steps: 19 | Train Loss: 1.1202712 Vali Loss: 3.0592401 Test Loss: 39.3859291
Validation loss decreased (inf --> 3.059240).  Saving model ...
Updating learning rate to 0.0001
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.5647263303648227:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7171256969835555:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7171256969835555:  11%|â–ˆ         | 2/19 [00:00<00:00, 17.19it/s]loss:0.8637520169311723:  11%|â–ˆ         | 2/19 [00:00<00:00, 17.19it/s]loss:0.9028813248621544:  11%|â–ˆ         | 2/19 [00:00<00:00, 17.19it/s]loss:1.0881481573903362:  11%|â–ˆ         | 2/19 [00:00<00:00, 17.19it/s]loss:1.0881481573903362:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 20.06it/s]loss:0.8290360338612247:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 20.06it/s]loss:0.86938885341444:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 20.06it/s]  loss:0.8752624630876283:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 20.06it/s]loss:0.8752624630876283:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 21.27it/s]loss:1.4119093101718607:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 21.27it/s]loss:1.071245397019769:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 21.27it/s] loss:1.3963839925781962:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 21.27it/s]loss:1.3963839925781962:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.64it/s]loss:1.2504624419539405:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.64it/s]loss:1.1453963863979932:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.64it/s]loss:1.3822977845398765:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.64it/s]loss:1.3822977845398765:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.82it/s]loss:1.26850208159809:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.82it/s]  loss:1.408431458205412:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.82it/s]loss:1.304685287675651:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.82it/s]loss:1.304685287675651:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 21.87it/s]loss:1.2757179479488796:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 21.87it/s]loss:1.1796046807234615:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 21.87it/s]loss:1.1796046807234615: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 20.24it/s]
Epoch: 2 cost time: 1.4832687377929688
Epoch: 2, Steps: 19 | Train Loss: 1.0949978 Vali Loss: 3.0558944 Test Loss: 39.3931580
Validation loss decreased (3.059240 --> 3.055894).  Saving model ...
Updating learning rate to 5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.5533099723069493:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7667796560904254:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7667796560904254:  11%|â–ˆ         | 2/19 [00:00<00:00, 19.99it/s]loss:0.7731155505766341:  11%|â–ˆ         | 2/19 [00:00<00:00, 19.99it/s]loss:0.7457526355482784:  11%|â–ˆ         | 2/19 [00:00<00:00, 19.99it/s]loss:0.7218837865359542:  11%|â–ˆ         | 2/19 [00:00<00:00, 19.99it/s]loss:0.7218837865359542:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 21.68it/s]loss:1.0668787245937974:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 21.68it/s]loss:1.2596410012626862:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 21.68it/s]loss:0.922295581045546:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 21.68it/s] loss:0.922295581045546:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 22.13it/s]loss:1.1418316351626578:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 22.13it/s]loss:1.0309440750570544:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 22.13it/s]loss:1.1226887962390701:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 22.13it/s]loss:1.1226887962390701:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 22.19it/s]loss:1.2434377457240016:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 22.19it/s]loss:1.203184609252755:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 22.19it/s] loss:1.5293523833198313:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 22.19it/s]loss:1.5293523833198313:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 22.04it/s]loss:1.1330914518803885:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 22.04it/s]loss:1.2485293251804623:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 22.04it/s]loss:1.748028425468258:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 22.04it/s] loss:1.748028425468258:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 21.94it/s]loss:1.2649273549471032:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 21.94it/s]loss:1.4360486707906028:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 21.94it/s]loss:1.4360486707906028: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 20.78it/s]
Epoch: 3 cost time: 1.4419267177581787
Epoch: 3, Steps: 19 | Train Loss: 1.1006169 Vali Loss: 3.0545723 Test Loss: 39.3946075
Validation loss decreased (3.055894 --> 3.054572).  Saving model ...
Updating learning rate to 2.5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.7236364107805707:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5708469562345669:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6214841210853047:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6214841210853047:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:00, 20.55it/s]loss:0.7093787199672691:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:00, 20.55it/s]loss:0.8060786110613145:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:00, 20.55it/s]loss:0.9580662616616703:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:00, 20.55it/s]loss:0.9580662616616703:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:00, 22.07it/s]loss:0.9784949712263509:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:00, 22.07it/s]loss:0.9179472920446797:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:00, 22.07it/s]loss:1.227764743087865:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:00, 22.07it/s] loss:1.227764743087865:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 22.17it/s]loss:1.4709599926441757:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 22.17it/s]loss:1.0871236380762792:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 22.17it/s]loss:1.43342613058559:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 22.17it/s]  loss:1.43342613058559:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 22.45it/s]loss:1.1583565263833178:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 22.45it/s]loss:1.184859288449545:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 22.45it/s] loss:1.6946214926119845:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 22.45it/s]loss:1.6946214926119845:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 22.31it/s]loss:1.4301641780378138:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 22.31it/s]loss:1.3024739644863372:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 22.31it/s]loss:1.3029103756250573:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 22.31it/s]loss:1.3029103756250573:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:00<00:00, 21.19it/s]loss:1.4343845554701324:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:00<00:00, 21.19it/s]loss:1.4343845554701324: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 20.16it/s]
Epoch: 4 cost time: 1.5110442638397217
Epoch: 4, Steps: 19 | Train Loss: 1.1059462 Vali Loss: 3.0541017 Test Loss: 39.3948135
Validation loss decreased (3.054572 --> 3.054102).  Saving model ...
Updating learning rate to 1.25e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.7227861930988237:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.612258006750855:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.6936048314275652:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6936048314275652:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:00, 20.09it/s]loss:0.7220563567479671:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:00, 20.09it/s]loss:0.8944427236267349:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:00, 20.09it/s]loss:0.8559224776026447:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:00, 20.09it/s]loss:0.8559224776026447:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:00, 21.02it/s]loss:1.2555067908589836:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:00, 21.02it/s]loss:0.9713643535318595:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:00, 21.02it/s]loss:0.9171098305733949:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:00, 21.02it/s]loss:0.9171098305733949:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 21.60it/s]loss:1.2866414449372636:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 21.60it/s]loss:1.2219550736307534:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 21.60it/s]loss:1.1280459584257807:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 21.60it/s]loss:1.1280459584257807:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 21.31it/s]loss:1.072942858851311:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 21.31it/s] loss:1.1663928028668138:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 21.31it/s]loss:1.5542152921170376:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 21.31it/s]loss:1.5542152921170376:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 21.60it/s]loss:1.4290587593641433:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 21.60it/s]loss:1.3860297455901616:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 21.60it/s]loss:1.239490819980035:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 21.60it/s] loss:1.239490819980035:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:00<00:00, 21.74it/s]loss:1.7625254219826028:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:00<00:00, 21.74it/s]loss:1.7625254219826028: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 20.43it/s]
Epoch: 5 cost time: 1.4364089965820312
Epoch: 5, Steps: 19 | Train Loss: 1.0995974 Vali Loss: 3.0538416 Test Loss: 39.3947906
Validation loss decreased (3.054102 --> 3.053842).  Saving model ...
Updating learning rate to 6.25e-06
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.563664483198616:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5698411549497288:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5698411549497288:  11%|â–ˆ         | 2/19 [00:00<00:01, 16.54it/s]loss:0.6721962926689377:  11%|â–ˆ         | 2/19 [00:00<00:01, 16.54it/s]loss:0.6707804565419063:  11%|â–ˆ         | 2/19 [00:00<00:01, 16.54it/s]loss:0.7605461879312964:  11%|â–ˆ         | 2/19 [00:00<00:01, 16.54it/s]loss:0.7605461879312964:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 20.15it/s]loss:0.9562881966397828:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 20.15it/s]loss:1.1328445260441788:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 20.15it/s]loss:1.1638830738197112:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 20.15it/s]loss:1.1638830738197112:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 21.17it/s]loss:1.023327505048019:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 21.17it/s] loss:1.0740251369695568:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 21.17it/s]loss:1.5325991059474768:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 21.17it/s]loss:1.5325991059474768:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.58it/s]loss:1.43016688390865:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.58it/s]  loss:1.135251780656798:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.58it/s]loss:1.3145279814579467:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.58it/s]loss:1.3145279814579467:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.78it/s]loss:1.2542236667122069:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.78it/s]loss:1.2325369471492809:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.78it/s]loss:1.7444975098517872:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.78it/s]loss:1.7444975098517872:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 21.52it/s]loss:1.4571394931784394:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 21.52it/s]loss:1.433253082229378:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 21.52it/s] loss:1.433253082229378: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 20.29it/s]
Epoch: 6 cost time: 1.4328570365905762
Epoch: 6, Steps: 19 | Train Loss: 1.1116628 Vali Loss: 3.0536871 Test Loss: 39.3951797
Validation loss decreased (3.053842 --> 3.053687).  Saving model ...
Updating learning rate to 3.125e-06
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.5806876701486193:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.571486166095087:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.571486166095087:  11%|â–ˆ         | 2/19 [00:00<00:01, 16.63it/s]loss:0.6548459221136159:  11%|â–ˆ         | 2/19 [00:00<00:01, 16.63it/s]loss:0.8322455119987762:  11%|â–ˆ         | 2/19 [00:00<00:01, 16.63it/s]loss:0.9945037114926181:  11%|â–ˆ         | 2/19 [00:00<00:01, 16.63it/s]loss:0.9945037114926181:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 19.57it/s]loss:0.8610433696813399:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 19.57it/s]loss:0.9174289855514959:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 19.57it/s]loss:1.1636744214222752:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 19.57it/s]loss:1.1636744214222752:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 21.10it/s]loss:1.3721130191102806:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 21.10it/s]loss:1.4684734022309944:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 21.10it/s]loss:1.1920957065076092:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 21.10it/s]loss:1.1920957065076092:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.63it/s]loss:1.2902989566258423:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.63it/s]loss:1.0722372690081734:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.63it/s]loss:1.5178422636246975:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.63it/s]loss:1.5178422636246975:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.65it/s]loss:1.217360782183766:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.65it/s] loss:1.21363563542177:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.65it/s] loss:1.2479416213962409:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.65it/s]loss:1.2479416213962409:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 21.73it/s]loss:1.4295106705245353:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 21.73it/s]loss:1.2745842947622916:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 21.73it/s]loss:1.2745842947622916: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 19.96it/s]
Epoch: 7 cost time: 1.4788739681243896
Epoch: 7, Steps: 19 | Train Loss: 1.0985268 Vali Loss: 3.0536020 Test Loss: 39.3952179
Validation loss decreased (3.053687 --> 3.053602).  Saving model ...
Updating learning rate to 1.5625e-06
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.5636484405540071:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6188508312236549:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.948020911401648:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.948020911401648:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:00, 20.26it/s]loss:0.9205122696878398:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:00, 20.26it/s]loss:0.8946572925027998:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:00, 20.26it/s]loss:0.955766681318588:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:00, 20.26it/s] loss:0.955766681318588:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:00, 21.49it/s]loss:1.2290480334039902:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:00, 21.49it/s]loss:0.8668857338673444:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:00, 21.49it/s]loss:1.1160366033383156:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:00, 21.49it/s]loss:1.1160366033383156:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 22.02it/s]loss:1.0140190708859202:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 22.02it/s]loss:1.1122023503852703:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 22.02it/s]loss:1.163310241745889:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 22.02it/s] loss:1.163310241745889:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 22.22it/s]loss:1.1519618627833792:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 22.22it/s]loss:1.2340147145443194:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 22.22it/s]loss:1.343825884065254:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 22.22it/s] loss:1.343825884065254:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 22.15it/s]loss:1.5395304817385231:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 22.15it/s]loss:1.1651398951276484:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 22.15it/s]loss:1.2380964827663896:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 22.15it/s]loss:1.2380964827663896:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:00<00:00, 22.09it/s]loss:1.6230531925754945:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:00<00:00, 22.09it/s]loss:1.6230531925754945: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 20.83it/s]
Epoch: 8 cost time: 1.468297004699707
Epoch: 8, Steps: 19 | Train Loss: 1.0893990 Vali Loss: 3.0535715 Test Loss: 39.3953133
Validation loss decreased (3.053602 --> 3.053571).  Saving model ...
Updating learning rate to 7.8125e-07
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.5669764786145256:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6377873034925216:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6377873034925216:  11%|â–ˆ         | 2/19 [00:00<00:00, 18.79it/s]loss:0.768885491639894:  11%|â–ˆ         | 2/19 [00:00<00:00, 18.79it/s] loss:0.816473806693813:  11%|â–ˆ         | 2/19 [00:00<00:00, 18.79it/s]loss:0.7761968190796017:  11%|â–ˆ         | 2/19 [00:00<00:00, 18.79it/s]loss:0.7761968190796017:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 21.55it/s]loss:1.178267328792057:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 21.55it/s] loss:0.8659461464839086:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 21.55it/s]loss:1.033523601522187:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 21.55it/s] loss:1.033523601522187:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 22.06it/s]loss:1.0240369010125459:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 22.06it/s]loss:1.3192240111321387:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 22.06it/s]loss:1.0579662041635725:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 22.06it/s]loss:1.0579662041635725:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 22.25it/s]loss:1.0411432319148808:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 22.25it/s]loss:1.6099143461954744:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 22.25it/s]loss:1.4791272436607914:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 22.25it/s]loss:1.4791272436607914:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 22.38it/s]loss:1.127017460122745:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 22.38it/s] loss:1.4277509132873762:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 22.38it/s]loss:1.2478757171572903:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 22.38it/s]loss:1.2478757171572903:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 22.01it/s]loss:1.3018665023942613:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 22.01it/s]loss:1.6229933572826272:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 22.01it/s]loss:1.6229933572826272: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 20.45it/s]
Epoch: 9 cost time: 1.446692705154419
Epoch: 9, Steps: 19 | Train Loss: 1.1001565 Vali Loss: 3.0535557 Test Loss: 39.3953171
Validation loss decreased (3.053571 --> 3.053556).  Saving model ...
Updating learning rate to 3.90625e-07
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.5805938193349088:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6384213248638203:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6384213248638203:  11%|â–ˆ         | 2/19 [00:00<00:01, 16.38it/s]loss:0.6544600328778808:  11%|â–ˆ         | 2/19 [00:00<00:01, 16.38it/s]loss:0.8320038886402401:  11%|â–ˆ         | 2/19 [00:00<00:01, 16.38it/s]loss:0.7186087191462925:  11%|â–ˆ         | 2/19 [00:00<00:01, 16.38it/s]loss:0.7186087191462925:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 20.44it/s]loss:1.058648500349281:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 20.44it/s] loss:0.8891776024074234:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 20.44it/s]loss:0.9362670495734519:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 20.44it/s]loss:0.9362670495734519:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 21.47it/s]loss:0.981605234952377:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 21.47it/s] loss:1.072740766222922:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 21.47it/s]loss:1.3416991044989064:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 21.47it/s]loss:1.3416991044989064:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.83it/s]loss:1.0983516433035054:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.83it/s]loss:1.609879725152612:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.83it/s] loss:1.1055002137233787:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.83it/s]loss:1.1055002137233787:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 22.03it/s]loss:1.727207092049548:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 22.03it/s] loss:1.367417339718981:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 22.03it/s]loss:1.606817656999297:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 22.03it/s]loss:1.606817656999297:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 21.92it/s]loss:1.4293279242092882:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 21.92it/s]loss:1.458090486528083:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 21.92it/s] loss:1.458090486528083: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 20.19it/s]
Epoch: 10 cost time: 1.4746005535125732
Epoch: 10, Steps: 19 | Train Loss: 1.1108852 Vali Loss: 3.0535467 Test Loss: 39.3953400
Validation loss decreased (3.053556 --> 3.053547).  Saving model ...
Updating learning rate to 1.953125e-07
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.584328618393703:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6026300462896935:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6026300462896935:  11%|â–ˆ         | 2/19 [00:00<00:00, 19.10it/s]loss:0.6680724068971368:  11%|â–ˆ         | 2/19 [00:00<00:00, 19.10it/s]loss:0.9203189164403024:  11%|â–ˆ         | 2/19 [00:00<00:00, 19.10it/s]loss:1.079125124262277:  11%|â–ˆ         | 2/19 [00:00<00:00, 19.10it/s] loss:1.079125124262277:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 21.67it/s]loss:0.7712762701709769:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 21.67it/s]loss:1.2541966626569232:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 21.67it/s]loss:1.0774756272575141:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 21.67it/s]loss:1.0774756272575141:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 22.27it/s]loss:1.2262092097120867:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 22.27it/s]loss:1.0138884556559584:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 22.27it/s]loss:1.0860338414958588:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 22.27it/s]loss:1.0860338414958588:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 22.29it/s]loss:1.0377380616889544:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 22.29it/s]loss:1.2781419180528606:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 22.29it/s]loss:1.3460798433081724:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 22.29it/s]loss:1.3460798433081724:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 22.20it/s]loss:1.2539265813532157:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 22.20it/s]loss:1.2856113917725527:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 22.20it/s]loss:1.2478569547833283:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 22.20it/s]loss:1.2478569547833283:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 22.03it/s]loss:1.456528918843533:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 22.03it/s] loss:1.6229463045316923:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 22.03it/s]loss:1.6229463045316923: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 20.63it/s]
Epoch: 11 cost time: 1.434450626373291
Epoch: 11, Steps: 19 | Train Loss: 1.0953887 Vali Loss: 3.0535431 Test Loss: 39.3953476
Validation loss decreased (3.053547 --> 3.053543).  Saving model ...
Updating learning rate to 9.765625e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.5522724321441116:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6151673604089684:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6933179179815457:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6933179179815457:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:00, 19.71it/s]loss:0.748413020892437:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:00, 19.71it/s] loss:0.7185914252362129:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:00, 19.71it/s]loss:0.8553688884488232:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:00, 19.71it/s]loss:0.8553688884488232:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:00, 21.27it/s]loss:0.8210144029366668:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:00, 21.27it/s]loss:1.1634887397201479:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:00, 21.27it/s]loss:1.2579057326150802:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:00, 21.27it/s]loss:1.2579057326150802:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 21.89it/s]loss:1.0293481535818583:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 21.89it/s]loss:1.242481170194176:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 21.89it/s] loss:1.098058802914096:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 21.89it/s]loss:1.098058802914096:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 22.02it/s]loss:1.2781304339588446:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 22.02it/s]loss:1.1972510137265437:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 22.02it/s]loss:1.4029132249922116:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 22.02it/s]loss:1.4029132249922116:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 21.97it/s]loss:1.7222665263765538:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 21.97it/s]loss:1.779770537602231:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 21.97it/s] loss:1.4293085143491693:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 21.97it/s]loss:1.4293085143491693:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:00<00:00, 21.96it/s]loss:1.6229394201124572:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:00<00:00, 21.96it/s]loss:1.6229394201124572: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 20.61it/s]
Epoch: 12 cost time: 1.4657998085021973
Epoch: 12, Steps: 19 | Train Loss: 1.1172636 Vali Loss: 3.0535409 Test Loss: 39.3953438
Validation loss decreased (3.053543 --> 3.053541).  Saving model ...
Updating learning rate to 4.8828125e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.5849269769968399:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6026267450141025:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6026267450141025:  11%|â–ˆ         | 2/19 [00:00<00:00, 18.64it/s]loss:0.7688239484784485:  11%|â–ˆ         | 2/19 [00:00<00:00, 18.64it/s]loss:0.8971077982936447:  11%|â–ˆ         | 2/19 [00:00<00:00, 18.64it/s]loss:0.780771378137354:  11%|â–ˆ         | 2/19 [00:00<00:00, 18.64it/s] loss:0.780771378137354:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 20.71it/s]loss:1.063683715470702:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 20.71it/s]loss:0.8210120726803541:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 20.71it/s]loss:0.9362606984155917:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 20.71it/s]loss:0.9362606984155917:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 21.62it/s]loss:0.9668414592343442:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 21.62it/s]loss:1.1702170593263395:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 21.62it/s]loss:1.2442680545887326:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 21.62it/s]loss:1.2442680545887326:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.70it/s]loss:1.1620621165978398:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.70it/s]loss:1.1927656108961768:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.70it/s]loss:1.6887384378236459:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.70it/s]loss:1.6887384378236459:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.80it/s]loss:1.1269700591657377:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.80it/s]loss:1.7222613573353194:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.80it/s]loss:1.2478524226117138:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.80it/s]loss:1.2478524226117138:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 21.75it/s]loss:1.61113583169307:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 21.75it/s]  loss:1.398489204469659:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 21.75it/s]loss:1.398489204469659: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 20.12it/s]
Epoch: 13 cost time: 1.4986217021942139
Epoch: 13, Steps: 19 | Train Loss: 1.1045692 Vali Loss: 3.0535395 Test Loss: 39.3953476
Validation loss decreased (3.053541 --> 3.053540).  Saving model ...
Updating learning rate to 2.44140625e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.6486280139563091:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8552492001562878:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8552492001562878:  11%|â–ˆ         | 2/19 [00:00<00:00, 18.61it/s]loss:0.6680704158707947:  11%|â–ˆ         | 2/19 [00:00<00:00, 18.61it/s]loss:0.7436193653176901:  11%|â–ˆ         | 2/19 [00:00<00:00, 18.61it/s]loss:0.9942528124628963:  11%|â–ˆ         | 2/19 [00:00<00:00, 18.61it/s]loss:0.9942528124628963:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 20.40it/s]loss:1.0319181061305418:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 20.40it/s]loss:0.8210109827199881:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 20.40it/s]loss:0.9313909501969226:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 20.40it/s]loss:0.9313909501969226:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 21.06it/s]loss:1.0240147197566591:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 21.06it/s]loss:1.0136338215046174:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 21.06it/s]loss:1.0578904826461581:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 21.06it/s]loss:1.0578904826461581:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.49it/s]loss:1.0377257167930787:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.49it/s]loss:1.3344852455693943:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.49it/s]loss:1.517307707875761:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.49it/s] loss:1.517307707875761:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.56it/s]loss:1.224491788987859:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.56it/s]loss:1.401002106121852:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.56it/s]loss:1.7797631349887628:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.56it/s]loss:1.7797631349887628:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 21.64it/s]loss:1.3949955347029037:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 21.64it/s]loss:1.3134994446010164:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 21.64it/s]loss:1.3134994446010164: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 20.19it/s]
Epoch: 14 cost time: 1.4460434913635254
Epoch: 14, Steps: 19 | Train Loss: 1.0943658 Vali Loss: 3.0535390 Test Loss: 39.3953476
Validation loss decreased (3.053540 --> 3.053539).  Saving model ...
Updating learning rate to 1.220703125e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.7004159151860418:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6957169133551601:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6957169133551601:  11%|â–ˆ         | 2/19 [00:00<00:01, 16.95it/s]loss:0.6680705052622891:  11%|â–ˆ         | 2/19 [00:00<00:01, 16.95it/s]loss:0.707354038788776:  11%|â–ˆ         | 2/19 [00:00<00:01, 16.95it/s] loss:0.8055183134887393:  11%|â–ˆ         | 2/19 [00:00<00:01, 16.95it/s]loss:0.8055183134887393:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 20.02it/s]loss:1.063681046026223:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 20.02it/s] loss:0.8793463991994362:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 20.02it/s]loss:0.8696021792909359:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 20.02it/s]loss:0.8696021792909359:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 21.40it/s]loss:1.0164068070667727:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 21.40it/s]loss:1.3190823649053365:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 21.40it/s]loss:1.5010081122669545:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 21.40it/s]loss:1.5010081122669545:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.77it/s]loss:1.1620604316585776:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.77it/s]loss:1.278120491904376:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.77it/s] loss:1.3697151842009665:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.77it/s]loss:1.3697151842009665:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 22.07it/s]loss:1.727162358978755:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 22.07it/s] loss:1.427671566633896:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 22.07it/s]loss:1.1612891232667535:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 22.07it/s]loss:1.1612891232667535:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 22.09it/s]loss:1.2712816762669996:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 22.09it/s]loss:1.241153848345301:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 22.09it/s] loss:1.241153848345301: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 20.28it/s]
Epoch: 15 cost time: 1.5015935897827148
Epoch: 15, Steps: 19 | Train Loss: 1.0981399 Vali Loss: 3.0535390 Test Loss: 39.3953476
Validation loss decreased (3.053539 --> 3.053539).  Saving model ...
Updating learning rate to 6.103515625e-09
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.7185181833778651:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7644634089252654:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7644634089252654:  11%|â–ˆ         | 2/19 [00:00<00:01, 14.43it/s]loss:0.6933159417941264:  11%|â–ˆ         | 2/19 [00:00<00:01, 14.43it/s]loss:0.6705079434367172:  11%|â–ˆ         | 2/19 [00:00<00:01, 14.43it/s]loss:0.7185863139841517:  11%|â–ˆ         | 2/19 [00:00<00:01, 14.43it/s]loss:0.7185863139841517:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 19.11it/s]loss:0.9165764861444691:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 19.11it/s]loss:1.2289212093822441:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 19.11it/s]loss:0.9173880811014643:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 19.11it/s]loss:0.9173880811014643:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 20.56it/s]loss:1.115928959982022:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 20.56it/s] loss:1.0293459289319165:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 20.56it/s]loss:1.1192899271694743:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 20.56it/s]loss:1.1192899271694743:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.16it/s]loss:1.2899486785128769:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.16it/s]loss:1.1343291419110184:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.16it/s]loss:1.1902203495780252:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.16it/s]loss:1.1902203495780252:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.20it/s]loss:1.2539185791635983:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.20it/s]loss:1.4276711054138675:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.20it/s]loss:1.261782603301446:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.20it/s] loss:1.261782603301446:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 21.43it/s]loss:1.7931601536823907:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 21.43it/s]loss:1.622933249117375:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 21.43it/s] loss:1.622933249117375: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 19.72it/s]
Epoch: 16 cost time: 1.4988939762115479
Epoch: 16, Steps: 19 | Train Loss: 1.0982530 Vali Loss: 3.0535390 Test Loss: 39.3953438
Validation loss decreased (3.053539 --> 3.053539).  Saving model ...
Updating learning rate to 3.0517578125e-09
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.649562950174924:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6027668079356372:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6027668079356372:  11%|â–ˆ         | 2/19 [00:00<00:01, 15.66it/s]loss:0.6680705153094697:  11%|â–ˆ         | 2/19 [00:00<00:01, 15.66it/s]loss:1.0242692936138156:  11%|â–ˆ         | 2/19 [00:00<00:01, 15.66it/s]loss:0.8932420409521444:  11%|â–ˆ         | 2/19 [00:00<00:01, 15.66it/s]loss:0.8932420409521444:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 20.01it/s]loss:0.8617676948413493:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 20.01it/s]loss:0.9163970077077507:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 20.01it/s]loss:1.1634838229578377:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 20.01it/s]loss:1.1634838229578377:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 21.28it/s]loss:1.1159288355214934:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 21.28it/s]loss:0.9610585903231491:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 21.28it/s]loss:0.9995304393326025:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 21.28it/s]loss:0.9995304393326025:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.71it/s]loss:1.1546225188712562:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.71it/s]loss:1.164772092409008:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.71it/s] loss:1.5173041949418848:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.71it/s]loss:1.5173041949418848:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.84it/s]loss:1.5592970187543305:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.84it/s]loss:1.2323507919139236:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.84it/s]loss:1.3845703678505301:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.84it/s]loss:1.3845703678505301:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 21.80it/s]loss:1.7570505334007587:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 21.80it/s]loss:1.2411537237954857:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 21.80it/s]loss:1.2411537237954857: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 20.14it/s]
Epoch: 17 cost time: 1.4744632244110107
Epoch: 17, Steps: 19 | Train Loss: 1.0982736 Vali Loss: 3.0535390 Test Loss: 39.3953438
Validation loss decreased (3.053539 --> 3.053539).  Saving model ...
Updating learning rate to 1.52587890625e-09
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.7996984097594707:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.787993894106527:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.6205060318299775:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6205060318299775:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:00, 20.97it/s]loss:0.74840900635657:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:00, 20.97it/s]  loss:0.7807700583434323:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:00, 20.97it/s]loss:0.855365379828268:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:00, 20.97it/s] loss:0.855365379828268:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:00, 21.88it/s]loss:0.879346334388772:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:00, 21.88it/s]loss:1.0334366826201702:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:00, 21.88it/s]loss:1.0240142387213362:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:00, 21.88it/s]loss:1.0240142387213362:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 22.14it/s]loss:1.4385512729956431:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 22.14it/s]loss:1.3763500095535992:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 22.14it/s]loss:1.1209072800877957:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 22.14it/s]loss:1.1209072800877957:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 21.96it/s]loss:1.3325603865548328:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 21.96it/s]loss:1.3460670209918393:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 21.96it/s]loss:1.1927659395955466:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 21.96it/s]loss:1.1927659395955466:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 22.05it/s]loss:1.1468628189277092:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 22.05it/s]loss:1.4456287760715252:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 22.05it/s]loss:1.2380546985936034:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 22.05it/s]loss:1.2380546985936034:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:00<00:00, 22.03it/s]loss:1.5744700820835273:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:00<00:00, 22.03it/s]loss:1.5744700820835273: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 20.81it/s]
Epoch: 18 cost time: 1.452726125717163
Epoch: 18, Steps: 19 | Train Loss: 1.0916715 Vali Loss: 3.0535390 Test Loss: 39.3953438
Validation loss decreased (3.053539 --> 3.053539).  Saving model ...
Updating learning rate to 7.62939453125e-10
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.5849262084464664:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6336702503069072:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6336702503069072:  11%|â–ˆ         | 2/19 [00:00<00:01, 15.23it/s]loss:0.6544509440252215:  11%|â–ˆ         | 2/19 [00:00<00:01, 15.23it/s]loss:0.7484089854250454:  11%|â–ˆ         | 2/19 [00:00<00:01, 15.23it/s]loss:0.8932419088288439:  11%|â–ˆ         | 2/19 [00:00<00:01, 15.23it/s]loss:0.8932419088288439:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 19.35it/s]loss:0.8260694276364515:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 19.35it/s]loss:0.9996870518261927:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 19.35it/s]loss:1.0334366189449529:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 19.35it/s]loss:1.0334366189449529:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 20.84it/s]loss:1.1371718384655576:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 20.84it/s]loss:0.9579403222842947:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 20.84it/s]loss:1.50100744824824:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 20.84it/s]  loss:1.50100744824824:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.38it/s]loss:1.5903900976536822:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.38it/s]loss:1.1579352231944455:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.38it/s]loss:1.1054804031266334:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 21.38it/s]loss:1.1054804031266334:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.51it/s]loss:1.5592968967227097:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.51it/s]loss:1.2138229923695427:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.51it/s]loss:1.5990904066284077:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 21.51it/s]loss:1.5990904066284077:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 21.65it/s]loss:1.5705388060870642:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 21.65it/s]loss:1.2744636010174712:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 21.65it/s]loss:1.2744636010174712: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 19.92it/s]
Epoch: 19 cost time: 1.5231373310089111
Epoch: 19, Steps: 19 | Train Loss: 1.1074226 Vali Loss: 3.0535390 Test Loss: 39.3953438
Validation loss decreased (3.053539 --> 3.053539).  Saving model ...
Updating learning rate to 3.814697265625e-10
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.7835945905179299:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6384131803762364:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6384131803762364:  11%|â–ˆ         | 2/19 [00:00<00:00, 18.98it/s]loss:0.6205059930677675:  11%|â–ˆ         | 2/19 [00:00<00:00, 18.98it/s]loss:0.7968329212344436:  11%|â–ˆ         | 2/19 [00:00<00:00, 18.98it/s]loss:0.7807700382489671:  11%|â–ˆ         | 2/19 [00:00<00:00, 18.98it/s]loss:0.7807700382489671:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 21.41it/s]loss:0.8608752366285073:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 21.41it/s]loss:0.8839440043494913:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 21.41it/s]loss:1.0774553753702265:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 21.41it/s]loss:1.0774553753702265:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 21.90it/s]loss:1.1159287140280443:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 21.90it/s]loss:1.3190805537095143:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 21.90it/s]loss:1.0576414073123597:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 21.90it/s]loss:1.0576414073123597:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 22.10it/s]loss:1.3929429571478233:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 22.10it/s]loss:1.1345939678205699:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 22.10it/s]loss:1.2260203276817265:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 22.10it/s]loss:1.2260203276817265:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 22.14it/s]loss:1.2109722394176776:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 22.14it/s]loss:1.5868247281099825:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 22.14it/s]loss:1.1612885149369054:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 22.14it/s]loss:1.1612885149369054:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 21.97it/s]loss:1.7931597799639316:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 21.97it/s]loss:1.460157499670942:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 21.97it/s] loss:1.460157499670942: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 20.69it/s]
Epoch: 20 cost time: 1.4498844146728516
Epoch: 20, Steps: 19 | Train Loss: 1.1000527 Vali Loss: 3.0535390 Test Loss: 39.3953438
Validation loss decreased (3.053539 --> 3.053539).  Saving model ...
Updating learning rate to 1.9073486328125e-10
>>>>>>>testing : long_term_forecast_break_rayleigh_0_FiLM_job_demand_region_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 4
test shape: (4, 1, 3, 16345) (4, 1, 3, 16345)
test shape: (4, 3, 16345) (4, 3, 16345)
mse:35219.14453125, mae:34.279151916503906, dtw:-999
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           0                   Model:              Koopa               

[1mData Loader[0m
  Data:               job_demand_region   Root Path:          ../../dataset/demand/
  Data Path:          region.parquet      Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        .cache/checkpoints  

[1mForecasting Task[0m
  Seq Len:            6                   Label Len:          1                   
  Pred Len:           3                   Seasonal Patterns:  Monthly             
  Inverse:            1                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             16345               Dec In:             16345               
  C Out:              16345               d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           2                   d FF:               2048                
  Moving Avg:         25                  Factor:             1                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              learned             Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        32                  Itr:                1                   
  Train Epochs:       20                  Batch Size:         1                   
  Patience:           3                   Learning Rate:      0.0001              
  Des:                test                Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1                 

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
train 19
>>>>>>>start training : long_term_forecast_break_bartlett_0_Koopa_job_demand_region_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 19
val 1
test 4
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.92it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.92it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.92it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.92it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.92it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.92it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.92it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.92it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.92it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.92it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.92it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.92it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 33.35it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 33.35it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 33.35it/s]loss:0.052007811430451606:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 33.35it/s]loss:0.3174450825720608:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 33.35it/s]  loss:0.5085345260695655:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 33.35it/s]loss:0.8851556873189187:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 33.35it/s]loss:1.318650091193631:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 33.35it/s] loss:1.318650091193631: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 33.27it/s]
Epoch: 1 cost time: 1.034088134765625
Epoch: 1, Steps: 19 | Train Loss: 0.1621996 Vali Loss: 3.3762102 Test Loss: 46.2142792
Validation loss decreased (inf --> 3.376210).  Saving model ...
Updating learning rate to 0.0001
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 86.03it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 86.03it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 86.03it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 86.03it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 86.03it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 86.03it/s]loss:0.05033937239762967:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 86.03it/s]loss:0.3462750544139527:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 86.03it/s] loss:0.6175692524316274:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 86.03it/s]loss:1.1298118083520032:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 86.03it/s]loss:1.1298118083520032:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:00<00:00, 78.83it/s]loss:0.9932968645331239:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:00<00:00, 78.83it/s]loss:0.9932968645331239: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 66.56it/s]
Epoch: 2 cost time: 0.797459602355957
Epoch: 2, Steps: 19 | Train Loss: 0.1651207 Vali Loss: 3.3369539 Test Loss: 44.5562592
Validation loss decreased (3.376210 --> 3.336954).  Saving model ...
Updating learning rate to 5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 93.58it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 93.58it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 93.58it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 93.58it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 93.58it/s]loss:0.05532815299037368:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 93.58it/s]loss:0.4067124901288:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 93.58it/s]    loss:0.7600353511508232:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 93.58it/s]loss:0.746540395597824:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 93.58it/s] loss:1.1997768330904208:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 93.58it/s]loss:1.1997768330904208: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 84.91it/s]
Epoch: 3 cost time: 0.7915663719177246
Epoch: 3, Steps: 19 | Train Loss: 0.1667575 Vali Loss: 3.3184915 Test Loss: 44.7935638
Validation loss decreased (3.336954 --> 3.318491).  Saving model ...
Updating learning rate to 2.5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 78.65it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 78.65it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 78.65it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 78.65it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 78.65it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 78.65it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 78.65it/s]loss:0.06675380131068265:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 78.65it/s]loss:0.34890010727267734:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 78.65it/s]loss:0.5944404253111469:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 78.65it/s] loss:0.5944404253111469:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 84.81it/s]loss:0.9074531851208322:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 84.81it/s]loss:1.1631373755157506:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 84.81it/s]loss:1.1631373755157506: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 71.64it/s]
Epoch: 4 cost time: 0.8342645168304443
Epoch: 4, Steps: 19 | Train Loss: 0.1621413 Vali Loss: 3.3361974 Test Loss: 45.5038490
EarlyStopping counter: 1 out of 3
Updating learning rate to 1.25e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 85.54it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 85.54it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 85.54it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 85.54it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 85.54it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 85.54it/s]loss:0.06475682155087568:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 85.54it/s]loss:0.3270654182220716:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 85.54it/s] loss:0.7359470636382823:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 85.54it/s]loss:0.8765399168186355:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 85.54it/s]loss:0.8765399168186355:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:00<00:00, 81.86it/s]loss:0.9449006643926053:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:00<00:00, 81.86it/s]loss:0.9449006643926053: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 69.02it/s]
Epoch: 5 cost time: 0.795983076095581
Epoch: 5, Steps: 19 | Train Loss: 0.1552216 Vali Loss: 3.3344276 Test Loss: 45.7305603
EarlyStopping counter: 2 out of 3
Updating learning rate to 6.25e-06
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 113.94it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 113.94it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 113.94it/s]loss:0.06158259659613527:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 113.94it/s]loss:0.3172932397074151:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 113.94it/s] loss:0.5107195593997667:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 113.94it/s]loss:1.1363864841705222:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 113.94it/s]loss:1.208107643367452:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 113.94it/s] loss:1.208107643367452: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 89.67it/s] 
Epoch: 6 cost time: 0.7692294120788574
Epoch: 6, Steps: 19 | Train Loss: 0.1702152 Vali Loss: 3.3342073 Test Loss: 45.8541107
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : long_term_forecast_break_bartlett_0_Koopa_job_demand_region_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 4
test shape: (4, 1, 3, 16345) (4, 1, 3, 16345)
test shape: (4, 3, 16345) (4, 3, 16345)
mse:56837.8984375, mae:37.01570129394531, dtw:-999
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           0                   Model:              Koopa               

[1mData Loader[0m
  Data:               job_demand_region   Root Path:          ../../dataset/demand/
  Data Path:          region.parquet      Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        .cache/checkpoints  

[1mForecasting Task[0m
  Seq Len:            6                   Label Len:          1                   
  Pred Len:           3                   Seasonal Patterns:  Monthly             
  Inverse:            1                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             16345               Dec In:             16345               
  C Out:              16345               d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           2                   d FF:               2048                
  Moving Avg:         25                  Factor:             1                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              learned             Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        32                  Itr:                1                   
  Train Epochs:       20                  Batch Size:         1                   
  Patience:           3                   Learning Rate:      0.0001              
  Des:                test                Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1                 

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
train 19
>>>>>>>start training : long_term_forecast_break_parzen_0_Koopa_job_demand_region_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 19
val 1
test 4
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.77it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.77it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.77it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.77it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.77it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.77it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.77it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.77it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.77it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.77it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.77it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.77it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.77it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 35.63it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 35.63it/s]loss:0.00023586309038753397:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 35.63it/s]loss:0.05184454090277897:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 35.63it/s]   loss:0.2791552607345278:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 35.63it/s] loss:0.8652651075530199:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 35.63it/s]loss:1.3184062642181558:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 35.63it/s]loss:1.3184062642181558: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 34.73it/s]
Epoch: 1 cost time: 0.9829156398773193
Epoch: 1, Steps: 19 | Train Loss: 0.1323635 Vali Loss: 3.3357401 Test Loss: 46.3797836
Validation loss decreased (inf --> 3.335740).  Saving model ...
Updating learning rate to 0.0001
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 81.45it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 81.45it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 81.45it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 81.45it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 81.45it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 81.45it/s]loss:0.0002258914398833664:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 81.45it/s]loss:0.05811445874190071:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 81.45it/s]  loss:0.337767572668843:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 81.45it/s]  loss:1.088984800734365:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 81.45it/s]loss:1.088984800734365:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:00<00:00, 77.59it/s]loss:1.0335398957032866:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:00<00:00, 77.59it/s]loss:1.0335398957032866: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 64.54it/s]
Epoch: 2 cost time: 0.8520019054412842
Epoch: 2, Steps: 19 | Train Loss: 0.1325596 Vali Loss: 3.2988360 Test Loss: 48.7675018
Validation loss decreased (3.335740 --> 3.298836).  Saving model ...
Updating learning rate to 5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 80.97it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 80.97it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 80.97it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 80.97it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 80.97it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 80.97it/s]loss:0.00024723312634152895:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 80.97it/s]loss:0.06582683367190592:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 80.97it/s]   loss:0.41378404923632467:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 80.97it/s]loss:0.7201731675704579:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 80.97it/s] loss:0.7201731675704579:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:00<00:00, 82.44it/s]loss:1.2144340467550374:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:00<00:00, 82.44it/s]loss:1.2144340467550374: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 70.07it/s]
Epoch: 3 cost time: 0.839719295501709
Epoch: 3, Steps: 19 | Train Loss: 0.1270771 Vali Loss: 3.2955515 Test Loss: 48.4652214
Validation loss decreased (3.298836 --> 3.295552).  Saving model ...
Updating learning rate to 2.5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 84.75it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 84.75it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 84.75it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 84.75it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 84.75it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 84.75it/s]loss:0.00030280917315122455:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 84.75it/s]loss:0.057170842251781484:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 84.75it/s]  loss:0.3187886353054202:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 84.75it/s]  loss:0.8085492355157601:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 84.75it/s]loss:0.8085492355157601:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:00<00:00, 87.40it/s]loss:1.1311001389783302:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:00<00:00, 87.40it/s]loss:1.1311001389783302: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 74.68it/s]
Epoch: 4 cost time: 0.8387830257415771
Epoch: 4, Steps: 19 | Train Loss: 0.1218901 Vali Loss: 3.3131723 Test Loss: 49.4608269
EarlyStopping counter: 1 out of 3
Updating learning rate to 1.25e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 91.92it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 91.92it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 91.92it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 91.92it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 91.92it/s]loss:0.00029771356863211645:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 91.92it/s]loss:0.050024523150125844:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 91.92it/s]  loss:0.4030663323869435:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 91.92it/s]  loss:0.8778389202061376:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 91.92it/s]loss:0.9628139434778835:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 91.92it/s]loss:0.9628139434778835: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 68.93it/s]
Epoch: 5 cost time: 0.8010601997375488
Epoch: 5, Steps: 19 | Train Loss: 0.1207390 Vali Loss: 3.3165240 Test Loss: 49.6455612
EarlyStopping counter: 2 out of 3
Updating learning rate to 6.25e-06
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 108.65it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 108.65it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 108.65it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 108.65it/s]loss:0.0002262392723061227:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 108.65it/s]loss:0.05135248689947068:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 108.65it/s]  loss:0.2781411736263736:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 108.65it/s] loss:1.1248529793631865:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 108.65it/s]loss:1.1982050657859948:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 108.65it/s]loss:1.1982050657859948: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 76.76it/s] 
Epoch: 6 cost time: 0.8156735897064209
Epoch: 6, Steps: 19 | Train Loss: 0.1396199 Vali Loss: 3.3156457 Test Loss: 49.7106209
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : long_term_forecast_break_parzen_0_Koopa_job_demand_region_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 4
test shape: (4, 1, 3, 16345) (4, 1, 3, 16345)
test shape: (4, 3, 16345) (4, 3, 16345)
mse:56186.765625, mae:36.835506439208984, dtw:-999
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           0                   Model:              Koopa               

[1mData Loader[0m
  Data:               job_demand_region   Root Path:          ../../dataset/demand/
  Data Path:          region.parquet      Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        .cache/checkpoints  

[1mForecasting Task[0m
  Seq Len:            6                   Label Len:          1                   
  Pred Len:           3                   Seasonal Patterns:  Monthly             
  Inverse:            1                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             16345               Dec In:             16345               
  C Out:              16345               d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           2                   d FF:               2048                
  Moving Avg:         25                  Factor:             1                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              learned             Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        32                  Itr:                1                   
  Train Epochs:       20                  Batch Size:         1                   
  Patience:           3                   Learning Rate:      0.0001              
  Des:                test                Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1                 

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
train 19
>>>>>>>start training : long_term_forecast_break_tukey-hanning_0_Koopa_job_demand_region_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 19
val 1
test 4
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.86it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.86it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.86it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.86it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.86it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.86it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.86it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.86it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.86it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.86it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.86it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 30.84it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 30.84it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 30.84it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 30.84it/s]loss:0.006099284976933303:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 30.84it/s]loss:0.20917009618967003:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 30.84it/s] loss:0.5219044460563744:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 30.84it/s] loss:1.0086382102295341:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 30.84it/s]loss:1.0086382102295341:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:00<00:00, 41.52it/s]loss:1.318642305630995:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:00<00:00, 41.52it/s] loss:1.318642305630995: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 31.25it/s]
Epoch: 1 cost time: 1.009765386581421
Epoch: 1, Steps: 19 | Train Loss: 0.1612871 Vali Loss: 3.3644450 Test Loss: 46.2020683
Validation loss decreased (inf --> 3.364445).  Saving model ...
Updating learning rate to 0.0001
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 95.31it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 95.31it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 95.31it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 95.31it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 95.31it/s]loss:0.005866158929589269:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 95.31it/s]loss:0.23957785492452155:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 95.31it/s] loss:0.6275017803654774:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 95.31it/s] loss:1.2808425702374107:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 95.31it/s]loss:1.0037105064196745:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 95.31it/s]loss:1.0037105064196745: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 66.34it/s]
Epoch: 2 cost time: 0.8228888511657715
Epoch: 2, Steps: 19 | Train Loss: 0.1661842 Vali Loss: 3.3095908 Test Loss: 46.4302597
Validation loss decreased (3.364445 --> 3.309591).  Saving model ...
Updating learning rate to 5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 82.32it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 82.32it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 82.32it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 82.32it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 82.32it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 82.32it/s]loss:0.006419587906189212:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 82.32it/s]loss:0.2663971820067812:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 82.32it/s]  loss:0.7696678223239551:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 82.32it/s]loss:0.8552468923137022:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 82.32it/s]loss:0.8552468923137022:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:00<00:00, 78.16it/s]loss:1.2030633284229486:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:00<00:00, 78.16it/s]loss:1.2030633284229486: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 66.45it/s]
Epoch: 3 cost time: 0.8320009708404541
Epoch: 3, Steps: 19 | Train Loss: 0.1631997 Vali Loss: 3.3132601 Test Loss: 46.5028915
EarlyStopping counter: 1 out of 3
Updating learning rate to 2.5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 85.24it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 85.24it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 85.24it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 85.24it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 85.24it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 85.24it/s]loss:0.007826631610565848:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 85.24it/s]loss:0.23131678705145342:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 85.24it/s] loss:0.609769995541584:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 85.24it/s]  loss:0.9702155857959108:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 85.24it/s]loss:0.9702155857959108:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:00<00:00, 77.92it/s]loss:1.1298753940337318:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:00<00:00, 77.92it/s]loss:1.1298753940337318: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 62.34it/s]
Epoch: 4 cost time: 0.8518409729003906
Epoch: 4, Steps: 19 | Train Loss: 0.1552108 Vali Loss: 3.3297651 Test Loss: 47.3082314
EarlyStopping counter: 2 out of 3
Updating learning rate to 1.25e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 107.38it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 107.38it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 107.38it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 107.38it/s]loss:0.007534811467742779:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 107.38it/s]loss:0.20606752618929394:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 107.38it/s] loss:0.7558623113214412:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 107.38it/s] loss:1.0088612358768436:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 107.38it/s]loss:0.9688298639583194:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 107.38it/s]loss:0.9688298639583194: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 75.63it/s] 
Epoch: 5 cost time: 0.8168857097625732
Epoch: 5, Steps: 19 | Train Loss: 0.1551135 Vali Loss: 3.3299983 Test Loss: 47.5196991
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : long_term_forecast_break_tukey-hanning_0_Koopa_job_demand_region_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 4
test shape: (4, 1, 3, 16345) (4, 1, 3, 16345)
test shape: (4, 3, 16345) (4, 3, 16345)
mse:56259.3125, mae:36.85301208496094, dtw:-999
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           0                   Model:              Koopa               

[1mData Loader[0m
  Data:               job_demand_region   Root Path:          ../../dataset/demand/
  Data Path:          region.parquet      Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        .cache/checkpoints  

[1mForecasting Task[0m
  Seq Len:            6                   Label Len:          1                   
  Pred Len:           3                   Seasonal Patterns:  Monthly             
  Inverse:            1                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             16345               Dec In:             16345               
  C Out:              16345               d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           2                   d FF:               2048                
  Moving Avg:         25                  Factor:             1                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              learned             Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        32                  Itr:                1                   
  Train Epochs:       20                  Batch Size:         1                   
  Patience:           3                   Learning Rate:      0.0001              
  Des:                test                Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1                 

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
train 19
>>>>>>>start training : long_term_forecast_break_rayleigh_0_Koopa_job_demand_region_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 19
val 1
test 4
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.5117626378122887:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5117626378122887:   5%|â–Œ         | 1/19 [00:00<00:05,  3.08it/s]loss:0.47653064087916625:   5%|â–Œ         | 1/19 [00:00<00:05,  3.08it/s]loss:0.5909229583606023:   5%|â–Œ         | 1/19 [00:00<00:05,  3.08it/s] loss:0.7124975070491583:   5%|â–Œ         | 1/19 [00:00<00:05,  3.08it/s]loss:0.6476941452369899:   5%|â–Œ         | 1/19 [00:00<00:05,  3.08it/s]loss:0.6099091368810154:   5%|â–Œ         | 1/19 [00:00<00:05,  3.08it/s]loss:0.8147501327158196:   5%|â–Œ         | 1/19 [00:00<00:05,  3.08it/s]loss:1.0495269617948693:   5%|â–Œ         | 1/19 [00:00<00:05,  3.08it/s]loss:0.928808330169825:   5%|â–Œ         | 1/19 [00:00<00:05,  3.08it/s] loss:1.0912170512795702:   5%|â–Œ         | 1/19 [00:00<00:05,  3.08it/s]loss:1.0912170512795702:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 28.39it/s]loss:1.2777098049086497:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 28.39it/s]loss:1.0063593526522898:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 28.39it/s]loss:1.031251429119693:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 28.39it/s] loss:1.187267047531431:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 28.39it/s]loss:1.0586104147804356:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 28.39it/s]loss:1.081271242154967:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 28.39it/s] loss:1.027145572188746:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 28.39it/s]loss:1.027145572188746:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 39.69it/s]loss:1.158027405581069:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 39.69it/s]loss:1.355480824308835:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 39.69it/s]loss:1.355480824308835: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 30.90it/s]
Epoch: 1 cost time: 1.0322110652923584
Epoch: 1, Steps: 19 | Train Loss: 0.9271970 Vali Loss: 3.3868289 Test Loss: 45.8799400
Validation loss decreased (inf --> 3.386829).  Saving model ...
Updating learning rate to 0.0001
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.5027050327178441:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5227588523179985:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6314494927322337:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6746863627561092:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8320891842586012:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6907745989967348:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9770615425588455:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7243809683305977:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.1005139011451577:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9001100372060473:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9001100372060473:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 88.93it/s]loss:0.8159096179647006:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 88.93it/s]loss:0.8942604824484778:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 88.93it/s]loss:1.101467431487039:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 88.93it/s] loss:1.0641444464921275:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 88.93it/s]loss:1.0236877729080043:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 88.93it/s]loss:1.1237217692628894:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 88.93it/s]loss:1.1643324463801956:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 88.93it/s]loss:1.246912824299212:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 88.93it/s] loss:0.9656197909405987:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 88.93it/s]loss:0.9656197909405987: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 76.72it/s]loss:0.9656197909405987: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 64.61it/s]
Epoch: 2 cost time: 0.8297173976898193
Epoch: 2, Steps: 19 | Train Loss: 0.8924519 Vali Loss: 3.3341713 Test Loss: 46.3808136
Validation loss decreased (3.386829 --> 3.334171).  Saving model ...
Updating learning rate to 5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.5386056692663832:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5144832469650066:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6491028675168198:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6692966575304625:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6436377775733667:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7743198972549262:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7517724218382189:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7128888076599882:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.736535218024265:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.7687363904751479:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7687363904751479:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 98.53it/s]loss:0.9753252968123192:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 98.53it/s]loss:1.0161960229418439:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 98.53it/s]loss:1.2277379890943385:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 98.53it/s]loss:1.0599447030233238:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 98.53it/s]loss:1.1257759191803025:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 98.53it/s]loss:1.3264636057833519:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 98.53it/s]loss:1.385819549736176:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 98.53it/s] loss:0.9541567625664579:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 98.53it/s]loss:1.1258874064867324:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 98.53it/s]loss:1.1258874064867324: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 74.77it/s]
Epoch: 3 cost time: 0.7827990055084229
Epoch: 3, Steps: 19 | Train Loss: 0.8924572 Vali Loss: 3.3252907 Test Loss: 46.2241745
Validation loss decreased (3.334171 --> 3.325291).  Saving model ...
Updating learning rate to 2.5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.4161306914909219:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5656706326491742:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6335055569772274:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5477793669228319:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5836108732294272:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7468319077987313:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9356671652573822:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7761060444010642:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7761060444010642:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 69.76it/s]loss:0.8230630369335399:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 69.76it/s]loss:0.9556662655109308:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 69.76it/s]loss:0.7889160402398315:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 69.76it/s]loss:1.0120033183479886:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 69.76it/s]loss:1.0285173723434118:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 69.76it/s]loss:1.2741587739222484:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 69.76it/s]loss:1.342538142163395:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 69.76it/s] loss:1.342538142163395:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 67.55it/s]loss:1.1872448384096888:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 67.55it/s]loss:1.0874785926400108:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 67.55it/s]loss:1.0749069506134536:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 67.55it/s]loss:1.1011986986184201:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 67.55it/s]loss:1.1011986986184201: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 56.81it/s]
Epoch: 4 cost time: 0.933830738067627
Epoch: 4, Steps: 19 | Train Loss: 0.8884734 Vali Loss: 3.3245029 Test Loss: 46.2117386
Validation loss decreased (3.325291 --> 3.324503).  Saving model ...
Updating learning rate to 1.25e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.49007589792208794:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5500862189429317:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.49183846976242135:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6136517954802042:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.5868184240476344:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.734997589058204:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.7657976534425445:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8981907570638485:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8981907570638485:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 72.57it/s]loss:0.740734047699886:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 72.57it/s] loss:0.956427049413385:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 72.57it/s]loss:0.8995071585573361:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 72.57it/s]loss:1.0642952261078624:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 72.57it/s]loss:1.066016696949702:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 72.57it/s] loss:1.261063627768435:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 72.57it/s]loss:1.30067712527543:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 72.57it/s] loss:1.0260033223200073:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 72.57it/s]loss:1.0260033223200073:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 69.92it/s]loss:1.3828183008803214:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 69.92it/s]loss:1.1409699110098133:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 69.92it/s]loss:0.9222637262488111:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 69.92it/s]loss:0.9222637262488111: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 60.11it/s]
Epoch: 5 cost time: 0.9158213138580322
Epoch: 5, Steps: 19 | Train Loss: 0.8890649 Vali Loss: 3.3250492 Test Loss: 46.2254562
EarlyStopping counter: 1 out of 3
Updating learning rate to 6.25e-06
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.5013766705159171:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6777174824500887:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6169516995964394:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6264268138479084:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5863861424891886:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7634131367962559:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7823650978651725:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7823650978651725:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 64.50it/s]loss:0.7746357207164767:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 64.50it/s]loss:0.8533973022661141:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 64.50it/s]loss:0.7504982055906726:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 64.50it/s]loss:1.1521027813741342:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 64.50it/s]loss:1.0735321125681034:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 64.50it/s]loss:1.0450543401968537:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 64.50it/s]loss:0.8937314358286981:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 64.50it/s]loss:0.8937314358286981:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 64.23it/s]loss:1.0150048495270403:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 64.23it/s]loss:1.0523086873406473:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 64.23it/s]loss:0.9233454344821822:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 64.23it/s]loss:1.3400669632606101:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 64.23it/s]loss:1.2002120926018658:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 64.23it/s]loss:1.2002120926018658: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 55.77it/s]
Epoch: 6 cost time: 0.8618035316467285
Epoch: 6, Steps: 19 | Train Loss: 0.8751856 Vali Loss: 3.3240378 Test Loss: 46.2138062
Validation loss decreased (3.324503 --> 3.324038).  Saving model ...
Updating learning rate to 3.125e-06
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.5972088831256614:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.46435311464377393:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5017642139860957:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.6665892951101952:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6743959940591839:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9142556054756028:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6451111465406886:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8093408738167525:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9455951888730196:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9512725742617454:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.0232942007716566:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.0232942007716566:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 98.39it/s]loss:0.9967504640312409:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 98.39it/s]loss:0.9578184796467084:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 98.39it/s]loss:1.0532377729927358:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 98.39it/s]loss:1.0151317661455554:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 98.39it/s]loss:1.1172491342298585:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 98.39it/s]loss:0.9236038197022525:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 98.39it/s]loss:1.0741070583914725:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 98.39it/s]loss:1.351125142398418:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 98.39it/s] loss:1.351125142398418: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 68.07it/s]
Epoch: 7 cost time: 0.9132139682769775
Epoch: 7, Steps: 19 | Train Loss: 0.8780108 Vali Loss: 3.3242321 Test Loss: 46.2092819
EarlyStopping counter: 1 out of 3
Updating learning rate to 1.5625e-06
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.4989224334316392:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5825718911753037:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5950889416308043:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6632947072712218:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6463073245291026:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7954201555115288:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9730657514278094:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9916171599217085:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9916171599217085:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 78.93it/s]loss:0.9114812315558783:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 78.93it/s]loss:0.8935096736045924:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 78.93it/s]loss:0.9174210649438618:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 78.93it/s]loss:0.8465204997279141:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 78.93it/s]loss:0.840242586944806:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 78.93it/s] loss:0.9846851975073342:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 78.93it/s]loss:1.2982191863843824:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 78.93it/s]loss:1.0715045701365513:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 78.93it/s]loss:1.1315795945333242:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 78.93it/s]loss:0.9476657739297081:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 78.93it/s]loss:0.9327457354463685:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 78.93it/s]loss:0.9327457354463685: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 96.50it/s]loss:0.9327457354463685: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 77.73it/s]
Epoch: 8 cost time: 0.8441767692565918
Epoch: 8, Steps: 19 | Train Loss: 0.8695718 Vali Loss: 3.3242862 Test Loss: 46.2088547
EarlyStopping counter: 2 out of 3
Updating learning rate to 7.8125e-07
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.48719789635858035:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5442124517087604:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.7069342324513834:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6666518444421128:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6892662260484608:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6919921662494163:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7311035917498131:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6789134129183493:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7454251955347674:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7454251955347674:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 80.42it/s]loss:0.7762979822251547:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 80.42it/s]loss:1.18871994539576:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 80.42it/s]  loss:1.061593760309324:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 80.42it/s]loss:1.2352316375359247:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 80.42it/s]loss:1.074082205188916:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 80.42it/s] loss:1.0338439298298228:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 80.42it/s]loss:1.185840557373604:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 80.42it/s] loss:0.9222553009900245:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 80.42it/s]loss:1.0942683331654812:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 80.42it/s]loss:1.0942683331654812:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:00<00:00, 81.46it/s]loss:1.1650623516468497:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:00<00:00, 81.46it/s]loss:1.1650623516468497: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 68.87it/s]
Epoch: 9 cost time: 0.9299178123474121
Epoch: 9, Steps: 19 | Train Loss: 0.8778365 Vali Loss: 3.3243239 Test Loss: 46.2091484
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : long_term_forecast_break_rayleigh_0_Koopa_job_demand_region_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 4
test shape: (4, 1, 3, 16345) (4, 1, 3, 16345)
test shape: (4, 3, 16345) (4, 3, 16345)
mse:56041.19921875, mae:36.49810791015625, dtw:-999
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           0                   Model:              DLinear             

[1mData Loader[0m
  Data:               job_demand_region   Root Path:          ../../dataset/demand/
  Data Path:          region.parquet      Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        .cache/checkpoints  

[1mForecasting Task[0m
  Seq Len:            6                   Label Len:          1                   
  Pred Len:           3                   Seasonal Patterns:  Monthly             
  Inverse:            1                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             16345               Dec In:             16345               
  C Out:              16345               d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           2                   d FF:               2048                
  Moving Avg:         25                  Factor:             1                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              learned             Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        32                  Itr:                1                   
  Train Epochs:       20                  Batch Size:         1                   
  Patience:           3                   Learning Rate:      0.0001              
  Des:                test                Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1                 

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_break_bartlett_0_DLinear_job_demand_region_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 19
val 1
test 4
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:07,  2.30it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:07,  2.30it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:07,  2.30it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:07,  2.30it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:07,  2.30it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:07,  2.30it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:07,  2.30it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:07,  2.30it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:07,  2.30it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:07,  2.30it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:07,  2.30it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:07,  2.30it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:07,  2.30it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:07,  2.30it/s]loss:0.052694106653844476:   5%|â–Œ         | 1/19 [00:00<00:07,  2.30it/s]loss:0.3339367403339341:   5%|â–Œ         | 1/19 [00:00<00:07,  2.30it/s]  loss:0.5024325346130869:   5%|â–Œ         | 1/19 [00:00<00:07,  2.30it/s]loss:1.0533283536998832:   5%|â–Œ         | 1/19 [00:00<00:07,  2.30it/s]loss:1.1499627561205548:   5%|â–Œ         | 1/19 [00:00<00:07,  2.30it/s]loss:1.1499627561205548: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 36.99it/s]
Epoch: 1 cost time: 1.0492396354675293
Epoch: 1, Steps: 19 | Train Loss: 0.1627555 Vali Loss: 3.2155406 Test Loss: 42.3479156
Validation loss decreased (inf --> 3.215541).  Saving model ...
Updating learning rate to 0.0001
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.06567520690476826:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.2853730897930189:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.6107329572451331:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8508745061783944:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.3463275787200988:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.3463275787200988: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 229.44it/s]
Epoch: 2 cost time: 0.5586750507354736
Epoch: 2, Steps: 19 | Train Loss: 0.1662623 Vali Loss: 3.2139215 Test Loss: 42.3691177
Validation loss decreased (3.215541 --> 3.213922).  Saving model ...
Updating learning rate to 5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.045677829346630866:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.31483422789870774:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.704490956648755:   0%|          | 0/19 [00:00<?, ?it/s]  loss:0.8731095927407292:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.172908756444952:   0%|          | 0/19 [00:00<?, ?it/s] loss:1.172908756444952: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 250.95it/s]
Epoch: 3 cost time: 0.535158634185791
Epoch: 3, Steps: 19 | Train Loss: 0.1637380 Vali Loss: 3.2132826 Test Loss: 42.3866425
Validation loss decreased (3.213922 --> 3.213283).  Saving model ...
Updating learning rate to 2.5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 85.35it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 85.35it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 85.35it/s]loss:0.06217103022333628:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 85.35it/s]loss:0.28485769015044543:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 85.35it/s]loss:0.5838548298264021:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 85.35it/s] loss:0.8526443140584793:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 85.35it/s]loss:1.1598963857278637:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 85.35it/s]loss:1.1598963857278637: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 70.72it/s]
Epoch: 4 cost time: 0.7455761432647705
Epoch: 4, Steps: 19 | Train Loss: 0.1549171 Vali Loss: 3.2130194 Test Loss: 42.3976669
Validation loss decreased (3.213283 --> 3.213019).  Saving model ...
Updating learning rate to 1.25e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.05368748027932595:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.3196736792509298:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.49934536942843843:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.711207198144966:   0%|          | 0/19 [00:00<?, ?it/s]  loss:1.1639163773481622:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.1639163773481622: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 253.73it/s]
Epoch: 5 cost time: 0.5439422130584717
Epoch: 5, Steps: 19 | Train Loss: 0.1446226 Vali Loss: 3.2128291 Test Loss: 42.3989716
Validation loss decreased (3.213019 --> 3.212829).  Saving model ...
Updating learning rate to 6.25e-06
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.045608067460679066:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.28468033569284196:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.5835199144502993:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.7261456829680295:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.0367631777122768:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.0367631777122768: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 292.06it/s]
Epoch: 6 cost time: 0.5210680961608887
Epoch: 6, Steps: 19 | Train Loss: 0.1408799 Vali Loss: 3.2127445 Test Loss: 42.4003143
Validation loss decreased (3.212829 --> 3.212744).  Saving model ...
Updating learning rate to 3.125e-06
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.06398225221064367:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.2961840651350371:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.5771447355045828:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8926319852694177:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.1186232361335955:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.1186232361335955: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 210.61it/s]
Epoch: 7 cost time: 0.5703895092010498
Epoch: 7, Steps: 19 | Train Loss: 0.1551877 Vali Loss: 3.2126989 Test Loss: 42.4010849
Validation loss decreased (3.212744 --> 3.212699).  Saving model ...
Updating learning rate to 1.5625e-06
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.055413513021527944:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.29616575522712746:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.5834367631286936:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.8383236510280483:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.1270856313285615:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.1270856313285615: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 259.52it/s]
Epoch: 8 cost time: 0.5149064064025879
Epoch: 8, Steps: 19 | Train Loss: 0.1526540 Vali Loss: 3.2126720 Test Loss: 42.4015236
Validation loss decreased (3.212699 --> 3.212672).  Saving model ...
Updating learning rate to 7.8125e-07
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.04443198817864645:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.3220168007595535:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.6095398916348826:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7260016745010357:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.1017646154942748:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.1017646154942748: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 280.06it/s]
Epoch: 9 cost time: 0.5820772647857666
Epoch: 9, Steps: 19 | Train Loss: 0.1475661 Vali Loss: 3.2126689 Test Loss: 42.4017601
Validation loss decreased (3.212672 --> 3.212669).  Saving model ...
Updating learning rate to 3.90625e-07
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0639792360179294:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.26658798853647564:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.4991198489385349:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.7295742681626239:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.036534176420489:   0%|          | 0/19 [00:00<?, ?it/s] loss:1.036534176420489: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 236.56it/s]
Epoch: 10 cost time: 0.5622725486755371
Epoch: 10, Steps: 19 | Train Loss: 0.1366208 Vali Loss: 3.2126644 Test Loss: 42.4018478
Validation loss decreased (3.212669 --> 3.212664).  Saving model ...
Updating learning rate to 1.953125e-07
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 106.29it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 106.29it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 106.29it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 106.29it/s]loss:0.05246438298221376:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 106.29it/s]loss:0.33117869943146944:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 106.29it/s]loss:0.5015790301573725:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 106.29it/s] loss:0.9036625104850731:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 106.29it/s]loss:0.9330499106469164:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 106.29it/s]loss:0.9330499106469164: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 114.91it/s]
Epoch: 11 cost time: 0.6800076961517334
Epoch: 11, Steps: 19 | Train Loss: 0.1432597 Vali Loss: 3.2126613 Test Loss: 42.4018936
Validation loss decreased (3.212664 --> 3.212661).  Saving model ...
Updating learning rate to 9.765625e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.050624484309034705:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.32201045195241484:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.6095320272745204:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.8382845984545246:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9961833244389855:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9961833244389855: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 252.13it/s]
Epoch: 12 cost time: 0.545802116394043
Epoch: 12, Steps: 19 | Train Loss: 0.1482439 Vali Loss: 3.2126596 Test Loss: 42.4019089
Validation loss decreased (3.212661 --> 3.212660).  Saving model ...
Updating learning rate to 4.8828125e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.056478760455752605:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.37263193829709135:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.5218096198101332:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.852236910472278:   0%|          | 0/19 [00:00<?, ?it/s] loss:1.1446487844499253:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.1446487844499253: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 277.86it/s]
Epoch: 13 cost time: 0.5352129936218262
Epoch: 13, Steps: 19 | Train Loss: 0.1551477 Vali Loss: 3.2126594 Test Loss: 42.4019089
Validation loss decreased (3.212660 --> 3.212659).  Saving model ...
Updating learning rate to 2.44140625e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.053264784752551766:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.3311770376930026:   0%|          | 0/19 [00:00<?, ?it/s]  loss:0.5568682920743088:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8925670636832369:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.1860532791973564:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.1860532791973564: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 274.16it/s]
Epoch: 14 cost time: 0.5323858261108398
Epoch: 14, Steps: 19 | Train Loss: 0.1589437 Vali Loss: 3.2126591 Test Loss: 42.4019165
Validation loss decreased (3.212659 --> 3.212659).  Saving model ...
Updating learning rate to 1.220703125e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.05303727377502676:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.27358702272874613:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5771058833984302:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.8586928696722375:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9961811551771952:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9961811551771952: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 253.59it/s]
Epoch: 15 cost time: 0.5333938598632812
Epoch: 15, Steps: 19 | Train Loss: 0.1451897 Vali Loss: 3.2126591 Test Loss: 42.4019165
Validation loss decreased (3.212659 --> 3.212659).  Saving model ...
Updating learning rate to 6.103515625e-09
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.047437195957667724:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.2665842022493672:   0%|          | 0/19 [00:00<?, ?it/s]  loss:0.5015761739594546:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7897297870590837:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.3762422130793708:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.3762422130793708: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 261.71it/s]
Epoch: 16 cost time: 0.5382757186889648
Epoch: 16, Steps: 19 | Train Loss: 0.1569247 Vali Loss: 3.2126591 Test Loss: 42.4019165
Validation loss decreased (3.212659 --> 3.212659).  Saving model ...
Updating learning rate to 3.0517578125e-09
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.05519616435470713:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.28462317531850856:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6095311479487856:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.7295653421334181:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.100246145855529:   0%|          | 0/19 [00:00<?, ?it/s] loss:1.100246145855529: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 265.11it/s]
Epoch: 17 cost time: 0.5763661861419678
Epoch: 17, Steps: 19 | Train Loss: 0.1462717 Vali Loss: 3.2126591 Test Loss: 42.4019165
Validation loss decreased (3.212659 --> 3.212659).  Saving model ...
Updating learning rate to 1.52587890625e-09
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.052392673612167866:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.2722434169507283:   0%|          | 0/19 [00:00<?, ?it/s]  loss:0.7037676670929891:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9936837496087996:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9961811136780734:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9961811136780734: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 267.00it/s]
Epoch: 18 cost time: 0.5788044929504395
Epoch: 18, Steps: 19 | Train Loss: 0.1588562 Vali Loss: 3.2126591 Test Loss: 42.4019165
Validation loss decreased (3.212659 --> 3.212659).  Saving model ...
Updating learning rate to 7.62939453125e-10
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.056478721013627844:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.2735870032668719:   0%|          | 0/19 [00:00<?, ?it/s]  loss:0.5763194097237374:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8831386297916861:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.1714940339558697:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.1714940339558697: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 269.22it/s]
Epoch: 19 cost time: 0.5693447589874268
Epoch: 19, Steps: 19 | Train Loss: 0.1558430 Vali Loss: 3.2126591 Test Loss: 42.4019165
Validation loss decreased (3.212659 --> 3.212659).  Saving model ...
Updating learning rate to 3.814697265625e-10
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.05303727074513222:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.3311769861718821:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.5568681704650876:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8721127927260518:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.1017475470584626:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.1017475470584626: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 271.67it/s]
Epoch: 20 cost time: 0.5375769138336182
Epoch: 20, Steps: 19 | Train Loss: 0.1534180 Vali Loss: 3.2126591 Test Loss: 42.4019165
Validation loss decreased (3.212659 --> 3.212659).  Saving model ...
Updating learning rate to 1.9073486328125e-10
>>>>>>>testing : long_term_forecast_break_bartlett_0_DLinear_job_demand_region_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 4
test shape: (4, 1, 3, 16345) (4, 1, 3, 16345)
test shape: (4, 3, 16345) (4, 3, 16345)
mse:51027.03125, mae:35.03980255126953, dtw:-999
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           0                   Model:              DLinear             

[1mData Loader[0m
  Data:               job_demand_region   Root Path:          ../../dataset/demand/
  Data Path:          region.parquet      Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        .cache/checkpoints  

[1mForecasting Task[0m
  Seq Len:            6                   Label Len:          1                   
  Pred Len:           3                   Seasonal Patterns:  Monthly             
  Inverse:            1                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             16345               Dec In:             16345               
  C Out:              16345               d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           2                   d FF:               2048                
  Moving Avg:         25                  Factor:             1                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              learned             Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        32                  Itr:                1                   
  Train Epochs:       20                  Batch Size:         1                   
  Patience:           3                   Learning Rate:      0.0001              
  Des:                test                Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1                 

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_break_parzen_0_DLinear_job_demand_region_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 19
val 1
test 4
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.20it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.20it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.20it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.20it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.20it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.20it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.20it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.20it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.20it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.20it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.20it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.20it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.20it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.20it/s]loss:0.00023897554038024537:   5%|â–Œ         | 1/19 [00:00<00:08,  2.20it/s]loss:0.05452028141362083:   5%|â–Œ         | 1/19 [00:00<00:08,  2.20it/s]   loss:0.2756183732745759:   5%|â–Œ         | 1/19 [00:00<00:08,  2.20it/s] loss:1.0242610587064507:   5%|â–Œ         | 1/19 [00:00<00:08,  2.20it/s]loss:1.1500554571120465:   5%|â–Œ         | 1/19 [00:00<00:08,  2.20it/s]loss:1.1500554571120465: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 36.02it/s]
Epoch: 1 cost time: 1.063659429550171
Epoch: 1, Steps: 19 | Train Loss: 0.1318260 Vali Loss: 3.2156208 Test Loss: 42.3463669
Validation loss decreased (inf --> 3.215621).  Saving model ...
Updating learning rate to 0.0001
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0002979052250579413:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.04659990319275035:   0%|          | 0/19 [00:00<?, ?it/s]  loss:0.33510973057121846:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8276199167151521:   0%|          | 0/19 [00:00<?, ?it/s] loss:1.3466563388407686:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.3466563388407686: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 254.54it/s]
Epoch: 2 cost time: 0.5621707439422607
Epoch: 2, Steps: 19 | Train Loss: 0.1345413 Vali Loss: 3.2142746 Test Loss: 42.3656235
Validation loss decreased (3.215621 --> 3.214275).  Saving model ...
Updating learning rate to 5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.000207271468567148:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.05142654948943327:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.38654827234637107:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8493715637026263:   0%|          | 0/19 [00:00<?, ?it/s] loss:1.1734775440313414:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.1734775440313414: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 232.10it/s]
Epoch: 3 cost time: 0.5484073162078857
Epoch: 3, Steps: 19 | Train Loss: 0.1295280 Vali Loss: 3.2137477 Test Loss: 42.3831406
Validation loss decreased (3.214275 --> 3.213748).  Saving model ...
Updating learning rate to 2.5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.00028222958604800266:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.04653457496700252:   0%|          | 0/19 [00:00<?, ?it/s]   loss:0.3204577026409942:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.8295017641623295:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.1604521824719167:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.1604521824719167: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 236.22it/s]
Epoch: 4 cost time: 0.5571348667144775
Epoch: 4, Steps: 19 | Train Loss: 0.1240647 Vali Loss: 3.2135153 Test Loss: 42.3933640
Validation loss decreased (3.213748 --> 3.213515).  Saving model ...
Updating learning rate to 1.25e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0002436192479967889:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.05221935420059466:   0%|          | 0/19 [00:00<?, ?it/s]  loss:0.274143458133935:   0%|          | 0/19 [00:00<?, ?it/s]  loss:0.6920844184866273:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.164573916102371:   0%|          | 0/19 [00:00<?, ?it/s] loss:1.164573916102371: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 262.60it/s]
Epoch: 5 cost time: 0.5597507953643799
Epoch: 5, Steps: 19 | Train Loss: 0.1149087 Vali Loss: 3.2133458 Test Loss: 42.3944092
Validation loss decreased (3.213515 --> 3.213346).  Saving model ...
Updating learning rate to 6.25e-06
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.00020701179090369185:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.04651077385800056:   0%|          | 0/19 [00:00<?, ?it/s]   loss:0.32030564835086983:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.706695054981121:   0%|          | 0/19 [00:00<?, ?it/s]  loss:1.0377653801387525:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.0377653801387525: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 276.00it/s]
Epoch: 6 cost time: 0.555657148361206
Epoch: 6, Steps: 19 | Train Loss: 0.1111307 Vali Loss: 3.2132738 Test Loss: 42.3956909
Validation loss decreased (3.213346 --> 3.213274).  Saving model ...
Updating learning rate to 3.125e-06
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0002902903272498593:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.04840368285630406:   0%|          | 0/19 [00:00<?, ?it/s]  loss:0.31676808084551783:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8684923503441822:   0%|          | 0/19 [00:00<?, ?it/s] loss:1.1192520771159316:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.1192520771159316: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 249.64it/s]
Epoch: 7 cost time: 0.5160396099090576
Epoch: 7, Steps: 19 | Train Loss: 0.1238530 Vali Loss: 3.2132335 Test Loss: 42.3964615
Validation loss decreased (3.213274 --> 3.213233).  Saving model ...
Updating learning rate to 1.5625e-06
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.00025145515701701206:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.04840129984714553:   0%|          | 0/19 [00:00<?, ?it/s]   loss:0.3202678261430611:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.8157657969039114:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.127778982533734:   0%|          | 0/19 [00:00<?, ?it/s] loss:1.127778982533734: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 261.93it/s]
Epoch: 8 cost time: 0.5352845191955566
Epoch: 8, Steps: 19 | Train Loss: 0.1217087 Vali Loss: 3.2132106 Test Loss: 42.3968582
Validation loss decreased (3.213233 --> 3.213211).  Saving model ...
Updating learning rate to 7.8125e-07
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.00020167074020134692:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0526065586788993:   0%|          | 0/19 [00:00<?, ?it/s]    loss:0.33455721978252695:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7065716236409078:   0%|          | 0/19 [00:00<?, ?it/s] loss:1.1023929507681254:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.1023929507681254: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 275.84it/s]
Epoch: 9 cost time: 0.5842010974884033
Epoch: 9, Steps: 19 | Train Loss: 0.1155963 Vali Loss: 3.2132094 Test Loss: 42.3970718
Validation loss decreased (3.213211 --> 3.213209).  Saving model ...
Updating learning rate to 3.90625e-07
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0002902782101265983:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.043560345446384464:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.2740367641839423:   0%|          | 0/19 [00:00<?, ?it/s]  loss:0.7100263461554345:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.037566071827636:   0%|          | 0/19 [00:00<?, ?it/s] loss:1.037566071827636: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 253.01it/s]
Epoch: 10 cost time: 0.5845534801483154
Epoch: 10, Steps: 19 | Train Loss: 0.1087095 Vali Loss: 3.2132056 Test Loss: 42.3971405
Validation loss decreased (3.213209 --> 3.213206).  Saving model ...
Updating learning rate to 1.953125e-07
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.00023806963355934476:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.05410075607641326:   0%|          | 0/19 [00:00<?, ?it/s]   loss:0.27537810813132413:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8791722946115943:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.9338186483693288:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9338186483693288: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 257.59it/s]
Epoch: 11 cost time: 0.5383596420288086
Epoch: 11, Steps: 19 | Train Loss: 0.1127741 Vali Loss: 3.2132022 Test Loss: 42.3971786
Validation loss decreased (3.213206 --> 3.213202).  Saving model ...
Updating learning rate to 9.765625e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.00022973411852090093:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.05260574003780726:   0%|          | 0/19 [00:00<?, ?it/s]   loss:0.33455347556422055:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8157327818613043:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.9969141167178949:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9969141167178949: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 261.78it/s]
Epoch: 12 cost time: 0.5225260257720947
Epoch: 12, Steps: 19 | Train Loss: 0.1157914 Vali Loss: 3.2132003 Test Loss: 42.3971939
Validation loss decreased (3.213202 --> 3.213200).  Saving model ...
Updating learning rate to 4.8828125e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.00025628049657197576:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.06090769618385329:   0%|          | 0/19 [00:00<?, ?it/s]   loss:0.2864469337697131:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.8291565220562604:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.1453489442716718:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.1453489442716718: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 282.01it/s]
Epoch: 13 cost time: 0.5331478118896484
Epoch: 13, Steps: 19 | Train Loss: 0.1222167 Vali Loss: 3.2132003 Test Loss: 42.3971939
Validation loss decreased (3.213200 --> 3.213200).  Saving model ...
Updating learning rate to 2.44140625e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.00024170128342255976:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.054100537619519856:   0%|          | 0/19 [00:00<?, ?it/s]  loss:0.30566079723910017:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.8684367632955367:   0%|          | 0/19 [00:00<?, ?it/s] loss:1.1867063423831807:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.1867063423831807: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 249.83it/s]
Epoch: 14 cost time: 0.5279204845428467
Epoch: 14, Steps: 19 | Train Loss: 0.1271130 Vali Loss: 3.2132001 Test Loss: 42.3971939
Validation loss decreased (3.213200 --> 3.213200).  Saving model ...
Updating learning rate to 1.220703125e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.00024070306196827178:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.04470604658242794:   0%|          | 0/19 [00:00<?, ?it/s]   loss:0.31675059309979164:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.835480217606194:   0%|          | 0/19 [00:00<?, ?it/s]  loss:0.9969122479102193:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9969122479102193: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 183.07it/s]
Epoch: 15 cost time: 0.6010713577270508
Epoch: 15, Steps: 19 | Train Loss: 0.1154784 Vali Loss: 3.2131999 Test Loss: 42.3971939
Validation loss decreased (3.213200 --> 3.213200).  Saving model ...
Updating learning rate to 6.103515625e-09
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.00021529256282820384:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.04355985070228293:   0%|          | 0/19 [00:00<?, ?it/s]   loss:0.27537681957359883:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.768670428390188:   0%|          | 0/19 [00:00<?, ?it/s]  loss:1.3769704212002838:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.3769704212002838: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 261.14it/s]
Epoch: 16 cost time: 0.5420083999633789
Epoch: 16, Steps: 19 | Train Loss: 0.1297259 Vali Loss: 3.2131999 Test Loss: 42.3971939
Validation loss decreased (3.213200 --> 3.213200).  Saving model ...
Updating learning rate to 3.0517578125e-09
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0002504654391253032:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.04650319357283449:   0%|          | 0/19 [00:00<?, ?it/s]  loss:0.3345531043818745:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.7100189257444728:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.1010768227977064:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.1010768227977064: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 278.70it/s]
Epoch: 17 cost time: 0.552105188369751
Epoch: 17, Steps: 19 | Train Loss: 0.1153896 Vali Loss: 3.2131999 Test Loss: 42.3971939
Validation loss decreased (3.213200 --> 3.213200).  Saving model ...
Updating learning rate to 1.52587890625e-09
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.00023778788960105704:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.044487979312648016:   0%|          | 0/19 [00:00<?, ?it/s]  loss:0.38621339479403016:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.9673316775376486:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.996912212217641:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.996912212217641: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 276.65it/s]
Epoch: 18 cost time: 0.5232267379760742
Epoch: 18, Steps: 19 | Train Loss: 0.1260623 Vali Loss: 3.2131999 Test Loss: 42.3971939
Validation loss decreased (3.213200 --> 3.213200).  Saving model ...
Updating learning rate to 7.62939453125e-10
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.00025628036476555165:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.044706045171492764:   0%|          | 0/19 [00:00<?, ?it/s]  loss:0.3163767871142097:   0%|          | 0/19 [00:00<?, ?it/s]  loss:0.8592216889193615:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.1722185633581887:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.1722185633581887: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 236.86it/s]
Epoch: 19 cost time: 0.5535051822662354
Epoch: 19, Steps: 19 | Train Loss: 0.1259358 Vali Loss: 3.2131999 Test Loss: 42.3971939
Validation loss decreased (3.213200 --> 3.213200).  Saving model ...
Updating learning rate to 3.814697265625e-10
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0002407030558024231:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.05410053485106599:   0%|          | 0/19 [00:00<?, ?it/s]  loss:0.3056607660241292:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.8485298760806996:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.1023777453963406:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.1023777453963406: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 258.62it/s]
Epoch: 20 cost time: 0.550189733505249
Epoch: 20, Steps: 19 | Train Loss: 0.1216268 Vali Loss: 3.2131999 Test Loss: 42.3971939
Validation loss decreased (3.213200 --> 3.213200).  Saving model ...
Updating learning rate to 1.9073486328125e-10
>>>>>>>testing : long_term_forecast_break_parzen_0_DLinear_job_demand_region_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 4
test shape: (4, 1, 3, 16345) (4, 1, 3, 16345)
test shape: (4, 3, 16345) (4, 3, 16345)
mse:50993.6328125, mae:35.03951644897461, dtw:-999
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           0                   Model:              DLinear             

[1mData Loader[0m
  Data:               job_demand_region   Root Path:          ../../dataset/demand/
  Data Path:          region.parquet      Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        .cache/checkpoints  

[1mForecasting Task[0m
  Seq Len:            6                   Label Len:          1                   
  Pred Len:           3                   Seasonal Patterns:  Monthly             
  Inverse:            1                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             16345               Dec In:             16345               
  C Out:              16345               d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           2                   d FF:               2048                
  Moving Avg:         25                  Factor:             1                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              learned             Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        32                  Itr:                1                   
  Train Epochs:       20                  Batch Size:         1                   
  Patience:           3                   Learning Rate:      0.0001              
  Des:                test                Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1                 

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_break_tukey-hanning_0_DLinear_job_demand_region_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 19
val 1
test 4
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.25it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.25it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.25it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.25it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.25it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.25it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.25it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.25it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.25it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.25it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.25it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.25it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.25it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.25it/s]loss:0.006179771158348164:   5%|â–Œ         | 1/19 [00:00<00:08,  2.25it/s]loss:0.22002853290662389:   5%|â–Œ         | 1/19 [00:00<00:08,  2.25it/s] loss:0.5154507293253353:   5%|â–Œ         | 1/19 [00:00<00:08,  2.25it/s] loss:1.1979929422885072:   5%|â–Œ         | 1/19 [00:00<00:08,  2.25it/s]loss:1.1500128466534962:   5%|â–Œ         | 1/19 [00:00<00:08,  2.25it/s]loss:1.1500128466534962: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 36.42it/s]
Epoch: 1 cost time: 1.0672214031219482
Epoch: 1, Steps: 19 | Train Loss: 0.1626139 Vali Loss: 3.2155664 Test Loss: 42.3469391
Validation loss decreased (inf --> 3.215566).  Saving model ...
Updating learning rate to 0.0001
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.007702836445238645:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.18804535421369112:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.626615585647766:   0%|          | 0/19 [00:00<?, ?it/s]  loss:0.9678547536073507:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.346457284471384:   0%|          | 0/19 [00:00<?, ?it/s] loss:1.346457284471384: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 262.20it/s]
Epoch: 2 cost time: 0.5420515537261963
Epoch: 2, Steps: 19 | Train Loss: 0.1650882 Vali Loss: 3.2140441 Test Loss: 42.3670197
Validation loss decreased (3.215566 --> 3.214044).  Saving model ...
Updating learning rate to 5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.005358169663982545:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.207485323958175:   0%|          | 0/19 [00:00<?, ?it/s]   loss:0.7228156087360843:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9931934507698424:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.1731606043160232:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.1731606043160232: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 280.46it/s]
Epoch: 3 cost time: 0.5231893062591553
Epoch: 3, Steps: 19 | Train Loss: 0.1632639 Vali Loss: 3.2134180 Test Loss: 42.3835907
Validation loss decreased (3.214044 --> 3.213418).  Saving model ...
Updating learning rate to 2.5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.007293953890463146:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.1877288840001115:   0%|          | 0/19 [00:00<?, ?it/s]  loss:0.5991099509224967:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9699132243405351:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.1601021318386642:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.1601021318386642: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 267.11it/s]
Epoch: 4 cost time: 0.5945098400115967
Epoch: 4, Steps: 19 | Train Loss: 0.1539025 Vali Loss: 3.2131557 Test Loss: 42.3941422
Validation loss decreased (3.213418 --> 3.213156).  Saving model ...
Updating learning rate to 1.25e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.006297806516414755:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.2106727373448442:   0%|          | 0/19 [00:00<?, ?it/s]  loss:0.5124440370085317:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8091221075175518:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.1641609954250884:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.1641609954250884: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 228.46it/s]
Epoch: 5 cost time: 0.527787446975708
Epoch: 5, Steps: 19 | Train Loss: 0.1422472 Vali Loss: 3.2129672 Test Loss: 42.3953094
Validation loss decreased (3.213156 --> 3.212967).  Saving model ...
Updating learning rate to 6.25e-06
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.005350532156014998:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.18761852242442756:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.5987848421770734:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.8261476135192571:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.0371434454047328:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.0371434454047328: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 271.83it/s]
Epoch: 6 cost time: 0.5237054824829102
Epoch: 6, Steps: 19 | Train Loss: 0.1397392 Vali Loss: 3.2128880 Test Loss: 42.3966370
Validation loss decreased (3.212967 --> 3.212888).  Saving model ...
Updating learning rate to 3.125e-06
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.007504847377094834:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.1952258015007944:   0%|          | 0/19 [00:00<?, ?it/s]  loss:0.5922024017202634:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.0154687336747583:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.118857890665505:   0%|          | 0/19 [00:00<?, ?it/s] loss:1.118857890665505: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 214.53it/s]
Epoch: 7 cost time: 0.5853407382965088
Epoch: 7, Steps: 19 | Train Loss: 0.1541716 Vali Loss: 3.2128448 Test Loss: 42.3973885
Validation loss decreased (3.212888 --> 3.212845).  Saving model ...
Updating learning rate to 1.5625e-06
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.006500106316593647:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.1952145483590141:   0%|          | 0/19 [00:00<?, ?it/s]  loss:0.5987035615437586:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9537299800530956:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.1273742811082443:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.1273742811082443: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 260.11it/s]
Epoch: 8 cost time: 0.564918041229248
Epoch: 8, Steps: 19 | Train Loss: 0.1516591 Vali Loss: 3.2128198 Test Loss: 42.3978195
Validation loss decreased (3.212845 --> 3.212820).  Saving model ...
Updating learning rate to 7.8125e-07
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.00521251841480631:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.21222900422439878:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6254506816919964:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.8259894964452545:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.1019946682973951:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.1019946682973951: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 249.12it/s]
Epoch: 9 cost time: 0.5237681865692139
Epoch: 9, Steps: 19 | Train Loss: 0.1458356 Vali Loss: 3.2128167 Test Loss: 42.3980408
Validation loss decreased (3.212820 --> 3.212817).  Saving model ...
Updating learning rate to 3.90625e-07
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.007504509468201419:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.1757103491478606:   0%|          | 0/19 [00:00<?, ?it/s]  loss:0.5122206698869451:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8300414947782347:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.0369250656458255:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.0369250656458255: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 254.63it/s]
Epoch: 10 cost time: 0.5552830696105957
Epoch: 10, Steps: 19 | Train Loss: 0.1348633 Vali Loss: 3.2128122 Test Loss: 42.3981247
Validation loss decreased (3.212817 --> 3.212812).  Saving model ...
Updating learning rate to 1.953125e-07
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.006154116869367598:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.21825581904906458:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.5147364393839134:   0%|          | 0/19 [00:00<?, ?it/s] loss:1.027958882404544:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.9333556021312839:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9333556021312839: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 269.33it/s]
Epoch: 11 cost time: 0.547433614730835
Epoch: 11, Steps: 19 | Train Loss: 0.1421295 Vali Loss: 3.2128091 Test Loss: 42.3981590
Validation loss decreased (3.212812 --> 3.212809).  Saving model ...
Updating learning rate to 9.765625e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 139.57it/s]loss:0.005938550687193225:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 139.57it/s]loss:0.21222516368419408:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 139.57it/s] loss:0.625442801547487:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 139.57it/s]  loss:0.9536874051575872:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 139.57it/s]loss:0.9964316014623895:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 139.57it/s]loss:0.9964316014623895: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 123.90it/s]
Epoch: 12 cost time: 0.6059792041778564
Epoch: 12, Steps: 19 | Train Loss: 0.1470382 Vali Loss: 3.2128079 Test Loss: 42.3981705
Validation loss decreased (3.212809 --> 3.212808).  Saving model ...
Updating learning rate to 4.8828125e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.006624972643925103:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.24563336117933748:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.5354468267025231:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.9694677477663414:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.1449246624210223:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.1449246624210223: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 236.04it/s]
Epoch: 13 cost time: 0.5814731121063232
Epoch: 13, Steps: 19 | Train Loss: 0.1527420 Vali Loss: 3.2128069 Test Loss: 42.3981705
Validation loss decreased (3.212808 --> 3.212807).  Saving model ...
Updating learning rate to 2.44140625e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.00624802388321784:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.21825481117736362:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5714234775081178:   0%|          | 0/19 [00:00<?, ?it/s] loss:1.0153973064469495:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.1862953037996828:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.1862953037996828: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 269.10it/s]
Epoch: 14 cost time: 0.5288233757019043
Epoch: 14, Steps: 19 | Train Loss: 0.1577694 Vali Loss: 3.2128069 Test Loss: 42.3981743
Validation loss decreased (3.212807 --> 3.212807).  Saving model ...
Updating learning rate to 1.220703125e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.006221776676780546:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.18032665447720028:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.5921646183581646:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.9768568308955097:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9964295537360958:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9964295537360958: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 259.07it/s]
Epoch: 15 cost time: 0.535332202911377
Epoch: 15, Steps: 19 | Train Loss: 0.1448421 Vali Loss: 3.2128065 Test Loss: 42.3981781
Validation loss decreased (3.212807 --> 3.212806).  Saving model ...
Updating learning rate to 6.103515625e-09
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.005564647178439136:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.17570803478716787:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.5147336540628554:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.8985109690802445:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.3765491093792708:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.3765491093792708: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 260.10it/s]
Epoch: 16 cost time: 0.5323495864868164
Epoch: 16, Steps: 19 | Train Loss: 0.1563719 Vali Loss: 3.2128065 Test Loss: 42.3981781
Validation loss decreased (3.212806 --> 3.212806).  Saving model ...
Updating learning rate to 3.0517578125e-09
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.006474527506107154:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.18758293611382432:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.6254419490187401:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.8300317699343784:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.1005850225485214:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.1005850225485214: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 249.39it/s]
Epoch: 17 cost time: 0.5454604625701904
Epoch: 17, Steps: 19 | Train Loss: 0.1447430 Vali Loss: 3.2128065 Test Loss: 42.3981781
Validation loss decreased (3.212806 --> 3.212806).  Saving model ...
Updating learning rate to 1.52587890625e-09
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.00614631268543258:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.1794439096287952:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.7221017110130747:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.1306328812185393:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9964295091950368:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9964295091950368: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 269.82it/s]
Epoch: 18 cost time: 0.5609345436096191
Epoch: 18, Steps: 19 | Train Loss: 0.1597239 Vali Loss: 3.2128065 Test Loss: 42.3981781
Validation loss decreased (3.212806 --> 3.212806).  Saving model ...
Updating learning rate to 7.62939453125e-10
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.006624968458759747:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.1803266427930182:   0%|          | 0/19 [00:00<?, ?it/s]  loss:0.5914159221591856:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.0046125389770604:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.1718023209570392:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.1718023209570392: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 242.19it/s]
Epoch: 19 cost time: 0.6082780361175537
Epoch: 19, Steps: 19 | Train Loss: 0.1555149 Vali Loss: 3.2128065 Test Loss: 42.3981781
Validation loss decreased (3.212806 --> 3.212806).  Saving model ...
Updating learning rate to 3.814697265625e-10
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.006221776342420159:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.21825478639948914:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.5714233649954127:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.9921063250074325:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.101978247701558:   0%|          | 0/19 [00:00<?, ?it/s] loss:1.101978247701558: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 233.20it/s]
Epoch: 20 cost time: 0.5744915008544922
Epoch: 20, Steps: 19 | Train Loss: 0.1521044 Vali Loss: 3.2128065 Test Loss: 42.3981781
Validation loss decreased (3.212806 --> 3.212806).  Saving model ...
Updating learning rate to 1.9073486328125e-10
>>>>>>>testing : long_term_forecast_break_tukey-hanning_0_DLinear_job_demand_region_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 4
test shape: (4, 1, 3, 16345) (4, 1, 3, 16345)
test shape: (4, 3, 16345) (4, 3, 16345)
mse:51010.5703125, mae:35.0390625, dtw:-999
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           0                   Model:              DLinear             

[1mData Loader[0m
  Data:               job_demand_region   Root Path:          ../../dataset/demand/
  Data Path:          region.parquet      Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        .cache/checkpoints  

[1mForecasting Task[0m
  Seq Len:            6                   Label Len:          1                   
  Pred Len:           3                   Seasonal Patterns:  Monthly             
  Inverse:            1                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             16345               Dec In:             16345               
  C Out:              16345               d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           2                   d FF:               2048                
  Moving Avg:         25                  Factor:             1                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              learned             Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        32                  Itr:                1                   
  Train Epochs:       20                  Batch Size:         1                   
  Patience:           3                   Learning Rate:      0.0001              
  Des:                test                Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1                 

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_break_rayleigh_0_DLinear_job_demand_region_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 19
val 1
test 4
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.5175320953153876:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5175320953153876:   5%|â–Œ         | 1/19 [00:00<00:07,  2.32it/s]loss:0.578286358399423:   5%|â–Œ         | 1/19 [00:00<00:07,  2.32it/s] loss:0.7111301018179276:   5%|â–Œ         | 1/19 [00:00<00:07,  2.32it/s]loss:0.6298644359244966:   5%|â–Œ         | 1/19 [00:00<00:07,  2.32it/s]loss:0.6927420167909247:   5%|â–Œ         | 1/19 [00:00<00:07,  2.32it/s]loss:0.6996974218020594:   5%|â–Œ         | 1/19 [00:00<00:07,  2.32it/s]loss:0.9163393846294982:   5%|â–Œ         | 1/19 [00:00<00:07,  2.32it/s]loss:0.7698685344662561:   5%|â–Œ         | 1/19 [00:00<00:07,  2.32it/s]loss:0.7288578067051671:   5%|â–Œ         | 1/19 [00:00<00:07,  2.32it/s]loss:0.9602293009253362:   5%|â–Œ         | 1/19 [00:00<00:07,  2.32it/s]loss:0.8508536582230063:   5%|â–Œ         | 1/19 [00:00<00:07,  2.32it/s]loss:0.9918003249596481:   5%|â–Œ         | 1/19 [00:00<00:07,  2.32it/s]loss:0.8775619970615456:   5%|â–Œ         | 1/19 [00:00<00:07,  2.32it/s]loss:1.048015022173582:   5%|â–Œ         | 1/19 [00:00<00:07,  2.32it/s] loss:1.0588696138648677:   5%|â–Œ         | 1/19 [00:00<00:07,  2.32it/s]loss:1.1397811333122783:   5%|â–Œ         | 1/19 [00:00<00:07,  2.32it/s]loss:0.9448094183103184:   5%|â–Œ         | 1/19 [00:00<00:07,  2.32it/s]loss:1.3752533501827362:   5%|â–Œ         | 1/19 [00:00<00:07,  2.32it/s]loss:1.1462588831733562:   5%|â–Œ         | 1/19 [00:00<00:07,  2.32it/s]loss:1.1462588831733562: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 37.57it/s]
Epoch: 1 cost time: 1.0103514194488525
Epoch: 1, Steps: 19 | Train Loss: 0.8756711 Vali Loss: 3.2132316 Test Loss: 42.3907471
Validation loss decreased (inf --> 3.213232).  Saving model ...
Updating learning rate to 0.0001
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.5280338285033751:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.46499769776750266:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5937325593014258:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.6274588874941028:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6734420504769023:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6787018953364281:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7799874003256053:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7847445628656127:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7246200406403133:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9560612910082632:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8097358509959062:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.022342791253166:   0%|          | 0/19 [00:00<?, ?it/s] loss:1.044626550364446:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.2209658619629817:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.3203731144450133:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.970379392099106:   0%|          | 0/19 [00:00<?, ?it/s] loss:1.1496696946981533:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.106269460080877:   0%|          | 0/19 [00:00<?, ?it/s] loss:1.340832662715678:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.340832662715678: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 211.44it/s]
Epoch: 2 cost time: 0.5534651279449463
Epoch: 2, Steps: 19 | Train Loss: 0.8840513 Vali Loss: 3.2103536 Test Loss: 42.4429092
Validation loss decreased (3.213232 --> 3.210354).  Saving model ...
Updating learning rate to 5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.42140815239853485:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.54462826913021:   0%|          | 0/19 [00:00<?, ?it/s]   loss:0.6234660134751091:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7380717452290394:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6483679961606356:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.607325130386932:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.718188968339608:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8106577316785931:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.862398280946794:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.8087619940301524:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9819443842738911:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9856342474088932:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.25308125007905:   0%|          | 0/19 [00:00<?, ?it/s]  loss:1.0889349913951418:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9133318505803457:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.0682771607537815:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.3256621616915563:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.1361159198092783:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.1657451641418561:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.1657451641418561: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 228.62it/s]
Epoch: 3 cost time: 0.5669541358947754
Epoch: 3, Steps: 19 | Train Loss: 0.8790527 Vali Loss: 3.2089279 Test Loss: 42.4660873
Validation loss decreased (3.210354 --> 3.208928).  Saving model ...
Updating learning rate to 2.5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.5954864177894483:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5528449378720307:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6145272766320444:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5411015224039187:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.56639375335472:   0%|          | 0/19 [00:00<?, ?it/s]  loss:0.715475478598942:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6586104160443776:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.0121402524871668:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.901923513501288:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.8382640934641721:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9332968459088683:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9899715703582429:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9649407531194005:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.1083729325745755:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.2390434840988582:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9662500285249496:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.0937576085871956:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.10960433783223:   0%|          | 0/19 [00:00<?, ?it/s]  loss:1.1502534105302673:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.1502534105302673: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 252.11it/s]
Epoch: 4 cost time: 0.5719699859619141
Epoch: 4, Steps: 19 | Train Loss: 0.8711715 Vali Loss: 3.2082708 Test Loss: 42.4813385
Validation loss decreased (3.208928 --> 3.208271).  Saving model ...
Updating learning rate to 1.25e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.50603446121789:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5362652079289271:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5001276470612751:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6237196080610793:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6464608535719323:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8765285034356356:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8121872996314735:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7576184067929772:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7692292217242769:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9391047973290537:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.1662018628133735:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.0432609706625873:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.177331969115066:   0%|          | 0/19 [00:00<?, ?it/s] loss:1.024145231235331:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.0742399634279332:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.0871648517553205:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9330633344698296:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9207043815224614:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.1570369090224353:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.1570369090224353: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 270.13it/s]
Epoch: 5 cost time: 0.5359675884246826
Epoch: 5, Steps: 19 | Train Loss: 0.8710750 Vali Loss: 3.2079058 Test Loss: 42.4864655
Validation loss decreased (3.208271 --> 3.207906).  Saving model ...
Updating learning rate to 6.25e-06
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.5147041055846059:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5724300704937803:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7049918217782978:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7336690771460096:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6676942068944937:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7326313583055786:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.775615515533867:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.6819280153588211:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8521137904204082:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8613124948698275:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9687288508288351:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.0294188709951824:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.0504754361314181:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.2851561257287436:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9105002584240081:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9651892576302167:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.0926114952451713:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9396468781613883:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.024336541234224:   0%|          | 0/19 [00:00<?, ?it/s] loss:1.024336541234224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 266.92it/s]
Epoch: 6 cost time: 0.5321519374847412
Epoch: 6, Steps: 19 | Train Loss: 0.8612186 Vali Loss: 3.2077358 Test Loss: 42.4896355
Validation loss decreased (3.207906 --> 3.207736).  Saving model ...
Updating learning rate to 3.125e-06
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.5243667417806855:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5518959565731982:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5892964362077516:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6548299925046078:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5770445185785399:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6046511632117231:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7356608478552892:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7293806696200286:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8485391406022951:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9446701370592718:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.0967066828190717:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9762162336207381:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8659165432944878:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.2849728127371385:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.284296604468604:   0%|          | 0/19 [00:00<?, ?it/s] loss:1.0013659144557319:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.083001900341256:   0%|          | 0/19 [00:00<?, ?it/s] loss:1.1604199067742251:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.1114429150302148:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.1114429150302148: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 228.58it/s]
Epoch: 7 cost time: 0.5785095691680908
Epoch: 7, Steps: 19 | Train Loss: 0.8749829 Vali Loss: 3.2076604 Test Loss: 42.4911423
Validation loss decreased (3.207736 --> 3.207660).  Saving model ...
Updating learning rate to 1.5625e-06
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.48661440838840353:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6641104391232812:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.6059251596528186:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6007392185933361:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7883357448935058:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6468277901984156:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.660959631157653:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.6959192623213256:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.0409813348773682:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9500265274270719:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.0043108668102407:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9832631575692513:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8430034504147089:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.067632129306858:   0%|          | 0/19 [00:00<?, ?it/s] loss:1.1112461874209307:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.001243477699058:   0%|          | 0/19 [00:00<?, ?it/s] loss:1.092319519373291:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.0866500544505333:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.1173962686529468:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.1173962686529468: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 262.45it/s]
Epoch: 8 cost time: 0.6004753112792969
Epoch: 8, Steps: 19 | Train Loss: 0.8656581 Vali Loss: 3.2076125 Test Loss: 42.4919815
Validation loss decreased (3.207660 --> 3.207613).  Saving model ...
Updating learning rate to 7.8125e-07
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.4944036394304569:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5579142781870465:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5203627535502969:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6286283781535154:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6962236963456874:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6208705302993991:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7144123192510471:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.0106858303067385:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9059108610251829:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8609961268296633:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9282730657865776:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.1824892321091134:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.175911643560583:   0%|          | 0/19 [00:00<?, ?it/s] loss:1.107114188227438:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8861702079226806:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.0925034399870475:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.1450464518906924:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9392992272335683:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.0937747220214011:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.0937747220214011: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 246.86it/s]
Epoch: 9 cost time: 0.5171909332275391
Epoch: 9, Steps: 19 | Train Loss: 0.8716311 Vali Loss: 3.2075934 Test Loss: 42.4924164
Validation loss decreased (3.207613 --> 3.207593).  Saving model ...
Updating learning rate to 3.90625e-07
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.46898432022257225:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5289030094670201:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.678424214597988:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.6366472176373036:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7125979261637032:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7230692606679974:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7630962876205707:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.0106625669288753:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9007161064889546:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8059226047183582:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9791353516225162:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.0426238901529834:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.0386082603578701:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.0440022826695117:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.2841559175495896:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9017883285893032:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9322576692997091:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9448926552090199:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.023930620979229:   0%|          | 0/19 [00:00<?, ?it/s] loss:1.023930620979229: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 185.22it/s]
Epoch: 10 cost time: 0.5526227951049805
Epoch: 10, Steps: 19 | Train Loss: 0.8642326 Vali Loss: 3.2075827 Test Loss: 42.4926147
Validation loss decreased (3.207593 --> 3.207583).  Saving model ...
Updating learning rate to 1.953125e-07
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.5055420085656728:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6246847089146836:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.585995272072597:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.600673211293979:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6045451956631033:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7139296274358282:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8068844014162598:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7566478903351754:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.0409106067495701:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9499425876337995:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8023936244801211:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.2099674104226186:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.0211632041651453:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.0363770009658169:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.0508657789638258:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.123447054520555:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.9378217229070479:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.1755410087242943:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9222948984329139:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9222948984329139: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 201.64it/s]
Epoch: 11 cost time: 0.5369226932525635
Epoch: 11, Steps: 19 | Train Loss: 0.8668225 Vali Loss: 3.2075775 Test Loss: 42.4927177
Validation loss decreased (3.207583 --> 3.207577).  Saving model ...
Updating learning rate to 9.765625e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.45549752016568307:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5578860500097264:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.4863184853733543:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7330636762762242:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8188059168088961:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7230524796169722:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7753423958138608:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.808245872358755:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.885030278078462:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9624493657312145:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8023866403013373:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8380309023228456:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.2499312169881247:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.0926867084659724:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.0128678231520647:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.0924644838297444:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.145015350571252:   0%|          | 0/19 [00:00<?, ?it/s] loss:1.0865610472215692:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.98679808535747:   0%|          | 0/19 [00:00<?, ?it/s]  loss:0.98679808535747: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 241.24it/s]
Epoch: 12 cost time: 0.5734899044036865
Epoch: 12, Steps: 19 | Train Loss: 0.8690755 Vali Loss: 3.2075746 Test Loss: 42.4927673
Validation loss decreased (3.207577 --> 3.207575).  Saving model ...
Updating learning rate to 4.8828125e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.46897041851585597:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6640399821226081:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.5817136379114823:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5397209328687101:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6700576706384509:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7139206215546644:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6569361857018512:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7566367758454848:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9058671327571526:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.0915392215300592:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9791159513350431:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.0231812195914778:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.0211544858623791:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8664090968833498:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.1322686396394264:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.2579318025457207:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9769773074968848:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.108542155205018:   0%|          | 0/19 [00:00<?, ?it/s] loss:1.136396930144857:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.136396930144857: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 267.74it/s]
Epoch: 13 cost time: 0.5460333824157715
Epoch: 13, Steps: 19 | Train Loss: 0.8711253 Vali Loss: 3.2075734 Test Loss: 42.4927902
Validation loss decreased (3.207575 --> 3.207573).  Saving model ...
Updating learning rate to 2.44140625e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.48656107586489594:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6246698743344503:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.7211453561247145:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5834047349189676:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5650171127969952:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6467518825259689:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7928369008751076:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8152345802017451:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8483298550261865:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7689948601899869:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.1389283338490226:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.0231800401568125:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.0211531295039875:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8898466225249306:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.0677407787830129:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.1234374447499278:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.0437097278220768:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.1602498533806698:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.1784759218368186:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.1784759218368186: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 262.16it/s]
Epoch: 14 cost time: 0.5554425716400146
Epoch: 14, Steps: 19 | Train Loss: 0.8684036 Vali Loss: 3.2075727 Test Loss: 42.4928055
Validation loss decreased (3.207573 --> 3.207573).  Saving model ...
Updating learning rate to 1.220703125e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.45549280181827434:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6246688058336071:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.6214013621550449:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6627450774337367:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.576850545085469:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.6909284516768119:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9324751417440031:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8490753533774876:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8850256187892854:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8895968419092966:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7859195776365562:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.0231794192360817:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.2499260823296499:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.0439842944495439:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.0599474349710674:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9261608757878346:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.08286017498784:   0%|          | 0/19 [00:00<?, ?it/s]  loss:1.1145284622406697:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9867940013126173:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9867940013126173: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 247.67it/s]
Epoch: 15 cost time: 0.5178210735321045
Epoch: 15, Steps: 19 | Train Loss: 0.8663979 Vali Loss: 3.2075725 Test Loss: 42.4928207
Validation loss decreased (3.207573 --> 3.207572).  Saving model ...
Updating learning rate to 6.103515625e-09
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.41887916208121817:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6246681948700913:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.5859881545134101:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.658964681968727:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.6844986087122086:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7139178917966459:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7354891153903368:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8397601135112578:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8518079037632083:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.0915370868722563:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9400888523427123:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.042604109149198:   0%|          | 0/19 [00:00<?, ?it/s] loss:1.0501072328110572:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.0926813284312438:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9481012129480918:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9017650913510306:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9378103726242519:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.0213484184640955:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.3676367111456946:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.3676367111456946: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 247.53it/s]
Epoch: 16 cost time: 0.5869619846343994
Epoch: 16, Steps: 19 | Train Loss: 0.8688239 Vali Loss: 3.2075725 Test Loss: 42.4928207
Validation loss decreased (3.207572 --> 3.207572).  Saving model ...
Updating learning rate to 3.0517578125e-09
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.45549239112491957:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6640380817432187:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.5767223965527822:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7330549140054525:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8188018809712955:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7723801177372026:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6569332940859746:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8595335710510842:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8654932435498321:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9009721908944297:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7859192561638354:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.0053753804104415:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.0211519421667488:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.990327544817028:   0%|          | 0/19 [00:00<?, ?it/s] loss:1.1039473870453038:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9648390105000546:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.145011466748895:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.9448703888160546:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.0892753720896888:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.0892753720896888: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 258.84it/s]
Epoch: 17 cost time: 0.6027402877807617
Epoch: 17, Steps: 19 | Train Loss: 0.8607442 Vali Loss: 3.2075725 Test Loss: 42.4928207
Validation loss decreased (3.207572 --> 3.207572).  Saving model ...
Updating learning rate to 1.52587890625e-09
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.5174380869927366:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5578820549821397:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5992124813310129:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5255020345252959:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6272712155425567:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8963576484031814:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7354891159439572:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8546311142929358:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8701682851081787:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9075962009399142:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9320263007613006:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8380248578898454:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.0082529826055469:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.107075140025934:   0%|          | 0/19 [00:00<?, ?it/s] loss:1.0465642738324905:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9206523385430135:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.3232447563138108:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.283339070875897:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.9867939551471735:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9867939551471735: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 249.38it/s]
Epoch: 18 cost time: 0.5254921913146973
Epoch: 18, Steps: 19 | Train Loss: 0.8703959 Vali Loss: 3.2075725 Test Loss: 42.4928207
Validation loss decreased (3.207572 --> 3.207572).  Saving model ...
Updating learning rate to 7.62939453125e-10
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.6084042187274141:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5118521131225691:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.4863137841251232:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5834034714420884:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6045360225447913:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7283630122136121:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7696796520250465:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9507209670176108:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7333202300536098:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9280784464052126:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9855205025289289:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9676408870461755:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.2215088648236792:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.0496233075842656:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.132266672659833:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.9261607015643346:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.0784369010444597:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.1461314213775675:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.1631532083615677:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.1631532083615677: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 270.27it/s]
Epoch: 19 cost time: 0.5603272914886475
Epoch: 19, Steps: 19 | Train Loss: 0.8723744 Vali Loss: 3.2075725 Test Loss: 42.4928207
Validation loss decreased (3.207572 --> 3.207572).  Saving model ...
Updating learning rate to 3.814697265625e-10
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.5144868162566215:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5721932635049887:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5398973385993202:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6627447206550899:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.580301481042743:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.6467509299353772:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.897596476610674:   0%|          | 0/19 [00:00<?, ?it/s] loss:1.0106404264636801:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7333202300536098:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8895964722126765:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.1389273165219287:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.9831872271491322:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.842904833965383:   0%|          | 0/19 [00:00<?, ?it/s] loss:1.0496233075842656:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.0599472184481298:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.1234364986694774:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.0437087367796134:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.1335575742283321:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.0937429959936686:   0%|          | 0/19 [00:00<?, ?it/s]loss:1.0937429959936686: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 198.57it/s]
Epoch: 20 cost time: 0.5579495429992676
Epoch: 20, Steps: 19 | Train Loss: 0.8692928 Vali Loss: 3.2075725 Test Loss: 42.4928207
Validation loss decreased (3.207572 --> 3.207572).  Saving model ...
Updating learning rate to 1.9073486328125e-10
>>>>>>>testing : long_term_forecast_break_rayleigh_0_DLinear_job_demand_region_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 4
test shape: (4, 1, 3, 16345) (4, 1, 3, 16345)
test shape: (4, 3, 16345) (4, 3, 16345)
mse:51622.41015625, mae:35.07091522216797, dtw:-999
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           0                   Model:              SegRNN              

[1mData Loader[0m
  Data:               job_demand_region   Root Path:          ../../dataset/demand/
  Data Path:          region.parquet      Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        .cache/checkpoints  

[1mForecasting Task[0m
  Seq Len:            6                   Label Len:          1                   
  Pred Len:           3                   Seasonal Patterns:  Monthly             
  Inverse:            1                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             16345               Dec In:             16345               
  C Out:              16345               d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           2                   d FF:               2048                
  Moving Avg:         25                  Factor:             1                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              learned             Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        32                  Itr:                1                   
  Train Epochs:       20                  Batch Size:         1                   
  Patience:           3                   Learning Rate:      0.0001              
  Des:                test                Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1                 

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_break_bartlett_0_SegRNN_job_demand_region_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 19
val 1
test 4
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.12it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.12it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.12it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.12it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.12it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.12it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.12it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.12it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.12it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 19.63it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 19.63it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 19.63it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 19.63it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 19.63it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 19.63it/s]loss:0.06163370533028923:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 19.63it/s]loss:0.457359173767573:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 19.63it/s]  loss:0.7888598904367344:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 19.63it/s]loss:0.7888598904367344:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 34.13it/s]loss:1.2130635554545615:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 34.13it/s]loss:1.8173336586344317:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 34.13it/s]loss:1.8173336586344317: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 25.45it/s]
Epoch: 1 cost time: 1.2824785709381104
Epoch: 1, Steps: 19 | Train Loss: 0.2283289 Vali Loss: 3.4575593 Test Loss: 37.3761063
Validation loss decreased (inf --> 3.457559).  Saving model ...
Updating learning rate to 0.0001
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 76.52it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 76.52it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 76.52it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 76.52it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 76.52it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 76.52it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 76.52it/s]loss:0.05684013335296124:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 76.52it/s]loss:0.4048071677390015:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 76.52it/s] loss:0.4048071677390015:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 78.30it/s]loss:0.7361277353256582:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 78.30it/s]loss:0.9812387990265468:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 78.30it/s]loss:1.1775117798996442:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 78.30it/s]loss:1.1775117798996442: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 66.93it/s]
Epoch: 2 cost time: 0.7868354320526123
Epoch: 2, Steps: 19 | Train Loss: 0.1766592 Vali Loss: 3.1675806 Test Loss: 36.9429092
Validation loss decreased (3.457559 --> 3.167581).  Saving model ...
Updating learning rate to 5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 76.68it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 76.68it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 76.68it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 76.68it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 76.68it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 76.68it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 76.68it/s]loss:0.0738329187254155:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 76.68it/s]loss:0.3452236596093698:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 76.68it/s]loss:0.3452236596093698:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 78.10it/s]loss:0.6532688972237999:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 78.10it/s]loss:1.1851335447156426:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 78.10it/s]loss:1.0261191684798625:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 78.10it/s]loss:1.0261191684798625: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 65.03it/s]
Epoch: 3 cost time: 0.7977690696716309
Epoch: 3, Steps: 19 | Train Loss: 0.1728199 Vali Loss: 3.1467268 Test Loss: 36.8377762
Validation loss decreased (3.167581 --> 3.146727).  Saving model ...
Updating learning rate to 2.5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 72.56it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 72.56it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 72.56it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 72.56it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 72.56it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 72.56it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 72.56it/s]loss:0.05635656494948798:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 72.56it/s]loss:0.4377400300620639:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 72.56it/s] loss:0.4377400300620639:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 74.77it/s]loss:0.4812021232098533:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 74.77it/s]loss:0.8753669349013491:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 74.77it/s]loss:0.9822612988018032:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 74.77it/s]loss:0.9822612988018032: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 64.36it/s]
Epoch: 4 cost time: 0.7981135845184326
Epoch: 4, Steps: 19 | Train Loss: 0.1491014 Vali Loss: 3.1049862 Test Loss: 36.7635918
Validation loss decreased (3.146727 --> 3.104986).  Saving model ...
Updating learning rate to 1.25e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 69.69it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 69.69it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 69.69it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 69.69it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 69.69it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 69.69it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 69.69it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 69.69it/s]loss:0.0469656629245169:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 69.69it/s]loss:0.0469656629245169:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 73.56it/s]loss:0.27574941668770464:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 73.56it/s]loss:0.6182733863607281:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 73.56it/s] loss:0.8593149488768698:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 73.56it/s]loss:1.393139936023672:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 73.56it/s] loss:1.393139936023672: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 63.14it/s]
Epoch: 5 cost time: 0.8060681819915771
Epoch: 5, Steps: 19 | Train Loss: 0.1680760 Vali Loss: 3.0935202 Test Loss: 36.7326164
Validation loss decreased (3.104986 --> 3.093520).  Saving model ...
Updating learning rate to 6.25e-06
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 74.39it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 74.39it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 74.39it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 74.39it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 74.39it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 74.39it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 74.39it/s]loss:0.05336424469094487:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 74.39it/s]loss:0.32007611470080394:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 74.39it/s]loss:0.32007611470080394:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 75.19it/s]loss:0.7090533331635168:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 75.19it/s] loss:0.8794518880830211:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 75.19it/s]loss:1.09722470774412:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 75.19it/s]  loss:1.09722470774412: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 61.81it/s]
Epoch: 6 cost time: 0.7815866470336914
Epoch: 6, Steps: 19 | Train Loss: 0.1610090 Vali Loss: 3.0800757 Test Loss: 36.7093620
Validation loss decreased (3.093520 --> 3.080076).  Saving model ...
Updating learning rate to 3.125e-06
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 75.32it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 75.32it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 75.32it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 75.32it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 75.32it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 75.32it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 75.32it/s]loss:0.05321195582797375:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 75.32it/s]loss:0.3289727883552796:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 75.32it/s] loss:0.5141376624268227:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 75.32it/s]loss:0.5141376624268227:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 77.89it/s]loss:0.7268398519600552:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 77.89it/s]loss:1.1504610509602946:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 77.89it/s]loss:1.1504610509602946: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 66.89it/s]
Epoch: 7 cost time: 0.761730432510376
Epoch: 7, Steps: 19 | Train Loss: 0.1459802 Vali Loss: 3.0774198 Test Loss: 36.7014275
Validation loss decreased (3.080076 --> 3.077420).  Saving model ...
Updating learning rate to 1.5625e-06
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 75.49it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 75.49it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 75.49it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 75.49it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 75.49it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 75.49it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 75.49it/s]loss:0.053158760829131735:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 75.49it/s]loss:0.2696477883944897:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 75.49it/s]  loss:0.2696477883944897:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 76.42it/s]loss:0.4633924039723994:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 76.42it/s]loss:1.0156135052054174:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 76.42it/s]loss:1.1487041588276672:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 76.42it/s]loss:1.1487041588276672: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 62.89it/s]
Epoch: 8 cost time: 0.8070549964904785
Epoch: 8, Steps: 19 | Train Loss: 0.1552903 Vali Loss: 3.0756669 Test Loss: 36.6976166
Validation loss decreased (3.077420 --> 3.075667).  Saving model ...
Updating learning rate to 7.8125e-07
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 71.42it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 71.42it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 71.42it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 71.42it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 71.42it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 71.42it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 71.42it/s]loss:0.053285593152601216:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 71.42it/s]loss:0.3113304736074109:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 71.42it/s]  loss:0.3113304736074109:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 72.91it/s]loss:0.6046545525335995:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 72.91it/s]loss:0.7194409035543163:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 72.91it/s]loss:1.166155540932674:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 72.91it/s] loss:1.166155540932674: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 63.36it/s]
Epoch: 9 cost time: 0.8104023933410645
Epoch: 9, Steps: 19 | Train Loss: 0.1502562 Vali Loss: 3.0743580 Test Loss: 36.6954117
Validation loss decreased (3.075667 --> 3.074358).  Saving model ...
Updating learning rate to 3.90625e-07
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 69.70it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 69.70it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 69.70it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 69.70it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 69.70it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 69.70it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 69.70it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 69.70it/s]loss:0.05194018828670332:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 69.70it/s]loss:0.05194018828670332:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 72.36it/s]loss:0.3594506480539669:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 72.36it/s] loss:0.4937788171817495:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 72.36it/s]loss:0.8881807658235733:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 72.36it/s]loss:1.1514341482294208:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 72.36it/s]loss:1.1514341482294208: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 62.74it/s]
Epoch: 10 cost time: 0.8321530818939209
Epoch: 10, Steps: 19 | Train Loss: 0.1549887 Vali Loss: 3.0741525 Test Loss: 36.6945648
Validation loss decreased (3.074358 --> 3.074152).  Saving model ...
Updating learning rate to 1.953125e-07
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 73.87it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 73.87it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 73.87it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 73.87it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 73.87it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 73.87it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 73.87it/s]loss:0.05185767688186985:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 73.87it/s]loss:0.32721073360877595:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 73.87it/s]loss:0.32721073360877595:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 75.33it/s]loss:0.6124227562014003:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 75.33it/s] loss:0.7457940686715339:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 75.33it/s]loss:1.2552590061720839:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 75.33it/s]loss:1.2552590061720839: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 65.32it/s]
Epoch: 11 cost time: 0.8290009498596191
Epoch: 11, Steps: 19 | Train Loss: 0.1575023 Vali Loss: 3.0740173 Test Loss: 36.6940994
Validation loss decreased (3.074152 --> 3.074017).  Saving model ...
Updating learning rate to 9.765625e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 73.12it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 73.12it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 73.12it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 73.12it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 73.12it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 73.12it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 73.12it/s]loss:0.04479181853516183:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 73.12it/s]loss:0.3275408705964911:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 73.12it/s] loss:0.3275408705964911:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 53.43it/s]loss:0.6955327343569084:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 53.43it/s]loss:0.7266862559335079:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 53.43it/s]loss:1.1100102252982234:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 53.43it/s]loss:1.1100102252982234: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 45.97it/s]
Epoch: 12 cost time: 0.9235002994537354
Epoch: 12, Steps: 19 | Train Loss: 0.1528717 Vali Loss: 3.0740411 Test Loss: 36.6939049
EarlyStopping counter: 1 out of 3
Updating learning rate to 4.8828125e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 63.57it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 63.57it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 63.57it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 63.57it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 63.57it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 63.57it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 63.57it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 63.57it/s]loss:0.04540877341578742:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 63.57it/s]loss:0.04540877341578742:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 70.89it/s]loss:0.3328750505981616:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 70.89it/s] loss:0.46401373168599114:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 70.89it/s]loss:0.7453294270281879:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 70.89it/s] loss:1.0911748218292432:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 70.89it/s]loss:1.0911748218292432: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 61.74it/s]
Epoch: 13 cost time: 0.7649586200714111
Epoch: 13, Steps: 19 | Train Loss: 0.1409896 Vali Loss: 3.0739853 Test Loss: 36.6937828
Validation loss decreased (3.074017 --> 3.073985).  Saving model ...
Updating learning rate to 2.44140625e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 75.89it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 75.89it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 75.89it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 75.89it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 75.89it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 75.89it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 75.89it/s]loss:0.04484695904560795:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 75.89it/s]loss:0.3588829112147869:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 75.89it/s] loss:0.3588829112147869:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 75.51it/s]loss:0.7590372628505335:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 75.51it/s]loss:0.8537749658943493:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 75.51it/s]loss:1.0908599396268461:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 75.51it/s]loss:1.0908599396268461: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 63.79it/s]
Epoch: 14 cost time: 0.7961587905883789
Epoch: 14, Steps: 19 | Train Loss: 0.1635475 Vali Loss: 3.0740123 Test Loss: 36.6937637
EarlyStopping counter: 1 out of 3
Updating learning rate to 1.220703125e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 73.39it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 73.39it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 73.39it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 73.39it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 73.39it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 73.39it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 73.39it/s]loss:0.04659855359450642:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 73.39it/s]loss:0.3334313596070162:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 73.39it/s] loss:0.3334313596070162:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 75.64it/s]loss:0.6009594322641734:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 75.64it/s]loss:0.8454209910060774:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 75.64it/s]loss:1.3261764877375743:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 75.64it/s]loss:1.3261764877375743: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 63.69it/s]
Epoch: 15 cost time: 0.8088281154632568
Epoch: 15, Steps: 19 | Train Loss: 0.1659256 Vali Loss: 3.0740027 Test Loss: 36.6937332
EarlyStopping counter: 2 out of 3
Updating learning rate to 6.103515625e-09
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 65.20it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 65.20it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 65.20it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 65.20it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 65.20it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 65.20it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 65.20it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 65.20it/s]loss:0.052847400519130006:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 65.20it/s]loss:0.3273935997280465:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 65.20it/s]  loss:0.3273935997280465:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 74.51it/s]loss:0.49323731204534865:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 74.51it/s]loss:0.7172824062684178:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 74.51it/s] loss:0.8863352529669757:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 74.51it/s]loss:0.8863352529669757: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 65.04it/s]
Epoch: 16 cost time: 0.7822742462158203
Epoch: 16, Steps: 19 | Train Loss: 0.1303735 Vali Loss: 3.0739889 Test Loss: 36.6937141
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : long_term_forecast_break_bartlett_0_SegRNN_job_demand_region_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 4
test shape: (4, 1, 3, 16345) (4, 1, 3, 16345)
test shape: (4, 3, 16345) (4, 3, 16345)
mse:40748.4296875, mae:33.369232177734375, dtw:-999
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           0                   Model:              SegRNN              

[1mData Loader[0m
  Data:               job_demand_region   Root Path:          ../../dataset/demand/
  Data Path:          region.parquet      Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        .cache/checkpoints  

[1mForecasting Task[0m
  Seq Len:            6                   Label Len:          1                   
  Pred Len:           3                   Seasonal Patterns:  Monthly             
  Inverse:            1                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             16345               Dec In:             16345               
  C Out:              16345               d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           2                   d FF:               2048                
  Moving Avg:         25                  Factor:             1                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              learned             Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        32                  Itr:                1                   
  Train Epochs:       20                  Batch Size:         1                   
  Patience:           3                   Learning Rate:      0.0001              
  Des:                test                Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1                 

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_break_parzen_0_SegRNN_job_demand_region_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 19
val 1
test 4
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.22it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.22it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.22it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.22it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.22it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.22it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.22it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.22it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.22it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 20.46it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 20.46it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 20.46it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 20.46it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 20.46it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 20.46it/s]loss:0.0002795179380058449:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 20.46it/s]loss:0.07491216332214688:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 20.46it/s]  loss:0.4357055865848625:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 20.46it/s] loss:0.4357055865848625:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 34.97it/s]loss:1.1891629310749916:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 34.97it/s]loss:1.8144315912637163:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 34.97it/s]loss:1.8144315912637163: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 26.11it/s]
Epoch: 1 cost time: 1.2676441669464111
Epoch: 1, Steps: 19 | Train Loss: 0.1849733 Vali Loss: 3.4856980 Test Loss: 37.4072037
Validation loss decreased (inf --> 3.485698).  Saving model ...
Updating learning rate to 0.0001
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 69.54it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 69.54it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 69.54it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 69.54it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 69.54it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 69.54it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 69.54it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 69.54it/s]loss:0.0002637375525766746:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 69.54it/s]loss:0.0002637375525766746:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 72.00it/s]loss:0.06535250973126572:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 72.00it/s]  loss:0.4282142020936521:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 72.00it/s] loss:1.0112753231867047:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 72.00it/s]loss:1.2525223743209108:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 72.00it/s]loss:1.2525223743209108: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 62.77it/s]
Epoch: 2 cost time: 0.8313601016998291
Epoch: 2, Steps: 19 | Train Loss: 0.1451383 Vali Loss: 3.2148528 Test Loss: 37.0160828
Validation loss decreased (3.485698 --> 3.214853).  Saving model ...
Updating learning rate to 5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 73.48it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 73.48it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 73.48it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 73.48it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 73.48it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 73.48it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 73.48it/s]loss:0.00034055285602208036:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 73.48it/s]loss:0.05839077548199702:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 73.48it/s]   loss:0.05839077548199702:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 73.46it/s]loss:0.3717958196526691:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 73.46it/s] loss:1.1661222965929325:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 73.46it/s]loss:1.0582517048389357:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 73.46it/s]loss:1.0582517048389357: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 63.68it/s]
Epoch: 3 cost time: 0.8280782699584961
Epoch: 3, Steps: 19 | Train Loss: 0.1397316 Vali Loss: 3.1637275 Test Loss: 36.9060135
Validation loss decreased (3.214853 --> 3.163728).  Saving model ...
Updating learning rate to 2.5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 74.69it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 74.69it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 74.69it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 74.69it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 74.69it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 74.69it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 74.69it/s]loss:0.00026249129107322363:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 74.69it/s]loss:0.07311806354175052:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 74.69it/s]   loss:0.07311806354175052:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 74.28it/s]loss:0.26893756423881554:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 74.28it/s]loss:0.8818597777446275:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 74.28it/s] loss:1.0095007912148373:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 74.28it/s]loss:1.0095007912148373: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 63.56it/s]
Epoch: 4 cost time: 0.7767467498779297
Epoch: 4, Steps: 19 | Train Loss: 0.1175620 Vali Loss: 3.1297746 Test Loss: 36.8408508
Validation loss decreased (3.163728 --> 3.129775).  Saving model ...
Updating learning rate to 1.25e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 72.53it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 72.53it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 72.53it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 72.53it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 72.53it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 72.53it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 72.53it/s]loss:0.0002213470030457333:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 72.53it/s]loss:0.04625132981404685:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 72.53it/s]  loss:0.04625132981404685:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 72.87it/s]loss:0.3528907558508869:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 72.87it/s] loss:0.8650313810531888:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 72.87it/s]loss:1.470280120122061:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 72.87it/s] loss:1.470280120122061: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 62.94it/s]
Epoch: 5 cost time: 0.8402888774871826
Epoch: 5, Steps: 19 | Train Loss: 0.1439303 Vali Loss: 3.1195924 Test Loss: 36.8124695
Validation loss decreased (3.129775 --> 3.119592).  Saving model ...
Updating learning rate to 6.25e-06
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 73.01it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 73.01it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 73.01it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 73.01it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 73.01it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 73.01it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 73.01it/s]loss:0.0002504854746276557:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 73.01it/s]loss:0.05408078205850851:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 73.01it/s]  loss:0.05408078205850851:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 72.34it/s]loss:0.4096958567103791:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 72.34it/s] loss:0.8800797592902188:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 72.34it/s]loss:1.1242912538601295:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 72.34it/s]loss:1.1242912538601295: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 63.72it/s]
Epoch: 6 cost time: 0.7955026626586914
Epoch: 6, Steps: 19 | Train Loss: 0.1299157 Vali Loss: 3.1046331 Test Loss: 36.7888756
Validation loss decreased (3.119592 --> 3.104633).  Saving model ...
Updating learning rate to 3.125e-06
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 71.70it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 71.70it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 71.70it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 71.70it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 71.70it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 71.70it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 71.70it/s]loss:0.000249642019677243:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 71.70it/s]loss:0.0552500339876915:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 71.70it/s]  loss:0.0552500339876915:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 74.64it/s]loss:0.2925326387212299:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 74.64it/s]loss:0.7257987854202853:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 74.64it/s]loss:1.1858813006516855:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 74.64it/s]loss:1.1858813006516855: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 63.65it/s]
Epoch: 7 cost time: 0.8052253723144531
Epoch: 7, Steps: 19 | Train Loss: 0.1189322 Vali Loss: 3.1015551 Test Loss: 36.7811012
Validation loss decreased (3.104633 --> 3.101555).  Saving model ...
Updating learning rate to 1.5625e-06
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 37.48it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 37.48it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 37.48it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 37.48it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 37.48it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 37.48it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 42.59it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 42.59it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 42.59it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 42.59it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 42.59it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 42.59it/s]loss:0.0002493486086091924:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 42.59it/s]loss:0.04527766788228167:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 42.59it/s]  loss:0.2584284547259756:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 42.59it/s] loss:0.2584284547259756:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 57.79it/s]loss:1.043601245445377:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 57.79it/s] loss:1.1813119700234302:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 57.79it/s]loss:1.1813119700234302: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 48.54it/s]
Epoch: 8 cost time: 0.9131879806518555
Epoch: 8, Steps: 19 | Train Loss: 0.1330984 Vali Loss: 3.0994809 Test Loss: 36.7771072
Validation loss decreased (3.101555 --> 3.099481).  Saving model ...
Updating learning rate to 7.8125e-07
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 71.77it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 71.77it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 71.77it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 71.77it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 71.77it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 71.77it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 71.77it/s]loss:0.0002426381507695078:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 71.77it/s]loss:0.05150127204844668:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 71.77it/s]  loss:0.05150127204844668:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 74.13it/s]loss:0.34413177359408276:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 74.13it/s]loss:0.7244573277418126:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 74.13it/s] loss:1.206725729663986:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 74.13it/s] loss:1.206725729663986: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 64.11it/s]
Epoch: 9 cost time: 0.8390400409698486
Epoch: 9, Steps: 19 | Train Loss: 0.1224768 Vali Loss: 3.0978403 Test Loss: 36.7745857
Validation loss decreased (3.099481 --> 3.097840).  Saving model ...
Updating learning rate to 3.90625e-07
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 48.74it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 48.74it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 48.74it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 48.74it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 48.74it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 48.74it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 48.74it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 48.74it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 48.74it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 63.53it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 63.53it/s]loss:0.0002410098318069411:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 63.53it/s]loss:0.06116466987755021:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 63.53it/s]  loss:0.2785287419492004:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 63.53it/s] loss:0.8936304353488591:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 63.53it/s]loss:1.1949794478485845:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 63.53it/s]loss:1.1949794478485845: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 45.53it/s]
Epoch: 10 cost time: 0.9238729476928711
Epoch: 10, Steps: 19 | Train Loss: 0.1278181 Vali Loss: 3.0972800 Test Loss: 36.7735596
Validation loss decreased (3.097840 --> 3.097280).  Saving model ...
Updating learning rate to 1.953125e-07
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 64.46it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 64.46it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 64.46it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 64.46it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 64.46it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 64.46it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 64.46it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 64.46it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 61.47it/s]loss:0.00023834099213863126:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 61.47it/s]loss:0.05491327930772863:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 61.47it/s]   loss:0.3490308142475975:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 61.47it/s] loss:0.7519983609060206:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 61.47it/s]loss:1.308603006465063:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 61.47it/s] loss:1.308603006465063: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 57.27it/s]
Epoch: 11 cost time: 0.9130048751831055
Epoch: 11, Steps: 19 | Train Loss: 0.1297255 Vali Loss: 3.0969632 Test Loss: 36.7730179
Validation loss decreased (3.097280 --> 3.096963).  Saving model ...
Updating learning rate to 9.765625e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 68.82it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 68.82it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 68.82it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 68.82it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 68.82it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 68.82it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 68.82it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 68.82it/s]loss:0.0002089209112825057:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 68.82it/s]loss:0.0002089209112825057:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 72.86it/s]loss:0.054968295202532866:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 72.86it/s] loss:0.40289592185908024:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 72.86it/s] loss:0.7251764861323751:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 72.86it/s] loss:1.1482306778858256:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 72.86it/s]loss:1.1482306778858256: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 64.45it/s]
Epoch: 12 cost time: 0.7989835739135742
Epoch: 12, Steps: 19 | Train Loss: 0.1227095 Vali Loss: 3.0969033 Test Loss: 36.7728004
Validation loss decreased (3.096963 --> 3.096903).  Saving model ...
Updating learning rate to 4.8828125e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 74.70it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 74.70it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 74.70it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 74.70it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 74.70it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 74.70it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 74.70it/s]loss:0.00021133975031986795:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 74.70it/s]loss:0.05623146177611817:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 74.70it/s]   loss:0.05623146177611817:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 77.16it/s]loss:0.25873237522117654:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 77.16it/s]loss:0.7514519081377852:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 77.16it/s] loss:1.1057037224012114:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 77.16it/s]loss:1.1057037224012114: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 66.65it/s]
Epoch: 13 cost time: 0.8222415447235107
Epoch: 13, Steps: 19 | Train Loss: 0.1143332 Vali Loss: 3.0968523 Test Loss: 36.7726822
Validation loss decreased (3.096903 --> 3.096852).  Saving model ...
Updating learning rate to 2.44140625e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 71.02it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 71.02it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 71.02it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 71.02it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 71.02it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 71.02it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 71.02it/s]loss:0.00020915733469723094:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 71.02it/s]loss:0.06107795887480493:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 71.02it/s]   loss:0.06107795887480493:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 73.77it/s]loss:0.434296129228435:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 73.77it/s]  loss:0.8330861697800034:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 73.77it/s]loss:1.1161813947810812:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 73.77it/s]loss:1.1161813947810812: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 65.35it/s]
Epoch: 14 cost time: 0.8364324569702148
Epoch: 14, Steps: 19 | Train Loss: 0.1286764 Vali Loss: 3.0968645 Test Loss: 36.7726555
EarlyStopping counter: 1 out of 3
Updating learning rate to 1.220703125e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 71.84it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 71.84it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 71.84it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 71.84it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 71.84it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 71.84it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 71.84it/s]loss:0.000219108148818101:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 71.84it/s]loss:0.05655779626469736:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 71.84it/s] loss:0.05655779626469736:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 62.55it/s]loss:0.3396309549230788:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 62.55it/s] loss:0.8502833889603564:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 62.55it/s]loss:1.4005445624247552:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 62.55it/s]loss:1.4005445624247552: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 57.38it/s]
Epoch: 15 cost time: 0.8569631576538086
Epoch: 15, Steps: 19 | Train Loss: 0.1393282 Vali Loss: 3.0968537 Test Loss: 36.7726326
EarlyStopping counter: 2 out of 3
Updating learning rate to 6.103515625e-09
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 74.55it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 74.55it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 74.55it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 74.55it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 74.55it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 74.55it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 74.55it/s]loss:0.00024792343036915567:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 74.55it/s]loss:0.05507626841445964:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 74.55it/s]   loss:0.05507626841445964:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 74.10it/s]loss:0.2802390442791512:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 74.10it/s] loss:0.7172697194951555:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 74.10it/s]loss:0.9008824996700571:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 74.10it/s]loss:0.9008824996700571: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 63.86it/s]
Epoch: 16 cost time: 0.8045089244842529
Epoch: 16, Steps: 19 | Train Loss: 0.1028271 Vali Loss: 3.0968390 Test Loss: 36.7726097
Validation loss decreased (3.096852 --> 3.096839).  Saving model ...
Updating learning rate to 3.0517578125e-09
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 63.54it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 63.54it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 63.54it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 63.54it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 63.54it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 63.54it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 63.54it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 63.54it/s]loss:0.00019441943384846216:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 63.54it/s]loss:0.00019441943384846216:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 69.41it/s]loss:0.06532624552258967:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 69.41it/s]   loss:0.3205338675154357:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 69.41it/s] loss:0.8991296427246303:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 69.41it/s]loss:1.0132922268956874:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 69.41it/s]loss:1.0132922268956874: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 59.43it/s]
Epoch: 17 cost time: 0.886871337890625
Epoch: 17, Steps: 19 | Train Loss: 0.1209724 Vali Loss: 3.0968387 Test Loss: 36.7726059
Validation loss decreased (3.096839 --> 3.096839).  Saving model ...
Updating learning rate to 1.52587890625e-09
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:00, 55.91it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:00, 55.91it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:00, 55.91it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:00, 55.91it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:00, 55.91it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:00, 55.91it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:00, 55.91it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:00, 55.91it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:00, 55.91it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 65.18it/s]loss:0.00023848509910015737:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 65.18it/s]loss:0.05563798806531977:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 65.18it/s]   loss:0.3385804796404503:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 65.18it/s] loss:0.8503501158803537:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 65.18it/s]loss:1.1250544048285056:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 65.18it/s]loss:1.1250544048285056: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 57.67it/s]
Epoch: 18 cost time: 0.8146960735321045
Epoch: 18, Steps: 19 | Train Loss: 0.1247296 Vali Loss: 3.0968385 Test Loss: 36.7726059
Validation loss decreased (3.096839 --> 3.096838).  Saving model ...
Updating learning rate to 7.62939453125e-10
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 73.84it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 73.84it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 73.84it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 73.84it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 73.84it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 73.84it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 73.84it/s]loss:0.0002620206250663464:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 73.84it/s]loss:0.05355128481278109:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 73.84it/s]  loss:0.05355128481278109:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 75.15it/s]loss:0.3396834321537273:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 75.15it/s] loss:0.7253488505016715:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 75.15it/s]loss:1.2043098113305692:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 75.15it/s]loss:1.2043098113305692: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 63.79it/s]
Epoch: 19 cost time: 0.7864675521850586
Epoch: 19, Steps: 19 | Train Loss: 0.1222713 Vali Loss: 3.0968385 Test Loss: 36.7726059
Validation loss decreased (3.096838 --> 3.096838).  Saving model ...
Updating learning rate to 3.814697265625e-10
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 71.90it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 71.90it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 71.90it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 71.90it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 71.90it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 71.90it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 71.90it/s]loss:0.0003264820820480603:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 71.90it/s]loss:0.052444641907756044:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 71.90it/s] loss:0.052444641907756044:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 71.62it/s]loss:0.3388063042807936:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 71.62it/s]  loss:1.0356784684933782:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 71.62it/s]loss:1.1921252668391107:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 71.62it/s]loss:1.1921252668391107: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 62.20it/s]
Epoch: 20 cost time: 0.8314273357391357
Epoch: 20, Steps: 19 | Train Loss: 0.1378622 Vali Loss: 3.0968385 Test Loss: 36.7726059
Validation loss decreased (3.096838 --> 3.096838).  Saving model ...
Updating learning rate to 1.9073486328125e-10
>>>>>>>testing : long_term_forecast_break_parzen_0_SegRNN_job_demand_region_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 4
test shape: (4, 1, 3, 16345) (4, 1, 3, 16345)
test shape: (4, 3, 16345) (4, 3, 16345)
mse:39773.17578125, mae:33.31510925292969, dtw:-999
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           0                   Model:              SegRNN              

[1mData Loader[0m
  Data:               job_demand_region   Root Path:          ../../dataset/demand/
  Data Path:          region.parquet      Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        .cache/checkpoints  

[1mForecasting Task[0m
  Seq Len:            6                   Label Len:          1                   
  Pred Len:           3                   Seasonal Patterns:  Monthly             
  Inverse:            1                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             16345               Dec In:             16345               
  C Out:              16345               d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           2                   d FF:               2048                
  Moving Avg:         25                  Factor:             1                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              learned             Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        32                  Itr:                1                   
  Train Epochs:       20                  Batch Size:         1                   
  Patience:           3                   Learning Rate:      0.0001              
  Des:                test                Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1                 

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_break_tukey-hanning_0_SegRNN_job_demand_region_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 19
val 1
test 4
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.17it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.17it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.17it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.17it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.17it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.17it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.17it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.17it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.17it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 20.08it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 20.08it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 20.08it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 20.08it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 20.08it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 20.08it/s]loss:0.007228174434843794:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 20.08it/s]loss:0.30142544400882687:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 20.08it/s] loss:0.8116524339164957:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 20.08it/s] loss:0.8116524339164957:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 34.63it/s]loss:1.3836462696283767:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 34.63it/s]loss:1.814968122072367:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 34.63it/s] loss:1.814968122072367: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 25.87it/s]
Epoch: 1 cost time: 1.2670931816101074
Epoch: 1, Steps: 19 | Train Loss: 0.2273116 Vali Loss: 3.4675837 Test Loss: 37.3867111
Validation loss decreased (inf --> 3.467584).  Saving model ...
Updating learning rate to 0.0001
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 67.97it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 67.97it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 67.97it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 67.97it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 67.97it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 67.97it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 67.97it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 67.97it/s]loss:0.0066763385444941975:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 67.97it/s]loss:0.0066763385444941975:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 70.77it/s]loss:0.26881529597293624:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 70.77it/s]  loss:0.7563920566553217:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 70.77it/s] loss:1.1197423423903825:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 70.77it/s]loss:1.183336760002919:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 70.77it/s] loss:1.183336760002919: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 59.61it/s]
Epoch: 2 cost time: 0.8088209629058838
Epoch: 2, Steps: 19 | Train Loss: 0.1755244 Vali Loss: 3.1804106 Test Loss: 36.9643669
Validation loss decreased (3.467584 --> 3.180411).  Saving model ...
Updating learning rate to 5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 73.12it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 73.12it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 73.12it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 73.12it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 73.12it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 73.12it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 73.12it/s]loss:0.00890456858177499:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 73.12it/s]loss:0.2297367048982991:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 73.12it/s] loss:0.2297367048982991:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 74.75it/s]loss:0.6792255063625914:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 74.75it/s]loss:1.375333322237734:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 74.75it/s] loss:1.03592092865439:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 74.75it/s] loss:1.03592092865439: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 65.05it/s]
Epoch: 3 cost time: 0.7572107315063477
Epoch: 3, Steps: 19 | Train Loss: 0.1752169 Vali Loss: 3.1652067 Test Loss: 36.8705673
Validation loss decreased (3.180411 --> 3.165207).  Saving model ...
Updating learning rate to 2.5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 71.23it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 71.23it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 71.23it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 71.23it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 71.23it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 71.23it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 71.23it/s]loss:0.006687705880576451:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 71.23it/s]loss:0.2946511929474887:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 71.23it/s]  loss:0.2946511929474887:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 72.90it/s]loss:0.4968276029298089:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 72.90it/s]loss:1.0068973888982948:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 72.90it/s]loss:0.9920279400210203:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 72.90it/s]loss:0.9920279400210203: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 62.66it/s]
Epoch: 4 cost time: 0.7655372619628906
Epoch: 4, Steps: 19 | Train Loss: 0.1472154 Vali Loss: 3.1205778 Test Loss: 36.7950668
Validation loss decreased (3.165207 --> 3.120578).  Saving model ...
Updating learning rate to 1.25e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 74.42it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 74.42it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 74.42it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 74.42it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 74.42it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 74.42it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 74.42it/s]loss:0.005558156251091573:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 74.42it/s]loss:0.1833927020506206:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 74.42it/s]  loss:0.1833927020506206:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 74.11it/s]loss:0.6408627082130333:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 74.11it/s]loss:0.9877329019045225:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 74.11it/s]loss:1.4356131741328628:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 74.11it/s]loss:1.4356131741328628: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 63.50it/s]
Epoch: 5 cost time: 0.8173468112945557
Epoch: 5, Steps: 19 | Train Loss: 0.1712189 Vali Loss: 3.1077623 Test Loss: 36.7626724
Validation loss decreased (3.120578 --> 3.107762).  Saving model ...
Updating learning rate to 6.25e-06
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 74.16it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 74.16it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 74.16it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 74.16it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 74.16it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 74.16it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 74.16it/s]loss:0.0063433320669483645:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 74.16it/s]loss:0.21299149254669034:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 74.16it/s]  loss:0.21299149254669034:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 74.82it/s]loss:0.7485445963611702:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 74.82it/s] loss:1.0110732288222857:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 74.82it/s]loss:1.1024008216615675:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 74.82it/s]loss:1.1024008216615675: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 64.26it/s]
Epoch: 6 cost time: 0.7752671241760254
Epoch: 6, Steps: 19 | Train Loss: 0.1621765 Vali Loss: 3.0926352 Test Loss: 36.7383118
Validation loss decreased (3.107762 --> 3.092635).  Saving model ...
Updating learning rate to 3.125e-06
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 75.59it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 75.59it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 75.59it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 75.59it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 75.59it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 75.59it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 75.59it/s]loss:0.00630147386883535:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 75.59it/s]loss:0.21898238457831354:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 75.59it/s]loss:0.21898238457831354:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 75.25it/s]loss:0.531655774810073:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 75.25it/s]  loss:0.83371343118089:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 75.25it/s] loss:1.1662731349252282:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 75.25it/s]loss:1.1662731349252282: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 65.07it/s]
Epoch: 7 cost time: 0.7879915237426758
Epoch: 7, Steps: 19 | Train Loss: 0.1451014 Vali Loss: 3.0890257 Test Loss: 36.7299423
Validation loss decreased (3.092635 --> 3.089026).  Saving model ...
Updating learning rate to 1.5625e-06
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 75.98it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 75.98it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 75.98it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 75.98it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 75.98it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 75.98it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 75.98it/s]loss:0.006294771903887789:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 75.98it/s]loss:0.17938977259481206:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 75.98it/s] loss:0.17938977259481206:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 77.06it/s]loss:0.4769707918647272:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 77.06it/s] loss:1.186967766871682:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 77.06it/s] loss:1.1602686086983376:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 77.06it/s]loss:1.1602686086983376: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 66.43it/s]
Epoch: 8 cost time: 0.7863192558288574
Epoch: 8, Steps: 19 | Train Loss: 0.1584154 Vali Loss: 3.0869825 Test Loss: 36.7259293
Validation loss decreased (3.089026 --> 3.086982).  Saving model ...
Updating learning rate to 7.8125e-07
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 68.66it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 68.66it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 68.66it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 68.66it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 68.66it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 68.66it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 68.66it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 68.66it/s]loss:0.006286627158150105:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 68.66it/s]loss:0.006286627158150105:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 72.56it/s]loss:0.20438328677847073:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 72.56it/s] loss:0.62847674264512:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 72.56it/s]   loss:0.8217010341420108:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 72.56it/s]loss:1.1829771220336585:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 72.56it/s]loss:1.1829771220336585: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 63.63it/s]
Epoch: 9 cost time: 0.7860887050628662
Epoch: 9, Steps: 19 | Train Loss: 0.1496750 Vali Loss: 3.0854089 Test Loss: 36.7234650
Validation loss decreased (3.086982 --> 3.085409).  Saving model ...
Updating learning rate to 3.90625e-07
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 73.60it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 73.60it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 73.60it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 73.60it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 73.60it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 73.60it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 73.60it/s]loss:0.006119455836559099:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 73.60it/s]loss:0.23883396738580576:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 73.60it/s] loss:0.23883396738580576:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 75.64it/s]loss:0.5113528544030911:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 75.64it/s] loss:1.0246369510517275:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 75.64it/s]loss:1.1665207252433272:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 75.64it/s]loss:1.1665207252433272: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 63.74it/s]
Epoch: 10 cost time: 0.7788875102996826
Epoch: 10, Steps: 19 | Train Loss: 0.1551297 Vali Loss: 3.0850425 Test Loss: 36.7224884
Validation loss decreased (3.085409 --> 3.085042).  Saving model ...
Updating learning rate to 1.953125e-07
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 75.01it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 75.01it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 75.01it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 75.01it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 75.01it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 75.01it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 75.01it/s]loss:0.006060727433104812:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 75.01it/s]loss:0.21770966093567307:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 75.01it/s] loss:0.21770966093567307:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 76.59it/s]loss:0.6341049409995252:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 76.59it/s] loss:0.8549630309528861:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 76.59it/s]loss:1.2659952352700112:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 76.59it/s]loss:1.2659952352700112: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 66.31it/s]
Epoch: 11 cost time: 0.8037059307098389
Epoch: 11, Steps: 19 | Train Loss: 0.1567807 Vali Loss: 3.0848246 Test Loss: 36.7219658
Validation loss decreased (3.085042 --> 3.084825).  Saving model ...
Updating learning rate to 9.765625e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:00, 29.53it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:00, 29.53it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:00, 29.53it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:00, 29.53it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:00, 29.53it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:00, 29.53it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:00, 29.53it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:00, 29.53it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:00, 29.53it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 56.06it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 56.06it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 56.06it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 56.06it/s]loss:0.005303040696511482:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 56.06it/s]loss:0.2179267567746526:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 56.06it/s]  loss:0.7326329290867277:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 56.06it/s]loss:0.8333165349084216:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 56.06it/s]loss:1.123830354302781:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 56.06it/s] loss:1.123830354302781: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 65.35it/s]loss:1.123830354302781: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 53.40it/s]
Epoch: 12 cost time: 0.864579439163208
Epoch: 12, Steps: 19 | Train Loss: 0.1533163 Vali Loss: 3.0848188 Test Loss: 36.7217484
Validation loss decreased (3.084825 --> 3.084819).  Saving model ...
Updating learning rate to 4.8828125e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 76.03it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 76.03it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 76.03it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 76.03it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 76.03it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 76.03it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 76.03it/s]loss:0.005369317203004872:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 76.03it/s]loss:0.22246320305847855:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 76.03it/s] loss:0.22246320305847855:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 77.84it/s]loss:0.47757039264725965:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 77.84it/s]loss:0.8543979322534025:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 77.84it/s] loss:1.0874172938725333:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 77.84it/s]loss:1.0874172938725333: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 65.68it/s]
Epoch: 13 cost time: 0.8061892986297607
Epoch: 13, Steps: 19 | Train Loss: 0.1393273 Vali Loss: 3.0847571 Test Loss: 36.7216225
Validation loss decreased (3.084819 --> 3.084757).  Saving model ...
Updating learning rate to 2.44140625e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 72.81it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 72.81it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 72.81it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 72.81it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 72.81it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 72.81it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 72.81it/s]loss:0.005309359179559512:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 72.81it/s]loss:0.23848432452220808:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 72.81it/s] loss:0.23848432452220808:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 74.96it/s]loss:0.7954680784042609:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 74.96it/s] loss:0.9765878510569669:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 74.96it/s]loss:1.0959495181984866:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 74.96it/s]loss:1.0959495181984866: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 63.51it/s]
Epoch: 14 cost time: 0.7750678062438965
Epoch: 14, Steps: 19 | Train Loss: 0.1637789 Vali Loss: 3.0847743 Test Loss: 36.7215996
EarlyStopping counter: 1 out of 3
Updating learning rate to 1.220703125e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 75.43it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 75.43it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 75.43it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 75.43it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 75.43it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 75.43it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 75.43it/s]loss:0.005508241000236479:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 75.43it/s]loss:0.22173631442124983:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 75.43it/s] loss:0.22173631442124983:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 75.73it/s]loss:0.6246412786867941:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 75.73it/s] loss:0.9734359564131977:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 75.73it/s]loss:1.3616406497464386:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 75.73it/s]loss:1.3616406497464386: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 65.23it/s]
Epoch: 15 cost time: 0.7737038135528564
Epoch: 15, Steps: 19 | Train Loss: 0.1677349 Vali Loss: 3.0847602 Test Loss: 36.7215729
EarlyStopping counter: 2 out of 3
Updating learning rate to 6.103515625e-09
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 64.09it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 64.09it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 64.09it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 64.09it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 64.09it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 64.09it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 64.09it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 64.09it/s]loss:0.006274798548270058:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 64.09it/s]loss:0.006274798548270058:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 72.51it/s]loss:0.21856950470197015:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 72.51it/s] loss:0.5082199442356853:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 72.51it/s] loss:0.823517898041682:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 72.51it/s] loss:0.8891952698631008:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 72.51it/s]loss:0.8891952698631008: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 61.92it/s]
Epoch: 16 cost time: 0.7703649997711182
Epoch: 16, Steps: 19 | Train Loss: 0.1287251 Vali Loss: 3.0847442 Test Loss: 36.7215462
Validation loss decreased (3.084757 --> 3.084744).  Saving model ...
Updating learning rate to 3.0517578125e-09
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 75.06it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 75.06it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 75.06it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 75.06it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 75.06it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 75.06it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 75.06it/s]loss:0.004962101288214079:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 75.06it/s]loss:0.25631379853272723:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 75.06it/s] loss:0.25631379853272723:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 75.65it/s]loss:0.5885934083438423:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 75.65it/s] loss:1.0216420873172152:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 75.65it/s]loss:0.9850290869152722:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 75.65it/s]loss:0.9850290869152722: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 64.82it/s]
Epoch: 17 cost time: 0.7841458320617676
Epoch: 17, Steps: 19 | Train Loss: 0.1503442 Vali Loss: 3.0847449 Test Loss: 36.7215462
EarlyStopping counter: 1 out of 3
Updating learning rate to 1.52587890625e-09
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 75.05it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 75.05it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 75.05it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 75.05it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 75.05it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 75.05it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 75.05it/s]loss:0.006064897629341141:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 75.05it/s]loss:0.21918739387505093:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 75.05it/s] loss:0.21918739387505093:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 75.70it/s]loss:0.6220684337613375:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 75.70it/s] loss:0.973506897596674:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 75.70it/s] loss:1.1276041607912646:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 75.70it/s]loss:1.1276041607912646: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 65.69it/s]
Epoch: 18 cost time: 0.7647628784179688
Epoch: 18, Steps: 19 | Train Loss: 0.1551806 Vali Loss: 3.0847449 Test Loss: 36.7215424
EarlyStopping counter: 2 out of 3
Updating learning rate to 7.62939453125e-10
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 72.56it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 72.56it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 72.56it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 72.56it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 72.56it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 72.56it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 72.56it/s]loss:0.006582284753489063:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 72.56it/s]loss:0.21151199395830858:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 72.56it/s] loss:0.21151199395830858:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 75.13it/s]loss:0.6247084582723743:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 75.13it/s] loss:0.8335337445138618:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 75.13it/s]loss:1.1805951399825245:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 75.13it/s]loss:1.1805951399825245: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 64.98it/s]
Epoch: 19 cost time: 0.7995820045471191
Epoch: 19, Steps: 19 | Train Loss: 0.1503648 Vali Loss: 3.0847442 Test Loss: 36.7215424
Validation loss decreased (3.084744 --> 3.084744).  Saving model ...
Updating learning rate to 3.814697265625e-10
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 72.37it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 72.37it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 72.37it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 72.37it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 72.37it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 72.37it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 72.37it/s]loss:0.008268196870675313:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 72.37it/s]loss:0.2121224946088781:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 72.37it/s]  loss:0.2121224946088781:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 71.84it/s]loss:0.6224648972338549:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 71.84it/s]loss:1.1994280110380062:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 71.84it/s]loss:1.163674419564818:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 71.84it/s] loss:1.163674419564818: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 62.58it/s]
Epoch: 20 cost time: 0.7835350036621094
Epoch: 20, Steps: 19 | Train Loss: 0.1687346 Vali Loss: 3.0847442 Test Loss: 36.7215424
Validation loss decreased (3.084744 --> 3.084744).  Saving model ...
Updating learning rate to 1.9073486328125e-10
>>>>>>>testing : long_term_forecast_break_tukey-hanning_0_SegRNN_job_demand_region_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 4
test shape: (4, 1, 3, 16345) (4, 1, 3, 16345)
test shape: (4, 3, 16345) (4, 3, 16345)
mse:40601.7421875, mae:33.351566314697266, dtw:-999
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           0                   Model:              SegRNN              

[1mData Loader[0m
  Data:               job_demand_region   Root Path:          ../../dataset/demand/
  Data Path:          region.parquet      Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        .cache/checkpoints  

[1mForecasting Task[0m
  Seq Len:            6                   Label Len:          1                   
  Pred Len:           3                   Seasonal Patterns:  Monthly             
  Inverse:            1                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             16345               Dec In:             16345               
  C Out:              16345               d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           2                   d FF:               2048                
  Moving Avg:         25                  Factor:             1                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              learned             Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        32                  Itr:                1                   
  Train Epochs:       20                  Batch Size:         1                   
  Patience:           3                   Learning Rate:      0.0001              
  Des:                test                Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1                 

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_break_rayleigh_0_SegRNN_job_demand_region_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 19
val 1
test 4
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.7183812059899228:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7183812059899228:   5%|â–Œ         | 1/19 [00:00<00:08,  2.07it/s]loss:0.7301118080901433:   5%|â–Œ         | 1/19 [00:00<00:08,  2.07it/s]loss:0.8255319560813459:   5%|â–Œ         | 1/19 [00:00<00:08,  2.07it/s]loss:0.7633506169550734:   5%|â–Œ         | 1/19 [00:00<00:08,  2.07it/s]loss:0.9488212999287362:   5%|â–Œ         | 1/19 [00:00<00:08,  2.07it/s]loss:0.9844654939004092:   5%|â–Œ         | 1/19 [00:00<00:08,  2.07it/s]loss:0.9048441716102736:   5%|â–Œ         | 1/19 [00:00<00:08,  2.07it/s]loss:1.386632136587486:   5%|â–Œ         | 1/19 [00:00<00:08,  2.07it/s] loss:1.2787174610484127:   5%|â–Œ         | 1/19 [00:00<00:08,  2.07it/s]loss:1.2787174610484127:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 19.57it/s]loss:1.111605979683903:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 19.57it/s] loss:1.2179968055450254:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 19.57it/s]loss:0.9885848531361381:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 19.57it/s]loss:0.9746197322029262:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 19.57it/s]loss:0.9338526331749885:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 19.57it/s]loss:0.9640304414166967:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 19.57it/s]loss:1.14810263152984:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 19.57it/s]  loss:1.1493247445768693:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 19.57it/s]loss:1.1493247445768693:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 33.94it/s]loss:1.1657082189590338:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 33.94it/s]loss:1.4621526114188053:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 33.94it/s]loss:1.4621526114188053: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 25.30it/s]
Epoch: 1 cost time: 1.2720730304718018
Epoch: 1, Steps: 19 | Train Loss: 1.0345703 Vali Loss: 3.0874758 Test Loss: 36.7187958
Validation loss decreased (inf --> 3.087476).  Saving model ...
Updating learning rate to 0.0001
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.5416811220481492:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5601692176209916:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5571162500633353:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6472991613005259:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6977053231198981:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7250695865355422:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.693632720823345:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.8213584778051781:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8213584778051781:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 75.98it/s]loss:0.9043747214934568:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 75.98it/s]loss:1.102970896568694:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 75.98it/s] loss:0.8962570764261755:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 75.98it/s]loss:0.8347015432010586:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 75.98it/s]loss:0.8318728807117357:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 75.98it/s]loss:0.8942025559769654:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 75.98it/s]loss:1.1088847923523724:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 75.98it/s]loss:1.2139781173239008:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 75.98it/s]loss:1.2139781173239008:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 76.70it/s]loss:1.214554108028673:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 76.70it/s] loss:1.1136480704168499:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 76.70it/s]loss:0.9476611932651757:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 76.70it/s]loss:0.9476611932651757: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 63.63it/s]
Epoch: 2 cost time: 0.7435214519500732
Epoch: 2, Steps: 19 | Train Loss: 0.8582704 Vali Loss: 3.1381671 Test Loss: 36.4884262
EarlyStopping counter: 1 out of 3
Updating learning rate to 5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.561722011793513:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5564133912812063:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6196085595261193:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6208794104636276:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6760107602145353:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7119674506729885:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7387271980318139:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7387271980318139:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 67.95it/s]loss:0.7743134175839333:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 67.95it/s]loss:0.7044082196071414:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 67.95it/s]loss:0.877497538163397:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 67.95it/s] loss:0.7312020968182515:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 67.95it/s]loss:0.7717017493441944:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 67.95it/s]loss:0.9332132921194509:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 67.95it/s]loss:0.8139785588508178:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 67.95it/s]loss:1.129528205970916:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:00, 67.95it/s] loss:1.129528205970916:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 71.96it/s]loss:1.0095627105205205:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 71.96it/s]loss:1.096085444487284:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 71.96it/s] loss:1.3185249753467982:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 71.96it/s]loss:0.9409701001353294:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 71.96it/s]loss:0.9409701001353294: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 62.29it/s]
Epoch: 3 cost time: 0.8226673603057861
Epoch: 3, Steps: 19 | Train Loss: 0.8203324 Vali Loss: 3.1856220 Test Loss: 36.5218430
EarlyStopping counter: 2 out of 3
Updating learning rate to 2.5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.4879314035857022:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5724455084358632:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.4641143380551855:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.616729259995932:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.6496233616800045:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.774332361313056:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.902796381512396:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7472533652341359:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7472533652341359:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 75.47it/s]loss:0.8328403351118765:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 75.47it/s]loss:0.7085835384575823:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 75.47it/s]loss:0.8742052482551508:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 75.47it/s]loss:0.7704118022780538:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 75.47it/s]loss:0.9647249502263053:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 75.47it/s]loss:0.9802333067310446:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 75.47it/s]loss:1.0706060745067074:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 75.47it/s]loss:1.2350260759334093:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 75.47it/s]loss:1.2350260759334093:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 76.88it/s]loss:0.8632235158265158:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 76.88it/s]loss:1.0289369624711115:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 76.88it/s]loss:0.9217173758870094:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 76.88it/s]loss:0.9217173758870094: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 63.15it/s]
Epoch: 4 cost time: 0.7466332912445068
Epoch: 4, Steps: 19 | Train Loss: 0.8139861 Vali Loss: 3.1195486 Test Loss: 36.4924126
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : long_term_forecast_break_rayleigh_0_SegRNN_job_demand_region_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 4
test shape: (4, 1, 3, 16345) (4, 1, 3, 16345)
test shape: (4, 3, 16345) (4, 3, 16345)
mse:46461.61328125, mae:34.68147659301758, dtw:-999
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           0                   Model:              PatchTST            

[1mData Loader[0m
  Data:               job_demand_r2       Root Path:          ../../dataset/demand/
  Data Path:          r2.parquet          Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        .cache/checkpoints  

[1mForecasting Task[0m
  Seq Len:            6                   Label Len:          1                   
  Pred Len:           3                   Seasonal Patterns:  Monthly             
  Inverse:            1                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             121420              Dec In:             121420              
  C Out:              121420              d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           2                   d FF:               2048                
  Moving Avg:         25                  Factor:             1                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              learned             Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        32                  Itr:                1                   
  Train Epochs:       20                  Batch Size:         1                   
  Patience:           3                   Learning Rate:      0.0001              
  Des:                test                Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1                 

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_break_bartlett_0_PatchTST_job_demand_r2_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 19
val 1
test 4
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:16,  1.10it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:01<00:16,  1.10it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:01<00:08,  2.09it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:01<00:08,  2.09it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.93it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.93it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:04,  3.61it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:04,  3.61it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:01<00:03,  4.14it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:01<00:03,  4.14it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:01<00:02,  4.55it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:01<00:02,  4.55it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:01<00:02,  4.85it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:02,  4.85it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:02<00:02,  5.09it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:02<00:02,  5.09it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:02<00:01,  5.23it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:02<00:01,  5.23it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:02<00:01,  5.35it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:02<00:01,  5.35it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:02<00:01,  5.41it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:02<00:01,  5.41it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:02<00:01,  5.49it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:03<00:01,  5.49it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:03<00:01,  5.51it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:03<00:01,  5.51it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:03<00:00,  5.56it/s]loss:0.038023366940805645:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:03<00:00,  5.56it/s]loss:0.038023366940805645:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:03<00:00,  5.51it/s]loss:0.17745557128865277:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:03<00:00,  5.51it/s] loss:0.17745557128865277:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:03<00:00,  5.50it/s]loss:0.3093276789424279:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:03<00:00,  5.50it/s] loss:0.3093276789424279:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:03<00:00,  5.46it/s]loss:0.6400273744299078:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:03<00:00,  5.46it/s]loss:0.6400273744299078:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:03<00:00,  5.45it/s]loss:0.7377045166499876:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:04<00:00,  5.45it/s]loss:0.7377045166499876: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:04<00:00,  5.44it/s]loss:0.7377045166499876: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:04<00:00,  4.54it/s]
Epoch: 1 cost time: 4.754286766052246
Epoch: 1, Steps: 19 | Train Loss: 0.1001336 Vali Loss: 3.1830835 Test Loss: 28.6145782
Validation loss decreased (inf --> 3.183084).  Saving model ...
Updating learning rate to 0.0001
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:03,  5.36it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:03,  5.36it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:03,  5.50it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:03,  5.50it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:02,  5.46it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:02,  5.46it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:02,  5.53it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:02,  5.53it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:02,  5.54it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:01<00:02,  5.54it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:01<00:02,  5.58it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:01<00:02,  5.58it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:01<00:02,  5.58it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:01<00:02,  5.58it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:01<00:01,  5.60it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:01<00:01,  5.60it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:01<00:01,  5.60it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:01<00:01,  5.60it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:01,  5.61it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:01,  5.61it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:01,  5.57it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:02<00:01,  5.57it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:02<00:01,  5.58it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:02<00:01,  5.58it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:02<00:01,  5.57it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:02<00:01,  5.57it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:02<00:00,  5.58it/s]loss:0.2763277600177235:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:02<00:00,  5.58it/s]loss:0.2763277600177235:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:02<00:00,  5.52it/s]loss:1.3550652284831812:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:02<00:00,  5.52it/s]loss:1.3550652284831812:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:02<00:00,  5.50it/s]loss:1.9938388985342947:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:03<00:00,  5.50it/s]loss:1.9938388985342947:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:03<00:00,  5.47it/s]loss:2.057208387120945:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:03<00:00,  5.47it/s] loss:2.057208387120945:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:03<00:00,  5.46it/s]loss:1.702784515735581:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:03<00:00,  5.46it/s]loss:1.702784515735581: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:03<00:00,  5.43it/s]loss:1.702784515735581: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:03<00:00,  5.42it/s]
Epoch: 2 cost time: 4.010692834854126
Epoch: 2, Steps: 19 | Train Loss: 0.3886960 Vali Loss: 3.4459960 Test Loss: 25.6138096
EarlyStopping counter: 1 out of 3
Updating learning rate to 5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:03,  5.39it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:03,  5.39it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:03,  5.47it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:03,  5.47it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:02,  5.52it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:02,  5.52it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:02,  5.57it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:02,  5.57it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:02,  5.56it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:01<00:02,  5.56it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:01<00:02,  5.55it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:01<00:02,  5.55it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:01<00:02,  5.55it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:01<00:02,  5.55it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:01<00:01,  5.58it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:01<00:01,  5.58it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:01<00:01,  5.57it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:01<00:01,  5.57it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:01,  5.58it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:01,  5.58it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:01,  5.55it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:02<00:01,  5.55it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:02<00:01,  5.58it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:02<00:01,  5.58it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:02<00:01,  5.57it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:02<00:01,  5.57it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:02<00:00,  5.58it/s]loss:0.08201339220843142:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:02<00:00,  5.58it/s]loss:0.08201339220843142:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:02<00:00,  5.53it/s]loss:0.5157413695556045:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:02<00:00,  5.53it/s] loss:0.5157413695556045:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:02<00:00,  5.51it/s]loss:0.9692391166853515:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:03<00:00,  5.51it/s]loss:0.9692391166853515:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:03<00:00,  5.48it/s]loss:1.3743635332866815:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:03<00:00,  5.48it/s]loss:1.3743635332866815:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:03<00:00,  5.48it/s]loss:1.277454822386066:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:03<00:00,  5.48it/s] loss:1.277454822386066: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:03<00:00,  5.46it/s]loss:1.277454822386066: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:03<00:00,  5.44it/s]
Epoch: 3 cost time: 4.01731538772583
Epoch: 3, Steps: 19 | Train Loss: 0.2220427 Vali Loss: 4.1400580 Test Loss: 38.8344498
EarlyStopping counter: 2 out of 3
Updating learning rate to 2.5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:03,  5.36it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:03,  5.36it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:03,  5.42it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:03,  5.42it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:02,  5.49it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:02,  5.49it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:02,  5.53it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:02,  5.53it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:02,  5.49it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:01<00:02,  5.49it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:01<00:02,  5.54it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:01<00:02,  5.54it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:01<00:02,  5.54it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:01<00:02,  5.54it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:01<00:01,  5.56it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:01<00:01,  5.56it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:01<00:01,  5.55it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:01<00:01,  5.55it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:01,  5.57it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:01,  5.57it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:01,  5.57it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:02<00:01,  5.57it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:02<00:01,  5.59it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:02<00:01,  5.59it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:02<00:01,  5.57it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:02<00:01,  5.57it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:02<00:00,  5.57it/s]loss:0.04125347894815723:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:02<00:00,  5.57it/s]loss:0.04125347894815723:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:02<00:00,  5.51it/s]loss:0.1731139873354868:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:02<00:00,  5.51it/s] loss:0.1731139873354868:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:02<00:00,  5.49it/s]loss:0.34054641108018263:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:03<00:00,  5.49it/s]loss:0.34054641108018263:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:03<00:00,  5.46it/s]loss:0.6683253650575498:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:03<00:00,  5.46it/s] loss:0.6683253650575498:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:03<00:00,  5.45it/s]loss:0.9005434782519788:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:03<00:00,  5.45it/s]loss:0.9005434782519788: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:03<00:00,  5.44it/s]loss:0.9005434782519788: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:03<00:00,  5.43it/s]
Epoch: 4 cost time: 4.058847904205322
Epoch: 4, Steps: 19 | Train Loss: 0.1117780 Vali Loss: 3.4431584 Test Loss: 36.4403458
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : long_term_forecast_break_bartlett_0_PatchTST_job_demand_r2_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 4
test shape: (4, 1, 3, 121420) (4, 1, 3, 121420)
test shape: (4, 3, 121420) (4, 3, 121420)
mse:17045.8984375, mae:6.68512487411499, dtw:-999
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           0                   Model:              PatchTST            

[1mData Loader[0m
  Data:               job_demand_r2       Root Path:          ../../dataset/demand/
  Data Path:          r2.parquet          Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        .cache/checkpoints  

[1mForecasting Task[0m
  Seq Len:            6                   Label Len:          1                   
  Pred Len:           3                   Seasonal Patterns:  Monthly             
  Inverse:            1                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             121420              Dec In:             121420              
  C Out:              121420              d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           2                   d FF:               2048                
  Moving Avg:         25                  Factor:             1                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              learned             Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        32                  Itr:                1                   
  Train Epochs:       20                  Batch Size:         1                   
  Patience:           3                   Learning Rate:      0.0001              
  Des:                test                Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1                 

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_break_parzen_0_PatchTST_job_demand_r2_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 19
val 1
test 4
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:14,  1.26it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:14,  1.26it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:07,  2.32it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:01<00:07,  2.32it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  3.16it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  3.16it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:03,  3.83it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:03,  3.83it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:01<00:03,  4.31it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:01<00:03,  4.31it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:01<00:02,  4.66it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:01<00:02,  4.66it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:01<00:02,  4.91it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:02,  4.91it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:02<00:02,  5.11it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:02<00:02,  5.11it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:02<00:01,  5.25it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:02<00:01,  5.25it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:02<00:01,  5.36it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:02<00:01,  5.36it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:02<00:01,  5.43it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:02<00:01,  5.43it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:02<00:01,  5.48it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:02<00:01,  5.48it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:02<00:01,  5.51it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:03<00:01,  5.51it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:03<00:00,  5.54it/s]loss:0.00017244157342768878:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:03<00:00,  5.54it/s]loss:0.00017244157342768878:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:03<00:00,  5.49it/s]loss:0.02928980049847715:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:03<00:00,  5.49it/s]   loss:0.02928980049847715:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:03<00:00,  5.48it/s]loss:0.16982689546877833:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:03<00:00,  5.48it/s]loss:0.16982689546877833:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:03<00:00,  5.46it/s]loss:0.5931088138848623:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:03<00:00,  5.46it/s] loss:0.5931088138848623:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:03<00:00,  5.46it/s]loss:0.7409938044946839:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:04<00:00,  5.46it/s]loss:0.7409938044946839: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:04<00:00,  5.43it/s]loss:0.7409938044946839: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:04<00:00,  4.63it/s]
Epoch: 1 cost time: 4.670320510864258
Epoch: 1, Steps: 19 | Train Loss: 0.0807048 Vali Loss: 3.1666646 Test Loss: 27.7846565
Validation loss decreased (inf --> 3.166665).  Saving model ...
Updating learning rate to 0.0001
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:03,  5.24it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:03,  5.24it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:03,  5.38it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:03,  5.38it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:02,  5.40it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:02,  5.40it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:02,  5.48it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:02,  5.48it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:02,  5.51it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:01<00:02,  5.51it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:01<00:02,  5.54it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:01<00:02,  5.54it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:01<00:02,  5.53it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:01<00:02,  5.53it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:01<00:01,  5.56it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:01<00:01,  5.56it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:01<00:01,  5.56it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:01<00:01,  5.56it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:01,  5.57it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:01,  5.57it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:01,  5.56it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:02<00:01,  5.56it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:02<00:01,  5.57it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:02<00:01,  5.57it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:02<00:01,  5.56it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:02<00:01,  5.56it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:02<00:00,  5.57it/s]loss:0.0008312891502373281:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:02<00:00,  5.57it/s]loss:0.0008312891502373281:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:02<00:00,  5.51it/s]loss:0.17442893213667165:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:02<00:00,  5.51it/s]  loss:0.17442893213667165:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:02<00:00,  5.49it/s]loss:0.9227151941599324:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:03<00:00,  5.49it/s] loss:0.9227151941599324:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:03<00:00,  5.46it/s]loss:1.8513135644415302:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:03<00:00,  5.46it/s]loss:1.8513135644415302:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:03<00:00,  5.47it/s]loss:1.6145559730032237:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:03<00:00,  5.47it/s]loss:1.6145559730032237: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:03<00:00,  5.43it/s]loss:1.6145559730032237: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:03<00:00,  5.41it/s]
Epoch: 2 cost time: 4.016390562057495
Epoch: 2, Steps: 19 | Train Loss: 0.2402024 Vali Loss: 3.5227923 Test Loss: 24.3058510
EarlyStopping counter: 1 out of 3
Updating learning rate to 5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:03,  5.39it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:03,  5.39it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:03,  5.53it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:03,  5.53it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:02,  5.45it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:02,  5.45it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:02,  5.52it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:02,  5.52it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:02,  5.48it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:01<00:02,  5.48it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:01<00:02,  5.52it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:01<00:02,  5.52it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:01<00:02,  5.52it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:01<00:02,  5.52it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:01<00:01,  5.56it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:01<00:01,  5.56it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:01<00:01,  5.55it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:01<00:01,  5.55it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:01,  5.58it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:01,  5.58it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:01,  5.57it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:02<00:01,  5.57it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:02<00:01,  5.59it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:02<00:01,  5.59it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:02<00:01,  5.58it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:02<00:01,  5.58it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:02<00:00,  5.59it/s]loss:0.00041845219073947883:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:02<00:00,  5.59it/s]loss:0.00041845219073947883:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:02<00:00,  5.53it/s]loss:0.09031445867023687:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:02<00:00,  5.53it/s]   loss:0.09031445867023687:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:02<00:00,  5.52it/s]loss:0.7098656587688015:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:03<00:00,  5.52it/s] loss:0.7098656587688015:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:03<00:00,  5.45it/s]loss:1.6753922198999145:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:03<00:00,  5.45it/s]loss:1.6753922198999145:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:03<00:00,  5.45it/s]loss:1.7200046626371763:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:03<00:00,  5.45it/s]loss:1.7200046626371763: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:03<00:00,  5.43it/s]loss:1.7200046626371763: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:03<00:00,  5.42it/s]
Epoch: 3 cost time: 4.024200916290283
Epoch: 3, Steps: 19 | Train Loss: 0.2208419 Vali Loss: 4.4521875 Test Loss: 42.0798187
EarlyStopping counter: 2 out of 3
Updating learning rate to 2.5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:03,  5.30it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:03,  5.30it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:03,  5.47it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:03,  5.47it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:02,  5.38it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:02,  5.38it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:02,  5.48it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:02,  5.48it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:02,  5.50it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:01<00:02,  5.50it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:01<00:02,  5.54it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:01<00:02,  5.54it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:01<00:02,  5.54it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:01<00:02,  5.54it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:01<00:01,  5.57it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:01<00:01,  5.57it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:01<00:01,  5.54it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:01<00:01,  5.54it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:01,  5.56it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:01,  5.56it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:01,  5.55it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:02<00:01,  5.55it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:02<00:01,  5.57it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:02<00:01,  5.57it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:02<00:01,  5.56it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:02<00:01,  5.56it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:02<00:00,  5.58it/s]loss:0.0001941981343557291:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:02<00:00,  5.58it/s]loss:0.0001941981343557291:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:02<00:00,  5.53it/s]loss:0.02855452210075556:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:02<00:00,  5.53it/s]  loss:0.02855452210075556:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:02<00:00,  5.51it/s]loss:0.19525728439534382:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:03<00:00,  5.51it/s]loss:0.19525728439534382:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:03<00:00,  5.46it/s]loss:0.6692514917593999:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:03<00:00,  5.46it/s] loss:0.6692514917593999:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:03<00:00,  5.45it/s]loss:0.9363467954919832:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:03<00:00,  5.45it/s]loss:0.9363467954919832: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:03<00:00,  5.43it/s]loss:0.9363467954919832: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:03<00:00,  5.41it/s]
Epoch: 4 cost time: 3.9913036823272705
Epoch: 4, Steps: 19 | Train Loss: 0.0962950 Vali Loss: 3.4765751 Test Loss: 35.8363228
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : long_term_forecast_break_parzen_0_PatchTST_job_demand_r2_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 4
test shape: (4, 1, 3, 121420) (4, 1, 3, 121420)
test shape: (4, 3, 121420) (4, 3, 121420)
mse:17257.236328125, mae:6.789883613586426, dtw:-999
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           0                   Model:              PatchTST            

[1mData Loader[0m
  Data:               job_demand_r2       Root Path:          ../../dataset/demand/
  Data Path:          r2.parquet          Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        .cache/checkpoints  

[1mForecasting Task[0m
  Seq Len:            6                   Label Len:          1                   
  Pred Len:           3                   Seasonal Patterns:  Monthly             
  Inverse:            1                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             121420              Dec In:             121420              
  C Out:              121420              d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           2                   d FF:               2048                
  Moving Avg:         25                  Factor:             1                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              learned             Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        32                  Itr:                1                   
  Train Epochs:       20                  Batch Size:         1                   
  Patience:           3                   Learning Rate:      0.0001              
  Des:                test                Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1                 

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_break_tukey-hanning_0_PatchTST_job_demand_r2_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 19
val 1
test 4
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:15,  1.19it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:01<00:15,  1.19it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:01<00:07,  2.22it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:01<00:07,  2.22it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  3.06it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  3.06it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:04,  3.73it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:04,  3.73it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:01<00:03,  4.23it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:01<00:03,  4.23it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:01<00:02,  4.61it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:01<00:02,  4.61it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:01<00:02,  4.86it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:02,  4.86it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:02<00:02,  5.08it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:02<00:02,  5.08it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:02<00:01,  5.20it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:02<00:01,  5.20it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:02<00:01,  5.32it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:02<00:01,  5.32it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:02<00:01,  5.38it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:02<00:01,  5.38it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:02<00:01,  5.45it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:02<00:01,  5.45it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:02<00:01,  5.48it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:03<00:01,  5.48it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:03<00:00,  5.52it/s]loss:0.004459240725109367:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:03<00:00,  5.52it/s]loss:0.004459240725109367:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:03<00:00,  5.47it/s]loss:0.11697372455735448:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:03<00:00,  5.47it/s] loss:0.11697372455735448:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:03<00:00,  5.46it/s]loss:0.31890938822842096:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:03<00:00,  5.46it/s]loss:0.31890938822842096:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:03<00:00,  5.43it/s]loss:0.7059534933277729:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:03<00:00,  5.43it/s] loss:0.7059534933277729:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:03<00:00,  5.44it/s]loss:0.7406581923648162:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:04<00:00,  5.44it/s]loss:0.7406581923648162: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:04<00:00,  5.43it/s]loss:0.7406581923648162: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:04<00:00,  4.59it/s]
Epoch: 1 cost time: 4.762051820755005
Epoch: 1, Steps: 19 | Train Loss: 0.0993134 Vali Loss: 3.1842785 Test Loss: 28.4096889
Validation loss decreased (inf --> 3.184278).  Saving model ...
Updating learning rate to 0.0001
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:03,  5.37it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:03,  5.37it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:03,  5.49it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:03,  5.49it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:02,  5.53it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:02,  5.53it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:02,  5.57it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:02,  5.57it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:02,  5.54it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:01<00:02,  5.54it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:01<00:02,  5.56it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:01<00:02,  5.56it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:01<00:02,  5.55it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:01<00:02,  5.55it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:01<00:01,  5.57it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:01<00:01,  5.57it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:01<00:01,  5.56it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:01<00:01,  5.56it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:01,  5.58it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:01,  5.58it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:01,  5.56it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:02<00:01,  5.56it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:02<00:01,  5.55it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:02<00:01,  5.55it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:02<00:01,  5.55it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:02<00:01,  5.55it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:02<00:00,  5.57it/s]loss:0.02619289643964156:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:02<00:00,  5.57it/s]loss:0.02619289643964156:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:02<00:00,  5.51it/s]loss:0.8175044224577261:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:02<00:00,  5.51it/s] loss:0.8175044224577261:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:02<00:00,  5.49it/s]loss:1.8956938168938933:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:03<00:00,  5.49it/s]loss:1.8956938168938933:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:03<00:00,  5.47it/s]loss:2.2604055860949805:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:03<00:00,  5.47it/s]loss:2.2604055860949805:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:03<00:00,  5.46it/s]loss:1.6584331803031716:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:03<00:00,  5.46it/s]loss:1.6584331803031716: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:03<00:00,  5.42it/s]loss:1.6584331803031716: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:03<00:00,  5.43it/s]
Epoch: 2 cost time: 4.05926513671875
Epoch: 2, Steps: 19 | Train Loss: 0.3504332 Vali Loss: 3.4988501 Test Loss: 24.9513340
EarlyStopping counter: 1 out of 3
Updating learning rate to 5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:03,  5.34it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:03,  5.34it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:03,  5.45it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:03,  5.45it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:02,  5.49it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:02,  5.49it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:02,  5.52it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:02,  5.52it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:02,  5.52it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:01<00:02,  5.52it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:01<00:02,  5.55it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:01<00:02,  5.55it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:01<00:02,  5.53it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:01<00:02,  5.53it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:01<00:01,  5.56it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:01<00:01,  5.56it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:01<00:01,  5.55it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:01<00:01,  5.55it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:01,  5.56it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:01,  5.56it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:01,  5.56it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:02<00:01,  5.56it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:02<00:01,  5.57it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:02<00:01,  5.57it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:02<00:01,  5.56it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:02<00:01,  5.56it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:02<00:00,  5.57it/s]loss:0.00980975832906411:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:02<00:00,  5.57it/s]loss:0.00980975832906411:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:02<00:00,  5.51it/s]loss:0.3511686322740817:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:02<00:00,  5.51it/s] loss:0.3511686322740817:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:02<00:00,  5.48it/s]loss:1.1040804945419755:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:03<00:00,  5.48it/s]loss:1.1040804945419755:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:03<00:00,  5.46it/s]loss:1.6833702186253954:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:03<00:00,  5.46it/s]loss:1.6833702186253954:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:03<00:00,  5.46it/s]loss:1.3934924409591445:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:03<00:00,  5.46it/s]loss:1.3934924409591445: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:03<00:00,  5.43it/s]loss:1.3934924409591445: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:03<00:00,  5.41it/s]
Epoch: 3 cost time: 4.03439998626709
Epoch: 3, Steps: 19 | Train Loss: 0.2390485 Vali Loss: 4.2564282 Test Loss: 39.7528839
EarlyStopping counter: 2 out of 3
Updating learning rate to 2.5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:03,  5.39it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:03,  5.39it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:03,  5.46it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:03,  5.46it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:02,  5.49it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:02,  5.49it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:02,  5.53it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:02,  5.53it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:02,  5.54it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:01<00:02,  5.54it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:01<00:02,  5.57it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:01<00:02,  5.57it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:01<00:02,  5.56it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:01<00:02,  5.56it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:01<00:01,  5.58it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:01<00:01,  5.58it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:01<00:01,  5.57it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:01<00:01,  5.57it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:01,  5.58it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:01,  5.58it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:01,  5.57it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:02<00:01,  5.57it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:02<00:01,  5.58it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:02<00:01,  5.58it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:02<00:01,  5.57it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:02<00:01,  5.57it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:02<00:00,  5.57it/s]loss:0.00466393420276743:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:02<00:00,  5.57it/s]loss:0.00466393420276743:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:02<00:00,  5.51it/s]loss:0.10822700545568537:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:02<00:00,  5.51it/s]loss:0.10822700545568537:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:02<00:00,  5.49it/s]loss:0.3472193702974975:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:03<00:00,  5.49it/s] loss:0.3472193702974975:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:03<00:00,  5.40it/s]loss:0.7351711102639128:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:03<00:00,  5.40it/s]loss:0.7351711102639128:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:03<00:00,  5.40it/s]loss:0.8902793106160021:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:03<00:00,  5.40it/s]loss:0.8902793106160021: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:03<00:00,  5.38it/s]loss:0.8902793106160021: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:03<00:00,  5.41it/s]
Epoch: 4 cost time: 4.023556232452393
Epoch: 4, Steps: 19 | Train Loss: 0.1097664 Vali Loss: 3.4218256 Test Loss: 36.3303452
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : long_term_forecast_break_tukey-hanning_0_PatchTST_job_demand_r2_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 4
test shape: (4, 1, 3, 121420) (4, 1, 3, 121420)
test shape: (4, 3, 121420) (4, 3, 121420)
mse:17097.140625, mae:6.690833568572998, dtw:-999
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           0                   Model:              PatchTST            

[1mData Loader[0m
  Data:               job_demand_r2       Root Path:          ../../dataset/demand/
  Data Path:          r2.parquet          Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        .cache/checkpoints  

[1mForecasting Task[0m
  Seq Len:            6                   Label Len:          1                   
  Pred Len:           3                   Seasonal Patterns:  Monthly             
  Inverse:            1                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             121420              Dec In:             121420              
  C Out:              121420              d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           2                   d FF:               2048                
  Moving Avg:         25                  Factor:             1                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              learned             Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        32                  Itr:                1                   
  Train Epochs:       20                  Batch Size:         1                   
  Patience:           3                   Learning Rate:      0.0001              
  Des:                test                Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1                 

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_break_rayleigh_0_PatchTST_job_demand_r2_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 19
val 1
test 4
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.3629242604917083:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.3629242604917083:   5%|â–Œ         | 1/19 [00:00<00:14,  1.27it/s]loss:0.3200703246852574:   5%|â–Œ         | 1/19 [00:00<00:14,  1.27it/s]loss:0.3200703246852574:  11%|â–ˆ         | 2/19 [00:00<00:07,  2.31it/s]loss:0.4084085733857828:  11%|â–ˆ         | 2/19 [00:01<00:07,  2.31it/s]loss:0.4084085733857828:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  3.12it/s]loss:0.44312592194153283:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  3.12it/s]loss:0.44312592194153283:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:03,  3.75it/s]loss:0.442222178488201:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:03,  3.75it/s]  loss:0.442222178488201:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:01<00:03,  4.17it/s]loss:0.5111066254650465:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:01<00:03,  4.17it/s]loss:0.5111066254650465:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:01<00:02,  4.53it/s]loss:0.6393784825921167:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:01<00:02,  4.53it/s]loss:0.6393784825921167:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:01<00:02,  4.78it/s]loss:0.5571087902100629:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:02,  4.78it/s]loss:0.5571087902100629:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:02<00:02,  4.97it/s]loss:0.5622922990841951:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:02<00:02,  4.97it/s]loss:0.5622922990841951:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:02<00:01,  5.09it/s]loss:0.6176088571601719:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:02<00:01,  5.09it/s]loss:0.6176088571601719:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:02<00:01,  5.19it/s]loss:0.6777403411560812:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:02<00:01,  5.19it/s]loss:0.6777403411560812:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:02<00:01,  5.24it/s]loss:0.5159538674877527:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:02<00:01,  5.24it/s]loss:0.5159538674877527:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:02<00:01,  5.30it/s]loss:0.5721440877224521:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:03<00:01,  5.30it/s]loss:0.5721440877224521:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:03<00:01,  5.30it/s]loss:0.5999040135184028:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:03<00:01,  5.30it/s]loss:0.5999040135184028:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:03<00:00,  5.34it/s]loss:0.607153431533836:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:03<00:00,  5.34it/s] loss:0.607153431533836:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:03<00:00,  5.36it/s]loss:0.5457055057982696:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:03<00:00,  5.36it/s]loss:0.5457055057982696:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:03<00:00,  5.37it/s]loss:0.5546114856881296:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:03<00:00,  5.37it/s]loss:0.5546114856881296:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:03<00:00,  5.37it/s]loss:0.765670807467231:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:03<00:00,  5.37it/s] loss:0.765670807467231:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:03<00:00,  5.39it/s]loss:0.7514988471803599:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:04<00:00,  5.39it/s]loss:0.7514988471803599: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:04<00:00,  5.39it/s]loss:0.7514988471803599: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:04<00:00,  4.54it/s]
Epoch: 1 cost time: 4.734293222427368
Epoch: 1, Steps: 19 | Train Loss: 0.5502436 Vali Loss: 3.1589053 Test Loss: 29.6611061
Validation loss decreased (inf --> 3.158905).  Saving model ...
Updating learning rate to 0.0001
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.3202767079605366:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.3202767079605366:   5%|â–Œ         | 1/19 [00:00<00:03,  5.18it/s]loss:0.3088632918391816:   5%|â–Œ         | 1/19 [00:00<00:03,  5.18it/s]loss:0.3088632918391816:  11%|â–ˆ         | 2/19 [00:00<00:03,  5.25it/s]loss:0.3835821936838703:  11%|â–ˆ         | 2/19 [00:00<00:03,  5.25it/s]loss:0.3835821936838703:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:03,  5.22it/s]loss:0.3817096225345907:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:03,  5.22it/s]loss:0.3817096225345907:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:02,  5.30it/s]loss:0.4516381466169004:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:02,  5.30it/s]loss:0.4516381466169004:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:02,  5.33it/s]loss:0.434192776604698:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:01<00:02,  5.33it/s] loss:0.434192776604698:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:01<00:02,  5.37it/s]loss:0.5475820100132511:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:01<00:02,  5.37it/s]loss:0.5475820100132511:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:01<00:02,  5.36it/s]loss:0.6380389179661997:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:01<00:02,  5.36it/s]loss:0.6380389179661997:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:01<00:02,  5.36it/s]loss:0.583339293232689:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:01<00:02,  5.36it/s] loss:0.583339293232689:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:01<00:01,  5.37it/s]loss:0.6163527746331741:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:01<00:01,  5.37it/s]loss:0.6163527746331741:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:01,  5.38it/s]loss:0.6139644730088091:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:02<00:01,  5.38it/s]loss:0.6139644730088091:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:02<00:01,  5.37it/s]loss:0.6447712521967267:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:02<00:01,  5.37it/s]loss:0.6447712521967267:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:02<00:01,  5.40it/s]loss:0.6681090189171995:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:02<00:01,  5.40it/s]loss:0.6681090189171995:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:02<00:01,  5.40it/s]loss:0.6827023127462725:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:02<00:01,  5.40it/s]loss:0.6827023127462725:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:02<00:00,  5.41it/s]loss:0.6728502162187269:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:02<00:00,  5.41it/s]loss:0.6728502162187269:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:02<00:00,  5.39it/s]loss:0.6304031497698249:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:02<00:00,  5.39it/s]loss:0.6304031497698249:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:02<00:00,  5.41it/s]loss:0.5424398697307942:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:03<00:00,  5.41it/s]loss:0.5424398697307942:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:03<00:00,  5.41it/s]loss:0.6196176856589805:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:03<00:00,  5.41it/s]loss:0.6196176856589805:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:03<00:00,  5.41it/s]loss:0.5914660465587656:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:03<00:00,  5.41it/s]loss:0.5914660465587656: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:03<00:00,  5.40it/s]loss:0.5914660465587656: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:03<00:00,  5.30it/s]
Epoch: 2 cost time: 4.14603853225708
Epoch: 2, Steps: 19 | Train Loss: 0.5437842 Vali Loss: 3.3309431 Test Loss: 33.2015762
EarlyStopping counter: 1 out of 3
Updating learning rate to 5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.3701615185330972:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.3701615185330972:   5%|â–Œ         | 1/19 [00:00<00:03,  5.21it/s]loss:0.3661752255863958:   5%|â–Œ         | 1/19 [00:00<00:03,  5.21it/s]loss:0.3661752255863958:  11%|â–ˆ         | 2/19 [00:00<00:03,  5.28it/s]loss:0.29148684850078943:  11%|â–ˆ         | 2/19 [00:00<00:03,  5.28it/s]loss:0.29148684850078943:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:03,  5.29it/s]loss:0.42097389760304277:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:03,  5.29it/s]loss:0.42097389760304277:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:02,  5.33it/s]loss:0.47261872964469553:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:02,  5.33it/s]loss:0.47261872964469553:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:02,  5.33it/s]loss:0.4789052664763267:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:01<00:02,  5.33it/s] loss:0.4789052664763267:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:01<00:02,  5.38it/s]loss:0.42123383886526:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:01<00:02,  5.38it/s]  loss:0.42123383886526:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:01<00:02,  5.38it/s]loss:0.4518255490493511:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:01<00:02,  5.38it/s]loss:0.4518255490493511:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:01<00:02,  5.41it/s]loss:0.5719397352013718:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:01<00:02,  5.41it/s]loss:0.5719397352013718:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:01<00:01,  5.40it/s]loss:0.522491380174319:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:01<00:01,  5.40it/s] loss:0.522491380174319:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:01,  5.40it/s]loss:0.6868803353215552:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:02<00:01,  5.40it/s]loss:0.6868803353215552:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:02<00:01,  5.39it/s]loss:0.508008703452802:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:02<00:01,  5.39it/s] loss:0.508008703452802:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:02<00:01,  5.41it/s]loss:0.6218130539886723:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:02<00:01,  5.41it/s]loss:0.6218130539886723:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:02<00:01,  5.39it/s]loss:0.5591142652751159:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:02<00:01,  5.39it/s]loss:0.5591142652751159:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:02<00:00,  5.39it/s]loss:0.5774077407462896:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:02<00:00,  5.39it/s]loss:0.5774077407462896:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:02<00:00,  5.38it/s]loss:0.7089600828730135:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:02<00:00,  5.38it/s]loss:0.7089600828730135:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:02<00:00,  5.40it/s]loss:0.6148565516352817:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:03<00:00,  5.40it/s]loss:0.6148565516352817:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:03<00:00,  5.39it/s]loss:0.689695846714822:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:03<00:00,  5.39it/s] loss:0.689695846714822:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:03<00:00,  5.39it/s]loss:0.6025426463685012:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:03<00:00,  5.39it/s]loss:0.6025426463685012: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:03<00:00,  5.39it/s]loss:0.6025426463685012: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:03<00:00,  5.30it/s]
Epoch: 3 cost time: 4.066323757171631
Epoch: 3, Steps: 19 | Train Loss: 0.5230048 Vali Loss: 3.2323494 Test Loss: 30.9499550
EarlyStopping counter: 2 out of 3
Updating learning rate to 2.5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.2790697186043454:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.2790697186043454:   5%|â–Œ         | 1/19 [00:00<00:03,  4.93it/s]loss:0.3345271247113132:   5%|â–Œ         | 1/19 [00:00<00:03,  4.93it/s]loss:0.3345271247113132:  11%|â–ˆ         | 2/19 [00:00<00:03,  5.14it/s]loss:0.3205565042623318:  11%|â–ˆ         | 2/19 [00:00<00:03,  5.14it/s]loss:0.3205565042623318:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:03,  5.16it/s]loss:0.34641968519639094:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:03,  5.16it/s]loss:0.34641968519639094:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:02,  5.20it/s]loss:0.3807275543403772:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:02,  5.20it/s] loss:0.3807275543403772:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:02,  5.23it/s]loss:0.4854977823746656:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:01<00:02,  5.23it/s]loss:0.4854977823746656:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:01<00:02,  5.29it/s]loss:0.45536401378805236:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:01<00:02,  5.29it/s]loss:0.45536401378805236:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:01<00:02,  5.33it/s]loss:0.5223657138107055:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:01<00:02,  5.33it/s] loss:0.5223657138107055:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:01<00:02,  5.35it/s]loss:0.44445952580709724:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:01<00:02,  5.35it/s]loss:0.44445952580709724:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:01<00:01,  5.34it/s]loss:0.5941231226395537:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:01<00:01,  5.34it/s] loss:0.5941231226395537:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:01,  5.37it/s]loss:0.4724401355834722:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:02<00:01,  5.37it/s]loss:0.4724401355834722:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:02<00:01,  5.38it/s]loss:0.5325082836206237:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:02<00:01,  5.38it/s]loss:0.5325082836206237:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:02<00:01,  5.40it/s]loss:0.6522980528640386:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:02<00:01,  5.40it/s]loss:0.6522980528640386:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:02<00:01,  5.39it/s]loss:0.655609986300747:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:02<00:01,  5.39it/s] loss:0.655609986300747:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:02<00:00,  5.40it/s]loss:0.6643153142144487:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:02<00:00,  5.40it/s]loss:0.6643153142144487:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:02<00:00,  5.40it/s]loss:0.523330741359519:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:02<00:00,  5.40it/s] loss:0.523330741359519:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:02<00:00,  5.41it/s]loss:0.5839816907106931:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:03<00:00,  5.41it/s]loss:0.5839816907106931:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:03<00:00,  5.39it/s]loss:0.7244084689404269:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:03<00:00,  5.39it/s]loss:0.7244084689404269:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:03<00:00,  5.40it/s]loss:0.7868885997283472:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:03<00:00,  5.40it/s]loss:0.7868885997283472: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:03<00:00,  5.40it/s]loss:0.7868885997283472: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:03<00:00,  5.27it/s]
Epoch: 4 cost time: 4.1447062492370605
Epoch: 4, Steps: 19 | Train Loss: 0.5136259 Vali Loss: 3.2018015 Test Loss: 31.9884701
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : long_term_forecast_break_rayleigh_0_PatchTST_job_demand_r2_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 4
test shape: (4, 1, 3, 121420) (4, 1, 3, 121420)
test shape: (4, 3, 121420) (4, 3, 121420)
mse:12772.439453125, mae:5.999276161193848, dtw:-999
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           0                   Model:              FiLM                

[1mData Loader[0m
  Data:               job_demand_r2       Root Path:          ../../dataset/demand/
  Data Path:          r2.parquet          Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        .cache/checkpoints  

[1mForecasting Task[0m
  Seq Len:            6                   Label Len:          1                   
  Pred Len:           3                   Seasonal Patterns:  Monthly             
  Inverse:            1                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             121420              Dec In:             121420              
  C Out:              121420              d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           2                   d FF:               2048                
  Moving Avg:         25                  Factor:             1                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              learned             Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        32                  Itr:                1                   
  Train Epochs:       20                  Batch Size:         1                   
  Patience:           3                   Learning Rate:      0.0001              
  Des:                test                Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1                 

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_break_bartlett_0_FiLM_job_demand_r2_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 19
val 1
test 4
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:16,  1.11it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:01<00:16,  1.11it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:01<00:09,  1.73it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:01<00:09,  1.73it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:07,  2.11it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:07,  2.11it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:06,  2.36it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:02<00:06,  2.36it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:02<00:05,  2.52it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:02<00:05,  2.52it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.62it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.62it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.70it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:03<00:04,  2.70it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:03<00:04,  2.74it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:03<00:04,  2.74it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.77it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:04<00:03,  2.77it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:04<00:03,  2.79it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:04<00:03,  2.79it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:04<00:02,  2.80it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:04<00:02,  2.80it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.81it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:05<00:02,  2.81it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:05<00:02,  2.78it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:05<00:02,  2.78it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.79it/s]loss:0.046533349161640855:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.79it/s]loss:0.046533349161640855:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.80it/s]loss:0.2569825891242398:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:06<00:01,  2.80it/s]  loss:0.2569825891242398:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:06<00:01,  2.80it/s]loss:0.4819191386264598:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:06<00:01,  2.80it/s]loss:0.4819191386264598:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.81it/s]loss:0.6279104839640209:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.81it/s]loss:0.6279104839640209:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.81it/s]loss:0.9772623608714314:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:07<00:00,  2.81it/s]loss:0.9772623608714314: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:07<00:00,  2.81it/s]loss:0.9772623608714314: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:07<00:00,  2.59it/s]
Epoch: 1 cost time: 7.861498594284058
Epoch: 1, Steps: 19 | Train Loss: 0.1258215 Vali Loss: 3.2242739 Test Loss: 28.5706329
Validation loss decreased (inf --> 3.224274).  Saving model ...
Updating learning rate to 0.0001
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.84it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.84it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:06,  2.83it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:01<00:06,  2.83it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.82it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.82it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.83it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.83it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:01<00:04,  2.82it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:02<00:04,  2.82it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.82it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.82it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.82it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.82it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:02<00:03,  2.81it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:03<00:03,  2.81it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.80it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.80it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:03<00:03,  2.80it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:03<00:03,  2.80it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:03<00:02,  2.79it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:04<00:02,  2.79it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.79it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.79it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:04<00:02,  2.79it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:04<00:02,  2.79it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:04<00:01,  2.79it/s]loss:0.043033697132801745:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.79it/s]loss:0.043033697132801745:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.79it/s]loss:0.2738400033662103:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.79it/s]  loss:0.2738400033662103:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:05<00:01,  2.79it/s]loss:0.4792575651162001:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:06<00:01,  2.79it/s]loss:0.4792575651162001:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.79it/s]loss:0.699119892607069:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.79it/s] loss:0.699119892607069:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.79it/s]loss:0.8216753596121172:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.79it/s]loss:0.8216753596121172: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:06<00:00,  2.79it/s]loss:0.8216753596121172: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:06<00:00,  2.78it/s]
Epoch: 2 cost time: 7.3441572189331055
Epoch: 2, Steps: 19 | Train Loss: 0.1219435 Vali Loss: 3.2239647 Test Loss: 28.5758934
Validation loss decreased (3.224274 --> 3.223965).  Saving model ...
Updating learning rate to 5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.74it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.74it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:06,  2.75it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:01<00:06,  2.75it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.75it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.75it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.76it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.76it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:01<00:05,  2.77it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:02<00:05,  2.77it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.77it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.77it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.76it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.76it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:02<00:04,  2.73it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:03<00:04,  2.73it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.74it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.74it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:03<00:03,  2.75it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:03<00:03,  2.75it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:03<00:02,  2.75it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:04<00:02,  2.75it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.76it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.76it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:04<00:02,  2.76it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:05<00:02,  2.76it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.77it/s]loss:0.0391443679147996:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.77it/s]loss:0.0391443679147996:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.76it/s]loss:0.26175902108984483:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.76it/s]loss:0.26175902108984483:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:05<00:01,  2.76it/s]loss:0.509952415464468:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:06<00:01,  2.76it/s]  loss:0.509952415464468:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.76it/s]loss:0.6959377881649601:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.76it/s]loss:0.6959377881649601:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.76it/s]loss:0.9567776929557726:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.76it/s]loss:0.9567776929557726: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:06<00:00,  2.75it/s]loss:0.9567776929557726: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:06<00:00,  2.73it/s]
Epoch: 3 cost time: 7.474334001541138
Epoch: 3, Steps: 19 | Train Loss: 0.1296616 Vali Loss: 3.2239559 Test Loss: 28.5784855
Validation loss decreased (3.223965 --> 3.223956).  Saving model ...
Updating learning rate to 2.5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.78it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.78it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:06,  2.79it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:01<00:06,  2.79it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.79it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.79it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.78it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.78it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:01<00:05,  2.78it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:02<00:05,  2.78it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.78it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.78it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.77it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.77it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:02<00:03,  2.78it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:03<00:03,  2.78it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.78it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.78it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:03<00:03,  2.73it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:03<00:03,  2.73it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:03<00:02,  2.74it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:04<00:02,  2.74it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.74it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.74it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:04<00:02,  2.74it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:05<00:02,  2.74it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.75it/s]loss:0.04633414368746294:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.75it/s]loss:0.04633414368746294:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.75it/s]loss:0.26370453081555145:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.75it/s]loss:0.26370453081555145:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:05<00:01,  2.76it/s]loss:0.4786935545102766:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:06<00:01,  2.76it/s] loss:0.4786935545102766:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.75it/s]loss:0.6795611982423722:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.75it/s]loss:0.6795611982423722:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.75it/s]loss:0.9561578862483606:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.75it/s]loss:0.9561578862483606: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:06<00:00,  2.75it/s]loss:0.9561578862483606: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:06<00:00,  2.74it/s]
Epoch: 4 cost time: 7.450678110122681
Epoch: 4, Steps: 19 | Train Loss: 0.1276027 Vali Loss: 3.2239141 Test Loss: 28.5782318
Validation loss decreased (3.223956 --> 3.223914).  Saving model ...
Updating learning rate to 1.25e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.80it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.80it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:06,  2.82it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:01<00:06,  2.82it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.79it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.79it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.70it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.70it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:01<00:05,  2.71it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:02<00:05,  2.71it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.70it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.70it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.71it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.71it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:02<00:04,  2.72it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:03<00:04,  2.72it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.72it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.72it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:03<00:03,  2.73it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:04<00:03,  2.73it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:04<00:02,  2.73it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:04<00:02,  2.73it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.73it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.73it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:04<00:02,  2.73it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:05<00:02,  2.73it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.73it/s]loss:0.04628087835421216:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.73it/s]loss:0.04628087835421216:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.73it/s]loss:0.26358598307686404:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.73it/s]loss:0.26358598307686404:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:05<00:01,  2.73it/s]loss:0.46969466540897525:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:06<00:01,  2.73it/s]loss:0.46969466540897525:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.73it/s]loss:0.6773565701239054:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.73it/s] loss:0.6773565701239054:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.74it/s]loss:0.972676545590213:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.74it/s] loss:0.972676545590213: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:06<00:00,  2.74it/s]loss:0.972676545590213: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:07<00:00,  2.71it/s]
Epoch: 5 cost time: 7.491956949234009
Epoch: 5, Steps: 19 | Train Loss: 0.1278734 Vali Loss: 3.2237790 Test Loss: 28.5769005
Validation loss decreased (3.223914 --> 3.223779).  Saving model ...
Updating learning rate to 6.25e-06
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.80it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.80it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:06,  2.78it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:01<00:06,  2.78it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.76it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.76it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.77it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.77it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:01<00:05,  2.76it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:02<00:05,  2.76it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.77it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.77it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.77it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.77it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:02<00:03,  2.77it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:03<00:03,  2.77it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.76it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.76it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:03<00:03,  2.76it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:03<00:03,  2.76it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:03<00:02,  2.76it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:04<00:02,  2.76it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.76it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.76it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:04<00:02,  2.76it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:05<00:02,  2.76it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.76it/s]loss:0.0424578593555986:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.76it/s]loss:0.0424578593555986:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.75it/s]loss:0.259327782432749:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.75it/s] loss:0.259327782432749:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:05<00:01,  2.76it/s]loss:0.5093880179897721:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:06<00:01,  2.76it/s]loss:0.5093880179897721:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.75it/s]loss:0.7026591950847736:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.75it/s]loss:0.7026591950847736:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.75it/s]loss:0.9557592710045494:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.75it/s]loss:0.9557592710045494: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:06<00:00,  2.76it/s]loss:0.9557592710045494: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:06<00:00,  2.74it/s]
Epoch: 6 cost time: 7.4517436027526855
Epoch: 6, Steps: 19 | Train Loss: 0.1299785 Vali Loss: 3.2236938 Test Loss: 28.5760231
Validation loss decreased (3.223779 --> 3.223694).  Saving model ...
Updating learning rate to 3.125e-06
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.82it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.82it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:06,  2.78it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:01<00:06,  2.78it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.77it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.77it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.77it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.77it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:01<00:05,  2.76it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:02<00:05,  2.76it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.75it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.75it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.75it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.75it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:02<00:03,  2.76it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:03<00:03,  2.76it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.76it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.76it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:03<00:03,  2.77it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:03<00:03,  2.77it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:03<00:02,  2.77it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:04<00:02,  2.77it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.77it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.77it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:04<00:02,  2.77it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:05<00:02,  2.77it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.77it/s]loss:0.043461466596115605:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.77it/s]loss:0.043461466596115605:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.77it/s]loss:0.25276533974484056:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.77it/s] loss:0.25276533974484056:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:05<00:01,  2.77it/s]loss:0.47539404859861106:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:06<00:01,  2.77it/s]loss:0.47539404859861106:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.77it/s]loss:0.728146044758475:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.77it/s]  loss:0.728146044758475:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.77it/s]loss:0.9150882718438079:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.77it/s]loss:0.9150882718438079: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:06<00:00,  2.76it/s]loss:0.9150882718438079: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:06<00:00,  2.74it/s]
Epoch: 7 cost time: 7.4347758293151855
Epoch: 7, Steps: 19 | Train Loss: 0.1270976 Vali Loss: 3.2236435 Test Loss: 28.5759811
Validation loss decreased (3.223694 --> 3.223644).  Saving model ...
Updating learning rate to 1.5625e-06
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.82it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.82it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:06,  2.82it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:01<00:06,  2.82it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.79it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.79it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.81it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.81it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:01<00:05,  2.79it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:02<00:05,  2.79it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.78it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.78it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.77it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.77it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:02<00:03,  2.78it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:03<00:03,  2.78it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.77it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.77it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:03<00:03,  2.76it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:03<00:03,  2.76it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:03<00:02,  2.75it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:04<00:02,  2.75it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.76it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.76it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:04<00:02,  2.75it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:05<00:02,  2.75it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.76it/s]loss:0.04268072512036672:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.76it/s]loss:0.04268072512036672:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.75it/s]loss:0.285036877142099:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.75it/s]  loss:0.285036877142099:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:05<00:01,  2.75it/s]loss:0.4302916582438361:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:06<00:01,  2.75it/s]loss:0.4302916582438361:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.74it/s]loss:0.6740183734398058:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.74it/s]loss:0.6740183734398058:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.74it/s]loss:0.9720748533225604:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.74it/s]loss:0.9720748533225604: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:06<00:00,  2.74it/s]loss:0.9720748533225604: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:06<00:00,  2.74it/s]
Epoch: 8 cost time: 7.456279516220093
Epoch: 8, Steps: 19 | Train Loss: 0.1265317 Vali Loss: 3.2236326 Test Loss: 28.5760593
Validation loss decreased (3.223644 --> 3.223633).  Saving model ...
Updating learning rate to 7.8125e-07
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.58it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.58it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:06,  2.69it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:01<00:06,  2.69it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.73it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.73it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.76it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.76it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:01<00:05,  2.76it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:02<00:05,  2.76it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.77it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.77it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.77it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.77it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:02<00:03,  2.78it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:03<00:03,  2.78it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.77it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.77it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:03<00:03,  2.77it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:03<00:03,  2.77it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:03<00:02,  2.76it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:04<00:02,  2.76it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.77it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.77it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:04<00:02,  2.76it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:05<00:02,  2.76it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.77it/s]loss:0.039027804655623076:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.77it/s]loss:0.039027804655623076:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.76it/s]loss:0.2634374768330739:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.76it/s]  loss:0.2634374768330739:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:05<00:01,  2.76it/s]loss:0.4753675581886418:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:06<00:01,  2.76it/s]loss:0.4753675581886418:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.75it/s]loss:0.6792703844382031:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.75it/s]loss:0.6792703844382031:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.71it/s]loss:0.972056590596211:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.71it/s] loss:0.972056590596211: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:06<00:00,  2.71it/s]loss:0.972056590596211: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:06<00:00,  2.72it/s]
Epoch: 9 cost time: 7.416938781738281
Epoch: 9, Steps: 19 | Train Loss: 0.1278505 Vali Loss: 3.2236247 Test Loss: 28.5760441
Validation loss decreased (3.223633 --> 3.223625).  Saving model ...
Updating learning rate to 3.90625e-07
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.75it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.75it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:06,  2.75it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:01<00:06,  2.75it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.75it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.75it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.76it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.76it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:01<00:05,  2.75it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:02<00:05,  2.75it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.76it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.76it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.76it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.76it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:02<00:03,  2.76it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:03<00:03,  2.76it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.75it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.75it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:03<00:03,  2.75it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:03<00:03,  2.75it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:03<00:02,  2.75it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:04<00:02,  2.75it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.75it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.75it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:04<00:02,  2.74it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:05<00:02,  2.74it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.75it/s]loss:0.046680952574518035:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.75it/s]loss:0.046680952574518035:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.74it/s]loss:0.2560770363674563:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.74it/s]  loss:0.2560770363674563:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:05<00:01,  2.74it/s]loss:0.5091671437457426:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:06<00:01,  2.74it/s]loss:0.5091671437457426:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.73it/s]loss:0.7280992939640263:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.73it/s]loss:0.7280992939640263:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.73it/s]loss:0.8935075983916151:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.73it/s]loss:0.8935075983916151: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:06<00:00,  2.73it/s]loss:0.8935075983916151: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:06<00:00,  2.72it/s]
Epoch: 10 cost time: 7.418979167938232
Epoch: 10, Steps: 19 | Train Loss: 0.1280806 Vali Loss: 3.2236204 Test Loss: 28.5759964
Validation loss decreased (3.223625 --> 3.223620).  Saving model ...
Updating learning rate to 1.953125e-07
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.78it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.78it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:06,  2.78it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:01<00:06,  2.78it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.76it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.76it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.76it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.76it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:01<00:05,  2.76it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:02<00:05,  2.76it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.76it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.76it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.76it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.76it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:02<00:03,  2.76it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:03<00:03,  2.76it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.76it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.76it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:03<00:03,  2.76it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:03<00:03,  2.76it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:03<00:02,  2.76it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:04<00:02,  2.76it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.76it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.76it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:04<00:02,  2.75it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:05<00:02,  2.75it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.75it/s]loss:0.04245387709438882:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.75it/s]loss:0.04245387709438882:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.74it/s]loss:0.2609705462554143:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.74it/s] loss:0.2609705462554143:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:05<00:01,  2.74it/s]loss:0.4753600888123526:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:06<00:01,  2.74it/s]loss:0.4753600888123526:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.73it/s]loss:0.702484059268048:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.73it/s] loss:0.702484059268048:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.73it/s]loss:0.972040687838166:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.73it/s]loss:0.972040687838166: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:06<00:00,  2.72it/s]loss:0.972040687838166: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:06<00:00,  2.73it/s]
Epoch: 11 cost time: 7.45536470413208
Epoch: 11, Steps: 19 | Train Loss: 0.1291215 Vali Loss: 3.2236185 Test Loss: 28.5759773
Validation loss decreased (3.223620 --> 3.223619).  Saving model ...
Updating learning rate to 9.765625e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.80it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.80it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:06,  2.77it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:01<00:06,  2.77it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.75it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.75it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.76it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.76it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:01<00:05,  2.75it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:02<00:05,  2.75it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.75it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.75it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.74it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.74it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:02<00:04,  2.74it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:03<00:04,  2.74it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.74it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.74it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:03<00:03,  2.74it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:04<00:03,  2.74it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:04<00:02,  2.74it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:04<00:02,  2.74it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.74it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.74it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:04<00:02,  2.73it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:05<00:02,  2.73it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.74it/s]loss:0.04390503955966981:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.74it/s]loss:0.04390503955966981:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.74it/s]loss:0.27780320909558065:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.74it/s]loss:0.27780320909558065:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:05<00:01,  2.75it/s]loss:0.5134855340943766:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:06<00:01,  2.75it/s] loss:0.5134855340943766:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.74it/s]loss:0.7280944441416713:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.74it/s]loss:0.7280944441416713:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.75it/s]loss:0.9720381770008599:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.75it/s]loss:0.9720381770008599: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:06<00:00,  2.71it/s]loss:0.9720381770008599: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:06<00:00,  2.72it/s]
Epoch: 12 cost time: 7.45631217956543
Epoch: 12, Steps: 19 | Train Loss: 0.1334382 Vali Loss: 3.2236173 Test Loss: 28.5759583
Validation loss decreased (3.223619 --> 3.223617).  Saving model ...
Updating learning rate to 4.8828125e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.79it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.79it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:06,  2.76it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:01<00:06,  2.76it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.76it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.76it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.77it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.77it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:01<00:05,  2.77it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:02<00:05,  2.77it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.77it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.77it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.76it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.76it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:02<00:03,  2.76it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:03<00:03,  2.76it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.76it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.76it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:03<00:03,  2.77it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:03<00:03,  2.77it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:03<00:02,  2.76it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:04<00:02,  2.76it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.77it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.77it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:04<00:02,  2.76it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:05<00:02,  2.76it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.76it/s]loss:0.03902728001018449:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.76it/s]loss:0.03902728001018449:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.75it/s]loss:0.27780281440782156:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.75it/s]loss:0.27780281440782156:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:05<00:01,  2.76it/s]loss:0.4753581944194373:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:06<00:01,  2.76it/s] loss:0.4753581944194373:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.75it/s]loss:0.7399729807416711:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.75it/s]loss:0.7399729807416711:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.76it/s]loss:0.8962573283383288:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.76it/s]loss:0.8962573283383288: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:06<00:00,  2.75it/s]loss:0.8962573283383288: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:06<00:00,  2.74it/s]
Epoch: 13 cost time: 7.430950164794922
Epoch: 13, Steps: 19 | Train Loss: 0.1278115 Vali Loss: 3.2236171 Test Loss: 28.5759525
Validation loss decreased (3.223617 --> 3.223617).  Saving model ...
Updating learning rate to 2.44140625e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.79it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.79it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:06,  2.79it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:01<00:06,  2.79it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.77it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.77it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.77it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.77it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:01<00:05,  2.76it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:02<00:05,  2.76it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.76it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.76it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.76it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.76it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:02<00:03,  2.76it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:03<00:03,  2.76it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.69it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.69it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:03<00:03,  2.70it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:04<00:03,  2.70it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:04<00:02,  2.71it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:04<00:02,  2.71it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.73it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.73it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:04<00:02,  2.73it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:05<00:02,  2.73it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.74it/s]loss:0.04357309392820801:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.74it/s]loss:0.04357309392820801:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.74it/s]loss:0.27303500375994566:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.74it/s]loss:0.27303500375994566:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:05<00:01,  2.74it/s]loss:0.5134843008275777:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:06<00:01,  2.74it/s] loss:0.5134843008275777:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.73it/s]loss:0.6828621451254464:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.73it/s]loss:0.6828621451254464:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.74it/s]loss:0.9013982691057587:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.74it/s]loss:0.9013982691057587: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:06<00:00,  2.73it/s]loss:0.9013982691057587: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:06<00:00,  2.72it/s]
Epoch: 14 cost time: 7.496476411819458
Epoch: 14, Steps: 19 | Train Loss: 0.1270712 Vali Loss: 3.2236164 Test Loss: 28.5759468
Validation loss decreased (3.223617 --> 3.223616).  Saving model ...
Updating learning rate to 1.220703125e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.79it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.79it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:06,  2.77it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:01<00:06,  2.77it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.74it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.74it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.75it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.75it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:01<00:05,  2.74it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:02<00:05,  2.74it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.74it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.74it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.74it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.74it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:02<00:04,  2.74it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:03<00:04,  2.74it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.73it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.73it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:03<00:03,  2.73it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:04<00:03,  2.73it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:04<00:02,  2.73it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:04<00:02,  2.73it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.73it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.73it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:04<00:02,  2.73it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:05<00:02,  2.73it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.73it/s]loss:0.04668037511082629:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.73it/s]loss:0.04668037511082629:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.73it/s]loss:0.26342962996760005:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.73it/s]loss:0.26342962996760005:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:05<00:01,  2.74it/s]loss:0.4292998383966171:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:06<00:01,  2.74it/s] loss:0.4292998383966171:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.74it/s]loss:0.6971693545576125:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.74it/s]loss:0.6971693545576125:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.71it/s]loss:0.8846274443217822:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.71it/s]loss:0.8846274443217822: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:06<00:00,  2.71it/s]loss:0.8846274443217822: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:07<00:00,  2.71it/s]
Epoch: 15 cost time: 7.488090515136719
Epoch: 15, Steps: 19 | Train Loss: 0.1221688 Vali Loss: 3.2236164 Test Loss: 28.5759430
Validation loss decreased (3.223616 --> 3.223616).  Saving model ...
Updating learning rate to 6.103515625e-09
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.77it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.77it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:06,  2.76it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:01<00:06,  2.76it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.73it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.73it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.74it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.74it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:01<00:05,  2.73it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:02<00:05,  2.73it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.74it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.74it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.73it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.73it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:02<00:04,  2.74it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:03<00:04,  2.74it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.73it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.73it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:03<00:03,  2.74it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:04<00:03,  2.74it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:04<00:02,  2.74it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:04<00:02,  2.74it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.74it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.74it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:04<00:02,  2.73it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:05<00:02,  2.73it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.74it/s]loss:0.04245375636160132:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.74it/s]loss:0.04245375636160132:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.73it/s]loss:0.2634295971463256:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.73it/s] loss:0.2634295971463256:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:05<00:01,  2.73it/s]loss:0.4793038937268962:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:06<00:01,  2.73it/s]loss:0.4793038937268962:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.73it/s]loss:0.746885966747534:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.73it/s] loss:0.746885966747534:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.74it/s]loss:0.9720361589468554:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.74it/s]loss:0.9720361589468554: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:06<00:00,  2.73it/s]loss:0.9720361589468554: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:06<00:00,  2.72it/s]
Epoch: 16 cost time: 7.489959716796875
Epoch: 16, Steps: 19 | Train Loss: 0.1317952 Vali Loss: 3.2236164 Test Loss: 28.5759430
Validation loss decreased (3.223616 --> 3.223616).  Saving model ...
Updating learning rate to 3.0517578125e-09
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.80it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.80it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:06,  2.81it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:01<00:06,  2.81it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.79it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.79it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.78it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.78it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:01<00:05,  2.78it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:02<00:05,  2.78it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.78it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.78it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.77it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.77it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:02<00:03,  2.77it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:03<00:03,  2.77it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.76it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.76it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:03<00:03,  2.77it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:03<00:03,  2.77it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:03<00:02,  2.76it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:04<00:02,  2.76it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.76it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.76it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:04<00:02,  2.75it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:05<00:02,  2.75it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.76it/s]loss:0.046287433996928494:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.76it/s]loss:0.046287433996928494:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.75it/s]loss:0.2592861584533158:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.75it/s]  loss:0.2592861584533158:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:05<00:01,  2.74it/s]loss:0.4694674307203091:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:06<00:01,  2.74it/s]loss:0.4694674307203091:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.74it/s]loss:0.740806853083003:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.74it/s] loss:0.740806853083003:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.74it/s]loss:0.8846273550346717:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.74it/s]loss:0.8846273550346717: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:06<00:00,  2.73it/s]loss:0.8846273550346717: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:06<00:00,  2.74it/s]
Epoch: 17 cost time: 7.395139932632446
Epoch: 17, Steps: 19 | Train Loss: 0.1263408 Vali Loss: 3.2236164 Test Loss: 28.5759430
Validation loss decreased (3.223616 --> 3.223616).  Saving model ...
Updating learning rate to 1.52587890625e-09
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.80it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.80it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:06,  2.80it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:01<00:06,  2.80it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.78it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.78it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.79it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.79it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:01<00:05,  2.78it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:02<00:05,  2.78it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.77it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.77it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.76it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.76it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:02<00:03,  2.76it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:03<00:03,  2.76it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.75it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.75it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:03<00:03,  2.75it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:03<00:03,  2.75it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:03<00:02,  2.75it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:04<00:02,  2.75it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.75it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.75it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:04<00:02,  2.74it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:05<00:02,  2.74it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.75it/s]loss:0.042316156142621346:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.75it/s]loss:0.042316156142621346:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.74it/s]loss:0.23416350432023064:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.74it/s] loss:0.23416350432023064:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:05<00:01,  2.74it/s]loss:0.4829542180762446:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:06<00:01,  2.74it/s] loss:0.4829542180762446:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.74it/s]loss:0.6740017749417786:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.74it/s]loss:0.6740017749417786:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.75it/s]loss:0.99759500396475:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.75it/s]  loss:0.99759500396475: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:06<00:00,  2.74it/s]loss:0.99759500396475: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:06<00:00,  2.73it/s]
Epoch: 18 cost time: 7.430827379226685
Epoch: 18, Steps: 19 | Train Loss: 0.1279490 Vali Loss: 3.2236164 Test Loss: 28.5759449
Validation loss decreased (3.223616 --> 3.223616).  Saving model ...
Updating learning rate to 7.62939453125e-10
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.80it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.80it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:06,  2.76it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:01<00:06,  2.76it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.76it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.76it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.77it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.77it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:01<00:05,  2.76it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:02<00:05,  2.76it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.77it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.77it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.76it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.76it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:02<00:03,  2.77it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:03<00:03,  2.77it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.76it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.76it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:03<00:03,  2.77it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:03<00:03,  2.77it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:03<00:02,  2.76it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:04<00:02,  2.76it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.76it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.76it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:04<00:02,  2.76it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:05<00:02,  2.76it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.76it/s]loss:0.04628743294564143:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.76it/s]loss:0.04628743294564143:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.75it/s]loss:0.25389693405344:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.75it/s]   loss:0.25389693405344:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:05<00:01,  2.75it/s]loss:0.5087303370921266:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:06<00:01,  2.75it/s]loss:0.5087303370921266:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.74it/s]loss:0.7600723752544736:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.74it/s]loss:0.7600723752544736:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.72it/s]loss:0.9150346664112946:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.72it/s]loss:0.9150346664112946: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:06<00:00,  2.72it/s]loss:0.9150346664112946: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:06<00:00,  2.73it/s]
Epoch: 19 cost time: 7.435983180999756
Epoch: 19, Steps: 19 | Train Loss: 0.1307380 Vali Loss: 3.2236164 Test Loss: 28.5759449
Validation loss decreased (3.223616 --> 3.223616).  Saving model ...
Updating learning rate to 3.814697265625e-10
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.66it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.66it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:06,  2.72it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:01<00:06,  2.72it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.73it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.73it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.74it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.74it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:01<00:05,  2.75it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:02<00:05,  2.75it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.75it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.75it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.73it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.73it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:02<00:04,  2.75it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:03<00:04,  2.75it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.73it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.73it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:03<00:03,  2.74it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:04<00:03,  2.74it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:04<00:02,  2.73it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:04<00:02,  2.73it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.74it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.74it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:04<00:02,  2.74it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:05<00:02,  2.74it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.71it/s]loss:0.04321435845442412:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.71it/s]loss:0.04321435845442412:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.71it/s]loss:0.27772459565042024:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.71it/s]loss:0.27772459565042024:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:05<00:01,  2.72it/s]loss:0.42929975588023916:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:06<00:01,  2.72it/s]loss:0.42929975588023916:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.72it/s]loss:0.7468858943695235:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.72it/s] loss:0.7468858943695235:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.73it/s]loss:0.922003466080973:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.73it/s] loss:0.922003466080973: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:06<00:00,  2.73it/s]loss:0.922003466080973: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:07<00:00,  2.71it/s]
Epoch: 20 cost time: 7.469562292098999
Epoch: 20, Steps: 19 | Train Loss: 0.1273225 Vali Loss: 3.2236164 Test Loss: 28.5759449
Validation loss decreased (3.223616 --> 3.223616).  Saving model ...
Updating learning rate to 1.9073486328125e-10
>>>>>>>testing : long_term_forecast_break_bartlett_0_FiLM_job_demand_r2_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 4
test shape: (4, 1, 3, 121420) (4, 1, 3, 121420)
test shape: (4, 3, 121420) (4, 3, 121420)
mse:9010.7216796875, mae:6.43086576461792, dtw:-999
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           0                   Model:              FiLM                

[1mData Loader[0m
  Data:               job_demand_r2       Root Path:          ../../dataset/demand/
  Data Path:          r2.parquet          Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        .cache/checkpoints  

[1mForecasting Task[0m
  Seq Len:            6                   Label Len:          1                   
  Pred Len:           3                   Seasonal Patterns:  Monthly             
  Inverse:            1                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             121420              Dec In:             121420              
  C Out:              121420              d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           2                   d FF:               2048                
  Moving Avg:         25                  Factor:             1                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              learned             Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        32                  Itr:                1                   
  Train Epochs:       20                  Batch Size:         1                   
  Patience:           3                   Learning Rate:      0.0001              
  Des:                test                Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1                 

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_break_parzen_0_FiLM_job_demand_r2_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 19
val 1
test 4
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:16,  1.10it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:01<00:16,  1.10it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:01<00:10,  1.70it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:01<00:10,  1.70it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:07,  2.06it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:07,  2.06it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:06,  2.29it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:02<00:06,  2.29it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:02<00:05,  2.44it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:02<00:05,  2.44it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:05,  2.54it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:03<00:05,  2.54it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:03<00:04,  2.61it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:03<00:04,  2.61it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:03<00:04,  2.66it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:03<00:04,  2.66it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.68it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:04<00:03,  2.68it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:04<00:03,  2.66it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:04<00:03,  2.66it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:04<00:02,  2.68it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:04<00:02,  2.68it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.70it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:05<00:02,  2.70it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:05<00:02,  2.71it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:05<00:02,  2.71it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.72it/s]loss:0.00021103559710494572:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:06<00:01,  2.72it/s]loss:0.00021103559710494572:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:06<00:01,  2.72it/s]loss:0.04195728349546747:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:06<00:01,  2.72it/s]   loss:0.04195728349546747:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:06<00:01,  2.73it/s]loss:0.26435432384026064:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:06<00:01,  2.73it/s]loss:0.26435432384026064:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.73it/s]loss:0.6105740999460386:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:07<00:00,  2.73it/s] loss:0.6105740999460386:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:07<00:00,  2.73it/s]loss:0.9775198096445769:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:07<00:00,  2.73it/s]loss:0.9775198096445769: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:07<00:00,  2.73it/s]loss:0.9775198096445769: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:07<00:00,  2.52it/s]
Epoch: 1 cost time: 8.066182613372803
Epoch: 1, Steps: 19 | Train Loss: 0.0997167 Vali Loss: 3.2244060 Test Loss: 28.5711784
Validation loss decreased (inf --> 3.224406).  Saving model ...
Updating learning rate to 0.0001
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.78it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.78it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:06,  2.77it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:01<00:06,  2.77it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.75it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.75it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.75it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.75it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:01<00:05,  2.74it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:02<00:05,  2.74it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.75it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.75it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.74it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.74it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:02<00:04,  2.74it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:03<00:04,  2.74it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.74it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.74it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:03<00:03,  2.74it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:04<00:03,  2.74it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:04<00:02,  2.73it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:04<00:02,  2.73it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.74it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.74it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:04<00:02,  2.73it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:05<00:02,  2.73it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.74it/s]loss:0.00019520179114080493:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.74it/s]loss:0.00019520179114080493:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.73it/s]loss:0.04471947806936606:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.73it/s]   loss:0.04471947806936606:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:05<00:01,  2.74it/s]loss:0.2629697943740061:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:06<00:01,  2.74it/s] loss:0.2629697943740061:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.73it/s]loss:0.6799235865209531:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.73it/s]loss:0.6799235865209531:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.74it/s]loss:0.8218868164567561:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.74it/s]loss:0.8218868164567561: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:06<00:00,  2.73it/s]loss:0.8218868164567561: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:06<00:00,  2.72it/s]
Epoch: 2 cost time: 7.485419273376465
Epoch: 2, Steps: 19 | Train Loss: 0.0952471 Vali Loss: 3.2242007 Test Loss: 28.5769844
Validation loss decreased (3.224406 --> 3.224201).  Saving model ...
Updating learning rate to 5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.79it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.79it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:06,  2.77it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:01<00:06,  2.77it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.75it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.75it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.75it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.75it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:01<00:05,  2.75it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:02<00:05,  2.75it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.75it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.75it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.74it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.74it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:02<00:04,  2.75it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:03<00:04,  2.75it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.74it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.74it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:03<00:03,  2.72it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:04<00:03,  2.72it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:04<00:02,  2.72it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:04<00:02,  2.72it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.73it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.73it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:04<00:02,  2.73it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:05<00:02,  2.73it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.74it/s]loss:0.00017755495944402145:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.74it/s]loss:0.00017755495944402145:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.73it/s]loss:0.042747037683882806:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.73it/s]  loss:0.042747037683882806:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:05<00:01,  2.73it/s]loss:0.2799340994097276:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:06<00:01,  2.73it/s]  loss:0.2799340994097276:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.73it/s]loss:0.6767812888483961:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.73it/s]loss:0.6767812888483961:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.73it/s]loss:0.9572928308289331:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.73it/s]loss:0.9572928308289331: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:06<00:00,  2.72it/s]loss:0.9572928308289331: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:06<00:00,  2.71it/s]
Epoch: 3 cost time: 7.514368772506714
Epoch: 3, Steps: 19 | Train Loss: 0.1029965 Vali Loss: 3.2242134 Test Loss: 28.5800438
EarlyStopping counter: 1 out of 3
Updating learning rate to 2.5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.78it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.78it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:06,  2.75it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:01<00:06,  2.75it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.72it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.72it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.73it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.73it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:01<00:05,  2.72it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:02<00:05,  2.72it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.73it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.73it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.72it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.72it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:02<00:04,  2.72it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:03<00:04,  2.72it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.72it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.72it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:03<00:03,  2.72it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:04<00:03,  2.72it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:04<00:02,  2.72it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:04<00:02,  2.72it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.72it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.72it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:04<00:02,  2.72it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:05<00:02,  2.72it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.71it/s]loss:0.00021031436622619704:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.71it/s]loss:0.00021031436622619704:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.69it/s]loss:0.04308226365678641:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.69it/s]   loss:0.04308226365678641:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:05<00:01,  2.70it/s]loss:0.2627180089829584:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:06<00:01,  2.70it/s] loss:0.2627180089829584:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.69it/s]loss:0.6610154819131596:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.69it/s]loss:0.6610154819131596:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.69it/s]loss:0.9567265877028296:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:07<00:00,  2.69it/s]loss:0.9567265877028296: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:07<00:00,  2.69it/s]loss:0.9567265877028296: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:07<00:00,  2.69it/s]
Epoch: 4 cost time: 7.559769868850708
Epoch: 4, Steps: 19 | Train Loss: 0.1012501 Vali Loss: 3.2242188 Test Loss: 28.5797863
EarlyStopping counter: 2 out of 3
Updating learning rate to 1.25e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.78it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.78it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:06,  2.76it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:01<00:06,  2.76it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.76it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.76it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.76it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.76it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:01<00:05,  2.74it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:02<00:05,  2.74it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.74it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.74it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.74it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.74it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:02<00:04,  2.73it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:03<00:04,  2.73it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.73it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.73it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:03<00:03,  2.73it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:04<00:03,  2.73it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:04<00:02,  2.73it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:04<00:02,  2.73it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.73it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.73it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:04<00:02,  2.73it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:05<00:02,  2.73it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.73it/s]loss:0.00021014864076552035:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.73it/s]loss:0.00021014864076552035:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.72it/s]loss:0.04307242915008275:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.72it/s]   loss:0.04307242915008275:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:05<00:01,  2.72it/s]loss:0.25790528850128996:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:06<00:01,  2.72it/s]loss:0.25790528850128996:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.72it/s]loss:0.6591709203220905:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.72it/s] loss:0.6591709203220905:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.72it/s]loss:0.9736244655978153:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.72it/s]loss:0.9736244655978153: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:06<00:00,  2.72it/s]loss:0.9736244655978153: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:07<00:00,  2.71it/s]
Epoch: 5 cost time: 7.531180143356323
Epoch: 5, Steps: 19 | Train Loss: 0.1017886 Vali Loss: 3.2241426 Test Loss: 28.5787888
Validation loss decreased (3.224201 --> 3.224143).  Saving model ...
Updating learning rate to 6.25e-06
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.79it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.79it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:06,  2.79it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:01<00:06,  2.79it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.78it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.78it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.78it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.78it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:01<00:05,  2.77it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:02<00:05,  2.77it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.77it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.77it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.77it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.77it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:02<00:03,  2.77it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:03<00:03,  2.77it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.75it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.75it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:03<00:03,  2.76it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:03<00:03,  2.76it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:03<00:02,  2.76it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:04<00:02,  2.76it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.76it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.76it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:04<00:02,  2.75it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:05<00:02,  2.75it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.76it/s]loss:0.0001926271763539271:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.76it/s]loss:0.0001926271763539271:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.75it/s]loss:0.04235033142651197:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.75it/s]  loss:0.04235033142651197:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:05<00:01,  2.75it/s]loss:0.27969776077319836:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:06<00:01,  2.75it/s]loss:0.27969776077319836:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.74it/s]loss:0.6839293418911845:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.74it/s] loss:0.6839293418911845:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.74it/s]loss:0.9563509666251294:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.74it/s]loss:0.9563509666251294: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:06<00:00,  2.74it/s]loss:0.9563509666251294: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:06<00:00,  2.73it/s]
Epoch: 6 cost time: 7.449892044067383
Epoch: 6, Steps: 19 | Train Loss: 0.1032906 Vali Loss: 3.2240806 Test Loss: 28.5780487
Validation loss decreased (3.224143 --> 3.224081).  Saving model ...
Updating learning rate to 3.125e-06
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.80it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.80it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:06,  2.81it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:01<00:06,  2.81it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.80it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.80it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.80it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.80it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:01<00:05,  2.80it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:02<00:05,  2.80it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.80it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.80it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.79it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.79it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:02<00:03,  2.78it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:03<00:03,  2.78it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.70it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.70it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:03<00:03,  2.71it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:03<00:03,  2.71it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:03<00:02,  2.71it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:04<00:02,  2.71it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.72it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.72it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:04<00:02,  2.73it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:05<00:02,  2.73it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.73it/s]loss:0.0001971086634215009:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.73it/s]loss:0.0001971086634215009:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.73it/s]loss:0.04128866152771117:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.73it/s]  loss:0.04128866152771117:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:05<00:01,  2.73it/s]loss:0.26084896614773867:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:06<00:01,  2.73it/s]loss:0.26084896614773867:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.72it/s]loss:0.7084632382614751:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.72it/s] loss:0.7084632382614751:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.72it/s]loss:0.9154039287860648:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.72it/s]loss:0.9154039287860648: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:06<00:00,  2.72it/s]loss:0.9154039287860648: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:06<00:00,  2.72it/s]
Epoch: 7 cost time: 7.531743764877319
Epoch: 7, Steps: 19 | Train Loss: 0.1013790 Vali Loss: 3.2240353 Test Loss: 28.5779667
Validation loss decreased (3.224081 --> 3.224035).  Saving model ...
Updating learning rate to 1.5625e-06
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.79it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.79it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:06,  2.76it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:01<00:06,  2.76it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.75it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.75it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.74it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.74it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:01<00:05,  2.74it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:02<00:05,  2.74it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.75it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.75it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.75it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.75it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:02<00:03,  2.76it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:03<00:03,  2.76it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.76it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.76it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:03<00:03,  2.76it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:03<00:03,  2.76it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:03<00:02,  2.76it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:04<00:02,  2.76it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.76it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.76it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:04<00:02,  2.74it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:05<00:02,  2.74it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.75it/s]loss:0.00019376325010728252:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.75it/s]loss:0.00019376325010728252:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.74it/s]loss:0.046564721624172155:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.74it/s]  loss:0.046564721624172155:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:05<00:01,  2.73it/s]loss:0.23609072397658434:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:06<00:01,  2.73it/s] loss:0.23609072397658434:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.71it/s]loss:0.6557290708573285:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.71it/s] loss:0.6557290708573285:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.71it/s]loss:0.9727092095868558:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.71it/s]loss:0.9727092095868558: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:06<00:00,  2.71it/s]loss:0.9727092095868558: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:06<00:00,  2.72it/s]
Epoch: 8 cost time: 7.522388219833374
Epoch: 8, Steps: 19 | Train Loss: 0.1005941 Vali Loss: 3.2240274 Test Loss: 28.5780296
Validation loss decreased (3.224035 --> 3.224027).  Saving model ...
Updating learning rate to 7.8125e-07
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.81it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.81it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:06,  2.81it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:01<00:06,  2.81it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.77it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.77it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.77it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.77it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:01<00:05,  2.76it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:02<00:05,  2.76it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.76it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.76it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.76it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.76it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:02<00:03,  2.75it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:03<00:03,  2.75it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.75it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.75it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:03<00:03,  2.75it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:03<00:03,  2.75it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:03<00:02,  2.74it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:04<00:02,  2.74it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.74it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.74it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:04<00:02,  2.75it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:05<00:02,  2.75it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.75it/s]loss:0.0001770698722907624:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.75it/s]loss:0.0001770698722907624:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.74it/s]loss:0.043054430025937895:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.74it/s] loss:0.043054430025937895:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:05<00:01,  2.75it/s]loss:0.2608377384300087:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:06<00:01,  2.75it/s]  loss:0.2608377384300087:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.73it/s]loss:0.6607625451964869:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.73it/s]loss:0.6607625451964869:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.74it/s]loss:0.9726923405341151:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.74it/s]loss:0.9726923405341151: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:06<00:00,  2.72it/s]loss:0.9726923405341151: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:06<00:00,  2.72it/s]
Epoch: 9 cost time: 7.5017335414886475
Epoch: 9, Steps: 19 | Train Loss: 0.1019750 Vali Loss: 3.2240207 Test Loss: 28.5780144
Validation loss decreased (3.224027 --> 3.224021).  Saving model ...
Updating learning rate to 3.90625e-07
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.78it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.78it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:06,  2.73it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:01<00:06,  2.73it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.73it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.73it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.74it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.74it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:01<00:05,  2.73it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:02<00:05,  2.73it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.72it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.72it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.72it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.72it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:02<00:04,  2.73it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:03<00:04,  2.73it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.71it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.71it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:03<00:03,  2.71it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:04<00:03,  2.71it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:04<00:02,  2.71it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:04<00:02,  2.71it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.72it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.72it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:04<00:02,  2.71it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:05<00:02,  2.71it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.72it/s]loss:0.000211891754960999:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.72it/s]loss:0.000211891754960999:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.69it/s]loss:0.041851808475147766:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.69it/s]loss:0.041851808475147766:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:05<00:01,  2.71it/s]loss:0.2794847672309099:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:06<00:01,  2.71it/s]  loss:0.2794847672309099:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.71it/s]loss:0.7084203724949903:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.71it/s]loss:0.7084203724949903:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.72it/s]loss:0.8945567357396799:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.72it/s]loss:0.8945567357396799: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:06<00:00,  2.72it/s]loss:0.8945567357396799: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:07<00:00,  2.70it/s]
Epoch: 10 cost time: 7.552714586257935
Epoch: 10, Steps: 19 | Train Loss: 0.1012908 Vali Loss: 3.2240171 Test Loss: 28.5779686
Validation loss decreased (3.224021 --> 3.224017).  Saving model ...
Updating learning rate to 1.953125e-07
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.77it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.77it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:06,  2.76it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:01<00:06,  2.76it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.73it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.73it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.72it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.72it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:01<00:05,  2.72it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:02<00:05,  2.72it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.72it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.72it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.72it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.72it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:02<00:04,  2.73it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:03<00:04,  2.73it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.72it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.72it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:03<00:03,  2.73it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:04<00:03,  2.73it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:04<00:02,  2.72it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:04<00:02,  2.72it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.73it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.73it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:04<00:02,  2.73it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:05<00:02,  2.73it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.73it/s]loss:0.0001926119608979502:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.73it/s]loss:0.0001926119608979502:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.72it/s]loss:0.042632647631981595:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.72it/s] loss:0.042632647631981595:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:05<00:01,  2.72it/s]loss:0.2608345624650367:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:06<00:01,  2.72it/s]  loss:0.2608345624650367:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.72it/s]loss:0.6837769237730877:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.72it/s]loss:0.6837769237730877:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.72it/s]loss:0.9726781882717283:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.72it/s]loss:0.9726781882717283: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:06<00:00,  2.71it/s]loss:0.9726781882717283: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:07<00:00,  2.70it/s]
Epoch: 11 cost time: 7.5272057056427
Epoch: 11, Steps: 19 | Train Loss: 0.1031639 Vali Loss: 3.2240157 Test Loss: 28.5779552
Validation loss decreased (3.224017 --> 3.224016).  Saving model ...
Updating learning rate to 9.765625e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.68it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.68it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:06,  2.75it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:01<00:06,  2.75it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.73it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.73it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.75it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.75it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:01<00:05,  2.70it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:02<00:05,  2.70it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.71it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.71it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.72it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.72it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:02<00:04,  2.73it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:03<00:04,  2.73it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.73it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.73it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:03<00:03,  2.74it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:04<00:03,  2.74it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:04<00:02,  2.73it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:04<00:02,  2.73it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.74it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.74it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:04<00:02,  2.72it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:05<00:02,  2.72it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.73it/s]loss:0.00019932184389977599:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.73it/s]loss:0.00019932184389977599:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.72it/s]loss:0.04540088039206864:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.72it/s]   loss:0.04540088039206864:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:05<00:01,  2.72it/s]loss:0.28191971991955783:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:06<00:01,  2.72it/s]loss:0.28191971991955783:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.72it/s]loss:0.7084160635814998:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.72it/s] loss:0.7084160635814998:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.73it/s]loss:0.9726758651189726:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.73it/s]loss:0.9726758651189726: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:06<00:00,  2.72it/s]loss:0.9726758651189726: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:07<00:00,  2.70it/s]
Epoch: 12 cost time: 7.517037391662598
Epoch: 12, Steps: 19 | Train Loss: 0.1057164 Vali Loss: 3.2240138 Test Loss: 28.5779438
Validation loss decreased (3.224016 --> 3.224014).  Saving model ...
Updating learning rate to 4.8828125e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.68it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.68it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:06,  2.73it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:01<00:06,  2.73it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.75it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.75it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.76it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.76it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:01<00:05,  2.76it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:02<00:05,  2.76it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.77it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.77it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.76it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.76it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:02<00:03,  2.75it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:03<00:03,  2.75it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.75it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.75it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:03<00:03,  2.75it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:04<00:03,  2.75it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:04<00:02,  2.74it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:04<00:02,  2.74it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.75it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.75it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:04<00:02,  2.74it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:05<00:02,  2.74it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.75it/s]loss:0.00017706779090815333:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.75it/s]loss:0.00017706779090815333:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.74it/s]loss:0.045400841766605055:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.74it/s]  loss:0.045400841766605055:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:05<00:01,  2.74it/s]loss:0.26083361810734934:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:06<00:01,  2.74it/s] loss:0.26083361810734934:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.74it/s]loss:0.7205116438881439:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.74it/s] loss:0.7205116438881439:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.74it/s]loss:0.897187968977568:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.74it/s] loss:0.897187968977568: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:06<00:00,  2.73it/s]loss:0.897187968977568: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:06<00:00,  2.72it/s]
Epoch: 13 cost time: 7.474698543548584
Epoch: 13, Steps: 19 | Train Loss: 0.1012690 Vali Loss: 3.2240138 Test Loss: 28.5779343
Validation loss decreased (3.224014 --> 3.224014).  Saving model ...
Updating learning rate to 2.44140625e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.80it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.80it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:06,  2.79it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:01<00:06,  2.79it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.78it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.78it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.77it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.77it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:01<00:05,  2.76it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:02<00:05,  2.76it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.76it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.76it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.75it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.75it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:02<00:03,  2.75it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:03<00:03,  2.75it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.75it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.75it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:03<00:03,  2.75it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:03<00:03,  2.75it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:03<00:02,  2.75it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:04<00:02,  2.75it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.75it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.75it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:04<00:02,  2.75it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:05<00:02,  2.75it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.75it/s]loss:0.0001976786352842744:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.75it/s]loss:0.0001976786352842744:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.74it/s]loss:0.04460506357427957:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.74it/s]  loss:0.04460506357427957:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:05<00:01,  2.75it/s]loss:0.2819191860732726:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:06<00:01,  2.75it/s] loss:0.2819191860732726:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.74it/s]loss:0.6646799832897148:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.74it/s]loss:0.6646799832897148:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.74it/s]loss:0.9018281158683887:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.74it/s]loss:0.9018281158683887: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:06<00:00,  2.74it/s]loss:0.9018281158683887: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:06<00:00,  2.73it/s]
Epoch: 14 cost time: 7.4668426513671875
Epoch: 14, Steps: 19 | Train Loss: 0.0996437 Vali Loss: 3.2240138 Test Loss: 28.5779305
Validation loss decreased (3.224014 --> 3.224014).  Saving model ...
Updating learning rate to 1.220703125e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.80it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.80it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:06,  2.77it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:01<00:06,  2.77it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.76it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.76it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.76it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.76it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:01<00:05,  2.75it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:02<00:05,  2.75it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.75it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.75it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.75it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.75it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:02<00:04,  2.74it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:03<00:04,  2.74it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.74it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.74it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:03<00:03,  2.74it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:04<00:03,  2.74it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:04<00:02,  2.73it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:04<00:02,  2.73it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.73it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.73it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:04<00:02,  2.73it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:05<00:02,  2.73it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.73it/s]loss:0.00021188959158427122:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.73it/s]loss:0.00021188959158427122:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.72it/s]loss:0.04305343686920294:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.72it/s]   loss:0.04305343686920294:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:05<00:01,  2.72it/s]loss:0.23558857229861682:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:06<00:01,  2.72it/s]loss:0.23558857229861682:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.71it/s]loss:0.6781364372208424:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.71it/s] loss:0.6781364372208424:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.72it/s]loss:0.8850859747374432:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.72it/s]loss:0.8850859747374432: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:06<00:00,  2.72it/s]loss:0.8850859747374432: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:07<00:00,  2.71it/s]
Epoch: 15 cost time: 7.51328706741333
Epoch: 15, Steps: 19 | Train Loss: 0.0969514 Vali Loss: 3.2240133 Test Loss: 28.5779266
Validation loss decreased (3.224014 --> 3.224013).  Saving model ...
Updating learning rate to 6.103515625e-09
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.80it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.80it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:06,  2.80it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:01<00:06,  2.80it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.79it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.79it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.79it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.79it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:01<00:05,  2.77it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:02<00:05,  2.77it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.76it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.76it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.73it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.73it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:02<00:04,  2.74it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:03<00:04,  2.74it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.73it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.73it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:03<00:03,  2.74it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:04<00:03,  2.74it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:04<00:02,  2.73it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:04<00:02,  2.73it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.73it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.73it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:04<00:02,  2.72it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:05<00:02,  2.72it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.73it/s]loss:0.00019261147580761255:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.73it/s]loss:0.00019261147580761255:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.72it/s]loss:0.04305343368175591:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.72it/s]   loss:0.04305343368175591:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:05<00:01,  2.72it/s]loss:0.26301135607250964:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:06<00:01,  2.72it/s]loss:0.26301135607250964:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.70it/s]loss:0.7268872126978142:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.70it/s] loss:0.7268872126978142:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.71it/s]loss:0.9726740861284012:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.71it/s]loss:0.9726740861284012: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:06<00:00,  2.71it/s]loss:0.9726740861284012: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:07<00:00,  2.71it/s]
Epoch: 16 cost time: 7.560124158859253
Epoch: 16, Steps: 19 | Train Loss: 0.1055694 Vali Loss: 3.2240133 Test Loss: 28.5779266
Validation loss decreased (3.224013 --> 3.224013).  Saving model ...
Updating learning rate to 3.0517578125e-09
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.77it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.77it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:06,  2.76it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:01<00:06,  2.76it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.75it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.75it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.75it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.75it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:01<00:05,  2.75it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:02<00:05,  2.75it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.75it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.75it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.73it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.73it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:02<00:04,  2.73it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:03<00:04,  2.73it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.73it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.73it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:03<00:03,  2.73it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:04<00:03,  2.73it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:04<00:02,  2.72it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:04<00:02,  2.72it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.73it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.73it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:04<00:02,  2.72it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:05<00:02,  2.72it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.73it/s]loss:0.00021005810136226464:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.73it/s]loss:0.00021005810136226464:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.72it/s]loss:0.04234501000663678:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.72it/s]   loss:0.04234501000663678:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:05<00:01,  2.73it/s]loss:0.25779222083224357:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:06<00:01,  2.73it/s]loss:0.25779222083224357:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.72it/s]loss:0.7210531019125767:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.72it/s] loss:0.7210531019125767:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.73it/s]loss:0.8850859035186951:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.73it/s]loss:0.8850859035186951: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:06<00:00,  2.72it/s]loss:0.8850859035186951: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:07<00:00,  2.71it/s]
Epoch: 17 cost time: 7.538455009460449
Epoch: 17, Steps: 19 | Train Loss: 0.1003414 Vali Loss: 3.2240133 Test Loss: 28.5779266
Validation loss decreased (3.224013 --> 3.224013).  Saving model ...
Updating learning rate to 1.52587890625e-09
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.76it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.76it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:06,  2.76it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:01<00:06,  2.76it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.75it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.75it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.76it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.76it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:01<00:05,  2.75it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:02<00:05,  2.75it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.75it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.75it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.74it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.74it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:02<00:04,  2.74it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:03<00:04,  2.74it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.74it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.74it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:03<00:03,  2.74it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:04<00:03,  2.74it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:04<00:02,  2.74it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:04<00:02,  2.74it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.74it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.74it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:04<00:02,  2.74it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:05<00:02,  2.74it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.69it/s]loss:0.00019207286077477465:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.69it/s]loss:0.00019207286077477465:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.69it/s]loss:0.03824661677935732:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.69it/s]   loss:0.03824661677935732:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:05<00:01,  2.70it/s]loss:0.26519717572952134:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:06<00:01,  2.70it/s]loss:0.26519717572952134:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.70it/s]loss:0.6557147409628109:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.70it/s] loss:0.6557147409628109:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.71it/s]loss:0.9982023269272469:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.71it/s]loss:0.9982023269272469: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:06<00:00,  2.71it/s]loss:0.9982023269272469: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:07<00:00,  2.71it/s]
Epoch: 18 cost time: 7.545201063156128
Epoch: 18, Steps: 19 | Train Loss: 0.1030291 Vali Loss: 3.2240133 Test Loss: 28.5779266
Validation loss decreased (3.224013 --> 3.224013).  Saving model ...
Updating learning rate to 7.62939453125e-10
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.77it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.77it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:06,  2.55it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:01<00:06,  2.55it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:06,  2.62it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:06,  2.62it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.68it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.68it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:01<00:05,  2.70it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:02<00:05,  2.70it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.72it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.72it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.73it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.73it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:02<00:04,  2.74it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:03<00:04,  2.74it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.74it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.74it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:03<00:03,  2.74it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:04<00:03,  2.74it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:04<00:02,  2.73it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:04<00:02,  2.73it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.74it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.74it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:04<00:02,  2.73it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:05<00:02,  2.73it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.73it/s]loss:0.00021005809803403803:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.73it/s]loss:0.00021005809803403803:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.73it/s]loss:0.04148773777486481:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.73it/s]   loss:0.04148773777486481:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:05<00:01,  2.73it/s]loss:0.2794458047904006:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:06<00:01,  2.73it/s] loss:0.2794458047904006:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.73it/s]loss:0.7395169095497814:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.73it/s]loss:0.7395169095497814:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.74it/s]loss:0.9153506480205679:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.74it/s]loss:0.9153506480205679: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:06<00:00,  2.74it/s]loss:0.9153506480205679: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:07<00:00,  2.70it/s]
Epoch: 19 cost time: 7.581664323806763
Epoch: 19, Steps: 19 | Train Loss: 0.1040006 Vali Loss: 3.2240133 Test Loss: 28.5779266
Validation loss decreased (3.224013 --> 3.224013).  Saving model ...
Updating learning rate to 3.814697265625e-10
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.79it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.79it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:06,  2.78it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:01<00:06,  2.78it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.76it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.76it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.76it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.76it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:01<00:05,  2.75it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:02<00:05,  2.75it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.75it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.75it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.74it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.74it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:02<00:04,  2.74it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:03<00:04,  2.74it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.74it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.74it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:03<00:03,  2.74it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:04<00:03,  2.74it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:04<00:02,  2.73it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:04<00:02,  2.73it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.74it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.74it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:04<00:02,  2.73it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:05<00:02,  2.73it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.73it/s]loss:0.0001960417103984978:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.73it/s]loss:0.0001960417103984978:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.72it/s]loss:0.045372548938040484:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.72it/s] loss:0.045372548938040484:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:05<00:01,  2.72it/s]loss:0.23558853443609737:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:06<00:01,  2.72it/s] loss:0.23558853443609737:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.71it/s]loss:0.7268871476826632:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.71it/s] loss:0.7268871476826632:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.72it/s]loss:0.9229578943181981:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.72it/s]loss:0.9229578943181981: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:06<00:00,  2.72it/s]loss:0.9229578943181981: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:07<00:00,  2.71it/s]
Epoch: 20 cost time: 7.508943796157837
Epoch: 20, Steps: 19 | Train Loss: 0.1016317 Vali Loss: 3.2240133 Test Loss: 28.5779266
Validation loss decreased (3.224013 --> 3.224013).  Saving model ...
Updating learning rate to 1.9073486328125e-10
>>>>>>>testing : long_term_forecast_break_parzen_0_FiLM_job_demand_r2_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 4
test shape: (4, 1, 3, 121420) (4, 1, 3, 121420)
test shape: (4, 3, 121420) (4, 3, 121420)
mse:9023.09375, mae:6.43392276763916, dtw:-999
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           0                   Model:              FiLM                

[1mData Loader[0m
  Data:               job_demand_r2       Root Path:          ../../dataset/demand/
  Data Path:          r2.parquet          Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        .cache/checkpoints  

[1mForecasting Task[0m
  Seq Len:            6                   Label Len:          1                   
  Pred Len:           3                   Seasonal Patterns:  Monthly             
  Inverse:            1                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             121420              Dec In:             121420              
  C Out:              121420              d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           2                   d FF:               2048                
  Moving Avg:         25                  Factor:             1                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              learned             Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        32                  Itr:                1                   
  Train Epochs:       20                  Batch Size:         1                   
  Patience:           3                   Learning Rate:      0.0001              
  Des:                test                Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1                 

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_break_tukey-hanning_0_FiLM_job_demand_r2_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 19
val 1
test 4
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:16,  1.09it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:01<00:16,  1.09it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:01<00:10,  1.66it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:01<00:10,  1.66it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:07,  2.02it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:02<00:07,  2.02it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:02<00:06,  2.26it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:02<00:06,  2.26it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:02<00:05,  2.42it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:02<00:05,  2.42it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:05,  2.53it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:03<00:05,  2.53it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:03<00:04,  2.59it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:03<00:04,  2.59it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:03<00:04,  2.64it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:03<00:04,  2.64it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.67it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:04<00:03,  2.67it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:04<00:03,  2.70it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:04<00:03,  2.70it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:04<00:02,  2.72it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:04<00:02,  2.72it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.73it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:05<00:02,  2.73it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:05<00:02,  2.73it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:05<00:02,  2.73it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.74it/s]loss:0.005457260162687902:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:06<00:01,  2.74it/s]loss:0.005457260162687902:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:06<00:01,  2.73it/s]loss:0.16932507951656872:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:06<00:01,  2.73it/s] loss:0.16932507951656872:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:06<00:01,  2.74it/s]loss:0.4943925822129261:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:06<00:01,  2.74it/s] loss:0.4943925822129261:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.74it/s]loss:0.7141446562209037:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:07<00:00,  2.74it/s]loss:0.7141446562209037:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:07<00:00,  2.74it/s]loss:0.9773651715712087:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:07<00:00,  2.74it/s]loss:0.9773651715712087: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:07<00:00,  2.73it/s]loss:0.9773651715712087: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:07<00:00,  2.51it/s]
Epoch: 1 cost time: 8.086038827896118
Epoch: 1, Steps: 19 | Train Loss: 0.1242466 Vali Loss: 3.2243445 Test Loss: 28.5709305
Validation loss decreased (inf --> 3.224344).  Saving model ...
Updating learning rate to 0.0001
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.75it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.75it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:06,  2.75it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:01<00:06,  2.75it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.73it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.73it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.73it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.73it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:01<00:05,  2.72it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:02<00:05,  2.72it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.72it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.72it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.72it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.72it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:02<00:04,  2.72it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:03<00:04,  2.72it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.72it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.72it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:03<00:03,  2.73it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:04<00:03,  2.73it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:04<00:02,  2.73it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:04<00:02,  2.73it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.69it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.69it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:04<00:02,  2.69it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:05<00:02,  2.69it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.70it/s]loss:0.005047096427428831:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.70it/s]loss:0.005047096427428831:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.70it/s]loss:0.1804473109562718:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.70it/s]  loss:0.1804473109562718:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:05<00:01,  2.71it/s]loss:0.4917260421559413:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:06<00:01,  2.71it/s]loss:0.4917260421559413:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.71it/s]loss:0.7951419023866735:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.71it/s]loss:0.7951419023866735:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.72it/s]loss:0.8217387405737726:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.72it/s]loss:0.8217387405737726: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:06<00:00,  2.72it/s]loss:0.8217387405737726: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:07<00:00,  2.69it/s]
Epoch: 2 cost time: 7.594944953918457
Epoch: 2, Steps: 19 | Train Loss: 0.1207422 Vali Loss: 3.2240953 Test Loss: 28.5772438
Validation loss decreased (3.224344 --> 3.224095).  Saving model ...
Updating learning rate to 5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.78it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.78it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:06,  2.74it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:01<00:06,  2.74it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.73it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.73it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.73it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.73it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:01<00:05,  2.73it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:02<00:05,  2.73it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.75it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.75it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.74it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.74it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:02<00:04,  2.74it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:03<00:04,  2.74it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.74it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.74it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:03<00:03,  2.74it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:04<00:03,  2.74it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:04<00:02,  2.73it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:04<00:02,  2.73it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.73it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.73it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:04<00:02,  2.72it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:05<00:02,  2.72it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.73it/s]loss:0.004590906129153775:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.73it/s]loss:0.004590906129153775:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.73it/s]loss:0.1724815309669311:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.73it/s]  loss:0.1724815309669311:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:05<00:01,  2.74it/s]loss:0.5232972365856469:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:06<00:01,  2.74it/s]loss:0.5232972365856469:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.74it/s]loss:0.7914917976344358:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.74it/s]loss:0.7914917976344358:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.75it/s]loss:0.9569810709148017:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.75it/s]loss:0.9569810709148017: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:06<00:00,  2.74it/s]loss:0.9569810709148017: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:06<00:00,  2.72it/s]
Epoch: 3 cost time: 7.481145620346069
Epoch: 3, Steps: 19 | Train Loss: 0.1288864 Vali Loss: 3.2240887 Test Loss: 28.5799294
Validation loss decreased (3.224095 --> 3.224089).  Saving model ...
Updating learning rate to 2.5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.77it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.77it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:06,  2.77it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:01<00:06,  2.77it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.75it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.75it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.76it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.76it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:01<00:05,  2.75it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:02<00:05,  2.75it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.75it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.75it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.73it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.73it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:02<00:04,  2.74it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:03<00:04,  2.74it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.73it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.73it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:03<00:03,  2.74it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:04<00:03,  2.74it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:04<00:02,  2.73it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:04<00:02,  2.73it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.74it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.74it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:04<00:02,  2.73it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:05<00:02,  2.73it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.73it/s]loss:0.005435503214560539:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.73it/s]loss:0.005435503214560539:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.73it/s]loss:0.17380761138553907:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.73it/s] loss:0.17380761138553907:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:05<00:01,  2.73it/s]loss:0.49116207012641655:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:06<00:01,  2.73it/s]loss:0.49116207012641655:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.73it/s]loss:0.7729908476176521:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.73it/s] loss:0.7729908476176521:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.73it/s]loss:0.9563900082910858:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.73it/s]loss:0.9563900082910858: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:06<00:00,  2.73it/s]loss:0.9563900082910858: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:07<00:00,  2.71it/s]
Epoch: 4 cost time: 7.519656181335449
Epoch: 4, Steps: 19 | Train Loss: 0.1263045 Vali Loss: 3.2240641 Test Loss: 28.5796089
Validation loss decreased (3.224089 --> 3.224064).  Saving model ...
Updating learning rate to 1.25e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.81it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.81it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:06,  2.79it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:01<00:06,  2.79it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.76it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.76it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.76it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.76it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:01<00:05,  2.75it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:02<00:05,  2.75it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.75it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.75it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.74it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.74it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:02<00:04,  2.74it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:03<00:04,  2.74it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.74it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.74it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:03<00:03,  2.74it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:04<00:03,  2.74it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:04<00:02,  2.73it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:04<00:02,  2.73it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.73it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.73it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:04<00:02,  2.73it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:05<00:02,  2.73it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.73it/s]loss:0.005430621303276296:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.73it/s]loss:0.005430621303276296:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.73it/s]loss:0.17374368955567437:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.73it/s] loss:0.17374368955567437:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:05<00:01,  2.73it/s]loss:0.48203472246458745:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:06<00:01,  2.73it/s]loss:0.48203472246458745:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.72it/s]loss:0.7706064561901186:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.72it/s] loss:0.7706064561901186:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.73it/s]loss:0.9730043637942332:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.73it/s]loss:0.9730043637942332: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:06<00:00,  2.72it/s]loss:0.9730043637942332: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:06<00:00,  2.72it/s]
Epoch: 5 cost time: 7.567800760269165
Epoch: 5, Steps: 19 | Train Loss: 0.1265695 Vali Loss: 3.2239523 Test Loss: 28.5782890
Validation loss decreased (3.224064 --> 3.223952).  Saving model ...
Updating learning rate to 6.25e-06
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.78it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.78it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:06,  2.77it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:01<00:06,  2.77it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.76it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.76it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.75it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.75it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:01<00:05,  2.75it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:02<00:05,  2.75it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.75it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.75it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.74it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.74it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:02<00:04,  2.70it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:03<00:04,  2.70it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.69it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.69it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:03<00:03,  2.70it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:04<00:03,  2.70it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:04<00:02,  2.71it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:04<00:02,  2.71it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.71it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.71it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:04<00:02,  2.71it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:05<00:02,  2.71it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.71it/s]loss:0.004980051138985144:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.71it/s]loss:0.004980051138985144:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.71it/s]loss:0.17089487288690736:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.71it/s] loss:0.17089487288690736:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:05<00:01,  2.71it/s]loss:0.522749175688218:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:06<00:01,  2.71it/s]  loss:0.522749175688218:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.70it/s]loss:0.7995011706059499:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.70it/s]loss:0.7995011706059499:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.71it/s]loss:0.9560033324186651:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.71it/s]loss:0.9560033324186651: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:06<00:00,  2.71it/s]loss:0.9560033324186651: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:07<00:00,  2.70it/s]
Epoch: 6 cost time: 7.598385810852051
Epoch: 6, Steps: 19 | Train Loss: 0.1291647 Vali Loss: 3.2238755 Test Loss: 28.5774002
Validation loss decreased (3.223952 --> 3.223876).  Saving model ...
Updating learning rate to 3.125e-06
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.79it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.79it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:06,  2.78it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:01<00:06,  2.78it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.77it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.77it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.78it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.78it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:01<00:05,  2.76it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:02<00:05,  2.76it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.76it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.76it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.76it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.76it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:02<00:03,  2.76it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:03<00:03,  2.76it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.74it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.74it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:03<00:03,  2.74it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:03<00:03,  2.74it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:03<00:02,  2.74it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:04<00:02,  2.74it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.74it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.74it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:04<00:02,  2.74it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:05<00:02,  2.74it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.74it/s]loss:0.005096730583442637:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.74it/s]loss:0.005096730583442637:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.74it/s]loss:0.1665796340851669:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.74it/s]  loss:0.1665796340851669:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:05<00:01,  2.74it/s]loss:0.48777371304256334:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:06<00:01,  2.74it/s]loss:0.48777371304256334:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.73it/s]loss:0.8283439847016453:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.73it/s] loss:0.8283439847016453:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.72it/s]loss:0.9151890966413474:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.72it/s]loss:0.9151890966413474: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:06<00:00,  2.72it/s]loss:0.9151890966413474: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:06<00:00,  2.72it/s]
Epoch: 7 cost time: 7.515654563903809
Epoch: 7, Steps: 19 | Train Loss: 0.1264728 Vali Loss: 3.2238247 Test Loss: 28.5773430
Validation loss decreased (3.223876 --> 3.223825).  Saving model ...
Updating learning rate to 1.5625e-06
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.75it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.75it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:06,  2.74it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:01<00:06,  2.74it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.74it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.74it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.75it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.75it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:01<00:05,  2.75it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:02<00:05,  2.75it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.76it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.76it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.75it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.75it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:02<00:03,  2.76it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:03<00:03,  2.76it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.76it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.76it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:03<00:03,  2.76it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:03<00:03,  2.76it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:03<00:02,  2.76it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:04<00:02,  2.76it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.76it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.76it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:04<00:02,  2.75it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:05<00:02,  2.75it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.76it/s]loss:0.0050073715555883575:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.76it/s]loss:0.0050073715555883575:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.75it/s]loss:0.18785049521858366:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.75it/s]  loss:0.18785049521858366:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:05<00:01,  2.75it/s]loss:0.44145818040412527:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:06<00:01,  2.75it/s]loss:0.44145818040412527:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.75it/s]loss:0.7667310553205763:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.75it/s] loss:0.7667310553205763:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.75it/s]loss:0.9723215681947587:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.75it/s]loss:0.9723215681947587: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:06<00:00,  2.75it/s]loss:0.9723215681947587: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:06<00:00,  2.73it/s]
Epoch: 8 cost time: 7.533700942993164
Epoch: 8, Steps: 19 | Train Loss: 0.1249141 Vali Loss: 3.2238138 Test Loss: 28.5774231
Validation loss decreased (3.223825 --> 3.223814).  Saving model ...
Updating learning rate to 7.8125e-07
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.76it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.76it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:06,  2.78it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:01<00:06,  2.78it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.77it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.77it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.77it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.77it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:01<00:05,  2.69it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:02<00:05,  2.69it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.72it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.72it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.73it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.73it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:02<00:04,  2.74it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:03<00:04,  2.74it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.74it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.74it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:03<00:03,  2.75it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:04<00:03,  2.75it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:04<00:02,  2.75it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:04<00:02,  2.75it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.75it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.75it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:04<00:02,  2.75it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:05<00:02,  2.75it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.75it/s]loss:0.004577911771739934:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.75it/s]loss:0.004577911771739934:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.75it/s]loss:0.17365393854152364:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.75it/s] loss:0.17365393854152364:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:05<00:01,  2.76it/s]loss:0.48774759183344546:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:06<00:01,  2.76it/s]loss:0.48774759183344546:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.75it/s]loss:0.7726646632780062:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.75it/s] loss:0.7726646632780062:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.76it/s]loss:0.9723044562019746:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.76it/s]loss:0.9723044562019746: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:06<00:00,  2.75it/s]loss:0.9723044562019746: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:06<00:00,  2.73it/s]
Epoch: 9 cost time: 7.481781244277954
Epoch: 9, Steps: 19 | Train Loss: 0.1268920 Vali Loss: 3.2238059 Test Loss: 28.5774155
Validation loss decreased (3.223814 --> 3.223806).  Saving model ...
Updating learning rate to 3.90625e-07
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.78it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.78it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:06,  2.75it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:01<00:06,  2.75it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.76it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.76it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.77it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.77it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:01<00:05,  2.76it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:02<00:05,  2.76it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.76it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.76it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.76it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.76it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:02<00:03,  2.76it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:03<00:03,  2.76it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.75it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.75it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:03<00:03,  2.76it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:03<00:03,  2.76it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:03<00:02,  2.75it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:04<00:02,  2.75it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.76it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.76it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:04<00:02,  2.75it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:05<00:02,  2.75it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.76it/s]loss:0.005476195065830859:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.76it/s]loss:0.005476195065830859:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.76it/s]loss:0.16879290752164514:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.76it/s] loss:0.16879290752164514:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:05<00:01,  2.76it/s]loss:0.5224771087869875:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:06<00:01,  2.76it/s] loss:0.5224771087869875:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.75it/s]loss:0.8282912573580931:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.75it/s]loss:0.8282912573580931:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.76it/s]loss:0.8938664251934199:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.76it/s]loss:0.8938664251934199: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:06<00:00,  2.75it/s]loss:0.8938664251934199: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:06<00:00,  2.74it/s]
Epoch: 10 cost time: 7.504440784454346
Epoch: 10, Steps: 19 | Train Loss: 0.1273107 Vali Loss: 3.2238023 Test Loss: 28.5773735
Validation loss decreased (3.223806 --> 3.223802).  Saving model ...
Updating learning rate to 1.953125e-07
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.80it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.80it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:06,  2.72it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:01<00:06,  2.72it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.72it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.72it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.72it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.72it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:01<00:05,  2.72it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:02<00:05,  2.72it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.73it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.73it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.72it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.72it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:02<00:04,  2.73it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:03<00:04,  2.73it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.72it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.72it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:03<00:03,  2.73it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:04<00:03,  2.73it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:04<00:02,  2.73it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:04<00:02,  2.73it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.73it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.73it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:04<00:02,  2.72it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:05<00:02,  2.72it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.73it/s]loss:0.00497961001636018:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.73it/s]loss:0.00497961001636018:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.73it/s]loss:0.1719832566987889:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.73it/s] loss:0.1719832566987889:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:05<00:01,  2.73it/s]loss:0.4877401625156304:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:06<00:01,  2.73it/s]loss:0.4877401625156304:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.73it/s]loss:0.7993014452504953:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.73it/s]loss:0.7993014452504953:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.73it/s]loss:0.9722890424999897:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.73it/s]loss:0.9722890424999897: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:06<00:00,  2.73it/s]loss:0.9722890424999897: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:07<00:00,  2.70it/s]
Epoch: 11 cost time: 7.570686101913452
Epoch: 11, Steps: 19 | Train Loss: 0.1282260 Vali Loss: 3.2237999 Test Loss: 28.5773563
Validation loss decreased (3.223802 --> 3.223800).  Saving model ...
Updating learning rate to 9.765625e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.71it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.71it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:06,  2.77it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:01<00:06,  2.77it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.70it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.70it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.73it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.73it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:01<00:05,  2.75it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:02<00:05,  2.75it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.77it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.77it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.77it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.77it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:02<00:03,  2.78it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:03<00:03,  2.78it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.77it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.77it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:03<00:03,  2.78it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:04<00:03,  2.78it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:04<00:02,  2.71it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:04<00:02,  2.71it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.73it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.73it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:04<00:02,  2.74it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:05<00:02,  2.74it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.76it/s]loss:0.005151312531681292:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.76it/s]loss:0.005151312531681292:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.75it/s]loss:0.18310475302022322:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.75it/s] loss:0.18310475302022322:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:05<00:01,  2.76it/s]loss:0.5269305407958975:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:06<00:01,  2.76it/s] loss:0.5269305407958975:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.75it/s]loss:0.8282857322686243:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.75it/s]loss:0.8282857322686243:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.76it/s]loss:0.9722866042309418:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.76it/s]loss:0.9722866042309418: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:06<00:00,  2.75it/s]loss:0.9722866042309418: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:06<00:00,  2.73it/s]
Epoch: 12 cost time: 7.5073652267456055
Epoch: 12, Steps: 19 | Train Loss: 0.1324084 Vali Loss: 3.2237990 Test Loss: 28.5773430
Validation loss decreased (3.223800 --> 3.223799).  Saving model ...
Updating learning rate to 4.8828125e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.79it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.79it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:06,  2.79it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:01<00:06,  2.79it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.77it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.77it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.77it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.77it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:01<00:05,  2.76it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:02<00:05,  2.76it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.76it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.76it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.75it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.75it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:02<00:03,  2.75it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:03<00:03,  2.75it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.75it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.75it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:03<00:03,  2.75it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:03<00:03,  2.75it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:03<00:02,  2.74it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:04<00:02,  2.74it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.74it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.74it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:04<00:02,  2.74it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:05<00:02,  2.74it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.74it/s]loss:0.004577853124110325:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.74it/s]loss:0.004577853124110325:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.73it/s]loss:0.18310453073764504:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.73it/s] loss:0.18310453073764504:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:05<00:01,  2.74it/s]loss:0.48773824318978315:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:06<00:01,  2.74it/s]loss:0.48773824318978315:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.69it/s]loss:0.84208185026649:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.69it/s]   loss:0.84208185026649:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.70it/s]loss:0.8966066112100521:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.70it/s]loss:0.8966066112100521: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:06<00:00,  2.71it/s]loss:0.8966066112100521: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:06<00:00,  2.71it/s]
Epoch: 13 cost time: 7.536406517028809
Epoch: 13, Steps: 19 | Train Loss: 0.1270584 Vali Loss: 3.2237983 Test Loss: 28.5773354
Validation loss decreased (3.223799 --> 3.223798).  Saving model ...
Updating learning rate to 2.44140625e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.79it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.79it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:06,  2.75it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:01<00:06,  2.75it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.74it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.74it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.75it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.75it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:01<00:05,  2.74it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:02<00:05,  2.74it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.75it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.75it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.75it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.75it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:02<00:04,  2.75it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:03<00:04,  2.75it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.75it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.75it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:03<00:03,  2.75it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:04<00:03,  2.75it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:04<00:02,  2.70it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:04<00:02,  2.70it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.72it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.72it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:04<00:02,  2.73it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:05<00:02,  2.73it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.70it/s]loss:0.005110662404261122:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.70it/s]loss:0.005110662404261122:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.72it/s]loss:0.17994705414565348:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.72it/s] loss:0.17994705414565348:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:05<00:01,  2.72it/s]loss:0.5269293631483511:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:06<00:01,  2.72it/s] loss:0.5269293631483511:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.72it/s]loss:0.7769322333770124:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.72it/s]loss:0.7769322333770124:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.73it/s]loss:0.9015464606916447:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.73it/s]loss:0.9015464606916447: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:06<00:00,  2.73it/s]loss:0.9015464606916447: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:07<00:00,  2.71it/s]
Epoch: 14 cost time: 7.5755181312561035
Epoch: 14, Steps: 19 | Train Loss: 0.1258140 Vali Loss: 3.2237983 Test Loss: 28.5773277
Validation loss decreased (3.223798 --> 3.223798).  Saving model ...
Updating learning rate to 1.220703125e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.77it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.77it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:06,  2.80it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:01<00:06,  2.80it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.78it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.78it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.78it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.78it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:01<00:05,  2.77it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:02<00:05,  2.77it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.76it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.76it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.75it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.75it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:02<00:04,  2.75it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:03<00:04,  2.75it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.74it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.74it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:03<00:03,  2.75it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:03<00:03,  2.75it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:03<00:02,  2.74it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:04<00:02,  2.74it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.75it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.75it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:04<00:02,  2.75it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:05<00:02,  2.75it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.75it/s]loss:0.005476131796300837:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.75it/s]loss:0.005476131796300837:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.75it/s]loss:0.17364915253905672:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.75it/s] loss:0.17364915253905672:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:05<00:01,  2.75it/s]loss:0.440493988563106:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:06<00:01,  2.75it/s]  loss:0.440493988563106:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.74it/s]loss:0.7929898410719549:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.74it/s]loss:0.7929898410719549:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.74it/s]loss:0.8848117453444329:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.74it/s]loss:0.8848117453444329: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:06<00:00,  2.73it/s]loss:0.8848117453444329: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:06<00:00,  2.73it/s]
Epoch: 15 cost time: 7.473473787307739
Epoch: 15, Steps: 19 | Train Loss: 0.1209169 Vali Loss: 3.2237983 Test Loss: 28.5773258
Validation loss decreased (3.223798 --> 3.223798).  Saving model ...
Updating learning rate to 6.103515625e-09
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.77it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.77it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:06,  2.78it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:01<00:06,  2.78it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.79it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.79it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.80it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.80it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:01<00:05,  2.79it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:02<00:05,  2.79it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.73it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.73it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.73it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.73it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:02<00:04,  2.74it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:03<00:04,  2.74it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.74it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.74it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:03<00:03,  2.75it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:03<00:03,  2.75it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:03<00:02,  2.75it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:04<00:02,  2.75it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.75it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.75it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:04<00:02,  2.75it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:05<00:02,  2.75it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.75it/s]loss:0.004979596722717288:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.75it/s]loss:0.004979596722717288:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.74it/s]loss:0.17364913628626683:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.74it/s] loss:0.17364913628626683:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:05<00:01,  2.75it/s]loss:0.49176252664731995:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:06<00:01,  2.75it/s]loss:0.49176252664731995:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.74it/s]loss:0.8496975849060471:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.74it/s] loss:0.8496975849060471:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.74it/s]loss:0.9722846901355083:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.74it/s]loss:0.9722846901355083: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:06<00:00,  2.74it/s]loss:0.9722846901355083: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:06<00:00,  2.73it/s]
Epoch: 16 cost time: 7.503785610198975
Epoch: 16, Steps: 19 | Train Loss: 0.1311776 Vali Loss: 3.2237983 Test Loss: 28.5773258
Validation loss decreased (3.223798 --> 3.223798).  Saving model ...
Updating learning rate to 3.0517578125e-09
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.77it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.77it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:06,  2.76it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:01<00:06,  2.76it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.75it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.75it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.75it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.75it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:01<00:05,  2.74it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:02<00:05,  2.74it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.75it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.75it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.74it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.74it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:02<00:04,  2.75it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:03<00:04,  2.75it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.74it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.74it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:03<00:03,  2.74it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:04<00:03,  2.74it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:04<00:02,  2.74it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:04<00:02,  2.74it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.75it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.75it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:04<00:02,  2.74it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:05<00:02,  2.74it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.70it/s]loss:0.005429808065771755:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.70it/s]loss:0.005429808065771755:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.71it/s]loss:0.17086925120392368:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.71it/s] loss:0.17086925120392368:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:05<00:01,  2.73it/s]loss:0.4818043481785447:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:06<00:01,  2.73it/s] loss:0.4818043481785447:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.73it/s]loss:0.8428174947273919:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.73it/s]loss:0.8428174947273919:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.74it/s]loss:0.8848116715277046:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.74it/s]loss:0.8848116715277046: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:06<00:00,  2.74it/s]loss:0.8848116715277046: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:07<00:00,  2.71it/s]
Epoch: 17 cost time: 7.5176920890808105
Epoch: 17, Steps: 19 | Train Loss: 0.1255649 Vali Loss: 3.2237983 Test Loss: 28.5773258
Validation loss decreased (3.223798 --> 3.223798).  Saving model ...
Updating learning rate to 1.52587890625e-09
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.80it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.80it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:06,  2.79it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:01<00:06,  2.79it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.77it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.77it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.77it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.77it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:01<00:05,  2.77it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:02<00:05,  2.77it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.77it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.77it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.75it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.75it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:02<00:03,  2.76it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:03<00:03,  2.76it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.76it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.76it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:03<00:03,  2.76it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:03<00:03,  2.76it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:03<00:02,  2.76it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:04<00:02,  2.76it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.76it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.76it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:04<00:02,  2.75it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:05<00:02,  2.75it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.76it/s]loss:0.004964248921849174:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.76it/s]loss:0.004964248921849174:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.75it/s]loss:0.1543182316502856:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.75it/s]  loss:0.1543182316502856:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:05<00:01,  2.75it/s]loss:0.49567299817599464:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:06<00:01,  2.75it/s]loss:0.49567299817599464:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.75it/s]loss:0.7667122385002665:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.75it/s] loss:0.7667122385002665:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.76it/s]loss:0.9978185008402576:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.76it/s]loss:0.9978185008402576: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:06<00:00,  2.76it/s]loss:0.9978185008402576: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:06<00:00,  2.74it/s]
Epoch: 18 cost time: 7.4617390632629395
Epoch: 18, Steps: 19 | Train Loss: 0.1273414 Vali Loss: 3.2237983 Test Loss: 28.5773258
Validation loss decreased (3.223798 --> 3.223798).  Saving model ...
Updating learning rate to 7.62939453125e-10
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.79it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.79it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:06,  2.78it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:01<00:06,  2.78it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.76it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.76it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.76it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.76it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:01<00:05,  2.76it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:02<00:05,  2.76it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.76it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.76it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.75it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.75it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:02<00:04,  2.75it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:03<00:04,  2.75it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.74it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.74it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:03<00:03,  2.74it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:04<00:03,  2.74it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:04<00:02,  2.73it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:04<00:02,  2.73it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.74it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.74it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:04<00:02,  2.73it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:05<00:02,  2.73it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.73it/s]loss:0.005429807969244727:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.73it/s]loss:0.005429807969244727:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.73it/s]loss:0.1673436526788872:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.73it/s]  loss:0.1673436526788872:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:05<00:01,  2.73it/s]loss:0.5222052379889413:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:06<00:01,  2.73it/s]loss:0.5222052379889413:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.73it/s]loss:0.8646355985807428:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.73it/s]loss:0.8646355985807428:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.72it/s]loss:0.915136751556304:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.72it/s] loss:0.915136751556304: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:06<00:00,  2.72it/s]loss:0.915136751556304: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:06<00:00,  2.72it/s]
Epoch: 19 cost time: 7.563544034957886
Epoch: 19, Steps: 19 | Train Loss: 0.1302501 Vali Loss: 3.2237983 Test Loss: 28.5773258
Validation loss decreased (3.223798 --> 3.223798).  Saving model ...
Updating learning rate to 3.814697265625e-10
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.76it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.76it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:06,  2.75it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:01<00:06,  2.75it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.74it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.74it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.75it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.75it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:01<00:05,  2.75it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:02<00:05,  2.75it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.76it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.76it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.75it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.75it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:02<00:03,  2.76it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:03<00:03,  2.76it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.75it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.75it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:03<00:03,  2.75it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:03<00:03,  2.75it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:03<00:02,  2.75it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:04<00:02,  2.75it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.74it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.74it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:04<00:02,  2.75it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:05<00:02,  2.75it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.75it/s]loss:0.005068835665672064:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.75it/s]loss:0.005068835665672064:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.75it/s]loss:0.18303753706196255:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.75it/s] loss:0.18303753706196255:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:05<00:01,  2.75it/s]loss:0.44049390378763426:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:06<00:01,  2.75it/s]loss:0.44049390378763426:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.75it/s]loss:0.8496975051116616:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.75it/s] loss:0.8496975051116616:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.75it/s]loss:0.9224138754619077:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.75it/s]loss:0.9224138754619077: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:06<00:00,  2.75it/s]loss:0.9224138754619077: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:06<00:00,  2.73it/s]
Epoch: 20 cost time: 7.490011215209961
Epoch: 20, Steps: 19 | Train Loss: 0.1263532 Vali Loss: 3.2237983 Test Loss: 28.5773258
Validation loss decreased (3.223798 --> 3.223798).  Saving model ...
Updating learning rate to 1.9073486328125e-10
>>>>>>>testing : long_term_forecast_break_tukey-hanning_0_FiLM_job_demand_r2_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 4
test shape: (4, 1, 3, 121420) (4, 1, 3, 121420)
test shape: (4, 3, 121420) (4, 3, 121420)
mse:9016.3720703125, mae:6.432260036468506, dtw:-999
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           0                   Model:              FiLM                

[1mData Loader[0m
  Data:               job_demand_r2       Root Path:          ../../dataset/demand/
  Data Path:          r2.parquet          Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        .cache/checkpoints  

[1mForecasting Task[0m
  Seq Len:            6                   Label Len:          1                   
  Pred Len:           3                   Seasonal Patterns:  Monthly             
  Inverse:            1                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             121420              Dec In:             121420              
  C Out:              121420              d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           2                   d FF:               2048                
  Moving Avg:         25                  Factor:             1                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              learned             Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        32                  Itr:                1                   
  Train Epochs:       20                  Batch Size:         1                   
  Patience:           3                   Learning Rate:      0.0001              
  Des:                test                Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1                 

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_break_rayleigh_0_FiLM_job_demand_r2_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 19
val 1
test 4
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.4041476033555477:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.4041476033555477:   5%|â–Œ         | 1/19 [00:00<00:17,  1.02it/s]loss:0.44503539077876:   5%|â–Œ         | 1/19 [00:01<00:17,  1.02it/s]  loss:0.44503539077876:  11%|â–ˆ         | 2/19 [00:01<00:10,  1.61it/s]loss:0.47079251054077803:  11%|â–ˆ         | 2/19 [00:01<00:10,  1.61it/s]loss:0.47079251054077803:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:08,  1.97it/s]loss:0.5157140498029973:  16%|â–ˆâ–Œ        | 3/19 [00:02<00:08,  1.97it/s] loss:0.5157140498029973:  21%|â–ˆâ–ˆ        | 4/19 [00:02<00:06,  2.22it/s]loss:0.5528490308452849:  21%|â–ˆâ–ˆ        | 4/19 [00:02<00:06,  2.22it/s]loss:0.5528490308452849:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:02<00:05,  2.39it/s]loss:0.6296774556108699:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:02<00:05,  2.39it/s]loss:0.6296774556108699:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:05,  2.50it/s]loss:0.6233749588831264:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:03<00:05,  2.50it/s]loss:0.6233749588831264:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:03<00:04,  2.58it/s]loss:0.7386787893844596:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:03<00:04,  2.58it/s]loss:0.7386787893844596:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:03<00:04,  2.63it/s]loss:0.7185970790275282:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:03<00:04,  2.63it/s]loss:0.7185970790275282:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.61it/s]loss:0.8041491918822307:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:04<00:03,  2.61it/s]loss:0.8041491918822307:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:04<00:03,  2.65it/s]loss:0.7789679805391683:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:04<00:03,  2.65it/s]loss:0.7789679805391683:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:04<00:02,  2.68it/s]loss:0.7837312860755514:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:05<00:02,  2.68it/s]loss:0.7837312860755514:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:05<00:02,  2.70it/s]loss:0.7524672737922924:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:05<00:02,  2.70it/s]loss:0.7524672737922924:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:05<00:02,  2.71it/s]loss:0.9145334948786176:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:05<00:02,  2.71it/s]loss:0.9145334948786176:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.72it/s]loss:0.934087549903522:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:06<00:01,  2.72it/s] loss:0.934087549903522:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:06<00:01,  2.71it/s]loss:0.8759288031142255:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:06<00:01,  2.71it/s]loss:0.8759288031142255:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:06<00:01,  2.73it/s]loss:0.9088692435288867:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:06<00:01,  2.73it/s]loss:0.9088692435288867:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.73it/s]loss:0.8202028121713054:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:07<00:00,  2.73it/s]loss:0.8202028121713054:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:07<00:00,  2.73it/s]loss:0.9743584922365245:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:07<00:00,  2.73it/s]loss:0.9743584922365245: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:07<00:00,  2.73it/s]loss:0.9743584922365245: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:07<00:00,  2.49it/s]
Epoch: 1 cost time: 8.25642466545105
Epoch: 1, Steps: 19 | Train Loss: 0.7182191 Vali Loss: 3.2227886 Test Loss: 28.5479126
Validation loss decreased (inf --> 3.222789).  Saving model ...
Updating learning rate to 0.0001
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.4061665331628537:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.4061665331628537:   5%|â–Œ         | 1/19 [00:00<00:06,  2.74it/s]loss:0.4342426410765396:   5%|â–Œ         | 1/19 [00:00<00:06,  2.74it/s]loss:0.4342426410765396:  11%|â–ˆ         | 2/19 [00:00<00:06,  2.74it/s]loss:0.5122604189806582:  11%|â–ˆ         | 2/19 [00:01<00:06,  2.74it/s]loss:0.5122604189806582:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.74it/s]loss:0.5677878493098807:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.74it/s]loss:0.5677878493098807:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.74it/s]loss:0.5960343173427639:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.74it/s]loss:0.5960343173427639:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:01<00:05,  2.74it/s]loss:0.5929740262806374:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:02<00:05,  2.74it/s]loss:0.5929740262806374:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.75it/s]loss:0.6168477196236684:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.75it/s]loss:0.6168477196236684:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.74it/s]loss:0.6072415643843203:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.74it/s]loss:0.6072415643843203:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:02<00:04,  2.74it/s]loss:0.7627008594884772:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:03<00:04,  2.74it/s]loss:0.7627008594884772:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.73it/s]loss:0.7269405830366841:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.73it/s]loss:0.7269405830366841:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:03<00:03,  2.73it/s]loss:0.8240036400278143:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:04<00:03,  2.73it/s]loss:0.8240036400278143:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:04<00:02,  2.72it/s]loss:0.7913790645300528:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:04<00:02,  2.72it/s]loss:0.7913790645300528:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.73it/s]loss:0.808855768549036:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.73it/s] loss:0.808855768549036:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:04<00:02,  2.72it/s]loss:0.8617082986623924:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:05<00:02,  2.72it/s]loss:0.8617082986623924:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.69it/s]loss:0.8641107920962027:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.69it/s]loss:0.8641107920962027:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.68it/s]loss:0.933534755719573:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.68it/s] loss:0.933534755719573:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:05<00:01,  2.69it/s]loss:0.9017592274314448:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:06<00:01,  2.69it/s]loss:0.9017592274314448:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.70it/s]loss:0.9126641069757877:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.70it/s]loss:0.9126641069757877:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.70it/s]loss:0.8189996790426697:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.70it/s]loss:0.8189996790426697: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:06<00:00,  2.70it/s]loss:0.8189996790426697: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:07<00:00,  2.70it/s]
Epoch: 2 cost time: 7.57105016708374
Epoch: 2, Steps: 19 | Train Loss: 0.7126427 Vali Loss: 3.2213178 Test Loss: 28.5417309
Validation loss decreased (3.222789 --> 3.221318).  Saving model ...
Updating learning rate to 5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.3926587049022757:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.3926587049022757:   5%|â–Œ         | 1/19 [00:00<00:06,  2.73it/s]loss:0.4824328610164857:   5%|â–Œ         | 1/19 [00:00<00:06,  2.73it/s]loss:0.4824328610164857:  11%|â–ˆ         | 2/19 [00:00<00:06,  2.76it/s]loss:0.4689280453849635:  11%|â–ˆ         | 2/19 [00:01<00:06,  2.76it/s]loss:0.4689280453849635:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.75it/s]loss:0.5062034525274436:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.75it/s]loss:0.5062034525274436:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.75it/s]loss:0.5013909902040818:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.75it/s]loss:0.5013909902040818:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:01<00:05,  2.73it/s]loss:0.6310443969211198:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:02<00:05,  2.73it/s]loss:0.6310443969211198:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.74it/s]loss:0.6806382367490971:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.74it/s]loss:0.6806382367490971:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.68it/s]loss:0.6520741826413315:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.68it/s]loss:0.6520741826413315:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:02<00:04,  2.69it/s]loss:0.7126109284915783:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:03<00:04,  2.69it/s]loss:0.7126109284915783:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.70it/s]loss:0.7372088502772499:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.70it/s]loss:0.7372088502772499:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:03<00:03,  2.72it/s]loss:0.7649000643623556:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:04<00:03,  2.72it/s]loss:0.7649000643623556:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:04<00:02,  2.72it/s]loss:0.7878334767866845:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:04<00:02,  2.72it/s]loss:0.7878334767866845:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.73it/s]loss:0.8312666772748778:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.73it/s]loss:0.8312666772748778:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:04<00:02,  2.73it/s]loss:0.9078893515249139:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:05<00:02,  2.73it/s]loss:0.9078893515249139:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.73it/s]loss:0.7878471355656845:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.73it/s]loss:0.7878471355656845:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.72it/s]loss:0.8932465815984664:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.72it/s]loss:0.8932465815984664:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:05<00:01,  2.72it/s]loss:0.9579495921855709:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:06<00:01,  2.72it/s]loss:0.9579495921855709:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.71it/s]loss:0.9084450848589207:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.71it/s]loss:0.9084450848589207:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.72it/s]loss:0.9523333449083449:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.72it/s]loss:0.9523333449083449: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:06<00:00,  2.71it/s]loss:0.9523333449083449: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:07<00:00,  2.70it/s]
Epoch: 3 cost time: 7.58355975151062
Epoch: 3, Steps: 19 | Train Loss: 0.7135212 Vali Loss: 3.2207403 Test Loss: 28.5362206
Validation loss decreased (3.221318 --> 3.220740).  Saving model ...
Updating learning rate to 2.5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.42962508118177106:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.42962508118177106:   5%|â–Œ         | 1/19 [00:00<00:06,  2.73it/s]loss:0.3968024239969429:   5%|â–Œ         | 1/19 [00:00<00:06,  2.73it/s] loss:0.3968024239969429:  11%|â–ˆ         | 2/19 [00:00<00:06,  2.73it/s]loss:0.43219562064838596:  11%|â–ˆ         | 2/19 [00:01<00:06,  2.73it/s]loss:0.43219562064838596:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.73it/s]loss:0.5018689444953395:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.73it/s] loss:0.5018689444953395:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.73it/s]loss:0.5492446980319723:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.73it/s]loss:0.5492446980319723:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:01<00:05,  2.72it/s]loss:0.581464009672709:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:02<00:05,  2.72it/s] loss:0.581464009672709:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.72it/s]loss:0.6202071510001353:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.72it/s]loss:0.6202071510001353:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.71it/s]loss:0.6515536826620455:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.71it/s]loss:0.6515536826620455:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:02<00:04,  2.71it/s]loss:0.7726048082191995:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:03<00:04,  2.71it/s]loss:0.7726048082191995:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.71it/s]loss:0.7949306129070352:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.71it/s]loss:0.7949306129070352:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:03<00:03,  2.72it/s]loss:0.7777895097645049:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:04<00:03,  2.72it/s]loss:0.7777895097645049:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:04<00:02,  2.72it/s]loss:0.8493297042159663:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:04<00:02,  2.72it/s]loss:0.8493297042159663:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.72it/s]loss:0.8317843066261412:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.72it/s]loss:0.8317843066261412:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:04<00:02,  2.71it/s]loss:0.847203098056536:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:05<00:02,  2.71it/s] loss:0.847203098056536:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.71it/s]loss:0.9287163041742131:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.71it/s]loss:0.9287163041742131:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.71it/s]loss:0.8932454579435761:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.71it/s]loss:0.8932454579435761:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:05<00:01,  2.71it/s]loss:0.8994934190600445:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:06<00:01,  2.71it/s]loss:0.8994934190600445:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.71it/s]loss:0.8845483041955583:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.71it/s]loss:0.8845483041955583:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.71it/s]loss:0.9514166820426675:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.71it/s]loss:0.9514166820426675: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:06<00:00,  2.71it/s]loss:0.9514166820426675: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:07<00:00,  2.69it/s]
Epoch: 4 cost time: 7.6023712158203125
Epoch: 4, Steps: 19 | Train Loss: 0.7154749 Vali Loss: 3.2205801 Test Loss: 28.5334949
Validation loss decreased (3.220740 --> 3.220580).  Saving model ...
Updating learning rate to 1.25e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.4291865544733274:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.4291865544733274:   5%|â–Œ         | 1/19 [00:00<00:06,  2.79it/s]loss:0.43776954159952663:   5%|â–Œ         | 1/19 [00:00<00:06,  2.79it/s]loss:0.43776954159952663:  11%|â–ˆ         | 2/19 [00:00<00:06,  2.75it/s]loss:0.47898674546605746:  11%|â–ˆ         | 2/19 [00:01<00:06,  2.75it/s]loss:0.47898674546605746:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.74it/s]loss:0.5184341130404937:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.74it/s] loss:0.5184341130404937:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.73it/s]loss:0.5429879316539479:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.73it/s]loss:0.5429879316539479:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:01<00:05,  2.73it/s]loss:0.5810953589850548:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:02<00:05,  2.73it/s]loss:0.5810953589850548:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.73it/s]loss:0.6785269057201004:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.73it/s]loss:0.6785269057201004:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.72it/s]loss:0.6619375630907526:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.72it/s]loss:0.6619375630907526:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:02<00:04,  2.73it/s]loss:0.6379848779242723:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:03<00:04,  2.73it/s]loss:0.6379848779242723:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.73it/s]loss:0.8096880330539552:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.73it/s]loss:0.8096880330539552:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:03<00:03,  2.73it/s]loss:0.8105385795174183:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:04<00:03,  2.73it/s]loss:0.8105385795174183:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:04<00:02,  2.73it/s]loss:0.8070562219186186:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:04<00:02,  2.73it/s]loss:0.8070562219186186:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.73it/s]loss:0.7461937888972637:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.73it/s]loss:0.7461937888972637:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:04<00:02,  2.72it/s]loss:0.8279380786475928:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:05<00:02,  2.72it/s]loss:0.8279380786475928:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.73it/s]loss:0.9214182303138126:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.73it/s]loss:0.9214182303138126:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.72it/s]loss:0.8927652161755734:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.72it/s]loss:0.8927652161755734:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:05<00:01,  2.73it/s]loss:0.8788519911936981:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:06<00:01,  2.73it/s]loss:0.8788519911936981:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.73it/s]loss:0.8773799591023812:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.73it/s]loss:0.8773799591023812:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.73it/s]loss:0.9659372717373124:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.73it/s]loss:0.9659372717373124: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:06<00:00,  2.73it/s]loss:0.9659372717373124: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:07<00:00,  2.71it/s]
Epoch: 5 cost time: 7.547719478607178
Epoch: 5, Steps: 19 | Train Loss: 0.7107725 Vali Loss: 3.2204585 Test Loss: 28.5322990
Validation loss decreased (3.220580 --> 3.220459).  Saving model ...
Updating learning rate to 6.25e-06
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.40467683400701565:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.40467683400701565:   5%|â–Œ         | 1/19 [00:00<00:06,  2.79it/s]loss:0.3963477389609311:   5%|â–Œ         | 1/19 [00:00<00:06,  2.79it/s] loss:0.3963477389609311:  11%|â–ˆ         | 2/19 [00:00<00:06,  2.78it/s]loss:0.4809229247582443:  11%|â–ˆ         | 2/19 [00:01<00:06,  2.78it/s]loss:0.4809229247582443:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.76it/s]loss:0.4666812917964654:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.76it/s]loss:0.4666812917964654:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.76it/s]loss:0.539854297335277:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.76it/s] loss:0.539854297335277:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:01<00:05,  2.75it/s]loss:0.5806112251273022:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:02<00:05,  2.75it/s]loss:0.5806112251273022:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.76it/s]loss:0.6727343141395642:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.76it/s]loss:0.6727343141395642:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.75it/s]loss:0.7324539845725749:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.75it/s]loss:0.7324539845725749:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:02<00:03,  2.75it/s]loss:0.697373088954527:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:03<00:03,  2.75it/s] loss:0.697373088954527:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.75it/s]loss:0.7416055580290661:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.75it/s]loss:0.7416055580290661:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:03<00:03,  2.75it/s]loss:0.8283179494670088:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:03<00:03,  2.75it/s]loss:0.8283179494670088:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:03<00:02,  2.74it/s]loss:0.8481001641291762:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:04<00:02,  2.74it/s]loss:0.8481001641291762:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.75it/s]loss:0.8036846757236049:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.75it/s]loss:0.8036846757236049:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:04<00:02,  2.74it/s]loss:0.8336079919317086:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:05<00:02,  2.74it/s]loss:0.8336079919317086:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.75it/s]loss:0.851535416911281:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.75it/s] loss:0.851535416911281:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.74it/s]loss:0.881240538107054:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.74it/s]loss:0.881240538107054:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:05<00:01,  2.75it/s]loss:0.9560811229555035:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:06<00:01,  2.75it/s]loss:0.9560811229555035:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.74it/s]loss:0.9104676631506256:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.74it/s]loss:0.9104676631506256:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.75it/s]loss:0.9507728981588822:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.75it/s]loss:0.9507728981588822: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:06<00:00,  2.73it/s]loss:0.9507728981588822: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:06<00:00,  2.73it/s]
Epoch: 6 cost time: 7.54616379737854
Epoch: 6, Steps: 19 | Train Loss: 0.7145826 Vali Loss: 3.2203896 Test Loss: 28.5314674
Validation loss decreased (3.220459 --> 3.220390).  Saving model ...
Updating learning rate to 3.125e-06
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.3942517050362632:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.3942517050362632:   5%|â–Œ         | 1/19 [00:00<00:06,  2.77it/s]loss:0.3976417712502113:   5%|â–Œ         | 1/19 [00:00<00:06,  2.77it/s]loss:0.3976417712502113:  11%|â–ˆ         | 2/19 [00:00<00:06,  2.78it/s]loss:0.46361492071675475:  11%|â–ˆ         | 2/19 [00:01<00:06,  2.78it/s]loss:0.46361492071675475:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.78it/s]loss:0.5200322823647019:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.78it/s] loss:0.5200322823647019:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.78it/s]loss:0.5906065959126555:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.78it/s]loss:0.5906065959126555:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:01<00:05,  2.77it/s]loss:0.586788454832456:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:02<00:05,  2.77it/s] loss:0.586788454832456:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.76it/s]loss:0.633452162782371:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.76it/s]loss:0.633452162782371:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.75it/s]loss:0.7323392097140489:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.75it/s]loss:0.7323392097140489:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:02<00:04,  2.75it/s]loss:0.7520046886556737:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:03<00:04,  2.75it/s]loss:0.7520046886556737:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.74it/s]loss:0.7936745455061961:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.74it/s]loss:0.7936745455061961:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:03<00:03,  2.74it/s]loss:0.7560094168268471:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:03<00:03,  2.74it/s]loss:0.7560094168268471:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:03<00:02,  2.74it/s]loss:0.7834840957222681:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:04<00:02,  2.74it/s]loss:0.7834840957222681:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.75it/s]loss:0.7458867596442214:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.75it/s]loss:0.7458867596442214:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:04<00:02,  2.75it/s]loss:0.9002508712327323:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:05<00:02,  2.75it/s]loss:0.9002508712327323:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.75it/s]loss:0.8739062493593686:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.75it/s]loss:0.8739062493593686:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.74it/s]loss:0.8614813159957374:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.74it/s]loss:0.8614813159957374:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:05<00:01,  2.75it/s]loss:0.8922400681787072:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:06<00:01,  2.75it/s]loss:0.8922400681787072:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.74it/s]loss:0.9483038656644046:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.74it/s]loss:0.9483038656644046:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.74it/s]loss:0.9118802408764807:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.74it/s]loss:0.9118802408764807: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:06<00:00,  2.74it/s]loss:0.9118802408764807: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:06<00:00,  2.73it/s]
Epoch: 7 cost time: 7.4624714851379395
Epoch: 7, Steps: 19 | Train Loss: 0.7125184 Vali Loss: 3.2203484 Test Loss: 28.5309525
Validation loss decreased (3.220390 --> 3.220348).  Saving model ...
Updating learning rate to 1.5625e-06
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.4046239920748572:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.4046239920748572:   5%|â–Œ         | 1/19 [00:00<00:06,  2.77it/s]loss:0.4427472730129944:   5%|â–Œ         | 1/19 [00:00<00:06,  2.77it/s]loss:0.4427472730129944:  11%|â–ˆ         | 2/19 [00:00<00:06,  2.77it/s]loss:0.5123875696637659:  11%|â–ˆ         | 2/19 [00:01<00:06,  2.77it/s]loss:0.5123875696637659:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.76it/s]loss:0.5459892234307127:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.76it/s]loss:0.5459892234307127:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.76it/s]loss:0.5590634703350909:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.76it/s]loss:0.5590634703350909:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:01<00:05,  2.75it/s]loss:0.5803679305768579:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:02<00:05,  2.75it/s]loss:0.5803679305768579:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.75it/s]loss:0.673602136565462:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.75it/s] loss:0.673602136565462:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.74it/s]loss:0.603059804354544:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.74it/s]loss:0.603059804354544:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:02<00:04,  2.74it/s]loss:0.7403591462583935:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:03<00:04,  2.74it/s]loss:0.7403591462583935:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.73it/s]loss:0.7179456423642416:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.73it/s]loss:0.7179456423642416:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:03<00:03,  2.73it/s]loss:0.75512708298421:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:04<00:03,  2.73it/s]  loss:0.75512708298421:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:04<00:02,  2.72it/s]loss:0.8031975814679979:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:04<00:02,  2.72it/s]loss:0.8031975814679979:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.73it/s]loss:0.8236114419499591:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.73it/s]loss:0.8236114419499591:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:04<00:02,  2.71it/s]loss:0.8409715143138006:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:05<00:02,  2.71it/s]loss:0.8409715143138006:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.71it/s]loss:0.8522741841387002:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.71it/s]loss:0.8522741841387002:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.71it/s]loss:0.968887546645444:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.71it/s] loss:0.968887546645444:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:05<00:01,  2.71it/s]loss:0.8107704263609642:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:06<00:01,  2.71it/s]loss:0.8107704263609642:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.71it/s]loss:0.8788435856212039:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.71it/s]loss:0.8788435856212039:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.71it/s]loss:0.9639097551039321:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.71it/s]loss:0.9639097551039321: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:06<00:00,  2.71it/s]loss:0.9639097551039321: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:07<00:00,  2.70it/s]
Epoch: 8 cost time: 7.594509124755859
Epoch: 8, Steps: 19 | Train Loss: 0.7093547 Vali Loss: 3.2203326 Test Loss: 28.5308380
Validation loss decreased (3.220348 --> 3.220333).  Saving model ...
Updating learning rate to 7.8125e-07
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.40563563945882114:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.40563563945882114:   5%|â–Œ         | 1/19 [00:00<00:06,  2.69it/s]loss:0.434648207676385:   5%|â–Œ         | 1/19 [00:00<00:06,  2.69it/s]  loss:0.434648207676385:  11%|â–ˆ         | 2/19 [00:00<00:06,  2.69it/s]loss:0.4668956022954998:  11%|â–ˆ         | 2/19 [00:01<00:06,  2.69it/s]loss:0.4668956022954998:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.70it/s]loss:0.5416385979205068:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.70it/s]loss:0.5416385979205068:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.72it/s]loss:0.5571997220954387:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.72it/s]loss:0.5571997220954387:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:01<00:05,  2.70it/s]loss:0.6368354232315981:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:02<00:05,  2.70it/s]loss:0.6368354232315981:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.72it/s]loss:0.6146784103300318:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.72it/s]loss:0.6146784103300318:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.72it/s]loss:0.6554824093051218:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.72it/s]loss:0.6554824093051218:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:02<00:04,  2.73it/s]loss:0.7070315839408714:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:03<00:04,  2.73it/s]loss:0.7070315839408714:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.72it/s]loss:0.7825163515625208:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.72it/s]loss:0.7825163515625208:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:03<00:03,  2.73it/s]loss:0.7490764607881015:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:04<00:03,  2.73it/s]loss:0.7490764607881015:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:04<00:02,  2.73it/s]loss:0.7244918995834793:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:04<00:02,  2.73it/s]loss:0.7244918995834793:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.74it/s]loss:0.8823442206988376:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.74it/s]loss:0.8823442206988376:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:04<00:02,  2.74it/s]loss:0.9308747301561914:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:05<00:02,  2.74it/s]loss:0.9308747301561914:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.76it/s]loss:0.7840453475265851:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.76it/s]loss:0.7840453475265851:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.75it/s]loss:0.8922080052575213:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.75it/s]loss:0.8922080052575213:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:05<00:01,  2.76it/s]loss:0.8921832510438082:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:06<00:01,  2.76it/s]loss:0.8921832510438082:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.75it/s]loss:0.8839017162593675:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.75it/s]loss:0.8839017162593675:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.75it/s]loss:0.9638800312945749:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.75it/s]loss:0.9638800312945749: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:06<00:00,  2.75it/s]loss:0.9638800312945749: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:07<00:00,  2.71it/s]
Epoch: 9 cost time: 7.540489435195923
Epoch: 9, Steps: 19 | Train Loss: 0.7108193 Vali Loss: 3.2203262 Test Loss: 28.5307465
Validation loss decreased (3.220333 --> 3.220326).  Saving model ...
Updating learning rate to 3.90625e-07
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.3941940022048737:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.3941940022048737:   5%|â–Œ         | 1/19 [00:00<00:06,  2.79it/s]loss:0.4407870497968626:   5%|â–Œ         | 1/19 [00:00<00:06,  2.79it/s]loss:0.4407870497968626:  11%|â–ˆ         | 2/19 [00:00<00:06,  2.79it/s]loss:0.46455853849161843:  11%|â–ˆ         | 2/19 [00:01<00:06,  2.79it/s]loss:0.46455853849161843:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.78it/s]loss:0.5199265157224997:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.78it/s] loss:0.5199265157224997:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.77it/s]loss:0.4999249364520678:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.77it/s]loss:0.4999249364520678:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:01<00:05,  2.76it/s]loss:0.6279647311818741:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:02<00:05,  2.76it/s]loss:0.6279647311818741:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.76it/s]loss:0.6361486623476855:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.76it/s]loss:0.6361486623476855:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.75it/s]loss:0.6721028097576663:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.75it/s]loss:0.6721028097576663:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:02<00:03,  2.75it/s]loss:0.7018095393128221:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:03<00:03,  2.75it/s]loss:0.7018095393128221:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.75it/s]loss:0.7310685406836479:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.75it/s]loss:0.7310685406836479:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:03<00:03,  2.75it/s]loss:0.8443870913875716:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:03<00:03,  2.75it/s]loss:0.8443870913875716:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:03<00:02,  2.74it/s]loss:0.7776801174821748:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:04<00:02,  2.74it/s]loss:0.7776801174821748:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.75it/s]loss:0.8823269150911389:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.75it/s]loss:0.8823269150911389:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:04<00:02,  2.74it/s]loss:0.7692842879156279:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:05<00:02,  2.74it/s]loss:0.7692842879156279:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.75it/s]loss:0.9335314754835694:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.75it/s]loss:0.9335314754835694:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.75it/s]loss:0.8672543917484671:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.75it/s]loss:0.8672543917484671:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:05<00:01,  2.75it/s]loss:0.9542756982537611:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:06<00:01,  2.75it/s]loss:0.9542756982537611:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.74it/s]loss:0.9482021385723268:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.74it/s]loss:0.9482021385723268:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.75it/s]loss:0.8854182680305182:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.75it/s]loss:0.8854182680305182: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:06<00:00,  2.75it/s]loss:0.8854182680305182: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:06<00:00,  2.73it/s]
Epoch: 10 cost time: 7.452823638916016
Epoch: 10, Steps: 19 | Train Loss: 0.7132024 Vali Loss: 3.2203217 Test Loss: 28.5307026
Validation loss decreased (3.220326 --> 3.220322).  Saving model ...
Updating learning rate to 1.953125e-07
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.3982179207319091:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.3982179207319091:   5%|â–Œ         | 1/19 [00:00<00:06,  2.71it/s]loss:0.42776804214666103:   5%|â–Œ         | 1/19 [00:00<00:06,  2.71it/s]loss:0.42776804214666103:  11%|â–ˆ         | 2/19 [00:00<00:06,  2.74it/s]loss:0.4795771830257998:  11%|â–ˆ         | 2/19 [00:01<00:06,  2.74it/s] loss:0.4795771830257998:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.75it/s]loss:0.5459168411802698:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.75it/s]loss:0.5459168411802698:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.76it/s]loss:0.5914368736913908:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.76it/s]loss:0.5914368736913908:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:01<00:05,  2.75it/s]loss:0.5367093796300414:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:02<00:05,  2.75it/s]loss:0.5367093796300414:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.75it/s]loss:0.6778767220469739:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.75it/s]loss:0.6778767220469739:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.74it/s]loss:0.6542930254260771:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.74it/s]loss:0.6542930254260771:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:02<00:04,  2.74it/s]loss:0.7717054295552757:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:03<00:04,  2.74it/s]loss:0.7717054295552757:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.73it/s]loss:0.7178804461871504:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.73it/s]loss:0.7178804461871504:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:03<00:03,  2.74it/s]loss:0.7769859522654291:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:04<00:03,  2.74it/s]loss:0.7769859522654291:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:04<00:02,  2.73it/s]loss:0.7219428275753278:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:04<00:02,  2.73it/s]loss:0.7219428275753278:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.73it/s]loss:0.8106367930536663:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.73it/s]loss:0.8106367930536663:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:04<00:02,  2.73it/s]loss:0.8929774945855888:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:05<00:02,  2.73it/s]loss:0.8929774945855888:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.73it/s]loss:0.8513542275567569:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.73it/s]loss:0.8513542275567569:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.73it/s]loss:0.8876245749591429:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.73it/s]loss:0.8876245749591429:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:05<00:01,  2.73it/s]loss:0.8921676208338334:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:06<00:01,  2.73it/s]loss:0.8921676208338334:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.72it/s]loss:0.9102053357190989:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.72it/s]loss:0.9102053357190989:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.72it/s]loss:0.9638564015254197:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.72it/s]loss:0.9638564015254197: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:06<00:00,  2.72it/s]loss:0.9638564015254197: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:06<00:00,  2.71it/s]
Epoch: 11 cost time: 7.548174858093262
Epoch: 11, Steps: 19 | Train Loss: 0.7110070 Vali Loss: 3.2203202 Test Loss: 28.5306816
Validation loss decreased (3.220322 --> 3.220320).  Saving model ...
Updating learning rate to 9.765625e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.3910354805804349:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.3910354805804349:   5%|â–Œ         | 1/19 [00:00<00:06,  2.78it/s]loss:0.44159849510217647:   5%|â–Œ         | 1/19 [00:00<00:06,  2.78it/s]loss:0.44159849510217647:  11%|â–ˆ         | 2/19 [00:00<00:06,  2.78it/s]loss:0.4786872279624267:  11%|â–ˆ         | 2/19 [00:01<00:06,  2.78it/s] loss:0.4786872279624267:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.77it/s]loss:0.5100413708927088:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.77it/s]loss:0.5100413708927088:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.77it/s]loss:0.49991714843593615:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.77it/s]loss:0.49991714843593615:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:01<00:05,  2.77it/s]loss:0.5807533027281059:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:02<00:05,  2.77it/s] loss:0.5807533027281059:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.77it/s]loss:0.5713221764498314:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.77it/s]loss:0.5713221764498314:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.76it/s]loss:0.7322331286830315:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.76it/s]loss:0.7322331286830315:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:02<00:03,  2.75it/s]loss:0.7461721586334021:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:03<00:03,  2.75it/s]loss:0.7461721586334021:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.75it/s]loss:0.7359425276493975:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.75it/s]loss:0.7359425276493975:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:03<00:03,  2.75it/s]loss:0.7544939812938655:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:03<00:03,  2.75it/s]loss:0.7544939812938655:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:03<00:02,  2.75it/s]loss:0.7794414796382695:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:04<00:02,  2.75it/s]loss:0.7794414796382695:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.75it/s]loss:0.8106310941259401:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.75it/s]loss:0.8106310941259401:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:04<00:02,  2.74it/s]loss:0.8565544838799604:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:05<00:02,  2.74it/s]loss:0.8565544838799604:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.74it/s]loss:0.8767015978306298:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.74it/s]loss:0.8767015978306298:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.74it/s]loss:0.9439246853057982:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.74it/s]loss:0.9439246853057982:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:05<00:01,  2.75it/s]loss:0.9619434076669249:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:06<00:01,  2.75it/s]loss:0.9619434076669249:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.74it/s]loss:0.9481915356488256:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.74it/s]loss:0.9481915356488256:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.75it/s]loss:0.9638528703556646:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.75it/s]loss:0.9638528703556646: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:06<00:00,  2.74it/s]loss:0.9638528703556646: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:06<00:00,  2.73it/s]
Epoch: 12 cost time: 7.482990026473999
Epoch: 12, Steps: 19 | Train Loss: 0.7149178 Vali Loss: 3.2203193 Test Loss: 28.5306625
Validation loss decreased (3.220320 --> 3.220319).  Saving model ...
Updating learning rate to 4.8828125e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.40385070245436916:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.40385070245436916:   5%|â–Œ         | 1/19 [00:00<00:06,  2.79it/s]loss:0.4277659849365463:   5%|â–Œ         | 1/19 [00:00<00:06,  2.79it/s] loss:0.4277659849365463:  11%|â–ˆ         | 2/19 [00:00<00:06,  2.79it/s]loss:0.46686702503036365:  11%|â–ˆ         | 2/19 [00:01<00:06,  2.79it/s]loss:0.46686702503036365:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.79it/s]loss:0.5645883687602468:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.79it/s] loss:0.5645883687602468:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.78it/s]loss:0.5585905736482416:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.78it/s]loss:0.5585905736482416:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:01<00:05,  2.77it/s]loss:0.6317147306116286:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:02<00:05,  2.77it/s]loss:0.6317147306116286:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.77it/s]loss:0.5713214296567536:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.77it/s]loss:0.5713214296567536:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.76it/s]loss:0.6720948803051674:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.76it/s]loss:0.6720948803051674:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:02<00:03,  2.76it/s]loss:0.6845716644178603:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:03<00:03,  2.76it/s]loss:0.6845716644178603:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.76it/s]loss:0.7763125442960659:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.76it/s]loss:0.7763125442960659:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:03<00:03,  2.76it/s]loss:0.7775626878249156:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:03<00:03,  2.76it/s]loss:0.7775626878249156:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:03<00:02,  2.76it/s]loss:0.7919422346611299:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:04<00:02,  2.76it/s]loss:0.7919422346611299:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.76it/s]loss:0.8098292257670369:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.76it/s]loss:0.8098292257670369:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:04<00:02,  2.76it/s]loss:0.9127419361306319:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:05<00:02,  2.76it/s]loss:0.9127419361306319:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.76it/s]loss:0.7840235573581724:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.76it/s]loss:0.7840235573581724:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.76it/s]loss:0.9439221399881202:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.76it/s]loss:0.9439221399881202:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:05<00:01,  2.75it/s]loss:0.8921639439632392:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:06<00:01,  2.75it/s]loss:0.8921639439632392:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.74it/s]loss:0.9557064657399365:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.74it/s]loss:0.9557064657399365:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.74it/s]loss:0.886967698159305:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.74it/s] loss:0.886967698159305: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:06<00:00,  2.74it/s]loss:0.886967698159305: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:06<00:00,  2.74it/s]
Epoch: 13 cost time: 7.493622779846191
Epoch: 13, Steps: 19 | Train Loss: 0.7111862 Vali Loss: 3.2203190 Test Loss: 28.5306606
Validation loss decreased (3.220319 --> 3.220319).  Saving model ...
Updating learning rate to 2.44140625e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.3938785165791454:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.3938785165791454:   5%|â–Œ         | 1/19 [00:00<00:06,  2.79it/s]loss:0.468737644252562:   5%|â–Œ         | 1/19 [00:00<00:06,  2.79it/s] loss:0.468737644252562:  11%|â–ˆ         | 2/19 [00:00<00:06,  2.77it/s]loss:0.47957430905031584:  11%|â–ˆ         | 2/19 [00:01<00:06,  2.77it/s]loss:0.47957430905031584:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.76it/s]loss:0.5048810305787657:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.76it/s] loss:0.5048810305787657:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.76it/s]loss:0.5904803641830889:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.76it/s]loss:0.5904803641830889:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:01<00:05,  2.76it/s]loss:0.6494304009740991:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:02<00:05,  2.76it/s]loss:0.6494304009740991:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.76it/s]loss:0.5713210297582174:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.76it/s]loss:0.5713210297582174:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.76it/s]loss:0.665906758107538:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.76it/s] loss:0.665906758107538:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:02<00:03,  2.76it/s]loss:0.7070093571000371:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:03<00:03,  2.76it/s]loss:0.7070093571000371:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.75it/s]loss:0.719513575945894:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.75it/s] loss:0.719513575945894:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:03<00:03,  2.76it/s]loss:0.7490395007240886:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:03<00:03,  2.76it/s]loss:0.7490395007240886:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:03<00:02,  2.75it/s]loss:0.7219373994003716:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:04<00:02,  2.75it/s]loss:0.7219373994003716:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.75it/s]loss:0.8339414401069176:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.75it/s]loss:0.8339414401069176:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:04<00:02,  2.74it/s]loss:0.9000495067043903:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:05<00:02,  2.74it/s]loss:0.9000495067043903:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.74it/s]loss:0.8760433025304948:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.74it/s]loss:0.8760433025304948:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.73it/s]loss:0.929413777259977:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.73it/s] loss:0.929413777259977:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:05<00:01,  2.74it/s]loss:0.9619398798417961:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:06<00:01,  2.74it/s]loss:0.9619398798417961:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.73it/s]loss:0.8847522870512174:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.73it/s]loss:0.8847522870512174:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.73it/s]loss:0.8951465172674523:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.73it/s]loss:0.8951465172674523: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:06<00:00,  2.73it/s]loss:0.8951465172674523: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:06<00:00,  2.72it/s]
Epoch: 14 cost time: 7.5189619064331055
Epoch: 14, Steps: 19 | Train Loss: 0.7106840 Vali Loss: 3.2203190 Test Loss: 28.5306549
Validation loss decreased (3.220319 --> 3.220319).  Saving model ...
Updating learning rate to 1.220703125e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.44080187205820337:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.44080187205820337:   5%|â–Œ         | 1/19 [00:00<00:06,  2.69it/s]loss:0.46153316256042076:   5%|â–Œ         | 1/19 [00:00<00:06,  2.69it/s]loss:0.46153316256042076:  11%|â–ˆ         | 2/19 [00:00<00:06,  2.73it/s]loss:0.47957429810940233:  11%|â–ˆ         | 2/19 [00:01<00:06,  2.73it/s]loss:0.47957429810940233:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.74it/s]loss:0.5008423064243015:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.74it/s] loss:0.5008423064243015:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.75it/s]loss:0.5561531255642682:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.75it/s]loss:0.5561531255642682:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:01<00:05,  2.74it/s]loss:0.6317134834904358:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:02<00:05,  2.74it/s]loss:0.6317134834904358:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.74it/s]loss:0.6286970222516383:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.74it/s]loss:0.6286970222516383:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.74it/s]loss:0.6051347368668808:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.74it/s]loss:0.6051347368668808:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:02<00:04,  2.74it/s]loss:0.6900903909823333:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:03<00:04,  2.74it/s]loss:0.6900903909823333:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.74it/s]loss:0.7824649642311722:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.74it/s]loss:0.7824649642311722:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:03<00:03,  2.74it/s]loss:0.8226597897854656:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:04<00:03,  2.74it/s]loss:0.8226597897854656:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:04<00:02,  2.74it/s]loss:0.7919412746531039:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:04<00:02,  2.74it/s]loss:0.7919412746531039:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.74it/s]loss:0.8106264194943622:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.74it/s]loss:0.8106264194943622:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:04<00:02,  2.73it/s]loss:0.8317582150026338:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:05<00:02,  2.73it/s]loss:0.8317582150026338:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.73it/s]loss:0.9335099121900584:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.73it/s]loss:0.9335099121900584:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.73it/s]loss:0.8921754436668571:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.73it/s]loss:0.8921754436668571:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:05<00:01,  2.73it/s]loss:0.8078998474928037:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:06<00:01,  2.73it/s]loss:0.8078998474928037:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.73it/s]loss:0.9095184447317729:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.73it/s]loss:0.9095184447317729:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.74it/s]loss:0.8810155821544279:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.74it/s]loss:0.8810155821544279: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:06<00:00,  2.73it/s]loss:0.8810155821544279: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:06<00:00,  2.72it/s]
Epoch: 15 cost time: 7.56409764289856
Epoch: 15, Steps: 19 | Train Loss: 0.7083216 Vali Loss: 3.2203190 Test Loss: 28.5306549
Validation loss decreased (3.220319 --> 3.220319).  Saving model ...
Updating learning rate to 6.103515625e-09
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.4262171017681484:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.4262171017681484:   5%|â–Œ         | 1/19 [00:00<00:06,  2.78it/s]loss:0.4811097458585416:   5%|â–Œ         | 1/19 [00:00<00:06,  2.78it/s]loss:0.4811097458585416:  11%|â–ˆ         | 2/19 [00:00<00:06,  2.79it/s]loss:0.4786853537508308:  11%|â–ˆ         | 2/19 [00:01<00:06,  2.79it/s]loss:0.4786853537508308:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.78it/s]loss:0.46659006158673116:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.78it/s]loss:0.46659006158673116:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.78it/s]loss:0.49991497039393074:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.78it/s]loss:0.49991497039393074:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:01<00:05,  2.77it/s]loss:0.5813232921656618:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:02<00:05,  2.77it/s] loss:0.5813232921656618:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.77it/s]loss:0.6735367544109344:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.77it/s]loss:0.6735367544109344:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.76it/s]loss:0.6495571897659097:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.76it/s]loss:0.6495571897659097:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:02<00:03,  2.76it/s]loss:0.7402986478896539:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:03<00:03,  2.76it/s]loss:0.7402986478896539:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.74it/s]loss:0.7359406065698011:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.74it/s]loss:0.7359406065698011:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:03<00:03,  2.74it/s]loss:0.7627933100830787:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:03<00:03,  2.74it/s]loss:0.7627933100830787:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:03<00:02,  2.74it/s]loss:0.783320196326032:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:04<00:02,  2.74it/s] loss:0.783320196326032:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.73it/s]loss:0.8051875814200583:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.73it/s]loss:0.8051875814200583:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:04<00:02,  2.73it/s]loss:0.8543994053960627:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:05<00:02,  2.73it/s]loss:0.8543994053960627:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.74it/s]loss:0.8513492859544226:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.74it/s]loss:0.8513492859544226:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.73it/s]loss:0.8921752954005212:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.73it/s]loss:0.8921752954005212:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:05<00:01,  2.73it/s]loss:0.9027224990844542:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:06<00:01,  2.73it/s]loss:0.9027224990844542:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.72it/s]loss:0.9691809811672293:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.72it/s]loss:0.9691809811672293:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.72it/s]loss:0.9638499914554407:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.72it/s]loss:0.9638499914554407: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:06<00:00,  2.72it/s]loss:0.9638499914554407: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:06<00:00,  2.72it/s]
Epoch: 16 cost time: 7.5565361976623535
Epoch: 16, Steps: 19 | Train Loss: 0.7114817 Vali Loss: 3.2203190 Test Loss: 28.5306530
Validation loss decreased (3.220319 --> 3.220319).  Saving model ...
Updating learning rate to 3.0517578125e-09
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.40592264407731815:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.40592264407731815:   5%|â–Œ         | 1/19 [00:00<00:06,  2.77it/s]loss:0.4267894413300629:   5%|â–Œ         | 1/19 [00:00<00:06,  2.77it/s] loss:0.4267894413300629:  11%|â–ˆ         | 2/19 [00:00<00:06,  2.76it/s]loss:0.4795742631498315:  11%|â–ˆ         | 2/19 [00:01<00:06,  2.76it/s]loss:0.4795742631498315:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.75it/s]loss:0.5536049426488282:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.75it/s]loss:0.5536049426488282:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.76it/s]loss:0.5424204670828524:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.76it/s]loss:0.5424204670828524:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:01<00:05,  2.75it/s]loss:0.5949892945492719:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:02<00:05,  2.75it/s]loss:0.5949892945492719:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.75it/s]loss:0.62452230468188:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.75it/s]  loss:0.62452230468188:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.74it/s]loss:0.7322305014859806:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.74it/s]loss:0.7322305014859806:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:02<00:04,  2.74it/s]loss:0.7402985921300408:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:03<00:04,  2.74it/s]loss:0.7402985921300408:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.73it/s]loss:0.668777223958513:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.73it/s] loss:0.668777223958513:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:03<00:03,  2.74it/s]loss:0.6953657221253684:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:04<00:03,  2.74it/s]loss:0.6953657221253684:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:04<00:02,  2.73it/s]loss:0.7839321374062193:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:04<00:02,  2.73it/s]loss:0.7839321374062193:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.74it/s]loss:0.8333178614970794:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.74it/s]loss:0.8333178614970794:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:04<00:02,  2.73it/s]loss:0.9000484351014573:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:05<00:02,  2.73it/s]loss:0.9000484351014573:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.73it/s]loss:0.926056848989635:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.73it/s] loss:0.926056848989635:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.74it/s]loss:0.8810808471642844:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.74it/s]loss:0.8810808471642844:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:05<00:01,  2.74it/s]loss:0.8781406844564877:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:06<00:01,  2.74it/s]loss:0.8781406844564877:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.74it/s]loss:0.9629894463296637:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.74it/s]loss:0.9629894463296637:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.75it/s]loss:0.8810155321703371:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.75it/s]loss:0.8810155321703371: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:06<00:00,  2.74it/s]loss:0.8810155321703371: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:06<00:00,  2.72it/s]
Epoch: 17 cost time: 7.53054141998291
Epoch: 17, Steps: 19 | Train Loss: 0.7111093 Vali Loss: 3.2203190 Test Loss: 28.5306530
Validation loss decreased (3.220319 --> 3.220319).  Saving model ...
Updating learning rate to 1.52587890625e-09
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.43222715385111493:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.43222715385111493:   5%|â–Œ         | 1/19 [00:00<00:06,  2.80it/s]loss:0.46798469965703665:   5%|â–Œ         | 1/19 [00:00<00:06,  2.80it/s]loss:0.46798469965703665:  11%|â–ˆ         | 2/19 [00:00<00:06,  2.79it/s]loss:0.43179502135761216:  11%|â–ˆ         | 2/19 [00:01<00:06,  2.79it/s]loss:0.43179502135761216:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.77it/s]loss:0.5100389051371179:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.77it/s] loss:0.5100389051371179:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.77it/s]loss:0.5585896532242909:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.77it/s]loss:0.5585896532242909:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:01<00:05,  2.76it/s]loss:0.5807511988993144:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:02<00:05,  2.76it/s]loss:0.5807511988993144:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.76it/s]loss:0.6286969739806296:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.76it/s]loss:0.6286969739806296:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.75it/s]loss:0.6554400090636402:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.75it/s]loss:0.6554400090636402:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:02<00:03,  2.75it/s]loss:0.7070089866424398:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:03<00:03,  2.75it/s]loss:0.7070089866424398:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.75it/s]loss:0.7884290604780508:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.75it/s]loss:0.7884290604780508:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:03<00:03,  2.75it/s]loss:0.8164359897139637:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:03<00:03,  2.75it/s]loss:0.8164359897139637:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:03<00:02,  2.74it/s]loss:0.8046430229369225:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:04<00:02,  2.74it/s]loss:0.8046430229369225:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.74it/s]loss:0.8091961966557302:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.74it/s]loss:0.8091961966557302:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:04<00:02,  2.74it/s]loss:0.8929705117266937:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:05<00:02,  2.74it/s]loss:0.8929705117266937:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.74it/s]loss:0.844538794349236:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.74it/s] loss:0.844538794349236:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.73it/s]loss:0.7978637771324988:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.73it/s]loss:0.7978637771324988:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:05<00:01,  2.73it/s]loss:0.9033974159557233:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:06<00:01,  2.73it/s]loss:0.9033974159557233:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.73it/s]loss:0.8788157416982605:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.73it/s]loss:0.8788157416982605:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.73it/s]loss:0.9908818754761809:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.73it/s]loss:0.9908818754761809: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:06<00:00,  2.73it/s]loss:0.9908818754761809: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:06<00:00,  2.72it/s]
Epoch: 18 cost time: 7.526886463165283
Epoch: 18, Steps: 19 | Train Loss: 0.7105108 Vali Loss: 3.2203190 Test Loss: 28.5306511
Validation loss decreased (3.220319 --> 3.220319).  Saving model ...
Updating learning rate to 7.62939453125e-10
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.4038499358379506:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.4038499358379506:   5%|â–Œ         | 1/19 [00:00<00:06,  2.75it/s]loss:0.43023106651584114:   5%|â–Œ         | 1/19 [00:00<00:06,  2.75it/s]loss:0.43023106651584114:  11%|â–ˆ         | 2/19 [00:00<00:06,  2.74it/s]loss:0.4645528123310964:  11%|â–ˆ         | 2/19 [00:01<00:06,  2.74it/s] loss:0.4645528123310964:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.72it/s]loss:0.5100388943272061:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.72it/s]loss:0.5100388943272061:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.71it/s]loss:0.5424204194178103:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.71it/s]loss:0.5424204194178103:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:01<00:05,  2.72it/s]loss:0.5906061443949131:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:02<00:05,  2.72it/s]loss:0.5906061443949131:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.72it/s]loss:0.6631847089519209:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.72it/s]loss:0.6631847089519209:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.72it/s]loss:0.6554399828495105:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.72it/s]loss:0.6554399828495105:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:02<00:04,  2.72it/s]loss:0.7106375642818724:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:03<00:04,  2.72it/s]loss:0.7106375642818724:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.71it/s]loss:0.6664318360626849:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.71it/s]loss:0.6664318360626849:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:03<00:03,  2.72it/s]loss:0.8226595238567677:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:04<00:03,  2.72it/s]loss:0.8226595238567677:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:04<00:02,  2.71it/s]loss:0.8595862972146251:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:04<00:02,  2.71it/s]loss:0.8595862972146251:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.72it/s]loss:0.831223515693473:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.72it/s] loss:0.831223515693473:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:04<00:02,  2.73it/s]loss:0.7692768943618232:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:05<00:02,  2.73it/s]loss:0.7692768943618232:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.73it/s]loss:0.9260568004454507:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.73it/s]loss:0.9260568004454507:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.72it/s]loss:0.8594482784239598:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.72it/s]loss:0.8594482784239598:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:05<00:01,  2.72it/s]loss:0.9485632411808329:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:06<00:01,  2.72it/s]loss:0.9485632411808329:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.72it/s]loss:0.9884077592992798:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.72it/s]loss:0.9884077592992798:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.73it/s]loss:0.9117949317177232:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.73it/s]loss:0.9117949317177232: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:06<00:00,  2.72it/s]loss:0.9117949317177232: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:07<00:00,  2.70it/s]
Epoch: 19 cost time: 7.586090326309204
Epoch: 19, Steps: 19 | Train Loss: 0.7133900 Vali Loss: 3.2203190 Test Loss: 28.5306511
Validation loss decreased (3.220319 --> 3.220319).  Saving model ...
Updating learning rate to 3.814697265625e-10
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.4294659273052721:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.4294659273052721:   5%|â–Œ         | 1/19 [00:00<00:06,  2.69it/s]loss:0.4407788847680259:   5%|â–Œ         | 1/19 [00:00<00:06,  2.69it/s]loss:0.4407788847680259:  11%|â–ˆ         | 2/19 [00:00<00:06,  2.75it/s]loss:0.43179501539780324:  11%|â–ˆ         | 2/19 [00:01<00:06,  2.75it/s]loss:0.43179501539780324:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.75it/s]loss:0.505378028762313:  16%|â–ˆâ–Œ        | 3/19 [00:01<00:05,  2.75it/s]  loss:0.505378028762313:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.76it/s]loss:0.5585896393420628:  21%|â–ˆâ–ˆ        | 4/19 [00:01<00:05,  2.76it/s]loss:0.5585896393420628:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:01<00:05,  2.75it/s]loss:0.5866843732498671:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:02<00:05,  2.75it/s]loss:0.5866843732498671:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.75it/s]loss:0.6345389864036709:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:02<00:04,  2.75it/s]loss:0.6345389864036709:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.74it/s]loss:0.6542839054880061:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:02<00:04,  2.74it/s]loss:0.6542839054880061:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:02<00:04,  2.75it/s]loss:0.7402985398642286:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:03<00:04,  2.75it/s]loss:0.7402985398642286:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.75it/s]loss:0.7824644177969179:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:03<00:03,  2.75it/s]loss:0.7824644177969179:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:03<00:03,  2.75it/s]loss:0.750751902257945:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:04<00:03,  2.75it/s] loss:0.750751902257945:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:04<00:02,  2.74it/s]loss:0.8766390387249093:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:04<00:02,  2.74it/s]loss:0.8766390387249093:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.76it/s]loss:0.8033501199993265:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:04<00:02,  2.76it/s]loss:0.8033501199993265:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:04<00:02,  2.75it/s]loss:0.8324077649729347:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:05<00:02,  2.75it/s]loss:0.8324077649729347:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.76it/s]loss:0.8657960465092831:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:05<00:01,  2.76it/s]loss:0.8657960465092831:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.75it/s]loss:0.9424054153195528:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:05<00:01,  2.75it/s]loss:0.9424054153195528:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:05<00:01,  2.76it/s]loss:0.8078996509569857:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:06<00:01,  2.76it/s]loss:0.8078996509569857:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.75it/s]loss:0.9691808278771794:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:06<00:00,  2.75it/s]loss:0.9691808278771794:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.75it/s]loss:0.9124766810433736:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:06<00:00,  2.75it/s]loss:0.9124766810433736: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:06<00:00,  2.75it/s]loss:0.9124766810433736: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:06<00:00,  2.73it/s]
Epoch: 20 cost time: 7.477901220321655
Epoch: 20, Steps: 19 | Train Loss: 0.7118519 Vali Loss: 3.2203190 Test Loss: 28.5306511
Validation loss decreased (3.220319 --> 3.220319).  Saving model ...
Updating learning rate to 1.9073486328125e-10
>>>>>>>testing : long_term_forecast_break_rayleigh_0_FiLM_job_demand_r2_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 4
test shape: (4, 1, 3, 121420) (4, 1, 3, 121420)
test shape: (4, 3, 121420) (4, 3, 121420)
mse:8900.892578125, mae:6.397129058837891, dtw:-999
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           0                   Model:              Koopa               

[1mData Loader[0m
  Data:               job_demand_r2       Root Path:          ../../dataset/demand/
  Data Path:          r2.parquet          Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        .cache/checkpoints  

[1mForecasting Task[0m
  Seq Len:            6                   Label Len:          1                   
  Pred Len:           3                   Seasonal Patterns:  Monthly             
  Inverse:            1                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             121420              Dec In:             121420              
  C Out:              121420              d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           2                   d FF:               2048                
  Moving Avg:         25                  Factor:             1                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              learned             Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        32                  Itr:                1                   
  Train Epochs:       20                  Batch Size:         1                   
  Patience:           3                   Learning Rate:      0.0001              
  Des:                test                Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1                 

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
train 19
>>>>>>>start training : long_term_forecast_break_bartlett_0_Koopa_job_demand_r2_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 19
val 1
test 4
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.68it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.68it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.68it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.68it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.68it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.68it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:00, 15.58it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:00, 15.58it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:00, 15.58it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:00, 15.58it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:00, 15.58it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:00, 15.58it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 23.81it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 23.81it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 23.81it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 23.81it/s]loss:0.029839766707189002:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 23.81it/s]loss:0.18819740799674764:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 23.81it/s] loss:0.18819740799674764:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 29.14it/s]loss:0.3926182145198098:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 29.14it/s] loss:0.5930795428274321:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 29.14it/s]loss:0.8600689020034302:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 29.14it/s]loss:0.8600689020034302: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 21.76it/s]
Epoch: 1 cost time: 1.3215653896331787
Epoch: 1, Steps: 19 | Train Loss: 0.1086213 Vali Loss: 3.2454925 Test Loss: 31.7653008
Validation loss decreased (inf --> 3.245492).  Saving model ...
Updating learning rate to 0.0001
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 37.29it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 37.29it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 37.29it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 37.29it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 37.29it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 37.08it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 37.08it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 37.08it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 37.08it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 37.08it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 37.00it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 37.00it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 37.00it/s]loss:0.03499508128378424:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 37.00it/s]loss:0.18672312634591998:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 37.00it/s]loss:0.18672312634591998:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 36.14it/s]loss:0.33149605778152863:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 36.14it/s]loss:0.48022447054425027:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 36.14it/s]loss:0.7650940842361365:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 36.14it/s] loss:0.7650940842361365: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 32.42it/s]
Epoch: 2 cost time: 1.188828945159912
Epoch: 2, Steps: 19 | Train Loss: 0.0946596 Vali Loss: 3.2514443 Test Loss: 32.4679794
EarlyStopping counter: 1 out of 3
Updating learning rate to 5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 36.48it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 36.48it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 36.48it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 36.48it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 36.48it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 37.80it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 37.80it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 37.80it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 37.80it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 37.80it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 37.38it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 37.38it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 37.38it/s]loss:0.0343845926296108:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 37.38it/s]loss:0.21016178725140128:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 37.38it/s]loss:0.21016178725140128:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 36.43it/s]loss:0.39621356317151074:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 36.43it/s]loss:0.5492729069080076:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 36.43it/s] loss:0.7379269138660616:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 36.43it/s]loss:0.7379269138660616: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 32.98it/s]
Epoch: 3 cost time: 1.1443793773651123
Epoch: 3, Steps: 19 | Train Loss: 0.1014716 Vali Loss: 3.2527745 Test Loss: 32.3719025
EarlyStopping counter: 2 out of 3
Updating learning rate to 2.5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 37.60it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 37.60it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 37.60it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 37.60it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 37.60it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 37.60it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 40.28it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 40.28it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 40.28it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 40.28it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 40.28it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 40.28it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 39.36it/s]loss:0.03471910628461962:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 39.36it/s]loss:0.21553906610501186:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 39.36it/s]loss:0.3775529563909825:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 39.36it/s] loss:0.5856896362904299:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 39.36it/s]loss:0.5856896362904299:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:00<00:00, 38.47it/s]loss:0.5901143190290998:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:00<00:00, 38.47it/s]loss:0.5901143190290998: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 34.92it/s]
Epoch: 4 cost time: 1.1093883514404297
Epoch: 4, Steps: 19 | Train Loss: 0.0949271 Vali Loss: 3.2530282 Test Loss: 32.1315689
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : long_term_forecast_break_bartlett_0_Koopa_job_demand_r2_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 4
test shape: (4, 1, 3, 121420) (4, 1, 3, 121420)
test shape: (4, 3, 121420) (4, 3, 121420)
mse:13931.0458984375, mae:6.356349945068359, dtw:-999
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           0                   Model:              Koopa               

[1mData Loader[0m
  Data:               job_demand_r2       Root Path:          ../../dataset/demand/
  Data Path:          r2.parquet          Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        .cache/checkpoints  

[1mForecasting Task[0m
  Seq Len:            6                   Label Len:          1                   
  Pred Len:           3                   Seasonal Patterns:  Monthly             
  Inverse:            1                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             121420              Dec In:             121420              
  C Out:              121420              d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           2                   d FF:               2048                
  Moving Avg:         25                  Factor:             1                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              learned             Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        32                  Itr:                1                   
  Train Epochs:       20                  Batch Size:         1                   
  Patience:           3                   Learning Rate:      0.0001              
  Des:                test                Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1                 

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
train 19
>>>>>>>start training : long_term_forecast_break_parzen_0_Koopa_job_demand_r2_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 19
val 1
test 4
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.90it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.90it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.90it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.90it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.90it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.90it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:00, 16.24it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:00, 16.24it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:00, 16.24it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:00, 16.24it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:00, 16.24it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 23.06it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 23.06it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 23.06it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 23.06it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 23.06it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 27.95it/s]loss:0.00013532774016865664:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 27.95it/s]loss:0.03055590563833167:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 27.95it/s]   loss:0.21313421301183397:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 27.95it/s]loss:0.5565310803015457:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 27.95it/s] loss:0.5565310803015457:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:00<00:00, 31.48it/s]loss:0.8663720051447628:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:00<00:00, 31.48it/s]loss:0.8663720051447628: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 23.10it/s]
Epoch: 1 cost time: 1.255331039428711
Epoch: 1, Steps: 19 | Train Loss: 0.0877226 Vali Loss: 3.2733750 Test Loss: 33.1487083
Validation loss decreased (inf --> 3.273375).  Saving model ...
Updating learning rate to 0.0001
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 39.81it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 39.81it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 39.81it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 39.81it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 39.81it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 39.81it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 42.20it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 42.20it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 42.20it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 42.20it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 42.20it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 42.20it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 45.25it/s]loss:0.0001428931300638576:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 45.25it/s]loss:0.029727735735018225:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 45.25it/s] loss:0.17712369023697108:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 45.25it/s] loss:0.4828212754598335:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 45.25it/s] loss:0.7427621564500569:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 45.25it/s]loss:0.7427621564500569: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 43.17it/s]loss:0.7427621564500569: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 37.66it/s]
Epoch: 2 cost time: 1.027170181274414
Epoch: 2, Steps: 19 | Train Loss: 0.0753988 Vali Loss: 3.2488618 Test Loss: 32.6376114
Validation loss decreased (3.273375 --> 3.248862).  Saving model ...
Updating learning rate to 5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 40.04it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 40.04it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 40.04it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 40.04it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 40.04it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 40.04it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 38.77it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 38.77it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 38.77it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 38.77it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 38.77it/s]loss:0.00015960250554253712:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 38.77it/s]loss:0.00015960250554253712:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 39.65it/s]loss:0.0334870160268718:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 39.65it/s]    loss:0.23821634577181544:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 39.65it/s]loss:0.5371606309502389:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 39.65it/s] loss:0.7394493473490932:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 39.65it/s]loss:0.7394493473490932: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 36.47it/s]
Epoch: 3 cost time: 1.0552616119384766
Epoch: 3, Steps: 19 | Train Loss: 0.0814986 Vali Loss: 3.2493985 Test Loss: 32.5948296
EarlyStopping counter: 1 out of 3
Updating learning rate to 2.5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 38.73it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 38.73it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 38.73it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 38.73it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 38.73it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 38.73it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 39.61it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 39.61it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 39.61it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 39.61it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 39.61it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 38.60it/s]loss:0.00015649025519241593:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 38.60it/s]loss:0.03628322070087307:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 38.60it/s]   loss:0.2108276167181967:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 38.60it/s] loss:0.5650363634150442:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 38.60it/s]loss:0.5650363634150442:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:00<00:00, 37.90it/s]loss:0.5760582400762955:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:00<00:00, 37.90it/s]loss:0.5760582400762955: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 34.34it/s]
Epoch: 4 cost time: 1.0480763912200928
Epoch: 4, Steps: 19 | Train Loss: 0.0730717 Vali Loss: 3.2487462 Test Loss: 32.4580078
Validation loss decreased (3.248862 --> 3.248746).  Saving model ...
Updating learning rate to 1.25e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 40.45it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 40.45it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 40.45it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 40.45it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 40.45it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 40.45it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 40.98it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 40.98it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 40.98it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 40.98it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 40.98it/s]loss:0.00016603181068826093:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 40.98it/s]loss:0.00016603181068826093:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 40.76it/s]loss:0.029375740076431043:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 40.76it/s]  loss:0.17403150123503866:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 40.76it/s] loss:0.5934046888095414:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 40.76it/s] loss:0.6380313676536609:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 40.76it/s]loss:0.6380313676536609: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 35.94it/s]
Epoch: 5 cost time: 1.0680584907531738
Epoch: 5, Steps: 19 | Train Loss: 0.0755268 Vali Loss: 3.2502890 Test Loss: 32.5107193
EarlyStopping counter: 1 out of 3
Updating learning rate to 6.25e-06
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 40.81it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 40.81it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 40.81it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 40.81it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 40.81it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 40.81it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 42.53it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 42.53it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 42.53it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 42.53it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 42.53it/s]loss:0.00015547911680811055:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 42.53it/s]loss:0.00015547911680811055:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 40.84it/s]loss:0.04031015740559705:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 40.84it/s]   loss:0.17352494593269058:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 40.84it/s]loss:0.5343378963155911:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 40.84it/s] loss:0.6327891570543558:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 40.84it/s]loss:0.6327891570543558: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 36.21it/s]
Epoch: 6 cost time: 1.143401861190796
Epoch: 6, Steps: 19 | Train Loss: 0.0726904 Vali Loss: 3.2506814 Test Loss: 32.5627060
EarlyStopping counter: 2 out of 3
Updating learning rate to 3.125e-06
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 40.55it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 40.55it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 40.55it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 40.55it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 40.55it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 40.55it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 40.26it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 40.26it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 40.26it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 40.26it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 40.26it/s]loss:0.00018825958356482228:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 40.26it/s]loss:0.00018825958356482228:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 40.33it/s]loss:0.03351033992819304:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 40.33it/s]   loss:0.17595492307211813:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 40.33it/s]loss:0.47072303103307267:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 40.33it/s]loss:0.5580299767395313:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 40.33it/s] loss:0.5580299767395313: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 36.07it/s]
Epoch: 7 cost time: 1.0175931453704834
Epoch: 7, Steps: 19 | Train Loss: 0.0651793 Vali Loss: 3.2504561 Test Loss: 32.5690041
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : long_term_forecast_break_parzen_0_Koopa_job_demand_r2_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 4
test shape: (4, 1, 3, 121420) (4, 1, 3, 121420)
test shape: (4, 3, 121420) (4, 3, 121420)
mse:13488.58984375, mae:6.373195648193359, dtw:-999
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           0                   Model:              Koopa               

[1mData Loader[0m
  Data:               job_demand_r2       Root Path:          ../../dataset/demand/
  Data Path:          r2.parquet          Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        .cache/checkpoints  

[1mForecasting Task[0m
  Seq Len:            6                   Label Len:          1                   
  Pred Len:           3                   Seasonal Patterns:  Monthly             
  Inverse:            1                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             121420              Dec In:             121420              
  C Out:              121420              d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           2                   d FF:               2048                
  Moving Avg:         25                  Factor:             1                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              learned             Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        32                  Itr:                1                   
  Train Epochs:       20                  Batch Size:         1                   
  Patience:           3                   Learning Rate:      0.0001              
  Des:                test                Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1                 

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
train 19
>>>>>>>start training : long_term_forecast_break_tukey-hanning_0_Koopa_job_demand_r2_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 19
val 1
test 4
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.78it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.78it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.78it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.78it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.78it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:06,  2.78it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:00, 15.50it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:00, 15.50it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:00, 15.50it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:00, 15.50it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:00, 15.50it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:00, 15.50it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 23.64it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 23.64it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 23.64it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 23.64it/s]loss:0.003499498167419271:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 23.64it/s]loss:0.12406705497605715:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 23.64it/s] loss:0.12406705497605715:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 28.98it/s]loss:0.3946518161148569:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 28.98it/s] loss:0.6498444031115956:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 28.98it/s]loss:0.8449296310189655:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 28.98it/s]loss:0.8449296310189655: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 22.22it/s]
Epoch: 1 cost time: 1.3280038833618164
Epoch: 1, Steps: 19 | Train Loss: 0.1061575 Vali Loss: 3.3667710 Test Loss: 33.4127083
Validation loss decreased (inf --> 3.366771).  Saving model ...
Updating learning rate to 0.0001
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 34.55it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 34.55it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 34.55it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 34.55it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 34.55it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 36.29it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 36.29it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 36.29it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 36.29it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 36.29it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 36.72it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 36.72it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 36.72it/s]loss:0.004377092801090017:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 36.72it/s]loss:0.12138827795810815:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 36.72it/s] loss:0.12138827795810815:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 37.33it/s]loss:0.3916804261631252:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 37.33it/s] loss:0.5860162972311246:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 37.33it/s]loss:0.7818560810108744:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 37.33it/s]loss:0.7818560810108744: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 33.03it/s]
Epoch: 2 cost time: 1.1146769523620605
Epoch: 2, Steps: 19 | Train Loss: 0.0992273 Vali Loss: 3.3499506 Test Loss: 30.7052631
Validation loss decreased (3.366771 --> 3.349951).  Saving model ...
Updating learning rate to 5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 37.76it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 37.76it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 37.76it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 37.76it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 37.76it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 37.74it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 37.74it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 37.74it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 37.74it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 37.74it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 37.72it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 37.72it/s]loss:0.004691195285752762:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 37.72it/s]loss:0.15848469188679887:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 37.72it/s] loss:0.4649859959760374:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 37.72it/s] loss:0.4649859959760374:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 37.24it/s]loss:0.6546174969567935:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 37.24it/s]loss:0.8221956321088976:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 37.24it/s]loss:0.8221956321088976: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 33.62it/s]
Epoch: 3 cost time: 1.158505916595459
Epoch: 3, Steps: 19 | Train Loss: 0.1107882 Vali Loss: 3.3511832 Test Loss: 31.1956177
EarlyStopping counter: 1 out of 3
Updating learning rate to 2.5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 40.04it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 40.04it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 40.04it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 40.04it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 40.04it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 40.04it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 40.71it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 40.71it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 40.71it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 40.71it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 40.71it/s]loss:0.004410052390368038:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 40.71it/s]loss:0.004410052390368038:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 40.04it/s]loss:0.13925444284444588:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 40.04it/s] loss:0.4259470799981418:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 40.04it/s] loss:0.7144648105883462:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 40.04it/s]loss:0.6544362256881748:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 40.04it/s]loss:0.6544362256881748: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 36.35it/s]
Epoch: 4 cost time: 1.008521318435669
Epoch: 4, Steps: 19 | Train Loss: 0.1020270 Vali Loss: 3.3136756 Test Loss: 31.3130646
Validation loss decreased (3.349951 --> 3.313676).  Saving model ...
Updating learning rate to 1.25e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 36.57it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 36.57it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 36.57it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 36.57it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 36.57it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 36.57it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 40.89it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 40.89it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 40.89it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 40.89it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 40.89it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 40.89it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 43.73it/s]loss:0.004132784324157608:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 43.73it/s]loss:0.13141892595212687:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 43.73it/s] loss:0.32448170321396025:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 43.73it/s]loss:0.6928735123104218:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 43.73it/s] loss:0.6768754385416892:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 43.73it/s]loss:0.6768754385416892: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 44.33it/s]loss:0.6768754385416892: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 38.16it/s]
Epoch: 5 cost time: 1.0355870723724365
Epoch: 5, Steps: 19 | Train Loss: 0.0963043 Vali Loss: 3.3042572 Test Loss: 31.3884125
Validation loss decreased (3.313676 --> 3.304257).  Saving model ...
Updating learning rate to 6.25e-06
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 40.62it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 40.62it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 40.62it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 40.62it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 40.62it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 40.62it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 44.47it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 44.47it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 44.47it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 44.47it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 44.47it/s]loss:0.004068784114301391:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 44.47it/s]loss:0.004068784114301391:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 43.64it/s]loss:0.1507371137399782:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 43.64it/s]  loss:0.33742793309959546:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 43.64it/s]loss:0.6721287441189467:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 43.64it/s] loss:0.6018549824190869:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 43.64it/s]loss:0.6018549824190869: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 38.03it/s]
Epoch: 6 cost time: 1.0273430347442627
Epoch: 6, Steps: 19 | Train Loss: 0.0929588 Vali Loss: 3.3003328 Test Loss: 31.4213676
Validation loss decreased (3.304257 --> 3.300333).  Saving model ...
Updating learning rate to 3.125e-06
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 36.47it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 36.47it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 36.47it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 36.47it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 36.47it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 36.47it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 43.17it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 43.17it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 43.17it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 43.17it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 43.17it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 43.17it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 44.96it/s]loss:0.004471972683392666:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 44.96it/s]loss:0.14373743292753155:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 44.96it/s] loss:0.33452821712130887:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 44.96it/s]loss:0.577588920836145:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 44.96it/s]  loss:0.6280925672030677:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 44.96it/s]loss:0.6280925672030677: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 45.59it/s]loss:0.6280925672030677: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 40.25it/s]
Epoch: 7 cost time: 0.9954423904418945
Epoch: 7, Steps: 19 | Train Loss: 0.0888642 Vali Loss: 3.2978063 Test Loss: 31.4403763
Validation loss decreased (3.300333 --> 3.297806).  Saving model ...
Updating learning rate to 1.5625e-06
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 36.32it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 36.32it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 36.32it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 36.32it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 36.32it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 36.32it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 42.18it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 42.18it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 42.18it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 42.18it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 42.18it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 42.18it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 44.26it/s]loss:0.0036053232596401745:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 44.26it/s]loss:0.11353745923418247:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 44.26it/s]  loss:0.3911572509608547:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 44.26it/s] loss:0.6947821804870119:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 44.26it/s]loss:0.6026260281107432:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 44.26it/s]loss:0.6026260281107432: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 45.82it/s]loss:0.6026260281107432: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 39.89it/s]
Epoch: 8 cost time: 1.0697431564331055
Epoch: 8, Steps: 19 | Train Loss: 0.0950373 Vali Loss: 3.2972713 Test Loss: 31.4453793
Validation loss decreased (3.297806 --> 3.297271).  Saving model ...
Updating learning rate to 7.8125e-07
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 41.38it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 41.38it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 41.38it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 41.38it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 41.38it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 41.38it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 40.82it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 40.82it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 40.82it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 40.82it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 40.82it/s]loss:0.0041326268709706996:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 40.82it/s]loss:0.0041326268709706996:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 38.57it/s]loss:0.15083561178111696:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 38.57it/s]  loss:0.4245733737430804:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 38.57it/s] loss:0.5637935885068853:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 38.57it/s]loss:0.7253372536971433:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 38.57it/s]loss:0.7253372536971433: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 37.80it/s]loss:0.7253372536971433: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 34.71it/s]
Epoch: 9 cost time: 1.1462454795837402
Epoch: 9, Steps: 19 | Train Loss: 0.0983512 Vali Loss: 3.2971563 Test Loss: 31.4467621
Validation loss decreased (3.297271 --> 3.297156).  Saving model ...
Updating learning rate to 3.90625e-07
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 38.94it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 38.94it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 38.94it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 38.94it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 38.94it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 38.94it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 40.35it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 40.35it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 40.35it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 40.35it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 40.35it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 40.35it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 40.27it/s]loss:0.0035011893844705344:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 40.27it/s]loss:0.11327505825798612:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 40.27it/s]  loss:0.4282140238144214:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 40.27it/s] loss:0.6238443486566208:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 40.27it/s]loss:0.800149798825883:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 40.27it/s] loss:0.800149798825883: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 39.91it/s]loss:0.800149798825883: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 36.18it/s]
Epoch: 10 cost time: 1.148871660232544
Epoch: 10, Steps: 19 | Train Loss: 0.1036308 Vali Loss: 3.2970338 Test Loss: 31.4465961
Validation loss decreased (3.297156 --> 3.297034).  Saving model ...
Updating learning rate to 1.953125e-07
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 39.85it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 39.85it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 39.85it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 39.85it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 39.85it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 38.25it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 38.25it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 38.25it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 38.25it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 38.25it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 38.25it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 39.62it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 39.62it/s]loss:0.004529526760752214:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 39.62it/s]loss:0.12424758329302737:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 39.62it/s] loss:0.389449889798464:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 39.62it/s]  loss:0.5351623417225598:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 39.62it/s]loss:0.5351623417225598:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:00<00:00, 40.31it/s]loss:0.6382468912487097:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:00<00:00, 40.31it/s]loss:0.6382468912487097: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 35.65it/s]
Epoch: 11 cost time: 1.090907096862793
Epoch: 11, Steps: 19 | Train Loss: 0.0890335 Vali Loss: 3.2970097 Test Loss: 31.4470673
Validation loss decreased (3.297034 --> 3.297010).  Saving model ...
Updating learning rate to 9.765625e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 38.02it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 38.02it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 38.02it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 38.02it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 38.02it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 38.02it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 38.97it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 38.97it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 38.97it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 38.97it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 38.97it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 37.75it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 37.75it/s]loss:0.003656824893031732:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 37.75it/s]loss:0.1194746823662551:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 37.75it/s]  loss:0.38919423173571216:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 37.75it/s]loss:0.38919423173571216:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 36.82it/s]loss:0.6899648736892551:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 36.82it/s] loss:0.6458426071419711:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 36.82it/s]loss:0.6458426071419711: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 33.43it/s]
Epoch: 12 cost time: 1.077329158782959
Epoch: 12, Steps: 19 | Train Loss: 0.0972702 Vali Loss: 3.2969949 Test Loss: 31.4475632
Validation loss decreased (3.297010 --> 3.296995).  Saving model ...
Updating learning rate to 4.8828125e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 39.63it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 39.63it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 39.63it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 39.63it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 39.63it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 39.30it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 39.30it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 39.30it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 39.30it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 39.30it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 37.97it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 37.97it/s]loss:0.004413389567245221:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 37.97it/s]loss:0.11326977179364801:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 37.97it/s] loss:0.3895783457450149:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:00<00:00, 37.97it/s] loss:0.3895783457450149:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 36.84it/s]loss:0.5592279502202597:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 36.84it/s]loss:0.7921448123423581:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 36.84it/s]loss:0.7921448123423581: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 34.11it/s]
Epoch: 13 cost time: 1.1035141944885254
Epoch: 13, Steps: 19 | Train Loss: 0.0978229 Vali Loss: 3.2969816 Test Loss: 31.4475288
Validation loss decreased (3.296995 --> 3.296982).  Saving model ...
Updating learning rate to 2.44140625e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 39.15it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 39.15it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 39.15it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 39.15it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 39.15it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 39.15it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 42.69it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 42.69it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 42.69it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 42.69it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 42.69it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 42.69it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 44.26it/s]loss:0.0036974137911958255:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 44.26it/s]loss:0.1437711733356625:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 44.26it/s]   loss:0.4221289083268985:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 44.26it/s]loss:0.567830071399514:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 44.26it/s] loss:0.7969833469502402:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 44.26it/s]loss:0.7969833469502402: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 44.29it/s]loss:0.7969833469502402: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 38.76it/s]
Epoch: 14 cost time: 1.0362060070037842
Epoch: 14, Steps: 19 | Train Loss: 0.1018111 Vali Loss: 3.2969725 Test Loss: 31.4475098
Validation loss decreased (3.296982 --> 3.296973).  Saving model ...
Updating learning rate to 1.220703125e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 42.30it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 42.30it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 42.30it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 42.30it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 42.30it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 42.30it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 45.89it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 45.89it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 45.89it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 45.89it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 45.89it/s]loss:0.0036902124049964795:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 45.89it/s]loss:0.0036902124049964795:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 46.87it/s]loss:0.12635090890834377:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 46.87it/s]  loss:0.3323758355078921:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 46.87it/s] loss:0.6769668932810519:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 46.87it/s]loss:0.6447702611577203:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 46.87it/s]loss:0.6447702611577203: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 41.49it/s]
Epoch: 15 cost time: 0.9843862056732178
Epoch: 15, Steps: 19 | Train Loss: 0.0939028 Vali Loss: 3.2969689 Test Loss: 31.4475403
Validation loss decreased (3.296973 --> 3.296969).  Saving model ...
Updating learning rate to 6.103515625e-09
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 39.45it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 39.45it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 39.45it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 39.45it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 39.45it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 39.45it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 40.13it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 40.13it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 40.13it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 40.13it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 40.13it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 40.13it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 40.70it/s]loss:0.00336578764257691:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 40.70it/s]loss:0.1214483520798286:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 40.70it/s] loss:0.3213140784268444:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 40.70it/s]loss:0.6839905561165527:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 40.70it/s]loss:0.8001278999585534:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 40.70it/s]loss:0.8001278999585534: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 39.15it/s]loss:0.8001278999585534: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 35.47it/s]
Epoch: 16 cost time: 1.091719388961792
Epoch: 16, Steps: 19 | Train Loss: 0.1015919 Vali Loss: 3.2969682 Test Loss: 31.4475403
Validation loss decreased (3.296969 --> 3.296968).  Saving model ...
Updating learning rate to 3.0517578125e-09
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 40.52it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 40.52it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 40.52it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 40.52it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 40.52it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 40.52it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 42.91it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 42.91it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 42.91it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 42.91it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 42.91it/s]loss:0.004132943953940573:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 42.91it/s]loss:0.004132943953940573:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 39.60it/s]loss:0.1503548825812437:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 39.60it/s]  loss:0.3347871284846188:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 39.60it/s]loss:0.5682460653640048:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 39.60it/s]loss:0.6719218135717131:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 39.60it/s]loss:0.6719218135717131: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 37.37it/s]
Epoch: 17 cost time: 1.0480334758758545
Epoch: 17, Steps: 19 | Train Loss: 0.0910233 Vali Loss: 3.2969682 Test Loss: 31.4475403
Validation loss decreased (3.296968 --> 3.296968).  Saving model ...
Updating learning rate to 1.52587890625e-09
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 39.52it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 39.52it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 39.52it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 39.52it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 39.52it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 39.52it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 41.13it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 41.13it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 41.13it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 41.13it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 41.13it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 41.13it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 40.96it/s]loss:0.003960259938839746:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 40.96it/s]loss:0.1134292050058205:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 40.96it/s]  loss:0.3503429667900198:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 40.96it/s]loss:0.6779910737038632:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 40.96it/s]loss:0.5947900140546787:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 40.96it/s]loss:0.5947900140546787: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 39.22it/s]loss:0.5947900140546787: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 35.79it/s]
Epoch: 18 cost time: 1.0889077186584473
Epoch: 18, Steps: 19 | Train Loss: 0.0916060 Vali Loss: 3.2969682 Test Loss: 31.4475403
Validation loss decreased (3.296968 --> 3.296968).  Saving model ...
Updating learning rate to 7.62939453125e-10
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 40.76it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 40.76it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 40.76it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 40.76it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 40.76it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 40.76it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 39.54it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 39.54it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 39.54it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 39.54it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 39.54it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 37.41it/s]loss:0.00413005093917395:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 37.41it/s]loss:0.11324871228449622:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 37.41it/s]loss:0.323510285531464:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 37.41it/s]  loss:0.5643481371124539:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 37.41it/s]loss:0.5643481371124539:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:00<00:00, 37.25it/s]loss:0.6297716898090027:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:00<00:00, 37.25it/s]loss:0.6297716898090027: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 33.84it/s]
Epoch: 19 cost time: 1.1191084384918213
Epoch: 19, Steps: 19 | Train Loss: 0.0860531 Vali Loss: 3.2969677 Test Loss: 31.4475403
Validation loss decreased (3.296968 --> 3.296968).  Saving model ...
Updating learning rate to 3.814697265625e-10
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 35.50it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 35.50it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 35.50it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 35.50it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 35.50it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 35.50it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 38.93it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 38.93it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 38.93it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 38.93it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 38.93it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 38.93it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 40.67it/s]loss:0.003986555648218631:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 40.67it/s]loss:0.12359054536319185:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 40.67it/s] loss:0.3976849924301481:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 40.67it/s] loss:0.6846821100049041:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 40.67it/s]loss:0.6001342667641593:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 40.67it/s]loss:0.6001342667641593: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 41.01it/s]loss:0.6001342667641593: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 36.37it/s]
Epoch: 20 cost time: 1.1615114212036133
Epoch: 20, Steps: 19 | Train Loss: 0.0952673 Vali Loss: 3.2969677 Test Loss: 31.4475403
Validation loss decreased (3.296968 --> 3.296968).  Saving model ...
Updating learning rate to 1.9073486328125e-10
>>>>>>>testing : long_term_forecast_break_tukey-hanning_0_Koopa_job_demand_r2_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 4
test shape: (4, 1, 3, 121420) (4, 1, 3, 121420)
test shape: (4, 3, 121420) (4, 3, 121420)
mse:14351.8984375, mae:6.427217483520508, dtw:-999
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           0                   Model:              Koopa               

[1mData Loader[0m
  Data:               job_demand_r2       Root Path:          ../../dataset/demand/
  Data Path:          r2.parquet          Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        .cache/checkpoints  

[1mForecasting Task[0m
  Seq Len:            6                   Label Len:          1                   
  Pred Len:           3                   Seasonal Patterns:  Monthly             
  Inverse:            1                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             121420              Dec In:             121420              
  C Out:              121420              d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           2                   d FF:               2048                
  Moving Avg:         25                  Factor:             1                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              learned             Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        32                  Itr:                1                   
  Train Epochs:       20                  Batch Size:         1                   
  Patience:           3                   Learning Rate:      0.0001              
  Des:                test                Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1                 

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
train 19
>>>>>>>start training : long_term_forecast_break_rayleigh_0_Koopa_job_demand_r2_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 19
val 1
test 4
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.27117196563154905:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.27117196563154905:   5%|â–Œ         | 1/19 [00:00<00:06,  2.83it/s]loss:0.3164058810832295:   5%|â–Œ         | 1/19 [00:00<00:06,  2.83it/s] loss:0.4146063571322278:   5%|â–Œ         | 1/19 [00:00<00:06,  2.83it/s]loss:0.4379154055677093:   5%|â–Œ         | 1/19 [00:00<00:06,  2.83it/s]loss:0.5109208028070659:   5%|â–Œ         | 1/19 [00:00<00:06,  2.83it/s]loss:0.3699830718412863:   5%|â–Œ         | 1/19 [00:00<00:06,  2.83it/s]loss:0.3699830718412863:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:00, 15.61it/s]loss:0.530387956183851:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:00, 15.61it/s] loss:0.5015903334169216:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:00, 15.61it/s]loss:0.5595217158545298:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:00, 15.61it/s]loss:0.5190741780182156:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:00, 15.61it/s]loss:0.5190741780182156:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 22.24it/s]loss:0.5344017862169961:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 22.24it/s]loss:0.6429339847612949:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 22.24it/s]loss:0.5921447256316071:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 22.24it/s]loss:0.6709609381019929:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 22.24it/s]loss:0.6709609381019929:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 27.03it/s]loss:0.6231084229275089:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 27.03it/s]loss:0.6508027889140213:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 27.03it/s]loss:0.7085913779909896:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 27.03it/s]loss:0.7610730378556653:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 27.03it/s]loss:0.7610730378556653:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:00<00:00, 30.67it/s]loss:0.8271090875047656:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:00<00:00, 30.67it/s]loss:0.8271090875047656: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 22.25it/s]
Epoch: 1 cost time: 1.3034696578979492
Epoch: 1, Steps: 19 | Train Loss: 0.5496160 Vali Loss: 3.2741075 Test Loss: 32.8136940
Validation loss decreased (inf --> 3.274107).  Saving model ...
Updating learning rate to 0.0001
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.29106100573793814:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.3562396090849489:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.40537295766541437:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.3787899176266737:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.3787899176266737:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 38.35it/s]loss:0.427232322858861:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 38.35it/s] loss:0.4058145926946026:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 38.35it/s]loss:0.5200738216477631:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 38.35it/s]loss:0.5309586015975356:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 38.35it/s]loss:0.5867013100707814:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 38.35it/s]loss:0.5867013100707814:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 41.82it/s]loss:0.6599756681765845:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 41.82it/s]loss:0.5027890557038246:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 41.82it/s]loss:0.5924790577791121:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 41.82it/s]loss:0.7017217772196609:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 41.82it/s]loss:0.6108584700653023:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 41.82it/s]loss:0.6108584700653023:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 43.96it/s]loss:0.5994579739251804:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 43.96it/s]loss:0.6342600060401159:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 43.96it/s]loss:0.5424688422261875:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 43.96it/s]loss:0.5784754907933992:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 43.96it/s]loss:0.8349133639264992:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 43.96it/s]loss:0.8349133639264992: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 44.23it/s]loss:0.8349133639264992: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 38.56it/s]
Epoch: 2 cost time: 1.0338208675384521
Epoch: 2, Steps: 19 | Train Loss: 0.5347181 Vali Loss: 3.2742372 Test Loss: 31.5856514
EarlyStopping counter: 1 out of 3
Updating learning rate to 5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.2746753882583896:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.2795453773469508:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.3266779201808445:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.4590591058551356:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.39535724575517556:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.39535724575517556:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 42.21it/s]loss:0.5065967547207405:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 42.21it/s] loss:0.5664644386623379:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 42.21it/s]loss:0.509419118510698:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 42.21it/s] loss:0.423340906598837:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 42.21it/s]loss:0.5165678629873615:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:00, 42.21it/s]loss:0.5165678629873615:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 42.97it/s]loss:0.5433369820157161:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 42.97it/s]loss:0.5866686029206273:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 42.97it/s]loss:0.5317868478401538:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 42.97it/s]loss:0.6084839901782253:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 42.97it/s]loss:0.6956091355773213:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 42.97it/s]loss:0.6956091355773213:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 43.21it/s]loss:0.7093700568501409:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 43.21it/s]loss:0.7492651895694068:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 43.21it/s]loss:0.7482967239791349:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 43.21it/s]loss:0.7159979852683427:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:00<00:00, 43.21it/s]loss:0.7159979852683427: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 39.09it/s]
Epoch: 3 cost time: 1.0607588291168213
Epoch: 3, Steps: 19 | Train Loss: 0.5340273 Vali Loss: 3.2817774 Test Loss: 32.3200798
EarlyStopping counter: 2 out of 3
Updating learning rate to 2.5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.3580532500132943:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.3033627310215253:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.34933258150256524:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.35212079598568197:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.35212079598568197:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 38.35it/s]loss:0.4560451344561869:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 38.35it/s] loss:0.41143732905798003:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 38.35it/s]loss:0.4305442770512098:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 38.35it/s] loss:0.5089437731644104:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 38.35it/s]loss:0.5597349756140729:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 38.35it/s]loss:0.5597349756140729:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 40.43it/s]loss:0.5228699830442174:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 40.43it/s]loss:0.4871692168290759:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 40.43it/s]loss:0.5102448751696225:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 40.43it/s]loss:0.6884150888180525:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 40.43it/s]loss:0.608126997819149:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 40.43it/s] loss:0.608126997819149:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 42.07it/s]loss:0.6866784685991755:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 42.07it/s]loss:0.7678641317077011:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 42.07it/s]loss:0.7147619983301843:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 42.07it/s]loss:0.7760116020283006:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 42.07it/s]loss:0.5422947851634228:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:00<00:00, 42.07it/s]loss:0.5422947851634228: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 41.23it/s]loss:0.5422947851634228: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 36.71it/s]
Epoch: 4 cost time: 1.100966215133667
Epoch: 4, Steps: 19 | Train Loss: 0.5281059 Vali Loss: 3.2800448 Test Loss: 32.2387352
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : long_term_forecast_break_rayleigh_0_Koopa_job_demand_r2_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 4
test shape: (4, 1, 3, 121420) (4, 1, 3, 121420)
test shape: (4, 3, 121420) (4, 3, 121420)
mse:14249.49609375, mae:6.395132064819336, dtw:-999
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           0                   Model:              DLinear             

[1mData Loader[0m
  Data:               job_demand_r2       Root Path:          ../../dataset/demand/
  Data Path:          r2.parquet          Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        .cache/checkpoints  

[1mForecasting Task[0m
  Seq Len:            6                   Label Len:          1                   
  Pred Len:           3                   Seasonal Patterns:  Monthly             
  Inverse:            1                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             121420              Dec In:             121420              
  C Out:              121420              d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           2                   d FF:               2048                
  Moving Avg:         25                  Factor:             1                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              learned             Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        32                  Itr:                1                   
  Train Epochs:       20                  Batch Size:         1                   
  Patience:           3                   Learning Rate:      0.0001              
  Des:                test                Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1                 

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_break_bartlett_0_DLinear_job_demand_r2_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 19
val 1
test 4
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:07,  2.31it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:07,  2.31it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:07,  2.31it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:07,  2.31it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:07,  2.31it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:07,  2.31it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:07,  2.31it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:07,  2.31it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:07,  2.31it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:07,  2.31it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:07,  2.31it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:07,  2.31it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:07,  2.31it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:07,  2.31it/s]loss:0.033126535698950924:   5%|â–Œ         | 1/19 [00:00<00:07,  2.31it/s]loss:0.21637599265509708:   5%|â–Œ         | 1/19 [00:00<00:07,  2.31it/s] loss:0.338461928496884:   5%|â–Œ         | 1/19 [00:00<00:07,  2.31it/s]  loss:0.6185313664469304:   5%|â–Œ         | 1/19 [00:00<00:07,  2.31it/s]loss:0.7543036664166249:   5%|â–Œ         | 1/19 [00:00<00:07,  2.31it/s]loss:0.7543036664166249: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 34.74it/s]
Epoch: 1 cost time: 1.0494897365570068
Epoch: 1, Steps: 19 | Train Loss: 0.1032000 Vali Loss: 3.2155757 Test Loss: 30.7519569
Validation loss decreased (inf --> 3.215576).  Saving model ...
Updating learning rate to 0.0001
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.03857190711960231:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.18240102911776626:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.39571261060726837:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.504059176561108:   0%|          | 0/19 [00:00<?, ?it/s]  loss:0.7337858114831215:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7337858114831215: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 146.71it/s]
Epoch: 2 cost time: 0.5984170436859131
Epoch: 2, Steps: 19 | Train Loss: 0.0976069 Vali Loss: 3.2140007 Test Loss: 30.7597733
Validation loss decreased (3.215576 --> 3.214001).  Saving model ...
Updating learning rate to 5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.030951686538198967:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.197949607533007:   0%|          | 0/19 [00:00<?, ?it/s]   loss:0.3839683278532681:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5728448611873735:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7364234126871957:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7364234126871957: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 148.58it/s]
Epoch: 3 cost time: 0.5972621440887451
Epoch: 3, Steps: 19 | Train Loss: 0.1011652 Vali Loss: 3.2133636 Test Loss: 30.7669029
Validation loss decreased (3.214001 --> 3.213364).  Saving model ...
Updating learning rate to 2.5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.03621658668883864:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.1820027600039384:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.3458680213653936:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5509838303535131:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6227945342396772:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6227945342396772: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 182.01it/s]
Epoch: 4 cost time: 0.5590758323669434
Epoch: 4, Steps: 19 | Train Loss: 0.0914666 Vali Loss: 3.2130535 Test Loss: 30.7712288
Validation loss decreased (3.213364 --> 3.213053).  Saving model ...
Updating learning rate to 1.25e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0291596829824523:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.2065682569783572:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.33649085349767827:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.44270801554593636:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7538828406349566:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.7538828406349566: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 157.37it/s]
Epoch: 5 cost time: 0.5793194770812988
Epoch: 5, Steps: 19 | Train Loss: 0.0930952 Vali Loss: 3.2129064 Test Loss: 30.7713165
Validation loss decreased (3.213053 --> 3.212906).  Saving model ...
Updating learning rate to 6.25e-06
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.030906872906641878:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.18189303843013255:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.3456836241679588:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.48933670144110275:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6590271920349051:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.6590271920349051: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 158.46it/s]
Epoch: 6 cost time: 0.5588874816894531
Epoch: 6, Steps: 19 | Train Loss: 0.0898341 Vali Loss: 3.2128282 Test Loss: 30.7720470
Validation loss decreased (3.212906 --> 3.212828).  Saving model ...
Updating learning rate to 3.125e-06
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.034868914481062774:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.1882764505377176:   0%|          | 0/19 [00:00<?, ?it/s]  loss:0.372502793385974:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.5604510967202964:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7228150191995429:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7228150191995429: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 155.36it/s]
Epoch: 7 cost time: 0.6272268295288086
Epoch: 7, Steps: 19 | Train Loss: 0.0988902 Vali Loss: 3.2127869 Test Loss: 30.7723560
Validation loss decreased (3.212828 --> 3.212787).  Saving model ...
Updating learning rate to 1.5625e-06
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.035891018809421006:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.1882660725361149:   0%|          | 0/19 [00:00<?, ?it/s]  loss:0.34563714924675276:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5271468246319944:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.612167435871819:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.612167435871819: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 139.53it/s]
Epoch: 8 cost time: 0.6140625476837158
Epoch: 8, Steps: 19 | Train Loss: 0.0899531 Vali Loss: 3.2127657 Test Loss: 30.7725563
Validation loss decreased (3.212787 --> 3.212766).  Saving model ...
Updating learning rate to 7.8125e-07
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.027659148725739827:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.17490188704103385:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.39479414029172033:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.4892517933283249:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.7111005838595077:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7111005838595077: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 134.54it/s]
Epoch: 9 cost time: 0.5966708660125732
Epoch: 9, Steps: 19 | Train Loss: 0.0946162 Vali Loss: 3.2127588 Test Loss: 30.7726822
Validation loss decreased (3.212766 --> 3.212759).  Saving model ...
Updating learning rate to 3.90625e-07
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.03486681720948915:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.16595277562266916:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.3363567907119064:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.4944139803227131:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6589057548863647:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6589057548863647: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 159.21it/s]
Epoch: 10 cost time: 0.5627131462097168
Epoch: 10, Steps: 19 | Train Loss: 0.0889735 Vali Loss: 3.2127542 Test Loss: 30.7727318
Validation loss decreased (3.212759 --> 3.212754).  Saving model ...
Updating learning rate to 1.953125e-07
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.03386151639055565:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.17782548274244683:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.3399076171205835:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.5551796960933221:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.580830400577064:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.580830400577064: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 163.93it/s]
Epoch: 11 cost time: 0.5830626487731934
Epoch: 11, Steps: 19 | Train Loss: 0.0888213 Vali Loss: 3.2127512 Test Loss: 30.7727528
Validation loss decreased (3.212754 --> 3.212751).  Saving model ...
Updating learning rate to 9.765625e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.030935770507802437:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.17489870773881294:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.3947880206223534:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.5271266768931545:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6365006924907494:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6365006924907494: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 149.24it/s]
Epoch: 12 cost time: 0.644538402557373
Epoch: 12, Steps: 19 | Train Loss: 0.0928553 Vali Loss: 3.2127502 Test Loss: 30.7727661
Validation loss decreased (3.212751 --> 3.212750).  Saving model ...
Updating learning rate to 4.8828125e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.03469862131061029:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.2171035485435666:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.33340471505074454:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5506809349053148:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.7510045825826372:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7510045825826372: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 170.10it/s]
Epoch: 13 cost time: 0.6007769107818604
Epoch: 13, Steps: 19 | Train Loss: 0.0993101 Vali Loss: 3.2127497 Test Loss: 30.7727661
Validation loss decreased (3.212750 --> 3.212750).  Saving model ...
Updating learning rate to 2.44140625e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.034417541706630465:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.17782461866457464:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.3402928106701155:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.5604076496409349:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7286705472312773:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7286705472312773: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 158.27it/s]
Epoch: 14 cost time: 0.6081171035766602
Epoch: 14, Steps: 19 | Train Loss: 0.0969270 Vali Loss: 3.2127495 Test Loss: 30.7727661
Validation loss decreased (3.212750 --> 3.212749).  Saving model ...
Updating learning rate to 1.220703125e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.031420262142173944:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.1854031696157997:   0%|          | 0/19 [00:00<?, ?it/s]  loss:0.37247502983836217:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.4663956360320573:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.6364993459689043:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6364993459689043: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 158.25it/s]
Epoch: 15 cost time: 0.590972900390625
Epoch: 15, Steps: 19 | Train Loss: 0.0890628 Vali Loss: 3.2127495 Test Loss: 30.7727699
Validation loss decreased (3.212749 --> 3.212749).  Saving model ...
Updating learning rate to 6.103515625e-09
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.030309491061596014:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.16595071498951397:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.33990578588889114:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5020176722512328:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.8079040636483483:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8079040636483483: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 155.62it/s]
Epoch: 16 cost time: 0.5770101547241211
Epoch: 16, Steps: 19 | Train Loss: 0.0971625 Vali Loss: 3.2127492 Test Loss: 30.7727699
Validation loss decreased (3.212749 --> 3.212749).  Saving model ...
Updating learning rate to 3.0517578125e-09
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.029637429851676753:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.18185694555955004:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.3947873057560988:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.4944084132748682:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6918523584436075:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6918523584436075: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 152.94it/s]
Epoch: 17 cost time: 0.5692229270935059
Epoch: 17, Steps: 19 | Train Loss: 0.0943443 Vali Loss: 3.2127492 Test Loss: 30.7727699
Validation loss decreased (3.212749 --> 3.212749).  Saving model ...
Updating learning rate to 1.52587890625e-09
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.032945350402083476:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.18346509679994472:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.3835318823764564:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.5789420912878114:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6364993092798051:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6364993092798051: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 163.13it/s]
Epoch: 18 cost time: 0.6277501583099365
Epoch: 18, Steps: 19 | Train Loss: 0.0955465 Vali Loss: 3.2127492 Test Loss: 30.7727699
Validation loss decreased (3.212749 --> 3.212749).  Saving model ...
Updating learning rate to 7.62939453125e-10
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.03469859152448543:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.1854031548564411:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.36239885445224174:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.4741988777098058:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.7355348610627842:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7355348610627842: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 159.48it/s]
Epoch: 19 cost time: 0.5649595260620117
Epoch: 19, Steps: 19 | Train Loss: 0.0943281 Vali Loss: 3.2127492 Test Loss: 30.7727699
Validation loss decreased (3.212749 --> 3.212749).  Saving model ...
Updating learning rate to 3.814697265625e-10
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.03142025988092978:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.17782457914117714:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.34029271838398073:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5721935750270356:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.7110886486789738:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7110886486789738: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 153.10it/s]
Epoch: 20 cost time: 0.5913746356964111
Epoch: 20, Steps: 19 | Train Loss: 0.0964642 Vali Loss: 3.2127492 Test Loss: 30.7727699
Validation loss decreased (3.212749 --> 3.212749).  Saving model ...
Updating learning rate to 1.9073486328125e-10
>>>>>>>testing : long_term_forecast_break_bartlett_0_DLinear_job_demand_r2_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 4
test shape: (4, 1, 3, 121420) (4, 1, 3, 121420)
test shape: (4, 3, 121420) (4, 3, 121420)
mse:12613.484375, mae:6.192760467529297, dtw:-999
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           0                   Model:              DLinear             

[1mData Loader[0m
  Data:               job_demand_r2       Root Path:          ../../dataset/demand/
  Data Path:          r2.parquet          Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        .cache/checkpoints  

[1mForecasting Task[0m
  Seq Len:            6                   Label Len:          1                   
  Pred Len:           3                   Seasonal Patterns:  Monthly             
  Inverse:            1                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             121420              Dec In:             121420              
  C Out:              121420              d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           2                   d FF:               2048                
  Moving Avg:         25                  Factor:             1                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              learned             Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        32                  Itr:                1                   
  Train Epochs:       20                  Batch Size:         1                   
  Patience:           3                   Learning Rate:      0.0001              
  Des:                test                Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1                 

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_break_parzen_0_DLinear_job_demand_r2_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 19
val 1
test 4
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.12it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.12it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.12it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.12it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.12it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.12it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.12it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.12it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.12it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.12it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.12it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.12it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.12it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.12it/s]loss:0.00015023372199070604:   5%|â–Œ         | 1/19 [00:00<00:08,  2.12it/s]loss:0.035326716197670506:   5%|â–Œ         | 1/19 [00:00<00:08,  2.12it/s]  loss:0.18566666365092654:   5%|â–Œ         | 1/19 [00:00<00:08,  2.12it/s] loss:0.6014622511907534:   5%|â–Œ         | 1/19 [00:00<00:08,  2.12it/s] loss:0.7543526468904467:   5%|â–Œ         | 1/19 [00:00<00:08,  2.12it/s]loss:0.7543526468904467: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 32.10it/s]
Epoch: 1 cost time: 1.0909993648529053
Epoch: 1, Steps: 19 | Train Loss: 0.0829978 Vali Loss: 3.2156231 Test Loss: 30.7511501
Validation loss decreased (inf --> 3.215623).  Saving model ...
Updating learning rate to 0.0001
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.00017497232117534922:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.029787255919756096:   0%|          | 0/19 [00:00<?, ?it/s]  loss:0.21712532077904753:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.49028942837675854:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7340076300004799:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.7340076300004799: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 170.34it/s]
Epoch: 2 cost time: 0.5735747814178467
Epoch: 2, Steps: 19 | Train Loss: 0.0774413 Vali Loss: 3.2142572 Test Loss: 30.7587891
Validation loss decreased (3.215623 --> 3.214257).  Saving model ...
Updating learning rate to 5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.00014044672640256583:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.03233376639452557:   0%|          | 0/19 [00:00<?, ?it/s]   loss:0.2107044701122673:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.557280589176742:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.7368170056290018:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7368170056290018: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 147.78it/s]
Epoch: 3 cost time: 0.6085953712463379
Epoch: 3, Steps: 19 | Train Loss: 0.0809093 Vali Loss: 3.2137203 Test Loss: 30.7661934
Validation loss decreased (3.214257 --> 3.213720).  Saving model ...
Updating learning rate to 2.5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.000164379031433962:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.029733831593324777:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.18983649842709113:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.5360525509936032:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.6231574287557716:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6231574287557716: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 145.89it/s]
Epoch: 4 cost time: 0.6174259185791016
Epoch: 4, Steps: 19 | Train Loss: 0.0725760 Vali Loss: 3.2134478 Test Loss: 30.7701912
Validation loss decreased (3.213720 --> 3.213448).  Saving model ...
Updating learning rate to 1.25e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.00013232206420954942:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.033745071613252214:   0%|          | 0/19 [00:00<?, ?it/s]  loss:0.18472402096099516:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.43079129982655845:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7543241246058583:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.7543241246058583: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 151.15it/s]
Epoch: 5 cost time: 0.5972249507904053
Epoch: 5, Steps: 19 | Train Loss: 0.0738798 Vali Loss: 3.2133226 Test Loss: 30.7702522
Validation loss decreased (3.213448 --> 3.213323).  Saving model ...
Updating learning rate to 6.25e-06
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.00014027596253741567:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.029718891748737063:   0%|          | 0/19 [00:00<?, ?it/s]  loss:0.18975125070237248:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.4761981311517146:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.6595856872045776:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6595856872045776: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 134.14it/s]
Epoch: 6 cost time: 0.6161272525787354
Epoch: 6, Steps: 19 | Train Loss: 0.0713365 Vali Loss: 3.2132549 Test Loss: 30.7709999
Validation loss decreased (3.213323 --> 3.213255).  Saving model ...
Updating learning rate to 3.125e-06
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.00015822153936214124:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.03076528901695195:   0%|          | 0/19 [00:00<?, ?it/s]   loss:0.20446141023957404:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5453298784467053:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.7232626809591716:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7232626809591716: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 149.83it/s]
Epoch: 7 cost time: 0.586665153503418
Epoch: 7, Steps: 19 | Train Loss: 0.0791567 Vali Loss: 3.2132187 Test Loss: 30.7713318
Validation loss decreased (3.213255 --> 3.213219).  Saving model ...
Updating learning rate to 1.5625e-06
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0001628706569378335:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.030763891011149316:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.18972967925456075:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.5129343773096952:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.612557991870753:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.612557991870753: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 149.12it/s]
Epoch: 8 cost time: 0.6085329055786133
Epoch: 8, Steps: 19 | Train Loss: 0.0708499 Vali Loss: 3.2132008 Test Loss: 30.7715263
Validation loss decreased (3.213219 --> 3.213201).  Saving model ...
Updating learning rate to 7.8125e-07
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.00012553662831410944:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.028573660977904182:   0%|          | 0/19 [00:00<?, ?it/s]  loss:0.21669624522292275:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.4761257312777575:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.7115471999309876:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7115471999309876: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 160.43it/s]
Epoch: 9 cost time: 0.5536530017852783
Epoch: 9, Steps: 19 | Train Loss: 0.0754247 Vali Loss: 3.2131948 Test Loss: 30.7716427
Validation loss decreased (3.213201 --> 3.213195).  Saving model ...
Updating learning rate to 3.90625e-07
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.00015821333162324865:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.027115617971332315:   0%|          | 0/19 [00:00<?, ?it/s]  loss:0.184660807446398:   0%|          | 0/19 [00:00<?, ?it/s]   loss:0.48113733096473793:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6594800885974313:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.6594800885974313: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 156.35it/s]
Epoch: 10 cost time: 0.5789716243743896
Epoch: 10, Steps: 19 | Train Loss: 0.0711870 Vali Loss: 3.2131908 Test Loss: 30.7716789
Validation loss decreased (3.213195 --> 3.213191).  Saving model ...
Updating learning rate to 1.953125e-07
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0001536635995235941:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0290521767792575:   0%|          | 0/19 [00:00<?, ?it/s]   loss:0.1866054149987482:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5401900886455974:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5812875405323081:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5812875405323081: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 152.74it/s]
Epoch: 11 cost time: 0.593827486038208
Epoch: 11, Steps: 19 | Train Loss: 0.0703836 Vali Loss: 3.2131884 Test Loss: 30.7716980
Validation loss decreased (3.213191 --> 3.213188).  Saving model ...
Updating learning rate to 9.765625e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0001403965296990959:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.02857322838859083:   0%|          | 0/19 [00:00<?, ?it/s]  loss:0.21669332688379264:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5129173723840011:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.6369946249949252:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6369946249949252: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 144.62it/s]
Epoch: 12 cost time: 0.6077103614807129
Epoch: 12, Steps: 19 | Train Loss: 0.0734378 Vali Loss: 3.2131875 Test Loss: 30.7717075
Validation loss decreased (3.213188 --> 3.213187).  Saving model ...
Updating learning rate to 4.8828125e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.00015746642706822848:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.03547889342640538:   0%|          | 0/19 [00:00<?, ?it/s]   loss:0.1830299918983281:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.5357984748936013:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7514776687498026:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7514776687498026: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 146.83it/s]
Epoch: 13 cost time: 0.6514461040496826
Epoch: 13, Steps: 19 | Train Loss: 0.0792601 Vali Loss: 3.2131870 Test Loss: 30.7717094
Validation loss decreased (3.213187 --> 3.213187).  Saving model ...
Updating learning rate to 2.44140625e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.00015618664005781792:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.029052060704528947:   0%|          | 0/19 [00:00<?, ?it/s]  loss:0.029052060704528947:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 131.88it/s]loss:0.18679728391888734:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 131.88it/s] loss:0.5452931762745677:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 131.88it/s] loss:0.7291479119813707:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:00<00:00, 131.88it/s]loss:0.7291479119813707: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 91.47it/s] 
Epoch: 14 cost time: 0.6890654563903809
Epoch: 14, Steps: 19 | Train Loss: 0.0784446 Vali Loss: 3.2131867 Test Loss: 30.7717094
Validation loss decreased (3.213187 --> 3.213187).  Saving model ...
Updating learning rate to 1.220703125e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.00014259529916033753:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.030294317225725287:   0%|          | 0/19 [00:00<?, ?it/s]  loss:0.20444866132478462:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.4537977092174899:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.6369934837889052:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6369934837889052: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 165.43it/s]
Epoch: 15 cost time: 0.6096174716949463
Epoch: 15, Steps: 19 | Train Loss: 0.0697725 Vali Loss: 3.2131863 Test Loss: 30.7717094
Validation loss decreased (3.213187 --> 3.213186).  Saving model ...
Updating learning rate to 6.103515625e-09
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0001375647248559243:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.02711533814897642:   0%|          | 0/19 [00:00<?, ?it/s]  loss:0.1866045713996514:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.48857003348697864:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8084418484664745:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.8084418484664745: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 161.15it/s]
Epoch: 16 cost time: 0.6192643642425537
Epoch: 16, Steps: 19 | Train Loss: 0.0795194 Vali Loss: 3.2131863 Test Loss: 30.7717094
Validation loss decreased (3.213186 --> 3.213186).  Saving model ...
Updating learning rate to 3.0517578125e-09
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.00013450026475002427:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.029713980390489097:   0%|          | 0/19 [00:00<?, ?it/s]  loss:0.21669300094718508:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.4811326404695743:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.6923363528835798:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6923363528835798: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 148.32it/s]
Epoch: 17 cost time: 0.6490471363067627
Epoch: 17, Steps: 19 | Train Loss: 0.0747374 Vali Loss: 3.2131863 Test Loss: 30.7717094
Validation loss decreased (3.213186 --> 3.213186).  Saving model ...
Updating learning rate to 1.52587890625e-09
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.00014951654311668336:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.02997844317091015:   0%|          | 0/19 [00:00<?, ?it/s]   loss:0.21050139522603598:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.563473290588983:   0%|          | 0/19 [00:00<?, ?it/s]  loss:0.6369934537590759:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6369934537590759: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 141.77it/s]
Epoch: 18 cost time: 0.5885598659515381
Epoch: 18, Steps: 19 | Train Loss: 0.0758472 Vali Loss: 3.2131863 Test Loss: 30.7717094
Validation loss decreased (3.213186 --> 3.213186).  Saving model ...
Updating learning rate to 7.62939453125e-10
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.00015746632322135104:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.03029431575193121:   0%|          | 0/19 [00:00<?, ?it/s]   loss:0.19893176061595352:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.461403157687836:   0%|          | 0/19 [00:00<?, ?it/s]  loss:0.7360383379794231:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7360383379794231: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 151.48it/s]
Epoch: 19 cost time: 0.632131814956665
Epoch: 19, Steps: 19 | Train Loss: 0.0750961 Vali Loss: 3.2131863 Test Loss: 30.7717094
Validation loss decreased (3.213186 --> 3.213186).  Saving model ...
Updating learning rate to 3.814697265625e-10
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0001425952928055232:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.02905205715218553:   0%|          | 0/19 [00:00<?, ?it/s]  loss:0.1867972477754055:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.5567309694473936:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7115366340234782:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7115366340234782: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 153.34it/s]
Epoch: 20 cost time: 0.5963499546051025
Epoch: 20, Steps: 19 | Train Loss: 0.0781189 Vali Loss: 3.2131863 Test Loss: 30.7717094
Validation loss decreased (3.213186 --> 3.213186).  Saving model ...
Updating learning rate to 1.9073486328125e-10
>>>>>>>testing : long_term_forecast_break_parzen_0_DLinear_job_demand_r2_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 4
test shape: (4, 1, 3, 121420) (4, 1, 3, 121420)
test shape: (4, 3, 121420) (4, 3, 121420)
mse:12603.0048828125, mae:6.193379878997803, dtw:-999
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           0                   Model:              DLinear             

[1mData Loader[0m
  Data:               job_demand_r2       Root Path:          ../../dataset/demand/
  Data Path:          r2.parquet          Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        .cache/checkpoints  

[1mForecasting Task[0m
  Seq Len:            6                   Label Len:          1                   
  Pred Len:           3                   Seasonal Patterns:  Monthly             
  Inverse:            1                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             121420              Dec In:             121420              
  C Out:              121420              d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           2                   d FF:               2048                
  Moving Avg:         25                  Factor:             1                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              learned             Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        32                  Itr:                1                   
  Train Epochs:       20                  Batch Size:         1                   
  Patience:           3                   Learning Rate:      0.0001              
  Des:                test                Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1                 

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_break_tukey-hanning_0_DLinear_job_demand_r2_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 19
val 1
test 4
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.21it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.21it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.21it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.21it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.21it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.21it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.21it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.21it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.21it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.21it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.21it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.21it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.21it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:08,  2.21it/s]loss:0.003884958354701173:   5%|â–Œ         | 1/19 [00:00<00:08,  2.21it/s]loss:0.14256859936222577:   5%|â–Œ         | 1/19 [00:00<00:08,  2.21it/s] loss:0.34722782670923497:   5%|â–Œ         | 1/19 [00:00<00:08,  2.21it/s]loss:0.7034829082349299:   5%|â–Œ         | 1/19 [00:00<00:08,  2.21it/s] loss:0.7543297334738028:   5%|â–Œ         | 1/19 [00:00<00:08,  2.21it/s]loss:0.7543297334738028: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 33.16it/s]
Epoch: 1 cost time: 1.1005334854125977
Epoch: 1, Steps: 19 | Train Loss: 0.1027102 Vali Loss: 3.2155974 Test Loss: 30.7514954
Validation loss decreased (inf --> 3.215597).  Saving model ...
Updating learning rate to 0.0001
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.00452403702415398:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.12019570020090233:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.4059995364063174:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.573353571528517:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.7338700980216312:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7338700980216312: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 164.95it/s]
Epoch: 2 cost time: 0.5821192264556885
Epoch: 2, Steps: 19 | Train Loss: 0.0967338 Vali Loss: 3.2140906 Test Loss: 30.7588520
Validation loss decreased (3.215597 --> 3.214091).  Saving model ...
Updating learning rate to 5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0036306564727686544:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.13045248825455727:   0%|          | 0/19 [00:00<?, ?it/s]  loss:0.3939647278129004:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.6516225284466004:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.736571710603259:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.736571710603259: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 135.40it/s]
Epoch: 3 cost time: 0.6160798072814941
Epoch: 3, Steps: 19 | Train Loss: 0.1008548 Vali Loss: 3.2134790 Test Loss: 30.7656174
Validation loss decreased (3.214091 --> 3.213479).  Saving model ...
Updating learning rate to 2.5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0042486043071081996:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.11994847550157946:   0%|          | 0/19 [00:00<?, ?it/s]  loss:0.3548994756817:   0%|          | 0/19 [00:00<?, ?it/s]    loss:0.6267716622560855:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6229338264356866:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6229338264356866: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 159.62it/s]
Epoch: 4 cost time: 0.6323950290679932
Epoch: 4, Steps: 19 | Train Loss: 0.0909896 Vali Loss: 3.2131793 Test Loss: 30.7697830
Validation loss decreased (3.213479 --> 3.213179).  Saving model ...
Updating learning rate to 1.25e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.003420545071839527:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.1361355930761487:   0%|          | 0/19 [00:00<?, ?it/s]  loss:0.3453022537381339:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5036453461827608:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7540442513310959:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7540442513310959: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 150.12it/s]
Epoch: 5 cost time: 0.6140193939208984
Epoch: 5, Steps: 19 | Train Loss: 0.0917131 Vali Loss: 3.2130380 Test Loss: 30.7698421
Validation loss decreased (3.213179 --> 3.213038).  Saving model ...
Updating learning rate to 6.25e-06
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0036256889360560722:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.1198800084761092:   0%|          | 0/19 [00:00<?, ?it/s]   loss:0.354719270236724:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.5567018708385076:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6592298432855427:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6592298432855427: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 142.94it/s]
Epoch: 6 cost time: 0.6298444271087646
Epoch: 6, Steps: 19 | Train Loss: 0.0891661 Vali Loss: 3.2129629 Test Loss: 30.7705746
Validation loss decreased (3.213038 --> 3.212963).  Saving model ...
Updating learning rate to 3.125e-06
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 115.66it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 115.66it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 115.66it/s]loss:0.004090094731165272:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 115.66it/s]loss:0.1240925051479135:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 115.66it/s]  loss:0.3822300745977457:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 115.66it/s]loss:0.6375677195082451:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 115.66it/s]loss:0.7229785934067059:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:00<00:00, 115.66it/s]loss:0.7229785934067059: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 107.44it/s]
Epoch: 7 cost time: 0.6753735542297363
Epoch: 7, Steps: 19 | Train Loss: 0.0984715 Vali Loss: 3.2129235 Test Loss: 30.7708702
Validation loss decreased (3.212963 --> 3.212924).  Saving model ...
Updating learning rate to 1.5625e-06
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.004210105110519524:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.12408603353899095:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.35467375379537813:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.35467375379537813:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 168.72it/s]loss:0.5996912852941196:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 168.72it/s] loss:0.6123193008329619:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:00<00:00, 168.72it/s]loss:0.6123193008329619: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 117.47it/s]
Epoch: 8 cost time: 0.653160572052002
Epoch: 8, Steps: 19 | Train Loss: 0.0892095 Vali Loss: 3.2129035 Test Loss: 30.7710648
Validation loss decreased (3.212924 --> 3.212903).  Saving model ...
Updating learning rate to 7.8125e-07
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0032447478534058886:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.11527025575394573:   0%|          | 0/19 [00:00<?, ?it/s]  loss:0.40510168008063446:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5566089220514695:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.7112652651879754:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7112652651879754: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 155.10it/s]
Epoch: 9 cost time: 0.6211867332458496
Epoch: 9, Steps: 19 | Train Loss: 0.0942890 Vali Loss: 3.2128966 Test Loss: 30.7711849
Validation loss decreased (3.212903 --> 3.212897).  Saving model ...
Updating learning rate to 3.90625e-07
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.004089860483168436:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.10937835487020328:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.34517012321146695:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5624718162463154:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.6591135694403832:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6591135694403832: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 143.57it/s]
Epoch: 10 cost time: 0.6097419261932373
Epoch: 10, Steps: 19 | Train Loss: 0.0884328 Vali Loss: 3.2128925 Test Loss: 30.7712250
Validation loss decreased (3.212897 --> 3.212893).  Saving model ...
Updating learning rate to 1.953125e-07
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.003972074993543729:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.1171973447292255:   0%|          | 0/19 [00:00<?, ?it/s]  loss:0.34880776371854616:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6315634357348295:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.5810073273498957:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5810073273498957: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 169.49it/s]
Epoch: 11 cost time: 0.5668354034423828
Epoch: 11, Steps: 19 | Train Loss: 0.0885552 Vali Loss: 3.2128894 Test Loss: 30.7712421
Validation loss decreased (3.212893 --> 3.212889).  Saving model ...
Updating learning rate to 9.765625e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0036289881988456857:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.11526827450180668:   0%|          | 0/19 [00:00<?, ?it/s]  loss:0.40509557631772447:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5996692825635396:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.6366768563807214:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6366768563807214: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 149.27it/s]
Epoch: 12 cost time: 0.621239423751831
Epoch: 12, Steps: 19 | Train Loss: 0.0926494 Vali Loss: 3.2128885 Test Loss: 30.7712517
Validation loss decreased (3.212889 --> 3.212888).  Saving model ...
Updating learning rate to 4.8828125e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.004070287913857382:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.14309713496067966:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.34212748557082634:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6264412138326043:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.7511747504488193:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7511747504488193: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 136.15it/s]
Epoch: 13 cost time: 0.6172113418579102
Epoch: 13, Steps: 19 | Train Loss: 0.0982585 Vali Loss: 3.2128880 Test Loss: 30.7712517
Validation loss decreased (3.212888 --> 3.212888).  Saving model ...
Updating learning rate to 2.44140625e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.004037286799598806:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.11719681741145568:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.34919107233530544:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6375201203393004:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.7288426773738602:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7288426773738602: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 149.05it/s]
Epoch: 14 cost time: 0.6161131858825684
Epoch: 14, Steps: 19 | Train Loss: 0.0966731 Vali Loss: 3.2128878 Test Loss: 30.7712555
Validation loss decreased (3.212888 --> 3.212888).  Saving model ...
Updating learning rate to 1.220703125e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0036858149436308084:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.12219720679260936:   0%|          | 0/19 [00:00<?, ?it/s]  loss:0.3822029009947683:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.5305713803430844:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6366755672571648:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6366755672571648: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 159.72it/s]
Epoch: 15 cost time: 0.5880482196807861
Epoch: 15, Steps: 19 | Train Loss: 0.0881754 Vali Loss: 3.2128878 Test Loss: 30.7712574
Validation loss decreased (3.212888 --> 3.212888).  Saving model ...
Updating learning rate to 6.103515625e-09
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.00355556989792183:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.10937707639634427:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.34880598153450737:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5711327005315104:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.808105375401061:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.808105375401061: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 155.21it/s]
Epoch: 16 cost time: 0.582916259765625
Epoch: 16, Steps: 19 | Train Loss: 0.0968935 Vali Loss: 3.2128878 Test Loss: 30.7712574
Validation loss decreased (3.212888 --> 3.212888).  Saving model ...
Updating learning rate to 3.0517578125e-09
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.003476642548499777:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.1198574169581165:   0%|          | 0/19 [00:00<?, ?it/s]  loss:0.4050948759888907:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.562465737019764:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.69203713315124:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.69203713315124: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 150.22it/s]
Epoch: 17 cost time: 0.5683550834655762
Epoch: 17, Steps: 19 | Train Loss: 0.0938385 Vali Loss: 3.2128878 Test Loss: 30.7712555
Validation loss decreased (3.212888 --> 3.212888).  Saving model ...
Updating learning rate to 1.52587890625e-09
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0038647414993775975:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.12092203834589936:   0%|          | 0/19 [00:00<?, ?it/s]  loss:0.39353511802476404:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6586660097567723:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.6366755391503026:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6366755391503026: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 165.10it/s]
Epoch: 18 cost time: 0.5819101333618164
Epoch: 18, Steps: 19 | Train Loss: 0.0954560 Vali Loss: 3.2128878 Test Loss: 30.7712555
Validation loss decreased (3.212888 --> 3.212888).  Saving model ...
Updating learning rate to 7.62939453125e-10
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.004070284599429884:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.12219719966934871:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.37187656601586083:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5394492009538234:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.7357194326519451:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7357194326519451: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 136.56it/s]
Epoch: 19 cost time: 0.6327221393585205
Epoch: 19, Steps: 19 | Train Loss: 0.0933322 Vali Loss: 3.2128878 Test Loss: 30.7712555
Validation loss decreased (3.212888 --> 3.212888).  Saving model ...
Updating learning rate to 3.814697265625e-10
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0036858147500398917:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.11719679534105464:   0%|          | 0/19 [00:00<?, ?it/s]  loss:0.3491909820857722:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.6509119820650143:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7112537126668546:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7112537126668546: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 158.41it/s]
Epoch: 20 cost time: 0.6295104026794434
Epoch: 20, Steps: 19 | Train Loss: 0.0964336 Vali Loss: 3.2128878 Test Loss: 30.7712555
Validation loss decreased (3.212888 --> 3.212888).  Saving model ...
Updating learning rate to 1.9073486328125e-10
>>>>>>>testing : long_term_forecast_break_tukey-hanning_0_DLinear_job_demand_r2_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 4
test shape: (4, 1, 3, 121420) (4, 1, 3, 121420)
test shape: (4, 3, 121420) (4, 3, 121420)
mse:12608.6533203125, mae:6.192869186401367, dtw:-999
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           0                   Model:              DLinear             

[1mData Loader[0m
  Data:               job_demand_r2       Root Path:          ../../dataset/demand/
  Data Path:          r2.parquet          Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        .cache/checkpoints  

[1mForecasting Task[0m
  Seq Len:            6                   Label Len:          1                   
  Pred Len:           3                   Seasonal Patterns:  Monthly             
  Inverse:            1                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             121420              Dec In:             121420              
  C Out:              121420              d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           2                   d FF:               2048                
  Moving Avg:         25                  Factor:             1                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              learned             Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        32                  Itr:                1                   
  Train Epochs:       20                  Batch Size:         1                   
  Patience:           3                   Learning Rate:      0.0001              
  Des:                test                Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1                 

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_break_rayleigh_0_DLinear_job_demand_r2_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 19
val 1
test 4
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.27823519010286923:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.27823519010286923:   5%|â–Œ         | 1/19 [00:00<00:08,  2.24it/s]loss:0.355572704297044:   5%|â–Œ         | 1/19 [00:00<00:08,  2.24it/s]  loss:0.38780434814196824:   5%|â–Œ         | 1/19 [00:00<00:08,  2.24it/s]loss:0.4068627505477972:   5%|â–Œ         | 1/19 [00:00<00:08,  2.24it/s] loss:0.3765145216633251:   5%|â–Œ         | 1/19 [00:00<00:08,  2.24it/s]loss:0.4276872820468283:   5%|â–Œ         | 1/19 [00:00<00:08,  2.24it/s]loss:0.5331088555430827:   5%|â–Œ         | 1/19 [00:00<00:08,  2.24it/s]loss:0.48916830602512995:   5%|â–Œ         | 1/19 [00:00<00:08,  2.24it/s]loss:0.4539828741684335:   5%|â–Œ         | 1/19 [00:00<00:08,  2.24it/s] loss:0.6027658535823067:   5%|â–Œ         | 1/19 [00:00<00:08,  2.24it/s]loss:0.5440225404082705:   5%|â–Œ         | 1/19 [00:00<00:08,  2.24it/s]loss:0.6411035768387158:   5%|â–Œ         | 1/19 [00:00<00:08,  2.24it/s]loss:0.5947405390827447:   5%|â–Œ         | 1/19 [00:00<00:08,  2.24it/s]loss:0.6210794081563902:   5%|â–Œ         | 1/19 [00:00<00:08,  2.24it/s]loss:0.6659347227200397:   5%|â–Œ         | 1/19 [00:00<00:08,  2.24it/s]loss:0.7381534829030235:   5%|â–Œ         | 1/19 [00:00<00:08,  2.24it/s]loss:0.6367789147016959:   5%|â–Œ         | 1/19 [00:00<00:08,  2.24it/s]loss:0.8069210813127871:   5%|â–Œ         | 1/19 [00:00<00:08,  2.24it/s]loss:0.7516978794518011:   5%|â–Œ         | 1/19 [00:00<00:08,  2.24it/s]loss:0.7516978794518011: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 32.79it/s]
Epoch: 1 cost time: 1.116208553314209
Epoch: 1, Steps: 19 | Train Loss: 0.5427439 Vali Loss: 3.2134495 Test Loss: 30.7771683
Validation loss decreased (inf --> 3.213449).  Saving model ...
Updating learning rate to 0.0001
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.3243773046020706:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.3151652691963764:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.32269973537196567:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.4050568373375496:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.4235926464801686:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.43145632584069954:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5038932878806682:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.4795105168049719:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.45144037624790145:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5997844304465756:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.5458958548700131:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5492701353181302:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6849692774478991:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7114109629517994:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7741591370271673:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6200777617277582:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7440233095380776:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6555964918785194:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7299527245176203:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7299527245176203: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 147.22it/s]
Epoch: 2 cost time: 0.5832839012145996
Epoch: 2, Steps: 19 | Train Loss: 0.5406491 Vali Loss: 3.2105124 Test Loss: 30.8033028
Validation loss decreased (3.213449 --> 3.210512).  Saving model ...
Updating learning rate to 5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.28417075361466143:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.29594668431438165:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.38264873252733184:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.43031918140970554:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.3960820978282963:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.37842314856149695:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.4568273744136561:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.5230091591600471:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5110807799056423:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.516711956286446:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.5273778913850048:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.636295634687641:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.734400683387918:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7044936983008047:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6191681560579085:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6722146879918152:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7213820246012327:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7449216682975682:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7308911952323928:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7308911952323928: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 149.42it/s]
Epoch: 3 cost time: 0.6024785041809082
Epoch: 3, Steps: 19 | Train Loss: 0.5403350 Vali Loss: 3.2091253 Test Loss: 30.8147163
Validation loss decreased (3.210512 --> 3.209125).  Saving model ...
Updating learning rate to 2.5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.3240265892490201:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.3624834568699363:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.3852894862773124:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.3668311175951131:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.3529365622263175:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.45022571079659723:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.44422908656948423:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5930564304319428:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.5833999552620738:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5333378187291957:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6019768033634246:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.537847802060248:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.5893588130755639:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.679909415322878:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.7229092149553371:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6171813052978703:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6481802770660393:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7161016609377183:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6175825901174051:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6175825901174051: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 161.41it/s]
Epoch: 4 cost time: 0.5962915420532227
Epoch: 4, Steps: 19 | Train Loss: 0.5329928 Vali Loss: 3.2084424 Test Loss: 30.8223877
Validation loss decreased (3.209125 --> 3.208442).  Saving model ...
Updating learning rate to 1.25e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.3317833241131944:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.3178029645793841:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.33906598340871025:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.4022683761795159:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.39482850571645867:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.4768554458433268:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.5091618224559221:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.48208377039840666:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.491326216282699:   0%|          | 0/19 [00:00<?, ?it/s]  loss:0.5042046597994883:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.683204971522665:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.639892881075854:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6870291719939391:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6445128751634679:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5836084488197414:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7015618972856447:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6294222108225949:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5737405307677301:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7482902528736507:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7482902528736507: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 149.03it/s]
Epoch: 5 cost time: 0.6219546794891357
Epoch: 5, Steps: 19 | Train Loss: 0.5337181 Vali Loss: 3.2081087 Test Loss: 30.8248100
Validation loss decreased (3.208442 --> 3.208109).  Saving model ...
Updating learning rate to 6.25e-06
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.3328731519981592:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.3510914772281861:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.38350136097931037:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.42816555465374423:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.4202016391870404:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.3980211760967773:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5005014239088932:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.4249533693433602:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5495363836341582:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.526029729285064:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.6351338877729265:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6452983377399972:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.56397656690787:   0%|          | 0/19 [00:00<?, ?it/s]  loss:0.7528297836481436:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6173044182021478:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6164629669412992:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6475138255196493:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.633890279371537:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.6518577383882902:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6518577383882902: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 145.79it/s]
Epoch: 6 cost time: 0.5723330974578857
Epoch: 6, Steps: 19 | Train Loss: 0.5304812 Vali Loss: 3.2079442 Test Loss: 30.8265419
Validation loss decreased (3.208109 --> 3.207944).  Saving model ...
Updating learning rate to 3.125e-06
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.32159645623805033:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.36184038779190664:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.3201506379898855:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.35155949102895095:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.38927991866545014:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.3768038581968446:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.44928464027451637:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.46585100798845913:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5340265243860651:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.6109131180381925:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6400815722090162:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5785383120515143:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5870827372944659:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7526934788737574:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6985819329128683:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6372528046461818:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6984159679829307:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7273904671445957:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.717171875579021:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.717171875579021: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 149.14it/s]
Epoch: 7 cost time: 0.630718469619751
Epoch: 7, Steps: 19 | Train Loss: 0.5378166 Vali Loss: 3.2078631 Test Loss: 30.8272896
Validation loss decreased (3.207944 --> 3.207863).  Saving model ...
Updating learning rate to 1.5625e-06
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.3138113283374731:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.3890104662199112:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.32530102479389106:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.3668831434539805:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.4601157714342102:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.4131219990195869:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.4481255552606657:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.4694817747230518:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5662259186388187:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5955064189329602:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6159277654493542:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6344578914675196:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5253436980877798:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6999694044821727:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7186244204385569:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6371819310977757:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6473448794032219:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6838878200574712:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6070504009001628:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6070504009001628: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 137.52it/s]
Epoch: 8 cost time: 0.6338675022125244
Epoch: 8, Steps: 19 | Train Loss: 0.5324932 Vali Loss: 3.2078192 Test Loss: 30.8277016
Validation loss decreased (3.207863 --> 3.207819).  Saving model ...
Updating learning rate to 7.8125e-07
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.31901631995609775:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.29952258673660637:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.3323477652771505:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.3725461746594835:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.45646318440511713:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.42094614999715596:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.454647033329486:   0%|          | 0/19 [00:00<?, ?it/s]  loss:0.5920126162311725:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5678504411127837:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5258234729966846:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5842139328807067:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6431903142326212:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6863394942251748:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6789685611041782:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5522454122972429:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5935267759538089:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.74047728366792:   0%|          | 0/19 [00:00<?, ?it/s]  loss:0.6336751025108431:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7053517693145027:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7053517693145027: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 167.28it/s]
Epoch: 9 cost time: 0.6442656517028809
Epoch: 9, Steps: 19 | Train Loss: 0.5346929 Vali Loss: 3.2077990 Test Loss: 30.8279266
Validation loss decreased (3.207819 --> 3.207799).  Saving model ...
Updating learning rate to 3.90625e-07
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.28641584847283746:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.3328687153490632:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.39597494268231237:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.3458729389874443:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.44667556697376093:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.42851519294922663:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.4921039119332564:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.5919959494655092:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5824730789976607:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5147283690324397:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5256574482957705:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.639415428124068:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.680939071570283:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.673642692123162:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6984867146662381:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5619793572762896:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6289259946036203:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6406324067306407:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6516257850956384:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6516257850956384: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 150.95it/s]
Epoch: 10 cost time: 0.5898916721343994
Epoch: 10, Steps: 19 | Train Loss: 0.5325752 Vali Loss: 3.2077892 Test Loss: 30.8280373
Validation loss decreased (3.207799 --> 3.207789).  Saving model ...
Updating learning rate to 1.953125e-07
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.33144658016947776:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.36461030724740423:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.37811320547638255:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.36683975700014904:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.3861117714326565:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.44931706771252555:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5217931777161743:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.48152832933715345:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.566178226259528:   0%|          | 0/19 [00:00<?, ?it/s]  loss:0.5954482078448292:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5413166103436066:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7087366040309524:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5547695001320324:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6141917249328765:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6776785122425111:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6031313600453355:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6358385910314784:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7209282973281886:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5747590822077254:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5747590822077254: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 143.84it/s]
Epoch: 11 cost time: 0.6007969379425049
Epoch: 11, Steps: 19 | Train Loss: 0.5301440 Vali Loss: 3.2077837 Test Loss: 30.8280907
Validation loss decreased (3.207789 --> 3.207784).  Saving model ...
Updating learning rate to 9.765625e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.28987737275910497:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.2995054765266723:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.3030657493737879:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.4278688986250783:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.4453692726787726:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.4285051954378855:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5002886619259215:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5212184580703211:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5802487663580282:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5902445169294763:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5413122758087003:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5681810133820951:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7321443475647859:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6849231787708294:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6185724065808528:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5935053909046286:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7404533646149843:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6838359616260937:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6302488137991843:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6302488137991843: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 174.28it/s]
Epoch: 12 cost time: 0.5516467094421387
Epoch: 12, Steps: 19 | Train Loss: 0.5357563 Vali Loss: 3.2077811 Test Loss: 30.8281174
Validation loss decreased (3.207784 --> 3.207781).  Saving model ...
Updating learning rate to 4.8828125e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.28640671378456717:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.388959757395445:   0%|          | 0/19 [00:00<?, ?it/s]  loss:0.34474302614115576:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.3659282773875682:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.4321039893867365:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.44931175156016945:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.4431874714671848:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.48152180659975485:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5678198809054672:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.5937153532517944:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5256457715912054:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6616660122204066:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5547647017406402:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5399321928043208:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6943896131716002:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7342206896328329:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6239763706685336:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7152848130519387:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7450510468835814:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7450510468835814: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 159.22it/s]
Epoch: 13 cost time: 0.6056647300720215
Epoch: 13, Steps: 19 | Train Loss: 0.5341384 Vali Loss: 3.2077794 Test Loss: 30.8281307
Validation loss decreased (3.207781 --> 3.207779).  Saving model ...
Updating learning rate to 2.44140625e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.31377142360555377:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.36460293725627085:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.42240891979636:   0%|          | 0/19 [00:00<?, ?it/s]   loss:0.37127743832544197:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.35210958560386246:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.41306781374130314:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5198042410828941:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.48313541317365777:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5339034062921902:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.5187855087957812:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6194912953739382:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.661665117628571:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.5547639460448803:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6033119509032957:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6889576708945302:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6031257432473419:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6374078487185467:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7272730424149585:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7227270602395716:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7227270602395716: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 156.86it/s]
Epoch: 14 cost time: 0.6245450973510742
Epoch: 14, Steps: 19 | Train Loss: 0.5321890 Vali Loss: 3.2077792 Test Loss: 30.8281403
Validation loss decreased (3.207779 --> 3.207779).  Saving model ...
Updating learning rate to 1.220703125e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.28987459231579393:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.3646023799569972:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.38108845279828285:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.4154248500746423:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.38915958245544374:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.42195948449098974:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5071961899185773:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.4558323950111999:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5802455087230987:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5598751567329798:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.48977248330277784:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6616645807981496:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.7321405295466695:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6736287379825965:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6281604554905007:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6279328593893686:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6983100486321966:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6054921432435988:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6302459382289467:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6302459382289467: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 162.79it/s]
Epoch: 15 cost time: 0.627363920211792
Epoch: 15, Steps: 19 | Train Loss: 0.5322424 Vali Loss: 3.2077787 Test Loss: 30.8281403
Validation loss decreased (3.207779 --> 3.207779).  Saving model ...
Updating learning rate to 6.103515625e-09
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.282587670770442:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.3646020764368984:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.37810764619687043:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.42613598469041997:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.3718689560336057:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.44931016856206724:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.44917328108147553:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5505682652860343:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.5493100851028062:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.593713851371945:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.5571282329924329:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6394004626667482:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5637578093183166:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6849193819333397:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6055336136603173:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.56196556740352:   0%|          | 0/19 [00:00<?, ?it/s]  loss:0.635831162750307:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6499838770146346:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8010891473958205:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.8010891473958205: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 155.65it/s]
Epoch: 16 cost time: 0.6132485866546631
Epoch: 16, Steps: 19 | Train Loss: 0.5323677 Vali Loss: 3.2077787 Test Loss: 30.8281403
Validation loss decreased (3.207779 --> 3.207779).  Saving model ...
Updating learning rate to 3.0517578125e-09
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.2898743505930968:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.3889583362386303:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.3719141671139874:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.42786449104403695:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.44536646569994914:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.47367950835947753:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.44318568452923035:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5387766613790558:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.5584577238194275:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5339463838916452:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.4897722993396519:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.659149879134528:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.5547633006136731:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6048065995025267:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5926622920531748:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6162237138160892:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7404502828539714:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6406178201821714:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6855445224659692:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6855445224659692: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 159.54it/s]
Epoch: 17 cost time: 0.6011252403259277
Epoch: 17, Steps: 19 | Train Loss: 0.5292639 Vali Loss: 3.2077787 Test Loss: 30.8281403
Validation loss decreased (3.207779 --> 3.207779).  Saving model ...
Updating learning rate to 1.52587890625e-09
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.32434284621590426:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.2995030932822924:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.39285906635149703:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.32748445452803226:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.3991940140695842:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.5250388334414671:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.44917327901349696:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.552668568401257:   0%|          | 0/19 [00:00<?, ?it/s]  loss:0.4727381029506623:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5856245679259083:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6010409639027501:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5681770353495509:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5975245821406636:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6789387695099679:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6586639361630493:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6210979730530788:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7197453393696579:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7490505870764967:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.630245900775978:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.630245900775978: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 158.17it/s]
Epoch: 18 cost time: 0.5682969093322754
Epoch: 18, Steps: 19 | Train Loss: 0.5343743 Vali Loss: 3.2077787 Test Loss: 30.8281403
Validation loss decreased (3.207779 --> 3.207779).  Saving model ...
Updating learning rate to 7.62939453125e-10
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.3563709640248959:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.31259509701064114:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.3030629649261958:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.3712766762121935:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.38610527363132974:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.46997472250783406:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.4561380117413008:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.5549103226748721:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.49471846134490005:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.608472020789265:   0%|          | 0/19 [00:00<?, ?it/s]  loss:0.6373114597423829:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6240079374981427:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6644086871155176:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5702310000675324:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6943880416141879:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6279327331712962:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6787232391678457:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6153091022886715:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7290928669741107:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7290928669741107: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 156.50it/s]
Epoch: 19 cost time: 0.5872955322265625
Epoch: 19, Steps: 19 | Train Loss: 0.5344752 Vali Loss: 3.2077787 Test Loss: 30.8281403
Validation loss decreased (3.207779 --> 3.207779).  Saving model ...
Updating learning rate to 3.814697265625e-10
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.3327057560399092:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.35091040764866543:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.3435894696949238:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.4154245932356759:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.39344175847565777:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.41306710512112443:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5239029828387396:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.5919796279761809:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.49471846134490005:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5598749436223013:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.6194905537583334:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6343995185152879:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5252847985621694:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.5702310000675324:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6281603203379462:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6031251657369265:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.6374072226333676:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.7431894044553005:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.705328102832099:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.705328102832099: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 147.77it/s]
Epoch: 20 cost time: 0.5934720039367676
Epoch: 20, Steps: 19 | Train Loss: 0.5308543 Vali Loss: 3.2077787 Test Loss: 30.8281403
Validation loss decreased (3.207779 --> 3.207779).  Saving model ...
Updating learning rate to 1.9073486328125e-10
>>>>>>>testing : long_term_forecast_break_rayleigh_0_DLinear_job_demand_r2_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 4
test shape: (4, 1, 3, 121420) (4, 1, 3, 121420)
test shape: (4, 3, 121420) (4, 3, 121420)
mse:12783.525390625, mae:6.189250946044922, dtw:-999
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           0                   Model:              SegRNN              

[1mData Loader[0m
  Data:               job_demand_r2       Root Path:          ../../dataset/demand/
  Data Path:          r2.parquet          Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        .cache/checkpoints  

[1mForecasting Task[0m
  Seq Len:            6                   Label Len:          1                   
  Pred Len:           3                   Seasonal Patterns:  Monthly             
  Inverse:            1                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             121420              Dec In:             121420              
  C Out:              121420              d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           2                   d FF:               2048                
  Moving Avg:         25                  Factor:             1                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              learned             Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        32                  Itr:                1                   
  Train Epochs:       20                  Batch Size:         1                   
  Patience:           3                   Learning Rate:      0.0001              
  Des:                test                Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1                 

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_break_bartlett_0_SegRNN_job_demand_r2_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 19
val 1
test 4
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:09,  1.84it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:09,  1.84it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:09,  1.84it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:03,  4.82it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:03,  4.82it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:03,  4.82it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:02,  6.85it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:02,  6.85it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:01<00:02,  6.85it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:01<00:01,  8.25it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:01<00:01,  8.25it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:01<00:01,  8.25it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:01<00:01,  9.23it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:01<00:01,  9.23it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:01<00:01,  9.23it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00,  9.91it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00,  9.91it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00,  9.91it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.37it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.37it/s]loss:0.0483600310396582:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.37it/s]loss:0.0483600310396582:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.70it/s]loss:0.3076416666546484:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.70it/s]loss:0.5962150666477016:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.70it/s]loss:0.5962150666477016:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 10.94it/s]loss:0.7655166877737318:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:02<00:00, 10.94it/s]loss:0.9412379540458388:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:02<00:00, 10.94it/s]loss:0.9412379540458388: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:02<00:00, 11.08it/s]loss:0.9412379540458388: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:02<00:00,  8.75it/s]
Epoch: 1 cost time: 2.7101309299468994
Epoch: 1, Steps: 19 | Train Loss: 0.1399459 Vali Loss: 3.5180764 Test Loss: 25.6416073
Validation loss decreased (inf --> 3.518076).  Saving model ...
Updating learning rate to 0.0001
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 11.07it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 11.07it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 11.07it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 11.25it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 11.25it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 11.25it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 11.29it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 11.29it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 11.29it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 11.28it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 11.28it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 11.28it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 11.26it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 11.26it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:00, 11.26it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 11.34it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 11.34it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 11.34it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 11.34it/s]loss:0.0459765661364041:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 11.34it/s]loss:0.2904325089341071:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 11.34it/s]loss:0.2904325089341071:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 11.38it/s]loss:0.485230485250641:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 11.38it/s] loss:0.744172075348211:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 11.38it/s]loss:0.744172075348211:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 11.42it/s]loss:0.7252431036595072:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 11.42it/s]loss:0.7252431036595072: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.98it/s]
Epoch: 2 cost time: 2.267296075820923
Epoch: 2, Steps: 19 | Train Loss: 0.1205818 Vali Loss: 3.3084462 Test Loss: 25.3172283
Validation loss decreased (3.518076 --> 3.308446).  Saving model ...
Updating learning rate to 5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 11.00it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 11.00it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 11.00it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 11.00it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 11.00it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 11.00it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 11.20it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 11.20it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 11.20it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 11.26it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 11.26it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 11.26it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 11.32it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 11.32it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:00, 11.32it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 11.38it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 11.38it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 11.38it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 11.41it/s]loss:0.04002689151061296:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 11.41it/s]loss:0.22234418090925712:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 11.41it/s]loss:0.22234418090925712:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 11.43it/s]loss:0.3940308581901599:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 11.43it/s] loss:0.643118150336549:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 11.43it/s] loss:0.643118150336549:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 11.46it/s]loss:0.7904977886051053:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 11.46it/s]loss:0.7904977886051053: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 11.00it/s]
Epoch: 3 cost time: 2.2450380325317383
Epoch: 3, Steps: 19 | Train Loss: 0.1100009 Vali Loss: 3.2211607 Test Loss: 25.1873779
Validation loss decreased (3.308446 --> 3.221161).  Saving model ...
Updating learning rate to 2.5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 10.86it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 10.86it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 10.86it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 10.98it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 10.98it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 10.98it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 11.12it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 11.12it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 11.12it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 11.27it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 11.27it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 11.27it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 11.21it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 11.21it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:00, 11.21it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 11.25it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 11.25it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 11.25it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 11.32it/s]loss:0.03795610451528461:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 11.32it/s]loss:0.20397836610917242:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 11.32it/s]loss:0.20397836610917242:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 11.37it/s]loss:0.398540472165313:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 11.37it/s]  loss:0.6234814716774479:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 11.37it/s]loss:0.6234814716774479:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 11.39it/s]loss:0.7540373236032142:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 11.39it/s]loss:0.7540373236032142: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.95it/s]
Epoch: 4 cost time: 2.2760562896728516
Epoch: 4, Steps: 19 | Train Loss: 0.1062102 Vali Loss: 3.1986411 Test Loss: 25.1385078
Validation loss decreased (3.221161 --> 3.198641).  Saving model ...
Updating learning rate to 1.25e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 11.07it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 11.07it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 11.07it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 11.03it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 11.03it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 11.03it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 11.14it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 11.14it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 11.14it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 11.24it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 11.24it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 11.24it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 11.30it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 11.30it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:00, 11.30it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 11.34it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 11.34it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 11.34it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 11.36it/s]loss:0.03618043617639291:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 11.36it/s]loss:0.1821071608864704:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 11.36it/s] loss:0.1821071608864704:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 11.37it/s]loss:0.35136468460233355:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 11.37it/s]loss:0.5909475589715383:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 11.37it/s] loss:0.5909475589715383:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 11.36it/s]loss:0.7586404075465037:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 11.36it/s]loss:0.7586404075465037: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.98it/s]
Epoch: 5 cost time: 2.243535041809082
Epoch: 5, Steps: 19 | Train Loss: 0.1010126 Vali Loss: 3.1866784 Test Loss: 25.1159019
Validation loss decreased (3.198641 --> 3.186678).  Saving model ...
Updating learning rate to 6.25e-06
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 10.68it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 10.68it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 10.68it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 11.15it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 11.15it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 11.15it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 11.30it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 11.30it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 11.30it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 11.32it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 11.32it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 11.32it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 11.31it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 11.31it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:00, 11.31it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 11.33it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 11.33it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 11.33it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 11.38it/s]loss:0.03678154898148093:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 11.38it/s]loss:0.22005005302525782:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 11.38it/s]loss:0.22005005302525782:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 11.41it/s]loss:0.35870252434921746:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 11.41it/s]loss:0.5675409517293863:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 11.41it/s] loss:0.5675409517293863:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 11.41it/s]loss:0.6152964417237076:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 11.41it/s]loss:0.6152964417237076: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.97it/s]
Epoch: 6 cost time: 2.300107002258301
Epoch: 6, Steps: 19 | Train Loss: 0.0946511 Vali Loss: 3.1848919 Test Loss: 25.1057205
Validation loss decreased (3.186678 --> 3.184892).  Saving model ...
Updating learning rate to 3.125e-06
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:01,  9.25it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:01,  9.25it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:01,  9.25it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.57it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.57it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.57it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.90it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.90it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.90it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 11.12it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 11.12it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 11.12it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 11.21it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 11.21it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 11.21it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 11.28it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 11.28it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 11.28it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 11.32it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 11.32it/s]loss:0.029268460667455556:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 11.32it/s]loss:0.029268460667455556:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 11.35it/s]loss:0.1871136149459389:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 11.35it/s]  loss:0.3848372040733258:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 11.35it/s]loss:0.3848372040733258:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 11.37it/s]loss:0.4842361489067774:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 11.37it/s]loss:0.767029354803035:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 11.37it/s] loss:0.767029354803035: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 11.39it/s]loss:0.767029354803035: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.89it/s]
Epoch: 7 cost time: 2.239431142807007
Epoch: 7, Steps: 19 | Train Loss: 0.0974992 Vali Loss: 3.1841841 Test Loss: 25.1017513
Validation loss decreased (3.184892 --> 3.184184).  Saving model ...
Updating learning rate to 1.5625e-06
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 10.71it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 10.71it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 10.71it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 10.95it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 10.95it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 10.95it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 11.12it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 11.12it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 11.12it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 11.24it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 11.24it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 11.24it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 11.27it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 11.27it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:00, 11.27it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 11.28it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 11.28it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 11.28it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 11.27it/s]loss:0.031839445665164064:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 11.27it/s]loss:0.1866464073328726:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 11.27it/s]  loss:0.1866464073328726:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 11.30it/s]loss:0.35059927744009073:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 11.30it/s]loss:0.5592563997940231:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 11.30it/s] loss:0.5592563997940231:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 11.33it/s]loss:0.7677718556030189:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 11.33it/s]loss:0.7677718556030189: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.91it/s]
Epoch: 8 cost time: 2.2602968215942383
Epoch: 8, Steps: 19 | Train Loss: 0.0997954 Vali Loss: 3.1836395 Test Loss: 25.0995674
Validation loss decreased (3.184184 --> 3.183640).  Saving model ...
Updating learning rate to 7.8125e-07
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:01,  9.91it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:01,  9.91it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:01,  9.91it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.30it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.30it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.30it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.80it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.80it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.80it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 11.04it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 11.04it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 11.04it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 11.10it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 11.10it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:01<00:00, 11.10it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 11.11it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 11.11it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 11.11it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 11.16it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 11.16it/s]loss:0.03184198346394482:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 11.16it/s]loss:0.03184198346394482:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 11.23it/s]loss:0.20957559933689673:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 11.23it/s]loss:0.3859206144581678:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 11.23it/s] loss:0.3859206144581678:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 11.29it/s]loss:0.5586752040037278:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 11.29it/s]loss:0.6761209200676241:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 11.29it/s]loss:0.6761209200676241: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 11.33it/s]loss:0.6761209200676241: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.82it/s]
Epoch: 9 cost time: 2.278404712677002
Epoch: 9, Steps: 19 | Train Loss: 0.0980071 Vali Loss: 3.1830323 Test Loss: 25.0982552
Validation loss decreased (3.183640 --> 3.183032).  Saving model ...
Updating learning rate to 3.90625e-07
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:01,  9.82it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:01,  9.82it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:01,  9.82it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.70it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.70it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.70it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.80it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.80it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.80it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 11.02it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 11.02it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 11.02it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 11.15it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 11.15it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 11.15it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 11.20it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 11.20it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 11.20it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 11.25it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 11.25it/s]loss:0.03508745987824417:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 11.25it/s]loss:0.03508745987824417:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 11.26it/s]loss:0.19087642334497165:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 11.26it/s]loss:0.38560068642608775:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 11.26it/s]loss:0.38560068642608775:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 11.28it/s]loss:0.5734247609666866:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 11.28it/s] loss:0.7326577241450478:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 11.28it/s]loss:0.7326577241450478: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 11.31it/s]loss:0.7326577241450478: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.86it/s]
Epoch: 10 cost time: 2.282470941543579
Epoch: 10, Steps: 19 | Train Loss: 0.1009288 Vali Loss: 3.1827657 Test Loss: 25.0976219
Validation loss decreased (3.183032 --> 3.182766).  Saving model ...
Updating learning rate to 1.953125e-07
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:01,  9.75it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:01,  9.75it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:01,  9.75it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.60it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.60it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.60it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 11.01it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 11.01it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 11.01it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 11.02it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 11.02it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 11.02it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 11.16it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 11.16it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 11.16it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 11.21it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 11.21it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 11.21it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 11.28it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 11.28it/s]loss:0.031820182737157796:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 11.28it/s]loss:0.031820182737157796:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 11.31it/s]loss:0.1863113588536699:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 11.31it/s]  loss:0.38628610245760286:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 11.31it/s]loss:0.38628610245760286:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 11.31it/s]loss:0.5611846654795419:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 11.31it/s] loss:0.7649320757337584:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 11.31it/s]loss:0.7649320757337584: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 11.32it/s]loss:0.7649320757337584: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.86it/s]
Epoch: 11 cost time: 2.2463173866271973
Epoch: 11, Steps: 19 | Train Loss: 0.1016071 Vali Loss: 3.1826584 Test Loss: 25.0973015
Validation loss decreased (3.182766 --> 3.182658).  Saving model ...
Updating learning rate to 9.765625e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 11.05it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 11.05it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 11.05it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 11.28it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 11.28it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 11.28it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 11.34it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 11.34it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 11.34it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 11.35it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 11.35it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 11.35it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 11.35it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 11.35it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:00, 11.35it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 11.40it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 11.40it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 11.40it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 11.43it/s]loss:0.03488526232402759:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 11.43it/s]loss:0.2120001355409691:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 11.43it/s] loss:0.2120001355409691:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 11.45it/s]loss:0.3208340533087191:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 11.45it/s]loss:0.5084512850054612:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 11.45it/s]loss:0.5084512850054612:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 11.45it/s]loss:0.6676397970185693:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 11.45it/s]loss:0.6676397970185693: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 11.03it/s]
Epoch: 12 cost time: 2.2447516918182373
Epoch: 12, Steps: 19 | Train Loss: 0.0917795 Vali Loss: 3.1826277 Test Loss: 25.0971470
Validation loss decreased (3.182658 --> 3.182628).  Saving model ...
Updating learning rate to 4.8828125e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 10.87it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 10.87it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 10.87it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 11.20it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 11.20it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 11.20it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 11.17it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 11.17it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 11.17it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 11.28it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 11.28it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 11.28it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 11.29it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 11.29it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:00, 11.29it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 11.32it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 11.32it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 11.32it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 11.34it/s]loss:0.030134855209382864:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 11.34it/s]loss:0.19075129767380933:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 11.34it/s] loss:0.19075129767380933:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 11.23it/s]loss:0.4196560517488213:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 11.23it/s] loss:0.5577404227914413:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 11.23it/s]loss:0.5577404227914413:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 11.28it/s]loss:0.736388544751397:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 11.28it/s] loss:0.736388544751397: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.93it/s]
Epoch: 13 cost time: 2.314070224761963
Epoch: 13, Steps: 19 | Train Loss: 0.1018248 Vali Loss: 3.1826334 Test Loss: 25.0970860
EarlyStopping counter: 1 out of 3
Updating learning rate to 2.44140625e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 10.54it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 10.54it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 10.54it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 10.92it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 10.92it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 10.92it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 10.97it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 10.97it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 10.97it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 11.10it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 11.10it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 11.10it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 11.21it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 11.21it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:00, 11.21it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 11.24it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 11.24it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 11.24it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 11.27it/s]loss:0.03814902572034399:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 11.27it/s]loss:0.1862109383259602:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 11.27it/s] loss:0.1862109383259602:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 11.32it/s]loss:0.39401280227159924:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 11.32it/s]loss:0.5099294012861549:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 11.32it/s] loss:0.5099294012861549:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 11.35it/s]loss:0.7357876198302017:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 11.35it/s]loss:0.7357876198302017: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.85it/s]
Epoch: 14 cost time: 2.233161687850952
Epoch: 14, Steps: 19 | Train Loss: 0.0981100 Vali Loss: 3.1826296 Test Loss: 25.0970459
EarlyStopping counter: 2 out of 3
Updating learning rate to 1.220703125e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 10.99it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 10.99it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 10.99it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 11.28it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 11.28it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 11.28it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 11.33it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 11.33it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 11.33it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 11.32it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 11.32it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 11.32it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 11.31it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 11.31it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:00, 11.31it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 11.23it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 11.23it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 11.23it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 11.30it/s]loss:0.03503901136936485:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 11.30it/s]loss:0.19127593347358518:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 11.30it/s]loss:0.19127593347358518:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 11.32it/s]loss:0.41977942287312486:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 11.32it/s]loss:0.4666400487592951:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 11.32it/s] loss:0.4666400487592951:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 11.34it/s]loss:0.6672230606502061:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 11.34it/s]loss:0.6672230606502061: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.93it/s]
Epoch: 15 cost time: 2.2401320934295654
Epoch: 15, Steps: 19 | Train Loss: 0.0936820 Vali Loss: 3.1826313 Test Loss: 25.0970306
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : long_term_forecast_break_bartlett_0_SegRNN_job_demand_r2_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 4
test shape: (4, 1, 3, 121420) (4, 1, 3, 121420)
test shape: (4, 3, 121420) (4, 3, 121420)
mse:8578.744140625, mae:5.86263370513916, dtw:-999
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           0                   Model:              SegRNN              

[1mData Loader[0m
  Data:               job_demand_r2       Root Path:          ../../dataset/demand/
  Data Path:          r2.parquet          Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        .cache/checkpoints  

[1mForecasting Task[0m
  Seq Len:            6                   Label Len:          1                   
  Pred Len:           3                   Seasonal Patterns:  Monthly             
  Inverse:            1                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             121420              Dec In:             121420              
  C Out:              121420              d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           2                   d FF:               2048                
  Moving Avg:         25                  Factor:             1                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              learned             Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        32                  Itr:                1                   
  Train Epochs:       20                  Batch Size:         1                   
  Patience:           3                   Learning Rate:      0.0001              
  Des:                test                Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1                 

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_break_parzen_0_SegRNN_job_demand_r2_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 19
val 1
test 4
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:10,  1.76it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:10,  1.76it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:10,  1.76it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:03,  4.68it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:03,  4.68it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:03,  4.68it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:02,  6.74it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:01<00:02,  6.74it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:01<00:02,  6.74it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:01<00:01,  8.13it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:01<00:01,  8.13it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:01<00:01,  8.13it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:01<00:01,  9.13it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:01<00:01,  9.13it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:01<00:01,  9.13it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00,  9.82it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00,  9.82it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00,  9.82it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.22it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.22it/s]loss:0.00021931986866057987:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.22it/s]loss:0.00021931986866057987:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.58it/s]loss:0.05045924509519566:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.58it/s]   loss:0.32853612763534:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.58it/s]   loss:0.32853612763534:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 10.83it/s]loss:0.7500148215485212:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:02<00:00, 10.83it/s]loss:0.958185646120713:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:02<00:00, 10.83it/s] loss:0.958185646120713: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:02<00:00, 10.99it/s]loss:0.958185646120713: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:02<00:00,  8.64it/s]
Epoch: 1 cost time: 2.765352964401245
Epoch: 1, Steps: 19 | Train Loss: 0.1098640 Vali Loss: 3.5337136 Test Loss: 25.6643600
Validation loss decreased (inf --> 3.533714).  Saving model ...
Updating learning rate to 0.0001
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:01,  9.46it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:01,  9.46it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:01,  9.46it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.69it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.69it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.69it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 11.00it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 11.00it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 11.00it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 11.16it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 11.16it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 11.16it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 11.25it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 11.25it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 11.25it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 11.30it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 11.30it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 11.30it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 11.32it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 11.32it/s]loss:0.0002122581141114015:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 11.32it/s]loss:0.0002122581141114015:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 11.30it/s]loss:0.04817935777986258:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 11.30it/s]  loss:0.2713179108545783:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 11.30it/s] loss:0.2713179108545783:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 11.30it/s]loss:0.7603679462107261:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 11.30it/s]loss:0.758995905016596:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 11.30it/s] loss:0.758995905016596: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 11.32it/s]loss:0.758995905016596: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.85it/s]
Epoch: 2 cost time: 2.2156550884246826
Epoch: 2, Steps: 19 | Train Loss: 0.0967933 Vali Loss: 3.3583031 Test Loss: 25.3874397
Validation loss decreased (3.533714 --> 3.358303).  Saving model ...
Updating learning rate to 5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 10.98it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 10.98it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 10.98it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 11.08it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 11.08it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 11.08it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 11.15it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 11.15it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 11.15it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 11.23it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 11.23it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 11.23it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 11.30it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 11.30it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:00, 11.30it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 11.35it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 11.35it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 11.35it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 11.37it/s]loss:0.00018661191874090274:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 11.37it/s]loss:0.036612518969946585:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 11.37it/s]  loss:0.036612518969946585:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 11.34it/s]loss:0.2143561118752796:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 11.34it/s]  loss:0.6401709662838786:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 11.34it/s]loss:0.6401709662838786:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 11.34it/s]loss:0.8103760681920704:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 11.34it/s]loss:0.8103760681920704: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.96it/s]
Epoch: 3 cost time: 2.2604246139526367
Epoch: 3, Steps: 19 | Train Loss: 0.0895633 Vali Loss: 3.2522614 Test Loss: 25.2431011
Validation loss decreased (3.358303 --> 3.252261).  Saving model ...
Updating learning rate to 2.5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:01,  9.79it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:01,  9.79it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:01,  9.79it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.57it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.57it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.57it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.95it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.95it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.95it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 11.10it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 11.10it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 11.10it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 11.22it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 11.22it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 11.22it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 11.27it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 11.27it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 11.27it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 11.30it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 11.30it/s]loss:0.00017933265098107648:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 11.30it/s]loss:0.00017933265098107648:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 11.32it/s]loss:0.035096111514106014:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 11.32it/s]  loss:0.22831697252788308:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 11.32it/s] loss:0.22831697252788308:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 11.35it/s]loss:0.6206275770736891:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 11.35it/s] loss:0.7788227510461103:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 11.35it/s]loss:0.7788227510461103: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 11.36it/s]loss:0.7788227510461103: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.82it/s]
Epoch: 4 cost time: 2.2685084342956543
Epoch: 4, Steps: 19 | Train Loss: 0.0875286 Vali Loss: 3.2271683 Test Loss: 25.1959229
Validation loss decreased (3.252261 --> 3.227168).  Saving model ...
Updating learning rate to 1.25e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:01,  9.36it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:01,  9.36it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:01,  9.36it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.73it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.73it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.73it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 11.07it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 11.07it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 11.07it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 11.19it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 11.19it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 11.19it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 11.28it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 11.28it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 11.28it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 11.34it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 11.34it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 11.34it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 11.37it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 11.37it/s]loss:0.000172496768209476:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 11.37it/s]loss:0.000172496768209476:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 11.36it/s]loss:0.03165645934559456:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 11.36it/s] loss:0.20250564120216705:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 11.36it/s]loss:0.20250564120216705:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 11.26it/s]loss:0.5983153997388249:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 11.26it/s] loss:0.8066678941126024:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 11.26it/s]loss:0.8066678941126024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 11.30it/s]loss:0.8066678941126024: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.87it/s]
Epoch: 5 cost time: 2.2590138912200928
Epoch: 5, Steps: 19 | Train Loss: 0.0862799 Vali Loss: 3.2126589 Test Loss: 25.1730194
Validation loss decreased (3.227168 --> 3.212659).  Saving model ...
Updating learning rate to 6.25e-06
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 10.96it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 10.96it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 10.96it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 11.11it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 11.11it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 11.11it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 11.26it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 11.26it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 11.26it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 11.30it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 11.30it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 11.30it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 11.36it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 11.36it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:00, 11.36it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 11.40it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 11.40it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 11.40it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 11.40it/s]loss:0.00017363413155932668:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 11.40it/s]loss:0.03730743700860693:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 11.40it/s]   loss:0.03730743700860693:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 11.40it/s]loss:0.20745702045815556:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 11.40it/s]loss:0.5706795571663618:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 11.40it/s] loss:0.5706795571663618:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 11.42it/s]loss:0.6365307080063414:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 11.42it/s]loss:0.6365307080063414: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 11.00it/s]
Epoch: 6 cost time: 2.24484920501709
Epoch: 6, Steps: 19 | Train Loss: 0.0764289 Vali Loss: 3.2071629 Test Loss: 25.1605835
Validation loss decreased (3.212659 --> 3.207163).  Saving model ...
Updating learning rate to 3.125e-06
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 11.12it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 11.12it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 11.12it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 11.20it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 11.20it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 11.20it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 11.28it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 11.28it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 11.28it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 11.33it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 11.33it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 11.33it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 11.34it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 11.34it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:00, 11.34it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 11.38it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 11.38it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 11.38it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 11.39it/s]loss:0.00013724166529679424:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 11.39it/s]loss:0.03199857878172282:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 11.39it/s]   loss:0.03199857878172282:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 11.39it/s]loss:0.2167462740598465:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 11.39it/s] loss:0.4941579760165463:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 11.39it/s]loss:0.4941579760165463:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 11.40it/s]loss:0.7960264509872951:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 11.40it/s]loss:0.7960264509872951: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.98it/s]
Epoch: 7 cost time: 2.210081100463867
Epoch: 7, Steps: 19 | Train Loss: 0.0810035 Vali Loss: 3.2054648 Test Loss: 25.1562481
Validation loss decreased (3.207163 --> 3.205465).  Saving model ...
Updating learning rate to 1.5625e-06
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:02,  8.68it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:02,  8.68it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:02,  8.68it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.22it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.22it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.22it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.80it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.80it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.80it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 11.05it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 11.05it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 11.05it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 11.20it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 11.20it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 11.20it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 11.28it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 11.28it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 11.28it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 11.32it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 11.32it/s]loss:0.00015109317269082522:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 11.32it/s]loss:0.00015109317269082522:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 11.36it/s]loss:0.03190687634462301:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 11.36it/s]   loss:0.20301095578367917:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 11.36it/s]loss:0.20301095578367917:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 11.37it/s]loss:0.558672714404979:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 11.37it/s]  loss:0.7984051487932858:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 11.37it/s]loss:0.7984051487932858: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 11.39it/s]loss:0.7984051487932858: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.87it/s]
Epoch: 8 cost time: 2.2020316123962402
Epoch: 8, Steps: 19 | Train Loss: 0.0837972 Vali Loss: 3.2045262 Test Loss: 25.1538372
Validation loss decreased (3.205465 --> 3.204526).  Saving model ...
Updating learning rate to 7.8125e-07
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 11.09it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 11.09it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 11.09it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 11.25it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 11.25it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 11.25it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 11.31it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 11.31it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 11.31it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 11.35it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 11.35it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 11.35it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 11.36it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 11.36it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:00, 11.36it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 11.27it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 11.27it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 11.27it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 11.32it/s]loss:0.00015240462338822076:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 11.32it/s]loss:0.035644592108598966:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 11.32it/s]  loss:0.035644592108598966:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 11.35it/s]loss:0.21729067754360243:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 11.35it/s] loss:0.5580433865014406:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 11.35it/s] loss:0.5580433865014406:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 11.36it/s]loss:0.7120046527726761:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 11.36it/s]loss:0.7120046527726761: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.94it/s]
Epoch: 9 cost time: 2.2788541316986084
Epoch: 9, Steps: 19 | Train Loss: 0.0801650 Vali Loss: 3.2037544 Test Loss: 25.1524544
Validation loss decreased (3.204526 --> 3.203754).  Saving model ...
Updating learning rate to 3.90625e-07
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 10.87it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 10.87it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 10.87it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 11.15it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 11.15it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 11.15it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 11.20it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 11.20it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 11.20it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 11.27it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 11.27it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 11.27it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 11.33it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 11.33it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:00, 11.33it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 11.35it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 11.35it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 11.35it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 11.38it/s]loss:0.0001684659983792235:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 11.38it/s]loss:0.03288505161623757:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 11.38it/s]  loss:0.03288505161623757:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 11.38it/s]loss:0.217116497073645:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 11.38it/s]  loss:0.5850960567430155:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 11.38it/s]loss:0.5850960567430155:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 11.39it/s]loss:0.7631647881753952:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 11.39it/s]loss:0.7631647881753952: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.92it/s]
Epoch: 10 cost time: 2.216097354888916
Epoch: 10, Steps: 19 | Train Loss: 0.0841279 Vali Loss: 3.2033947 Test Loss: 25.1517715
Validation loss decreased (3.203754 --> 3.203395).  Saving model ...
Updating learning rate to 1.953125e-07
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 10.89it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 10.89it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 10.89it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 11.07it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 11.07it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 11.07it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 11.16it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 11.16it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 11.16it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 11.13it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 11.13it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 11.13it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 11.23it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 11.23it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:00, 11.23it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 11.27it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 11.27it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 11.27it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 11.30it/s]loss:0.00015226199545364212:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 11.30it/s]loss:0.03183818850771753:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 11.30it/s]   loss:0.03183818850771753:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 11.31it/s]loss:0.2190235449644612:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 11.31it/s] loss:0.5776552397843793:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 11.31it/s]loss:0.5776552397843793:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 11.33it/s]loss:0.7935712963065703:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 11.33it/s]loss:0.7935712963065703: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.86it/s]
Epoch: 11 cost time: 2.261337995529175
Epoch: 11, Steps: 19 | Train Loss: 0.0853811 Vali Loss: 3.2032354 Test Loss: 25.1514130
Validation loss decreased (3.203395 --> 3.203235).  Saving model ...
Updating learning rate to 9.765625e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 11.06it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 11.06it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 11.06it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 11.15it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 11.15it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 11.15it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 11.19it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 11.19it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 11.19it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 11.19it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 11.19it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 11.19it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 11.10it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 11.10it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:00, 11.10it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 11.21it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 11.21it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 11.21it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 11.28it/s]loss:0.00016478615710506284:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 11.28it/s]loss:0.03629734299077345:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 11.28it/s]   loss:0.03629734299077345:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 11.31it/s]loss:0.18187953336031076:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 11.31it/s]loss:0.5276064535148968:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 11.31it/s] loss:0.5276064535148968:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 11.28it/s]loss:0.7044260389509425:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 11.28it/s]loss:0.7044260389509425: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.90it/s]
Epoch: 12 cost time: 2.274120330810547
Epoch: 12, Steps: 19 | Train Loss: 0.0763355 Vali Loss: 3.2031660 Test Loss: 25.1512375
Validation loss decreased (3.203235 --> 3.203166).  Saving model ...
Updating learning rate to 4.8828125e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:01,  9.91it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:01,  9.91it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:01,  9.91it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.93it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.93it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.93it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 11.09it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 11.09it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 11.09it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 11.22it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 11.22it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 11.22it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 11.27it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 11.27it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 11.27it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 11.31it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 11.31it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 11.31it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 11.30it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 11.30it/s]loss:0.00014324085431647901:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 11.30it/s]loss:0.00014324085431647901:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 11.34it/s]loss:0.03285692710277417:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 11.34it/s]   loss:0.23543985203231557:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 11.34it/s]loss:0.23543985203231557:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 11.35it/s]loss:0.5648381903682622:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 11.35it/s] loss:0.7794817522682846:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 11.35it/s]loss:0.7794817522682846: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 11.31it/s]loss:0.7794817522682846: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.86it/s]
Epoch: 13 cost time: 2.266350507736206
Epoch: 13, Steps: 19 | Train Loss: 0.0848821 Vali Loss: 3.2031443 Test Loss: 25.1511574
Validation loss decreased (3.203166 --> 3.203144).  Saving model ...
Updating learning rate to 2.44140625e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 11.03it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 11.03it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 11.03it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 11.07it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 11.07it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 11.07it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 11.15it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 11.15it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 11.15it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 11.19it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 11.19it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 11.19it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 11.27it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 11.27it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:00, 11.27it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 11.21it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 11.21it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 11.21it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 11.24it/s]loss:0.0001769471377529795:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 11.24it/s]loss:0.03181839359845826:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 11.24it/s]  loss:0.03181839359845826:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 11.24it/s]loss:0.22675710821202866:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 11.24it/s]loss:0.5202855061037849:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 11.24it/s] loss:0.5202855061037849:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 11.29it/s]loss:0.7788731570663187:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 11.29it/s]loss:0.7788731570663187: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.87it/s]
Epoch: 14 cost time: 2.2643520832061768
Epoch: 14, Steps: 19 | Train Loss: 0.0819953 Vali Loss: 3.2031302 Test Loss: 25.1511135
Validation loss decreased (3.203144 --> 3.203130).  Saving model ...
Updating learning rate to 1.220703125e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 11.10it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 11.10it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 11.10it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 11.12it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 11.12it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 11.12it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 11.24it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 11.24it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 11.24it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 11.24it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 11.24it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 11.24it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 11.30it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 11.30it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:00, 11.30it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 11.33it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 11.33it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 11.33it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 11.35it/s]loss:0.00016308860236394622:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 11.35it/s]loss:0.032767818359460195:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 11.35it/s]  loss:0.032767818359460195:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 11.37it/s]loss:0.2355153834569491:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 11.37it/s]  loss:0.468916737184691:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 11.37it/s] loss:0.468916737184691:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 11.36it/s]loss:0.6979731492364006:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 11.36it/s]loss:0.6979731492364006: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.95it/s]
Epoch: 15 cost time: 2.2884018421173096
Epoch: 15, Steps: 19 | Train Loss: 0.0755440 Vali Loss: 3.2031252 Test Loss: 25.1510963
Validation loss decreased (3.203130 --> 3.203125).  Saving model ...
Updating learning rate to 6.103515625e-09
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 10.65it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 10.65it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 10.65it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 11.00it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 11.00it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 11.00it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 11.07it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 11.07it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 11.07it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 11.02it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 11.02it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 11.02it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 11.13it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 11.13it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:00, 11.13it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 11.20it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 11.20it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 11.20it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 11.26it/s]loss:0.00014729114280142566:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 11.26it/s]loss:0.03635207902740112:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 11.26it/s]   loss:0.03635207902740112:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 11.29it/s]loss:0.22666726036446716:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 11.29it/s]loss:0.5898676406433934:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 11.29it/s] loss:0.5898676406433934:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 11.31it/s]loss:0.7618302976156922:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 11.31it/s]loss:0.7618302976156922: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.80it/s]
Epoch: 16 cost time: 2.2273364067077637
Epoch: 16, Steps: 19 | Train Loss: 0.0849929 Vali Loss: 3.2031229 Test Loss: 25.1510868
Validation loss decreased (3.203125 --> 3.203123).  Saving model ...
Updating learning rate to 3.0517578125e-09
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 10.74it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 10.74it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 10.74it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 10.90it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 10.90it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 10.90it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 11.11it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 11.11it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 11.11it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 11.20it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 11.20it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 11.20it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 11.30it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 11.30it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:00, 11.30it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 11.30it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 11.30it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 11.30it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 11.34it/s]loss:0.00014066061528216403:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 11.34it/s]loss:0.032546145266471545:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 11.34it/s]  loss:0.032546145266471545:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 11.36it/s]loss:0.2023442421574675:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 11.36it/s]  loss:0.6069230384686236:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 11.36it/s]loss:0.6069230384686236:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 11.35it/s]loss:0.7104881656742263:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 11.35it/s]loss:0.7104881656742263: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.89it/s]
Epoch: 17 cost time: 2.2762084007263184
Epoch: 17, Steps: 19 | Train Loss: 0.0817075 Vali Loss: 3.2031205 Test Loss: 25.1510849
Validation loss decreased (3.203123 --> 3.203120).  Saving model ...
Updating learning rate to 1.52587890625e-09
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:01,  9.96it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:01,  9.96it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:01,  9.96it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.74it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.74it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.74it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.93it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.93it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.93it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 11.11it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 11.11it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 11.11it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 11.23it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 11.23it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 11.23it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 11.27it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 11.27it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 11.27it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 11.31it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 11.31it/s]loss:0.00016247543195334522:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 11.31it/s]loss:0.00016247543195334522:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 11.33it/s]loss:0.037030286246698435:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 11.33it/s]  loss:0.2005684103499885:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 11.33it/s]  loss:0.2005684103499885:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 11.33it/s]loss:0.5053510393491918:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 11.33it/s]loss:0.7104986360358836:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 11.33it/s]loss:0.7104986360358836: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 11.31it/s]loss:0.7104986360358836: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.86it/s]
Epoch: 18 cost time: 2.311570405960083
Epoch: 18, Steps: 19 | Train Loss: 0.0765058 Vali Loss: 3.2031200 Test Loss: 25.1510811
Validation loss decreased (3.203120 --> 3.203120).  Saving model ...
Updating learning rate to 7.62939453125e-10
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 11.02it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 11.02it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 11.02it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 11.23it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 11.23it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 11.23it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 11.25it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 11.25it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 11.25it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 11.27it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 11.27it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 11.27it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 11.26it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 11.26it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:00, 11.26it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 11.32it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 11.32it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 11.32it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 11.33it/s]loss:0.00015075739737444008:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 11.33it/s]loss:0.03322197916497708:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 11.33it/s]   loss:0.03322197916497708:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 11.36it/s]loss:0.20183269135613652:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 11.36it/s]loss:0.5575056149236519:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 11.36it/s] loss:0.5575056149236519:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 11.39it/s]loss:0.7554453329535915:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 11.39it/s]loss:0.7554453329535915: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.96it/s]
Epoch: 19 cost time: 2.253838062286377
Epoch: 19, Steps: 19 | Train Loss: 0.0814819 Vali Loss: 3.2031198 Test Loss: 25.1510811
Validation loss decreased (3.203120 --> 3.203120).  Saving model ...
Updating learning rate to 3.814697265625e-10
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 10.63it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 10.63it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 10.63it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 11.06it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 11.06it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 11.06it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 11.16it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 11.16it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 11.16it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 11.25it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 11.25it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 11.25it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 11.31it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 11.31it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:00, 11.31it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 11.28it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 11.28it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 11.28it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 11.31it/s]loss:0.000150674675111246:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 11.31it/s]loss:0.03630439476917043:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 11.31it/s] loss:0.03630439476917043:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 11.35it/s]loss:0.20244638954723154:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 11.35it/s]loss:0.5598502992232072:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 11.35it/s] loss:0.5598502992232072:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 11.37it/s]loss:0.6628084048824119:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 11.37it/s]loss:0.6628084048824119: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.97it/s]
Epoch: 20 cost time: 2.2752819061279297
Epoch: 20, Steps: 19 | Train Loss: 0.0769242 Vali Loss: 3.2031193 Test Loss: 25.1510811
Validation loss decreased (3.203120 --> 3.203119).  Saving model ...
Updating learning rate to 1.9073486328125e-10
>>>>>>>testing : long_term_forecast_break_parzen_0_SegRNN_job_demand_r2_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 4
test shape: (4, 1, 3, 121420) (4, 1, 3, 121420)
test shape: (4, 3, 121420) (4, 3, 121420)
mse:8162.10107421875, mae:5.85420560836792, dtw:-999
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           0                   Model:              SegRNN              

[1mData Loader[0m
  Data:               job_demand_r2       Root Path:          ../../dataset/demand/
  Data Path:          r2.parquet          Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        .cache/checkpoints  

[1mForecasting Task[0m
  Seq Len:            6                   Label Len:          1                   
  Pred Len:           3                   Seasonal Patterns:  Monthly             
  Inverse:            1                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             121420              Dec In:             121420              
  C Out:              121420              d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           2                   d FF:               2048                
  Moving Avg:         25                  Factor:             1                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              learned             Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        32                  Itr:                1                   
  Train Epochs:       20                  Batch Size:         1                   
  Patience:           3                   Learning Rate:      0.0001              
  Des:                test                Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1                 

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_break_tukey-hanning_0_SegRNN_job_demand_r2_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 19
val 1
test 4
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:09,  1.83it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:09,  1.83it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:09,  1.83it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:03,  4.81it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:03,  4.81it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:03,  4.81it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:02,  6.86it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:02,  6.86it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:01<00:02,  6.86it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:01<00:01,  8.25it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:01<00:01,  8.25it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:01<00:01,  8.25it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:01<00:01,  9.21it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:01<00:01,  9.21it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:01<00:01,  9.21it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00,  9.88it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00,  9.88it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00,  9.88it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.35it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.35it/s]loss:0.005671486699621235:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.35it/s]loss:0.005671486699621235:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.68it/s]loss:0.2027777978375446:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.68it/s]  loss:0.6126047504285825:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.68it/s]loss:0.6126047504285825:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 10.86it/s]loss:0.8731067265659689:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:02<00:00, 10.86it/s]loss:0.9477224632027668:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:02<00:00, 10.86it/s]loss:0.9477224632027668: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:02<00:00, 11.00it/s]loss:0.9477224632027668: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:02<00:00,  8.68it/s]
Epoch: 1 cost time: 2.7307510375976562
Epoch: 1, Steps: 19 | Train Loss: 0.1390465 Vali Loss: 3.5236633 Test Loss: 25.6495228
Validation loss decreased (inf --> 3.523663).  Saving model ...
Updating learning rate to 0.0001
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 10.89it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 10.89it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 10.89it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 11.08it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 11.08it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 11.08it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 11.12it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 11.12it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 11.12it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 11.12it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 11.12it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 11.12it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 11.23it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 11.23it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:00, 11.23it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 11.27it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 11.27it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 11.27it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 11.33it/s]loss:0.005397337397544858:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 11.33it/s]loss:0.19153773367889798:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 11.33it/s] loss:0.19153773367889798:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 11.33it/s]loss:0.502486027582471:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 11.33it/s]  loss:0.8572308808707321:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 11.33it/s]loss:0.8572308808707321:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 11.36it/s]loss:0.7361858801410599:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 11.36it/s]loss:0.7361858801410599: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.87it/s]
Epoch: 2 cost time: 2.2552573680877686
Epoch: 2, Steps: 19 | Train Loss: 0.1206757 Vali Loss: 3.3228991 Test Loss: 25.3383694
Validation loss decreased (3.523663 --> 3.322899).  Saving model ...
Updating learning rate to 5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 10.94it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 10.94it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 10.94it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 11.22it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 11.22it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 11.22it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 11.25it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 11.25it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 11.25it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 11.23it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 11.23it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 11.23it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 11.27it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 11.27it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:00, 11.27it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 11.33it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 11.33it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 11.33it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 11.37it/s]loss:0.004738608334644092:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 11.37it/s]loss:0.14736920167169584:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 11.37it/s] loss:0.14736920167169584:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 11.35it/s]loss:0.40449820967820715:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 11.35it/s]loss:0.7387595126896335:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 11.35it/s] loss:0.7387595126896335:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 11.37it/s]loss:0.7981510823979105:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 11.37it/s]loss:0.7981510823979105: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.97it/s]
Epoch: 3 cost time: 2.25422739982605
Epoch: 3, Steps: 19 | Train Loss: 0.1101851 Vali Loss: 3.2315006 Test Loss: 25.2061920
Validation loss decreased (3.322899 --> 3.231501).  Saving model ...
Updating learning rate to 2.5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 11.00it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 11.00it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 11.00it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 11.08it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 11.08it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 11.08it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 11.13it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 11.13it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 11.13it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 11.04it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 11.04it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 11.04it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 11.17it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 11.17it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:00, 11.17it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 11.25it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 11.25it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 11.25it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 11.31it/s]loss:0.004505290433896282:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 11.31it/s]loss:0.136204591664286:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 11.31it/s]   loss:0.136204591664286:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 11.33it/s]loss:0.41405497690957505:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 11.33it/s]loss:0.7147086103313338:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 11.33it/s] loss:0.7147086103313338:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 11.34it/s]loss:0.7622277314566295:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 11.34it/s]loss:0.7622277314566295: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.93it/s]
Epoch: 4 cost time: 2.214062452316284
Epoch: 4, Steps: 19 | Train Loss: 0.1069316 Vali Loss: 3.2068467 Test Loss: 25.1566563
Validation loss decreased (3.231501 --> 3.206847).  Saving model ...
Updating learning rate to 1.25e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 10.90it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 10.90it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 10.90it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 11.03it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 11.03it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 11.03it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 11.03it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 11.03it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 11.03it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 11.16it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 11.16it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 11.16it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 11.23it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 11.23it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:00, 11.23it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 11.26it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 11.26it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 11.26it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 11.29it/s]loss:0.004308330659526784:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 11.29it/s]loss:0.12224517646425782:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 11.29it/s] loss:0.12224517646425782:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 11.33it/s]loss:0.3659726917341545:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 11.33it/s] loss:0.6806278344652072:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 11.33it/s]loss:0.6806278344652072:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 11.33it/s]loss:0.7729688289534589:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 11.33it/s]loss:0.7729688289534589: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.87it/s]
Epoch: 5 cost time: 2.2278544902801514
Epoch: 5, Steps: 19 | Train Loss: 0.1024275 Vali Loss: 3.1941981 Test Loss: 25.1340523
Validation loss decreased (3.206847 --> 3.194198).  Saving model ...
Updating learning rate to 6.25e-06
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:01,  9.76it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:01,  9.76it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:01,  9.76it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.90it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.90it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.90it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 11.14it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 11.14it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 11.14it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 11.27it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 11.27it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 11.27it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 11.35it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 11.35it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 11.35it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 11.41it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 11.41it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 11.41it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 11.44it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 11.44it/s]loss:0.004368414525305319:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 11.44it/s]loss:0.004368414525305319:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 11.45it/s]loss:0.1466874861844119:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 11.45it/s]  loss:0.3743159476540604:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 11.45it/s]loss:0.3743159476540604:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 11.45it/s]loss:0.6528798762574668:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 11.45it/s]loss:0.6214954738896378:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 11.45it/s]loss:0.6214954738896378: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 11.45it/s]loss:0.6214954738896378: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 11.04it/s]
Epoch: 6 cost time: 2.2171642780303955
Epoch: 6, Steps: 19 | Train Loss: 0.0947235 Vali Loss: 3.1910620 Test Loss: 25.1229973
Validation loss decreased (3.194198 --> 3.191062).  Saving model ...
Updating learning rate to 3.125e-06
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:01,  9.85it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:01,  9.85it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:01,  9.85it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.70it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.70it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.70it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 11.08it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 11.08it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 11.08it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 11.04it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 11.04it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 11.04it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 11.13it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 11.13it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 11.13it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 11.21it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 11.21it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 11.21it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 11.26it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 11.26it/s]loss:0.003467615883968714:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 11.26it/s]loss:0.003467615883968714:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 11.31it/s]loss:0.1250447130480377:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 11.31it/s]  loss:0.39830433495665646:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 11.31it/s]loss:0.39830433495665646:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 11.35it/s]loss:0.5589350664871423:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 11.35it/s] loss:0.7758408704279915:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 11.35it/s]loss:0.7758408704279915: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 11.34it/s]loss:0.7758408704279915: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.89it/s]
Epoch: 7 cost time: 2.253767967224121
Epoch: 7, Steps: 19 | Train Loss: 0.0979786 Vali Loss: 3.1899345 Test Loss: 25.1187840
Validation loss decreased (3.191062 --> 3.189934).  Saving model ...
Updating learning rate to 1.5625e-06
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 10.74it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 10.74it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 10.74it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 11.12it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 11.12it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 11.12it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 11.22it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 11.22it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 11.22it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 11.25it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 11.25it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 11.25it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 11.30it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 11.30it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:00, 11.30it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 11.35it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 11.35it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 11.35it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 11.36it/s]loss:0.003785817567620972:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 11.36it/s]loss:0.12471741313006686:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 11.36it/s] loss:0.12471741313006686:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 11.39it/s]loss:0.36561821440602454:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 11.39it/s]loss:0.6417957240888359:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 11.39it/s] loss:0.6417957240888359:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 11.36it/s]loss:0.7770594254842769:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 11.36it/s]loss:0.7770594254842769: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.94it/s]
Epoch: 8 cost time: 2.262554168701172
Epoch: 8, Steps: 19 | Train Loss: 0.1006830 Vali Loss: 3.1892519 Test Loss: 25.1165237
Validation loss decreased (3.189934 --> 3.189252).  Saving model ...
Updating learning rate to 7.8125e-07
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:02,  8.12it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:02,  8.12it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:02,  8.12it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.13it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.13it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.13it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.54it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.54it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.54it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 10.91it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 10.91it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 10.91it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 11.09it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 11.09it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:01<00:00, 11.09it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 11.20it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 11.20it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 11.20it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 11.24it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 11.24it/s]loss:0.0037957023058794717:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 11.24it/s]loss:0.0037957023058794717:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 11.28it/s]loss:0.13979736981269697:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 11.28it/s]  loss:0.39887675222291674:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 11.28it/s]loss:0.39887675222291674:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 11.31it/s]loss:0.6411003164772958:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 11.31it/s] loss:0.6868991159382152:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 11.31it/s]loss:0.6868991159382152: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 11.34it/s]loss:0.6868991159382152: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.71it/s]
Epoch: 9 cost time: 2.2774603366851807
Epoch: 9, Steps: 19 | Train Loss: 0.0984458 Vali Loss: 3.1885796 Test Loss: 25.1151772
Validation loss decreased (3.189252 --> 3.188580).  Saving model ...
Updating learning rate to 3.90625e-07
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:01,  9.87it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:01,  9.87it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:01,  9.87it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.38it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.38it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.38it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.85it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.85it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.85it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 11.06it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 11.06it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 11.06it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 11.20it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 11.20it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 11.20it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 11.21it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 11.21it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 11.21it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 11.17it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 11.17it/s]loss:0.004187908713326886:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 11.17it/s]loss:0.004187908713326886:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 11.25it/s]loss:0.12783514707027893:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 11.25it/s] loss:0.3985377256782117:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 11.25it/s] loss:0.3985377256782117:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 11.24it/s]loss:0.6615038516309384:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 11.24it/s]loss:0.7417103572104821:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 11.24it/s]loss:0.7417103572104821: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 11.28it/s]loss:0.7417103572104821: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.81it/s]
Epoch: 10 cost time: 2.2397098541259766
Epoch: 10, Steps: 19 | Train Loss: 0.1017776 Vali Loss: 3.1882708 Test Loss: 25.1145134
Validation loss decreased (3.188580 --> 3.188271).  Saving model ...
Updating learning rate to 1.953125e-07
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:02,  8.71it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:02,  8.71it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:02,  8.71it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.27it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.27it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.27it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.81it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.81it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.81it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 10.99it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 10.99it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 10.99it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 11.13it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 11.13it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:01<00:00, 11.13it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 11.20it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 11.20it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 11.20it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 11.28it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 11.28it/s]loss:0.0037930072827428575:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 11.28it/s]loss:0.0037930072827428575:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 11.33it/s]loss:0.12448322218331075:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 11.33it/s]  loss:0.4004800138252734:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 11.33it/s] loss:0.4004800138252734:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 11.29it/s]loss:0.6495547983624438:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 11.29it/s]loss:0.7736140980563773:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 11.29it/s]loss:0.7736140980563773: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 11.30it/s]loss:0.7736140980563773: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.78it/s]
Epoch: 11 cost time: 2.2696826457977295
Epoch: 11, Steps: 19 | Train Loss: 0.1027329 Vali Loss: 3.1881454 Test Loss: 25.1141663
Validation loss decreased (3.188271 --> 3.188145).  Saving model ...
Updating learning rate to 9.765625e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 10.82it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 10.82it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 10.82it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 10.87it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 10.87it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 10.87it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 11.09it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 11.09it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 11.09it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 11.22it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 11.22it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 11.22it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 11.27it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 11.27it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:00, 11.27it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 11.31it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 11.31it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 11.31it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 11.32it/s]loss:0.0041416670499308215:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 11.32it/s]loss:0.14176198963338615:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 11.32it/s]  loss:0.14176198963338615:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 11.32it/s]loss:0.33247490662542223:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 11.32it/s]loss:0.5899933546735864:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 11.32it/s] loss:0.5899933546735864:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 11.31it/s]loss:0.6785934264941256:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 11.31it/s]loss:0.6785934264941256: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.87it/s]
Epoch: 12 cost time: 2.349121332168579
Epoch: 12, Steps: 19 | Train Loss: 0.0919455 Vali Loss: 3.1881044 Test Loss: 25.1140003
Validation loss decreased (3.188145 --> 3.188104).  Saving model ...
Updating learning rate to 4.8828125e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 10.96it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 10.96it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 10.96it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 11.23it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 11.23it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 11.23it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 11.30it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 11.30it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 11.30it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 11.35it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 11.35it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 11.35it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 11.38it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 11.38it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:00, 11.38it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 11.38it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 11.38it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 11.38it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 11.39it/s]loss:0.003585362771546936:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 11.39it/s]loss:0.12774472941684084:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 11.39it/s] loss:0.12774472941684084:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 11.39it/s]loss:0.4335148240141953:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 11.39it/s] loss:0.6421366778707758:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 11.39it/s]loss:0.6421366778707758:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 11.38it/s]loss:0.7494160491289393:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 11.38it/s]loss:0.7494160491289393: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 11.04it/s]
Epoch: 13 cost time: 2.300323724746704
Epoch: 13, Steps: 19 | Train Loss: 0.1029683 Vali Loss: 3.1881001 Test Loss: 25.1139297
Validation loss decreased (3.188104 --> 3.188100).  Saving model ...
Updating learning rate to 2.44140625e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 10.92it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 10.92it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 10.92it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 11.08it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 11.08it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 11.08it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 11.22it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 11.22it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 11.22it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 11.30it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 11.30it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 11.30it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 11.31it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 11.31it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:00, 11.31it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 11.25it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 11.25it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 11.25it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 11.31it/s]loss:0.004505128083548613:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 11.31it/s]loss:0.12441270424264213:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 11.31it/s] loss:0.12441270424264213:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 11.32it/s]loss:0.4099712066324774:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 11.32it/s] loss:0.5885814366807632:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 11.32it/s]loss:0.5885814366807632:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 11.31it/s]loss:0.7488126908247031:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 11.31it/s]loss:0.7488126908247031: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.94it/s]
Epoch: 14 cost time: 2.2458572387695312
Epoch: 14, Steps: 19 | Train Loss: 0.0987517 Vali Loss: 3.1880927 Test Loss: 25.1138859
Validation loss decreased (3.188100 --> 3.188093).  Saving model ...
Updating learning rate to 1.220703125e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:01,  9.35it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:01,  9.35it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:01,  9.35it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.87it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.87it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.87it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 11.08it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 11.08it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 11.08it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 11.18it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 11.18it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 11.18it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 11.26it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 11.26it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 11.26it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 11.34it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 11.34it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 11.34it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 11.36it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 11.36it/s]loss:0.004139754760941685:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 11.36it/s]loss:0.004139754760941685:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 11.38it/s]loss:0.12790528674723287:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 11.38it/s] loss:0.4336454799589452:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 11.38it/s] loss:0.4336454799589452:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 11.39it/s]loss:0.536095329475004:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 11.39it/s] loss:0.6763942644540921:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 11.39it/s]loss:0.6763942644540921: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 11.40it/s]loss:0.6763942644540921: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.95it/s]
Epoch: 15 cost time: 2.2275338172912598
Epoch: 15, Steps: 19 | Train Loss: 0.0935884 Vali Loss: 3.1880920 Test Loss: 25.1138668
Validation loss decreased (3.188093 --> 3.188092).  Saving model ...
Updating learning rate to 6.103515625e-09
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 10.80it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 10.80it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 10.80it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 10.97it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 10.97it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 10.97it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 11.14it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 11.14it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 11.14it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 11.14it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 11.14it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 11.14it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 11.25it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 11.25it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:00, 11.25it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 11.31it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 11.31it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 11.31it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 11.34it/s]loss:0.003690267699812228:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 11.34it/s]loss:0.14104653210716722:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 11.34it/s] loss:0.14104653210716722:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 11.29it/s]loss:0.4098055015135362:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 11.29it/s] loss:0.6716174679852426:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 11.29it/s]loss:0.6716174679852426:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 11.30it/s]loss:0.7448567508011832:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 11.30it/s]loss:0.7448567508011832: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.87it/s]
Epoch: 16 cost time: 2.273803234100342
Epoch: 16, Steps: 19 | Train Loss: 0.1037377 Vali Loss: 3.1880896 Test Loss: 25.1138573
Validation loss decreased (3.188092 --> 3.188090).  Saving model ...
Updating learning rate to 3.0517578125e-09
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 10.74it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 10.74it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 10.74it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 10.83it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 10.83it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 10.83it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 10.96it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 10.96it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 10.96it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 11.08it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 11.08it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 11.08it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 11.17it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 11.17it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:00, 11.17it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 11.23it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 11.23it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 11.23it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 11.29it/s]loss:0.0034881661058184183:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 11.29it/s]loss:0.1272859418336481:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 11.29it/s]   loss:0.1272859418336481:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 11.30it/s]loss:0.36456708631501017:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 11.30it/s]loss:0.6989011115221249:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 11.30it/s] loss:0.6989011115221249:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 11.33it/s]loss:0.6857237250027224:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 11.33it/s]loss:0.6857237250027224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.86it/s]
Epoch: 17 cost time: 2.273533344268799
Epoch: 17, Steps: 19 | Train Loss: 0.0989456 Vali Loss: 3.1880879 Test Loss: 25.1138535
Validation loss decreased (3.188090 --> 3.188088).  Saving model ...
Updating learning rate to 1.52587890625e-09
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 10.94it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 10.94it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 10.94it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 11.03it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 11.03it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 11.03it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 11.19it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 11.19it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 11.19it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 11.30it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 11.30it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 11.30it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 11.36it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 11.36it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:00, 11.36it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 11.39it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 11.39it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 11.39it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 11.39it/s]loss:0.004126474751428903:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 11.39it/s]loss:0.14569635988527604:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 11.39it/s] loss:0.14569635988527604:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 11.38it/s]loss:0.36352133521911784:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 11.38it/s]loss:0.5726725388641113:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 11.38it/s] loss:0.5726725388641113:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 11.38it/s]loss:0.685740153547399:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 11.38it/s] loss:0.685740153547399: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.94it/s]
Epoch: 18 cost time: 2.264002799987793
Epoch: 18, Steps: 19 | Train Loss: 0.0932504 Vali Loss: 3.1880875 Test Loss: 25.1138515
Validation loss decreased (3.188088 --> 3.188087).  Saving model ...
Updating learning rate to 7.62939453125e-10
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 10.74it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 10.74it/s]loss:0.0:  11%|â–ˆ         | 2/19 [00:00<00:01, 10.74it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 11.01it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 11.01it/s]loss:0.0:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 11.01it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 11.19it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 11.19it/s]loss:0.0:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 11.19it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 11.25it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 11.25it/s]loss:0.0:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 11.25it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 11.28it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 11.28it/s]loss:0.0:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:00, 11.28it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 11.32it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 11.32it/s]loss:0.0:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 11.32it/s]loss:0.0:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 11.34it/s]loss:0.0037781093395493808:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 11.34it/s]loss:0.12819288762636424:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 11.34it/s]  loss:0.12819288762636424:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 11.36it/s]loss:0.36508052804862584:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 11.36it/s]loss:0.6404316653242124:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 11.36it/s] loss:0.6404316653242124:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 11.38it/s]loss:0.7415462703792829:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 11.38it/s]loss:0.7415462703792829: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.95it/s]
Epoch: 19 cost time: 2.284245252609253
Epoch: 19, Steps: 19 | Train Loss: 0.0988963 Vali Loss: 3.1880875 Test Loss: 25.1138515
Validation loss decreased (3.188087 --> 3.188087).  Saving model ...
Updating learning rate to 3.814697265625e-10
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:02,  8.57it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:02,  8.57it/s]loss:0.0:   5%|â–Œ         | 1/19 [00:00<00:02,  8.57it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.37it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.37it/s]loss:0.0:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.37it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.87it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.87it/s]loss:0.0:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.87it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 11.02it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 11.02it/s]loss:0.0:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 11.02it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 11.19it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 11.19it/s]loss:0.0:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 11.19it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 11.26it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 11.26it/s]loss:0.0:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 11.26it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 11.28it/s]loss:0.0:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 11.28it/s]loss:0.0037759542097489302:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 11.28it/s]loss:0.0037759542097489302:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 11.30it/s]loss:0.1417876141267434:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 11.30it/s]   loss:0.3647414040574715:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 11.30it/s]loss:0.3647414040574715:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 11.34it/s]loss:0.642770350150021:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 11.34it/s] loss:0.6415515749050189:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 11.34it/s]loss:0.6415515749050189: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 11.25it/s]loss:0.6415515749050189: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.76it/s]
Epoch: 20 cost time: 2.2288451194763184
Epoch: 20, Steps: 19 | Train Loss: 0.0944540 Vali Loss: 3.1880875 Test Loss: 25.1138515
Validation loss decreased (3.188087 --> 3.188087).  Saving model ...
Updating learning rate to 1.9073486328125e-10
>>>>>>>testing : long_term_forecast_break_tukey-hanning_0_SegRNN_job_demand_r2_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 4
test shape: (4, 1, 3, 121420) (4, 1, 3, 121420)
test shape: (4, 3, 121420) (4, 3, 121420)
mse:8434.5419921875, mae:5.856172561645508, dtw:-999
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           0                   Model:              SegRNN              

[1mData Loader[0m
  Data:               job_demand_r2       Root Path:          ../../dataset/demand/
  Data Path:          r2.parquet          Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        .cache/checkpoints  

[1mForecasting Task[0m
  Seq Len:            6                   Label Len:          1                   
  Pred Len:           3                   Seasonal Patterns:  Monthly             
  Inverse:            1                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             121420              Dec In:             121420              
  C Out:              121420              d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           2                   d FF:               2048                
  Moving Avg:         25                  Factor:             1                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              learned             Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        32                  Itr:                1                   
  Train Epochs:       20                  Batch Size:         1                   
  Patience:           3                   Learning Rate:      0.0001              
  Des:                test                Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1                 

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_break_rayleigh_0_SegRNN_job_demand_r2_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 19
val 1
test 4
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.4974787067778096:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.4974787067778096:   5%|â–Œ         | 1/19 [00:00<00:10,  1.69it/s]loss:0.4947052773318766:   5%|â–Œ         | 1/19 [00:00<00:10,  1.69it/s]loss:0.5527749110117912:   5%|â–Œ         | 1/19 [00:00<00:10,  1.69it/s]loss:0.5527749110117912:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:03,  4.55it/s]loss:0.5621736430619311:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:03,  4.55it/s]loss:0.6210164500549563:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:03,  4.55it/s]loss:0.6210164500549563:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:02,  6.60it/s]loss:0.7351183878742544:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:01<00:02,  6.60it/s]loss:0.6294622693321759:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:01<00:02,  6.60it/s]loss:0.6294622693321759:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:01<00:01,  8.04it/s]loss:0.6974832294108901:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:01<00:01,  8.04it/s]loss:0.7018042340306591:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:01<00:01,  8.04it/s]loss:0.7018042340306591:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:01<00:01,  9.05it/s]loss:0.7541369324684533:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:01<00:01,  9.05it/s]loss:0.6316635567820629:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:01<00:01,  9.05it/s]loss:0.6316635567820629:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00,  9.74it/s]loss:0.8267857082536135:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00,  9.74it/s]loss:0.8131050917085175:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00,  9.74it/s]loss:0.8131050917085175:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.25it/s]loss:0.8525468632841748:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.25it/s]loss:0.7206536243729258:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 10.25it/s]loss:0.7206536243729258:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.59it/s]loss:0.7295142058069276:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.59it/s]loss:0.8356248954014766:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 10.59it/s]loss:0.8356248954014766:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 10.83it/s]loss:0.7006706444686376:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:02<00:00, 10.83it/s]loss:0.6286146839030583:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:02<00:00, 10.83it/s]loss:0.6286146839030583: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:02<00:00, 11.00it/s]loss:0.6286146839030583: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:02<00:00,  8.56it/s]
Epoch: 1 cost time: 2.765052080154419
Epoch: 1, Steps: 19 | Train Loss: 0.6834386 Vali Loss: 3.2128541 Test Loss: 25.1401501
Validation loss decreased (inf --> 3.212854).  Saving model ...
Updating learning rate to 0.0001
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.3016960470339502:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.3589603714054055:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.3589603714054055:  11%|â–ˆ         | 2/19 [00:00<00:01, 10.76it/s]loss:0.31774976199131566:  11%|â–ˆ         | 2/19 [00:00<00:01, 10.76it/s]loss:0.34463677198076215:  11%|â–ˆ         | 2/19 [00:00<00:01, 10.76it/s]loss:0.34463677198076215:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 10.93it/s]loss:0.446433544284156:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 10.93it/s]  loss:0.45305773615122724:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 10.93it/s]loss:0.45305773615122724:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 11.10it/s]loss:0.4321955717906657:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 11.10it/s] loss:0.5195179636798704:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 11.10it/s]loss:0.5195179636798704:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 11.21it/s]loss:0.5664706025563925:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 11.21it/s]loss:0.567285210586856:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 11.21it/s] loss:0.567285210586856:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 11.28it/s]loss:0.6135960992977726:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 11.28it/s]loss:0.5490607062598705:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:00, 11.28it/s]loss:0.5490607062598705:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 11.32it/s]loss:0.5458188154783724:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 11.32it/s]loss:0.5893775625273445:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 11.32it/s]loss:0.5893775625273445:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 11.34it/s]loss:0.6608961930400341:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 11.34it/s]loss:0.7127839610424611:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 11.34it/s]loss:0.7127839610424611:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 11.36it/s]loss:0.5926152619118145:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 11.36it/s]loss:0.7828299492492437:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 11.36it/s]loss:0.7828299492492437:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 11.40it/s]loss:0.5308316082588009:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 11.40it/s]loss:0.5308316082588009: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.95it/s]
Epoch: 2 cost time: 2.263485908508301
Epoch: 2, Steps: 19 | Train Loss: 0.5203060 Vali Loss: 3.2557347 Test Loss: 24.9951229
EarlyStopping counter: 1 out of 3
Updating learning rate to 5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.3033653960170514:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.28986923346289806:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.28986923346289806:  11%|â–ˆ         | 2/19 [00:00<00:01, 10.50it/s]loss:0.40975678446069386:  11%|â–ˆ         | 2/19 [00:00<00:01, 10.50it/s]loss:0.36943283055058607:  11%|â–ˆ         | 2/19 [00:00<00:01, 10.50it/s]loss:0.36943283055058607:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 10.85it/s]loss:0.4269413845614855:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 10.85it/s] loss:0.3685230562420736:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 10.85it/s]loss:0.3685230562420736:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 11.13it/s]loss:0.42211071185248905:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 11.13it/s]loss:0.3859286073408501:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 11.13it/s] loss:0.3859286073408501:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 11.19it/s]loss:0.49017524406087554:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 11.19it/s]loss:0.5665808201767029:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 11.19it/s] loss:0.5665808201767029:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 11.26it/s]loss:0.6163371080047834:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 11.26it/s]loss:0.5255906198934723:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:00, 11.26it/s]loss:0.5255906198934723:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 11.30it/s]loss:0.6536214314632822:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 11.30it/s]loss:0.532921428840903:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 11.30it/s] loss:0.532921428840903:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 11.35it/s]loss:0.6823260917092187:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 11.35it/s]loss:0.5843190039457622:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 11.35it/s]loss:0.5843190039457622:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 11.37it/s]loss:0.555473149345818:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 11.37it/s] loss:0.6585751767480604:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 11.37it/s]loss:0.6585751767480604:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 11.36it/s]loss:0.716245704417898:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 11.36it/s] loss:0.716245704417898: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.90it/s]
Epoch: 3 cost time: 2.2185921669006348
Epoch: 3, Steps: 19 | Train Loss: 0.5030576 Vali Loss: 3.2154746 Test Loss: 24.9894714
EarlyStopping counter: 2 out of 3
Updating learning rate to 2.5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.31322722787592977:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.31322722787592977:   5%|â–Œ         | 1/19 [00:00<00:02,  8.89it/s]loss:0.2864688049330373:   5%|â–Œ         | 1/19 [00:00<00:02,  8.89it/s] loss:0.3147964767903265:   5%|â–Œ         | 1/19 [00:00<00:02,  8.89it/s]loss:0.3147964767903265:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.61it/s]loss:0.37516674155003693:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.61it/s]loss:0.42848316126090347:  16%|â–ˆâ–Œ        | 3/19 [00:00<00:01, 10.61it/s]loss:0.42848316126090347:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.96it/s]loss:0.3478635021190068:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.96it/s] loss:0.45126568471829387:  26%|â–ˆâ–ˆâ–‹       | 5/19 [00:00<00:01, 10.96it/s]loss:0.45126568471829387:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 11.16it/s]loss:0.43108949701416044:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 11.16it/s]loss:0.5530266608448341:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [00:00<00:01, 11.16it/s] loss:0.5530266608448341:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 11.26it/s]loss:0.4519074305104835:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 11.26it/s]loss:0.5943432577034854:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [00:00<00:00, 11.26it/s]loss:0.5943432577034854:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:00<00:00, 11.29it/s]loss:0.5333527067290832:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 11.29it/s]loss:0.5347389648317611:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [00:01<00:00, 11.29it/s]loss:0.5347389648317611:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 11.34it/s]loss:0.5133138491711056:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 11.34it/s]loss:0.6813162605510248:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [00:01<00:00, 11.34it/s]loss:0.6813162605510248:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 11.37it/s]loss:0.5904537047458088:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 11.37it/s]loss:0.6684024510192521:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [00:01<00:00, 11.37it/s]loss:0.6684024510192521:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 11.40it/s]loss:0.7584396621279398:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 11.40it/s]loss:0.6975303831860374:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [00:01<00:00, 11.40it/s]loss:0.6975303831860374: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 11.41it/s]loss:0.6975303831860374: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.89it/s]
Epoch: 4 cost time: 2.2165353298187256
Epoch: 4, Steps: 19 | Train Loss: 0.5013256 Vali Loss: 3.2060504 Test Loss: 24.9889450
Validation loss decreased (3.212854 --> 3.206050).  Saving model ...
Updating learning rate to 1.25e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.26279744763667967:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.28951059827698555:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.28951059827698555:  11%|â–ˆ         | 2/19 [00:00<00:01, 10.66it/s]loss:0.31889411712318155:  11%|â–ˆ         | 2/19 [00:00<00:01, 10.66it/s]loss:0.39354491115601303:  11%|â–ˆ         | 2/19 [00:00<00:01, 10.66it/s]loss:0.39354491115601303:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 10.65it/s]loss:0.3399832416308443:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 10.65it/s] loss:0.4462761217291286:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 10.65it/s]loss:0.4462761217291286:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 10.93it/s]loss:0.40850130131541:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 10.93it/s]  loss:0.5598230311681403:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 10.93it/s]loss:0.5598230311681403:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 11.11it/s]loss:0.54753213146831:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 11.11it/s]  loss:0.45977519776824105:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 11.11it/s]loss:0.45977519776824105:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 11.22it/s]loss:0.588772314947903:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 11.22it/s]  loss:0.5936545095935152:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:00, 11.22it/s]loss:0.5936545095935152:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 11.32it/s]loss:0.5164876330016813:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 11.32it/s]loss:0.6607150126051824:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 11.32it/s]loss:0.6607150126051824:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 11.36it/s]loss:0.6333246129329448:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 11.36it/s]loss:0.5146700471206788:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 11.36it/s]loss:0.5146700471206788:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 11.37it/s]loss:0.5757963313549038:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 11.37it/s]loss:0.6987867473543917:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 11.37it/s]loss:0.6987867473543917:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 11.38it/s]loss:0.6388358649776321:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 11.38it/s]loss:0.6388358649776321: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.88it/s]
Epoch: 5 cost time: 2.2799713611602783
Epoch: 5, Steps: 19 | Train Loss: 0.4972464 Vali Loss: 3.1973598 Test Loss: 24.9781799
Validation loss decreased (3.206050 --> 3.197360).  Saving model ...
Updating learning rate to 6.25e-06
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.24836196451517517:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.282261366956629:   0%|          | 0/19 [00:00<?, ?it/s]  loss:0.282261366956629:  11%|â–ˆ         | 2/19 [00:00<00:01, 11.12it/s]loss:0.3087777103107362:  11%|â–ˆ         | 2/19 [00:00<00:01, 11.12it/s]loss:0.3748284456892169:  11%|â–ˆ         | 2/19 [00:00<00:01, 11.12it/s]loss:0.3748284456892169:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 11.15it/s]loss:0.43045355736248353:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 11.15it/s]loss:0.4519163554722311:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 11.15it/s] loss:0.4519163554722311:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 11.25it/s]loss:0.480214160053616:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 11.25it/s] loss:0.38707514808292187:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 11.25it/s]loss:0.38707514808292187:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 11.32it/s]loss:0.5869719603301486:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 11.32it/s] loss:0.4614955343190677:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 11.32it/s]loss:0.4614955343190677:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 11.35it/s]loss:0.5710788543922288:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 11.35it/s]loss:0.5237058148032189:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:00, 11.35it/s]loss:0.5237058148032189:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 11.38it/s]loss:0.5826466569087384:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 11.38it/s]loss:0.5659678823882923:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 11.38it/s]loss:0.5659678823882923:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 11.39it/s]loss:0.6740592336732528:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 11.39it/s]loss:0.6846771064080497:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 11.39it/s]loss:0.6846771064080497:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 11.36it/s]loss:0.5906975878063752:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 11.36it/s]loss:0.6800032700174693:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 11.36it/s]loss:0.6800032700174693:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 11.37it/s]loss:0.5591860136195568:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 11.37it/s]loss:0.5591860136195568: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 11.02it/s]
Epoch: 6 cost time: 2.3030941486358643
Epoch: 6, Steps: 19 | Train Loss: 0.4970726 Vali Loss: 3.2001159 Test Loss: 24.9770737
EarlyStopping counter: 1 out of 3
Updating learning rate to 3.125e-06
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.3352458613551548:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.33058257967367843:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.33058257967367843:  11%|â–ˆ         | 2/19 [00:00<00:01, 10.53it/s]loss:0.3533570812150338:  11%|â–ˆ         | 2/19 [00:00<00:01, 10.53it/s] loss:0.3214044880545097:  11%|â–ˆ         | 2/19 [00:00<00:01, 10.53it/s]loss:0.3214044880545097:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 11.04it/s]loss:0.32014308298362576:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 11.04it/s]loss:0.3875522987588471:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 11.04it/s] loss:0.3875522987588471:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 11.19it/s]loss:0.40778130116195116:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 11.19it/s]loss:0.5086943336994916:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 11.19it/s] loss:0.5086943336994916:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 11.24it/s]loss:0.5476635444455716:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 11.24it/s]loss:0.4861144669351902:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 11.24it/s]loss:0.4861144669351902:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 11.30it/s]loss:0.5979568349891311:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 11.30it/s]loss:0.5633013969791216:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:00, 11.30it/s]loss:0.5633013969791216:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 11.30it/s]loss:0.5509686453819063:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 11.30it/s]loss:0.6164228683116936:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 11.30it/s]loss:0.6164228683116936:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 11.34it/s]loss:0.5378812733758715:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 11.34it/s]loss:0.5670747447360902:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 11.34it/s]loss:0.5670747447360902:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 11.37it/s]loss:0.6828202954306902:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 11.37it/s]loss:0.5523169928267445:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 11.37it/s]loss:0.5523169928267445:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 11.35it/s]loss:0.6996367352090013:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 11.35it/s]loss:0.6996367352090013: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.89it/s]
Epoch: 7 cost time: 2.2372891902923584
Epoch: 7, Steps: 19 | Train Loss: 0.4929957 Vali Loss: 3.2010295 Test Loss: 24.9763069
EarlyStopping counter: 2 out of 3
Updating learning rate to 1.5625e-06
  0%|          | 0/19 [00:00<?, ?it/s]loss:0.30592624017876835:   0%|          | 0/19 [00:00<?, ?it/s]loss:0.3413959537800314:   0%|          | 0/19 [00:00<?, ?it/s] loss:0.3413959537800314:  11%|â–ˆ         | 2/19 [00:00<00:01, 10.52it/s]loss:0.3355703801497018:  11%|â–ˆ         | 2/19 [00:00<00:01, 10.52it/s]loss:0.37361223533089205:  11%|â–ˆ         | 2/19 [00:00<00:01, 10.52it/s]loss:0.37361223533089205:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 10.90it/s]loss:0.4105698763692274:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 10.90it/s] loss:0.3420876079202897:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:01, 10.90it/s]loss:0.3420876079202897:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 11.12it/s]loss:0.38560184581290574:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 11.12it/s]loss:0.5028447568939739:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [00:00<00:01, 11.12it/s] loss:0.5028447568939739:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 11.21it/s]loss:0.46380476006583277:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 11.21it/s]loss:0.4562660096417572:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [00:00<00:00, 11.21it/s] loss:0.4562660096417572:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 11.27it/s]loss:0.48025679887304434:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:00<00:00, 11.27it/s]loss:0.5215081841214185:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [00:01<00:00, 11.27it/s] loss:0.5215081841214185:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 11.30it/s]loss:0.6895772263294648:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 11.30it/s]loss:0.6573174287449866:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [00:01<00:00, 11.30it/s]loss:0.6573174287449866:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 11.32it/s]loss:0.5785315417414173:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 11.32it/s]loss:0.5666132194708839:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [00:01<00:00, 11.32it/s]loss:0.5666132194708839:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 11.36it/s]loss:0.5781567391412441:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 11.36it/s]loss:0.6883007939203778:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [00:01<00:00, 11.36it/s]loss:0.6883007939203778:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 11.39it/s]loss:0.7019112738356519:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [00:01<00:00, 11.39it/s]loss:0.7019112738356519: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 10.91it/s]
Epoch: 8 cost time: 2.2488629817962646
Epoch: 8, Steps: 19 | Train Loss: 0.4936765 Vali Loss: 3.2019219 Test Loss: 24.9761124
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : long_term_forecast_break_rayleigh_0_SegRNN_job_demand_r2_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 4
test shape: (4, 1, 3, 121420) (4, 1, 3, 121420)
test shape: (4, 3, 121420) (4, 3, 121420)
mse:11148.306640625, mae:6.119400501251221, dtw:-999
