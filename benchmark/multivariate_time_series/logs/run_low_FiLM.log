True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           0                   Model:              FiLM                

[1mData Loader[0m
  Data:               job_demand_region   Root Path:          ../../dataset/demand/
  Data Path:          region.parquet      Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        .cache/checkpoints  

[1mForecasting Task[0m
  Seq Len:            6                   Label Len:          1                   
  Pred Len:           3                   Seasonal Patterns:  Monthly             
  Inverse:            1                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             16345               Dec In:             16345               
  C Out:              16345               d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           2                   d FF:               2048                
  Moving Avg:         25                  Factor:             1                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              learned             Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        32                  Itr:                1                   
  Train Epochs:       20                  Batch Size:         1                   
  Patience:           3                   Learning Rate:      0.0001              
  Des:                test                Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            0                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1                 

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use CPU
>>>>>>>start training : long_term_forecast_low_0_FiLM_job_demand_region_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 19
val 1
test 4
  0%|          | 0/19 [00:00<?, ?it/s]loss:23.327856063842773:   0%|          | 0/19 [00:14<?, ?it/s]loss:23.327856063842773:   5%|â–Œ         | 1/19 [00:14<04:22, 14.58s/it]loss:23.506261825561523:   5%|â–Œ         | 1/19 [00:28<04:22, 14.58s/it]loss:23.506261825561523:  11%|â–ˆ         | 2/19 [00:28<04:06, 14.49s/it]loss:23.36537742614746:  11%|â–ˆ         | 2/19 [00:43<04:06, 14.49s/it] loss:23.36537742614746:  16%|â–ˆâ–Œ        | 3/19 [00:43<03:50, 14.38s/it]loss:23.3535213470459:  16%|â–ˆâ–Œ        | 3/19 [00:57<03:50, 14.38s/it] loss:23.3535213470459:  21%|â–ˆâ–ˆ        | 4/19 [00:57<03:32, 14.19s/it]loss:23.513151168823242:  21%|â–ˆâ–ˆ        | 4/19 [01:10<03:32, 14.19s/it]loss:23.513151168823242:  26%|â–ˆâ–ˆâ–‹       | 5/19 [01:10<03:16, 14.01s/it]loss:23.56635856628418:  26%|â–ˆâ–ˆâ–‹       | 5/19 [01:24<03:16, 14.01s/it] loss:23.56635856628418:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [01:24<03:00, 13.92s/it]loss:23.341495513916016:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [01:38<03:00, 13.92s/it]loss:23.341495513916016:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [01:38<02:47, 13.92s/it]loss:23.725521087646484:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [01:52<02:47, 13.92s/it]loss:23.725521087646484:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [01:52<02:33, 13.92s/it]loss:23.625497817993164:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [02:06<02:33, 13.92s/it]loss:23.625497817993164:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [02:06<02:19, 13.92s/it]loss:24.05207061767578:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [02:20<02:19, 13.92s/it] loss:24.05207061767578:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [02:20<02:04, 13.88s/it]loss:23.372468948364258:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [02:34<02:04, 13.88s/it]loss:23.372468948364258:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [02:34<01:52, 14.02s/it]loss:23.378965377807617:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [02:48<01:52, 14.02s/it]loss:23.378965377807617:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [02:48<01:37, 13.94s/it]loss:23.261018753051758:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [03:01<01:37, 13.94s/it]loss:23.261018753051758:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [03:01<01:23, 13.86s/it]loss:23.812280654907227:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [03:15<01:23, 13.86s/it]loss:23.812280654907227:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [03:15<01:08, 13.72s/it]loss:23.9312744140625:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [03:28<01:08, 13.72s/it]  loss:23.9312744140625:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [03:28<00:54, 13.70s/it]loss:23.6018009185791:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [03:42<00:54, 13.70s/it]loss:23.6018009185791:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [03:42<00:40, 13.58s/it]loss:23.403583526611328:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [03:55<00:40, 13.58s/it]loss:23.403583526611328:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [03:55<00:27, 13.60s/it]loss:23.23026466369629:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [04:09<00:27, 13.60s/it] loss:23.23026466369629:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [04:09<00:13, 13.59s/it]loss:24.029680252075195:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [04:23<00:13, 13.59s/it]loss:24.029680252075195: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [04:23<00:00, 13.67s/it]loss:24.029680252075195: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [04:23<00:00, 13.86s/it]
Epoch: 1 cost time: 263.91036224365234
Epoch: 1, Steps: 19 | Train Loss: 23.5472868 Vali Loss: 3.0582812 Test Loss: 39.3811951
Validation loss decreased (inf --> 3.058281).  Saving model ...
Updating learning rate to 0.0001
  0%|          | 0/19 [00:00<?, ?it/s]loss:23.408552169799805:   0%|          | 0/19 [00:13<?, ?it/s]loss:23.408552169799805:   5%|â–Œ         | 1/19 [00:13<04:09, 13.86s/it]loss:23.618309020996094:   5%|â–Œ         | 1/19 [00:27<04:09, 13.86s/it]loss:23.618309020996094:  11%|â–ˆ         | 2/19 [00:27<03:52, 13.70s/it]loss:23.839977264404297:  11%|â–ˆ         | 2/19 [00:40<03:52, 13.70s/it]loss:23.839977264404297:  16%|â–ˆâ–Œ        | 3/19 [00:40<03:37, 13.59s/it]loss:23.779857635498047:  16%|â–ˆâ–Œ        | 3/19 [00:54<03:37, 13.59s/it]loss:23.779857635498047:  21%|â–ˆâ–ˆ        | 4/19 [00:54<03:22, 13.47s/it]loss:24.04629898071289:  21%|â–ˆâ–ˆ        | 4/19 [01:07<03:22, 13.47s/it] loss:24.04629898071289:  26%|â–ˆâ–ˆâ–‹       | 5/19 [01:07<03:06, 13.35s/it]loss:23.418563842773438:  26%|â–ˆâ–ˆâ–‹       | 5/19 [01:20<03:06, 13.35s/it]loss:23.418563842773438:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [01:20<02:53, 13.37s/it]loss:23.43273162841797:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [01:33<02:53, 13.37s/it] loss:23.43273162841797:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [01:33<02:39, 13.33s/it]loss:23.311067581176758:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [01:47<02:39, 13.33s/it]loss:23.311067581176758:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [01:47<02:27, 13.37s/it]loss:24.113218307495117:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [02:04<02:27, 13.37s/it]loss:24.113218307495117:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [02:04<02:25, 14.54s/it]loss:23.423826217651367:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [02:17<02:25, 14.54s/it]loss:23.423826217651367:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [02:17<02:07, 14.19s/it]loss:23.969615936279297:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [02:31<02:07, 14.19s/it]loss:23.969615936279297:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [02:31<01:51, 13.99s/it]loss:23.60063934326172:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [02:45<01:51, 13.99s/it] loss:23.60063934326172:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [02:45<01:36, 13.85s/it]loss:23.46368408203125:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [02:58<01:36, 13.85s/it]loss:23.46368408203125:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [02:58<01:22, 13.76s/it]loss:23.705005645751953:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [03:12<01:22, 13.76s/it]loss:23.705005645751953:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [03:12<01:08, 13.77s/it]loss:23.467082977294922:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [03:26<01:08, 13.77s/it]loss:23.467082977294922:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [03:26<00:55, 13.80s/it]loss:23.674428939819336:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [03:39<00:55, 13.80s/it]loss:23.674428939819336:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [03:39<00:41, 13.72s/it]loss:23.643054962158203:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [03:53<00:41, 13.72s/it]loss:23.643054962158203:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [03:53<00:27, 13.65s/it]loss:23.481542587280273:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [04:06<00:27, 13.65s/it]loss:23.481542587280273:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [04:06<00:13, 13.53s/it]loss:23.300806045532227:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [04:19<00:13, 13.53s/it]loss:23.300806045532227: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [04:19<00:00, 13.47s/it]loss:23.300806045532227: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [04:19<00:00, 13.68s/it]
Epoch: 2 cost time: 261.15016436576843
Epoch: 2, Steps: 19 | Train Loss: 23.6156981 Vali Loss: 3.0546615 Test Loss: 39.3865967
Validation loss decreased (3.058281 --> 3.054662).  Saving model ...
Updating learning rate to 5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:23.482839584350586:   0%|          | 0/19 [00:14<?, ?it/s]loss:23.482839584350586:   5%|â–Œ         | 1/19 [00:14<04:12, 14.03s/it]loss:23.840456008911133:   5%|â–Œ         | 1/19 [00:27<04:12, 14.03s/it]loss:23.840456008911133:  11%|â–ˆ         | 2/19 [00:27<03:54, 13.82s/it]loss:23.6817684173584:  11%|â–ˆ         | 2/19 [00:41<03:54, 13.82s/it]  loss:23.6817684173584:  16%|â–ˆâ–Œ        | 3/19 [00:41<03:38, 13.64s/it]loss:23.466896057128906:  16%|â–ˆâ–Œ        | 3/19 [00:54<03:38, 13.64s/it]loss:23.466896057128906:  21%|â–ˆâ–ˆ        | 4/19 [00:54<03:24, 13.66s/it]loss:23.310991287231445:  21%|â–ˆâ–ˆ        | 4/19 [01:08<03:24, 13.66s/it]loss:23.310991287231445:  26%|â–ˆâ–ˆâ–‹       | 5/19 [01:08<03:10, 13.61s/it]loss:23.998117446899414:  26%|â–ˆâ–ˆâ–‹       | 5/19 [01:21<03:10, 13.61s/it]loss:23.998117446899414:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [01:21<02:56, 13.58s/it]loss:24.16120719909668:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [01:35<02:56, 13.58s/it] loss:24.16120719909668:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [01:35<02:43, 13.64s/it]loss:23.4993896484375:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [01:49<02:43, 13.64s/it] loss:23.4993896484375:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [01:49<02:30, 13.67s/it]loss:23.73741912841797:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [02:03<02:30, 13.67s/it]loss:23.73741912841797:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [02:03<02:16, 13.68s/it]loss:23.490129470825195:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [02:16<02:16, 13.68s/it]loss:23.490129470825195:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [02:16<02:02, 13.66s/it]loss:23.504858016967773:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [02:30<02:02, 13.66s/it]loss:23.504858016967773:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [02:30<01:49, 13.64s/it]loss:23.645648956298828:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [02:43<01:49, 13.64s/it]loss:23.645648956298828:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [02:43<01:35, 13.64s/it]loss:23.678756713867188:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [02:57<01:35, 13.64s/it]loss:23.678756713867188:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [02:57<01:22, 13.70s/it]loss:23.922531127929688:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [03:11<01:22, 13.70s/it]loss:23.922531127929688:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [03:11<01:08, 13.67s/it]loss:23.37893295288086:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [03:24<01:08, 13.67s/it] loss:23.37893295288086:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [03:24<00:54, 13.65s/it]loss:23.517974853515625:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [03:38<00:54, 13.65s/it]loss:23.517974853515625:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [03:38<00:40, 13.65s/it]loss:24.125513076782227:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [03:51<00:40, 13.65s/it]loss:24.125513076782227:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [03:51<00:27, 13.55s/it]loss:23.519866943359375:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [04:05<00:27, 13.55s/it]loss:23.519866943359375:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [04:05<00:13, 13.49s/it]loss:23.7224178314209:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [04:18<00:13, 13.49s/it]  loss:23.7224178314209: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [04:18<00:00, 13.48s/it]loss:23.7224178314209: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [04:18<00:00, 13.62s/it]
Epoch: 3 cost time: 259.93599820137024
Epoch: 3, Steps: 19 | Train Loss: 23.6676692 Vali Loss: 3.0531826 Test Loss: 39.3899651
Validation loss decreased (3.054662 --> 3.053183).  Saving model ...
Updating learning rate to 2.5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:23.933210372924805:   0%|          | 0/19 [00:13<?, ?it/s]loss:23.933210372924805:   5%|â–Œ         | 1/19 [00:13<04:08, 13.78s/it]loss:23.33814811706543:   5%|â–Œ         | 1/19 [00:27<04:08, 13.78s/it] loss:23.33814811706543:  11%|â–ˆ         | 2/19 [00:27<03:52, 13.70s/it]loss:23.389930725097656:  11%|â–ˆ         | 2/19 [00:40<03:52, 13.70s/it]loss:23.389930725097656:  16%|â–ˆâ–Œ        | 3/19 [00:40<03:37, 13.57s/it]loss:23.52267837524414:  16%|â–ˆâ–Œ        | 3/19 [00:54<03:37, 13.57s/it] loss:23.52267837524414:  21%|â–ˆâ–ˆ        | 4/19 [00:54<03:22, 13.53s/it]loss:23.525550842285156:  21%|â–ˆâ–ˆ        | 4/19 [01:07<03:22, 13.53s/it]loss:23.525550842285156:  26%|â–ˆâ–ˆâ–‹       | 5/19 [01:07<03:08, 13.45s/it]loss:23.71483612060547:  26%|â–ˆâ–ˆâ–‹       | 5/19 [01:20<03:08, 13.45s/it] loss:23.71483612060547:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [01:20<02:54, 13.42s/it]loss:23.664297103881836:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [01:34<02:54, 13.42s/it]loss:23.664297103881836:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [01:34<02:41, 13.45s/it]loss:23.52584457397461:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [01:48<02:41, 13.45s/it] loss:23.52584457397461:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [01:48<02:28, 13.48s/it]loss:23.88113784790039:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [02:01<02:28, 13.48s/it]loss:23.88113784790039:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [02:01<02:15, 13.53s/it]loss:24.191370010375977:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [02:15<02:15, 13.53s/it]loss:24.191370010375977:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [02:15<02:02, 13.65s/it]loss:23.535058975219727:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [02:29<02:02, 13.65s/it]loss:23.535058975219727:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [02:29<01:48, 13.59s/it]loss:24.02379608154297:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [02:42<01:48, 13.59s/it] loss:24.02379608154297:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [02:42<01:34, 13.55s/it]loss:23.53553009033203:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [02:56<01:34, 13.55s/it]loss:23.53553009033203:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [02:56<01:21, 13.64s/it]loss:23.5219669342041:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [03:09<01:21, 13.64s/it] loss:23.5219669342041:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [03:09<01:07, 13.58s/it]loss:24.1433048248291:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [03:23<01:07, 13.58s/it]loss:24.1433048248291:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [03:23<00:54, 13.62s/it]loss:23.769180297851562:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [03:37<00:54, 13.62s/it]loss:23.769180297851562:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [03:37<00:40, 13.59s/it]loss:23.7089786529541:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [03:50<00:40, 13.59s/it]  loss:23.7089786529541:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [03:50<00:27, 13.61s/it]loss:23.512916564941406:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [04:04<00:27, 13.61s/it]loss:23.512916564941406:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [04:04<00:13, 13.65s/it]loss:23.740903854370117:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [04:17<00:13, 13.65s/it]loss:23.740903854370117: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [04:17<00:00, 13.63s/it]loss:23.740903854370117: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [04:18<00:00, 13.58s/it]
Epoch: 4 cost time: 259.2112240791321
Epoch: 4, Steps: 19 | Train Loss: 23.6936127 Vali Loss: 3.0526538 Test Loss: 39.3907623
Validation loss decreased (3.053183 --> 3.052654).  Saving model ...
Updating learning rate to 1.25e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:23.9500789642334:   0%|          | 0/19 [00:14<?, ?it/s]loss:23.9500789642334:   5%|â–Œ         | 1/19 [00:14<04:15, 14.22s/it]loss:23.52838706970215:   5%|â–Œ         | 1/19 [00:27<04:15, 14.22s/it]loss:23.52838706970215:  11%|â–ˆ         | 2/19 [00:27<03:56, 13.91s/it]loss:23.713035583496094:  11%|â–ˆ         | 2/19 [00:41<03:56, 13.91s/it]loss:23.713035583496094:  16%|â–ˆâ–Œ        | 3/19 [00:41<03:39, 13.70s/it]loss:23.544227600097656:  16%|â–ˆâ–Œ        | 3/19 [00:54<03:39, 13.70s/it]loss:23.544227600097656:  21%|â–ˆâ–ˆ        | 4/19 [00:54<03:24, 13.63s/it]loss:23.72875213623047:  21%|â–ˆâ–ˆ        | 4/19 [01:08<03:24, 13.63s/it] loss:23.72875213623047:  26%|â–ˆâ–ˆâ–‹       | 5/19 [01:08<03:11, 13.68s/it]loss:23.517303466796875:  26%|â–ˆâ–ˆâ–‹       | 5/19 [01:22<03:11, 13.68s/it]loss:23.517303466796875:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [01:22<02:57, 13.68s/it]loss:24.202898025512695:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [01:36<02:57, 13.68s/it]loss:24.202898025512695:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [01:36<02:45, 13.78s/it]loss:23.54303741455078:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [01:49<02:45, 13.78s/it] loss:23.54303741455078:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [01:49<02:30, 13.65s/it]loss:23.40938377380371:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [02:03<02:30, 13.65s/it]loss:23.40938377380371:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [02:03<02:15, 13.57s/it]loss:23.895822525024414:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [02:16<02:15, 13.57s/it]loss:23.895822525024414:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [02:16<02:02, 13.58s/it]loss:23.746665954589844:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [02:30<02:02, 13.58s/it]loss:23.746665954589844:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [02:30<01:48, 13.58s/it]loss:23.549339294433594:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [02:43<01:48, 13.58s/it]loss:23.549339294433594:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [02:43<01:34, 13.57s/it]loss:23.359792709350586:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [02:57<01:34, 13.57s/it]loss:23.359792709350586:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [02:57<01:21, 13.58s/it]loss:23.54395294189453:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [03:10<01:21, 13.58s/it] loss:23.54395294189453:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [03:10<01:07, 13.56s/it]loss:24.034730911254883:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [03:24<01:07, 13.56s/it]loss:24.034730911254883:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [03:24<00:54, 13.59s/it]loss:23.779430389404297:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [03:37<00:54, 13.59s/it]loss:23.779430389404297:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [03:37<00:40, 13.51s/it]loss:23.682573318481445:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [03:51<00:40, 13.51s/it]loss:23.682573318481445:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [03:51<00:26, 13.47s/it]loss:23.54427146911621:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [04:04<00:26, 13.47s/it] loss:23.54427146911621:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [04:04<00:13, 13.46s/it]loss:24.15618133544922:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [04:18<00:13, 13.46s/it]loss:24.15618133544922: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [04:18<00:00, 13.53s/it]loss:24.15618133544922: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [04:18<00:00, 13.61s/it]
Epoch: 5 cost time: 259.65153408050537
Epoch: 5, Steps: 19 | Train Loss: 23.7068350 Vali Loss: 3.0523849 Test Loss: 39.3902702
Validation loss decreased (3.052654 --> 3.052385).  Saving model ...
Updating learning rate to 6.25e-06
  0%|          | 0/19 [00:00<?, ?it/s]loss:23.552183151245117:   0%|          | 0/19 [00:14<?, ?it/s]loss:23.552183151245117:   5%|â–Œ         | 1/19 [00:14<04:17, 14.33s/it]loss:23.363073348999023:   5%|â–Œ         | 1/19 [00:27<04:17, 14.33s/it]loss:23.363073348999023:  11%|â–ˆ         | 2/19 [00:27<03:54, 13.81s/it]loss:23.553647994995117:  11%|â–ˆ         | 2/19 [00:41<03:54, 13.81s/it]loss:23.553647994995117:  16%|â–ˆâ–Œ        | 3/19 [00:41<03:39, 13.72s/it]loss:23.41514778137207:  16%|â–ˆâ–Œ        | 3/19 [00:54<03:39, 13.72s/it] loss:23.41514778137207:  21%|â–ˆâ–ˆ        | 4/19 [00:54<03:24, 13.62s/it]loss:23.54781723022461:  21%|â–ˆâ–ˆ        | 4/19 [01:08<03:24, 13.62s/it]loss:23.54781723022461:  26%|â–ˆâ–ˆâ–‹       | 5/19 [01:08<03:09, 13.53s/it]loss:23.73641586303711:  26%|â–ˆâ–ˆâ–‹       | 5/19 [01:21<03:09, 13.53s/it]loss:23.73641586303711:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [01:21<02:55, 13.49s/it]loss:23.959985733032227:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [01:35<02:55, 13.49s/it]loss:23.959985733032227:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [01:35<02:41, 13.48s/it]loss:23.90213966369629:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [01:48<02:41, 13.48s/it] loss:23.90213966369629:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [01:48<02:28, 13.47s/it]loss:23.55059051513672:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [02:01<02:28, 13.47s/it]loss:23.55059051513672:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [02:01<02:14, 13.46s/it]loss:23.72385597229004:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [02:15<02:14, 13.46s/it]loss:23.72385597229004:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [02:15<02:01, 13.49s/it]loss:24.21076011657715:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [02:28<02:01, 13.49s/it]loss:24.21076011657715:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [02:28<01:47, 13.47s/it]loss:24.038270950317383:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [02:42<01:47, 13.47s/it]loss:24.038270950317383:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [02:42<01:33, 13.42s/it]loss:23.547761917114258:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [02:55<01:33, 13.42s/it]loss:23.547761917114258:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [02:55<01:20, 13.36s/it]loss:23.68661117553711:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [03:08<01:20, 13.36s/it] loss:23.68661117553711:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [03:08<01:06, 13.32s/it]loss:23.527294158935547:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [03:22<01:06, 13.32s/it]loss:23.527294158935547:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [03:22<00:53, 13.33s/it]loss:23.540796279907227:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [03:35<00:53, 13.33s/it]loss:23.540796279907227:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [03:35<00:40, 13.39s/it]loss:24.160188674926758:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [03:49<00:40, 13.39s/it]loss:24.160188674926758:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [03:49<00:26, 13.46s/it]loss:23.784799575805664:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [04:02<00:26, 13.46s/it]loss:23.784799575805664:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [04:02<00:13, 13.40s/it]loss:23.755033493041992:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [04:15<00:13, 13.40s/it]loss:23.755033493041992: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [04:15<00:00, 13.38s/it]loss:23.755033493041992: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [04:15<00:00, 13.47s/it]
Epoch: 6 cost time: 257.1494653224945
Epoch: 6, Steps: 19 | Train Loss: 23.7134933 Vali Loss: 3.0522470 Test Loss: 39.3908653
Validation loss decreased (3.052385 --> 3.052247).  Saving model ...
Updating learning rate to 3.125e-06
  0%|          | 0/19 [00:00<?, ?it/s]loss:23.528491973876953:   0%|          | 0/19 [00:13<?, ?it/s]loss:23.528491973876953:   5%|â–Œ         | 1/19 [00:13<04:11, 13.99s/it]loss:23.418943405151367:   5%|â–Œ         | 1/19 [00:27<04:11, 13.99s/it]loss:23.418943405151367:  11%|â–ˆ         | 2/19 [00:27<03:53, 13.71s/it]loss:23.549524307250977:  11%|â–ˆ         | 2/19 [00:40<03:53, 13.71s/it]loss:23.549524307250977:  16%|â–ˆâ–Œ        | 3/19 [00:40<03:37, 13.61s/it]loss:23.785511016845703:  16%|â–ˆâ–Œ        | 3/19 [00:54<03:37, 13.61s/it]loss:23.785511016845703:  21%|â–ˆâ–ˆ        | 4/19 [00:54<03:22, 13.52s/it]loss:23.963359832763672:  21%|â–ˆâ–ˆ        | 4/19 [01:08<03:22, 13.52s/it]loss:23.963359832763672:  26%|â–ˆâ–ˆâ–‹       | 5/19 [01:08<03:10, 13.58s/it]loss:23.553834915161133:  26%|â–ˆâ–ˆâ–‹       | 5/19 [01:21<03:10, 13.58s/it]loss:23.553834915161133:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [01:21<02:56, 13.59s/it]loss:23.727157592773438:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [01:35<02:56, 13.59s/it]loss:23.727157592773438:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [01:35<02:42, 13.53s/it]loss:23.90580177307129:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [01:48<02:42, 13.53s/it] loss:23.90580177307129:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [01:48<02:29, 13.58s/it]loss:24.16175079345703:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [02:02<02:29, 13.58s/it]loss:24.16175079345703:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [02:02<02:15, 13.60s/it]loss:24.213748931884766:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [02:16<02:15, 13.60s/it]loss:24.213748931884766:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [02:16<02:02, 13.62s/it]loss:23.68901252746582:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [02:29<02:02, 13.62s/it] loss:23.68901252746582:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [02:29<01:49, 13.63s/it]loss:23.740636825561523:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [02:43<01:49, 13.63s/it]loss:23.740636825561523:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [02:43<01:34, 13.53s/it]loss:23.368515014648438:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [02:56<01:34, 13.53s/it]loss:23.368515014648438:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [02:56<01:21, 13.52s/it]loss:24.04072380065918:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [03:09<01:21, 13.52s/it] loss:24.04072380065918:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [03:09<01:07, 13.47s/it]loss:23.558834075927734:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [03:23<01:07, 13.47s/it]loss:23.558834075927734:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [03:23<00:53, 13.44s/it]loss:23.553340911865234:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [03:36<00:53, 13.44s/it]loss:23.553340911865234:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [03:36<00:40, 13.43s/it]loss:23.543779373168945:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [03:49<00:40, 13.43s/it]loss:23.543779373168945:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [03:49<00:26, 13.38s/it]loss:23.757339477539062:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [04:03<00:26, 13.38s/it]loss:23.757339477539062:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [04:03<00:13, 13.44s/it]loss:23.56007194519043:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [04:17<00:13, 13.44s/it] loss:23.56007194519043: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [04:17<00:00, 13.46s/it]loss:23.56007194519043: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [04:17<00:00, 13.53s/it]
Epoch: 7 cost time: 258.3002073764801
Epoch: 7, Steps: 19 | Train Loss: 23.7168620 Vali Loss: 3.0521638 Test Loss: 39.3909607
Validation loss decreased (3.052247 --> 3.052164).  Saving model ...
Updating learning rate to 1.5625e-06
  0%|          | 0/19 [00:00<?, ?it/s]loss:23.559465408325195:   0%|          | 0/19 [00:14<?, ?it/s]loss:23.559465408325195:   5%|â–Œ         | 1/19 [00:14<04:14, 14.15s/it]loss:23.560253143310547:   5%|â–Œ         | 1/19 [00:27<04:14, 14.15s/it]loss:23.560253143310547:  11%|â–ˆ         | 2/19 [00:27<03:55, 13.84s/it]loss:24.214967727661133:  11%|â–ˆ         | 2/19 [00:41<03:55, 13.84s/it]loss:24.214967727661133:  16%|â–ˆâ–Œ        | 3/19 [00:41<03:40, 13.80s/it]loss:24.0413818359375:  16%|â–ˆâ–Œ        | 3/19 [00:54<03:40, 13.80s/it]  loss:24.0413818359375:  21%|â–ˆâ–ˆ        | 4/19 [00:54<03:24, 13.66s/it]loss:23.787439346313477:  21%|â–ˆâ–ˆ        | 4/19 [01:08<03:24, 13.66s/it]loss:23.787439346313477:  26%|â–ˆâ–ˆâ–‹       | 5/19 [01:08<03:10, 13.61s/it]loss:23.741783142089844:  26%|â–ˆâ–ˆâ–‹       | 5/19 [01:21<03:10, 13.61s/it]loss:23.741783142089844:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [01:21<02:55, 13.52s/it]loss:24.163326263427734:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [01:35<02:55, 13.52s/it]loss:24.163326263427734:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [01:35<02:41, 13.47s/it]loss:23.369699478149414:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [01:48<02:41, 13.47s/it]loss:23.369699478149414:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [01:48<02:27, 13.44s/it]loss:23.758037567138672:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [02:02<02:27, 13.44s/it]loss:23.758037567138672:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [02:02<02:14, 13.47s/it]loss:23.55192756652832:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [02:15<02:14, 13.47s/it] loss:23.55192756652832:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [02:15<02:01, 13.49s/it]loss:23.531389236450195:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [02:29<02:01, 13.49s/it]loss:23.531389236450195:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [02:29<01:48, 13.59s/it]loss:23.72954750061035:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [02:42<01:48, 13.59s/it] loss:23.72954750061035:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [02:42<01:34, 13.52s/it]loss:23.544889450073242:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [02:56<01:34, 13.52s/it]loss:23.544889450073242:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [02:56<01:21, 13.51s/it]loss:23.556333541870117:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [03:09<01:21, 13.51s/it]loss:23.556333541870117:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [03:09<01:07, 13.54s/it]loss:23.690750122070312:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [03:23<01:07, 13.54s/it]loss:23.690750122070312:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [03:23<00:54, 13.61s/it]loss:23.908126831054688:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [03:37<00:54, 13.61s/it]loss:23.908126831054688:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [03:37<00:40, 13.66s/it]loss:23.42198371887207:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [03:51<00:40, 13.66s/it] loss:23.42198371887207:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [03:51<00:27, 13.68s/it]loss:23.55487632751465:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [04:04<00:27, 13.68s/it]loss:23.55487632751465:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [04:04<00:13, 13.61s/it]loss:23.966096878051758:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [04:18<00:13, 13.61s/it]loss:23.966096878051758: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [04:18<00:00, 13.61s/it]loss:23.966096878051758: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [04:18<00:00, 13.60s/it]
Epoch: 8 cost time: 259.5555284023285
Epoch: 8, Steps: 19 | Train Loss: 23.7185408 Vali Loss: 3.0521305 Test Loss: 39.3910904
Validation loss decreased (3.052164 --> 3.052130).  Saving model ...
Updating learning rate to 7.8125e-07
  0%|          | 0/19 [00:00<?, ?it/s]loss:23.56134796142578:   0%|          | 0/19 [00:14<?, ?it/s]loss:23.56134796142578:   5%|â–Œ         | 1/19 [00:14<04:14, 14.12s/it]loss:23.556720733642578:   5%|â–Œ         | 1/19 [00:27<04:14, 14.12s/it]loss:23.556720733642578:  11%|â–ˆ         | 2/19 [00:27<03:53, 13.74s/it]loss:23.742595672607422:  11%|â–ˆ         | 2/19 [00:41<03:53, 13.74s/it]loss:23.742595672607422:  16%|â–ˆâ–Œ        | 3/19 [00:41<03:39, 13.71s/it]loss:23.75876235961914:  16%|â–ˆâ–Œ        | 3/19 [00:54<03:39, 13.71s/it] loss:23.75876235961914:  21%|â–ˆâ–ˆ        | 4/19 [00:54<03:23, 13.54s/it]loss:23.5607852935791:  21%|â–ˆâ–ˆ        | 4/19 [01:07<03:23, 13.54s/it] loss:23.5607852935791:  26%|â–ˆâ–ˆâ–‹       | 5/19 [01:07<03:08, 13.49s/it]loss:24.216039657592773:  26%|â–ˆâ–ˆâ–‹       | 5/19 [01:21<03:08, 13.49s/it]loss:24.216039657592773:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [01:21<02:56, 13.61s/it]loss:23.555171966552734:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [01:35<02:56, 13.61s/it]loss:23.555171966552734:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [01:35<02:42, 13.57s/it]loss:23.691200256347656:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [01:48<02:42, 13.57s/it]loss:23.691200256347656:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [01:48<02:29, 13.58s/it]loss:23.73029899597168:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [02:02<02:29, 13.58s/it] loss:23.73029899597168:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [02:02<02:14, 13.49s/it]loss:24.042280197143555:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [02:15<02:14, 13.49s/it]loss:24.042280197143555:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [02:15<02:01, 13.54s/it]loss:23.55274772644043:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [02:29<02:01, 13.54s/it] loss:23.55274772644043:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [02:29<01:48, 13.62s/it]loss:23.42247200012207:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [02:43<01:48, 13.62s/it]loss:23.42247200012207:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [02:43<01:35, 13.64s/it]loss:24.16438865661621:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [02:56<01:35, 13.64s/it]loss:24.16438865661621:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [02:56<01:21, 13.56s/it]loss:23.908740997314453:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [03:10<01:21, 13.56s/it]loss:23.908740997314453:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [03:10<01:07, 13.59s/it]loss:23.37076187133789:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [03:24<01:07, 13.59s/it] loss:23.37076187133789:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [03:24<00:54, 13.61s/it]loss:23.788679122924805:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [03:37<00:54, 13.61s/it]loss:23.788679122924805:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [03:37<00:40, 13.58s/it]loss:23.54580307006836:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [03:50<00:40, 13.58s/it] loss:23.54580307006836:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [03:50<00:27, 13.51s/it]loss:23.53243064880371:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [04:04<00:27, 13.51s/it]loss:23.53243064880371:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [04:04<00:13, 13.54s/it]loss:23.966646194458008:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [04:18<00:13, 13.54s/it]loss:23.966646194458008: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [04:18<00:00, 13.57s/it]loss:23.966646194458008: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [04:18<00:00, 13.59s/it]
Epoch: 9 cost time: 259.42438769340515
Epoch: 9, Steps: 19 | Train Loss: 23.7193618 Vali Loss: 3.0521159 Test Loss: 39.3910866
Validation loss decreased (3.052130 --> 3.052116).  Saving model ...
Updating learning rate to 3.90625e-07
  0%|          | 0/19 [00:00<?, ?it/s]loss:23.532487869262695:   0%|          | 0/19 [00:13<?, ?it/s]loss:23.532487869262695:   5%|â–Œ         | 1/19 [00:13<04:11, 13.98s/it]loss:23.73065948486328:   5%|â–Œ         | 1/19 [00:27<04:11, 13.98s/it] loss:23.73065948486328:  11%|â–ˆ         | 2/19 [00:27<03:53, 13.76s/it]loss:23.55558967590332:  11%|â–ˆ         | 2/19 [00:41<03:53, 13.76s/it]loss:23.55558967590332:  16%|â–ˆâ–Œ        | 3/19 [00:41<03:39, 13.70s/it]loss:23.788816452026367:  16%|â–ˆâ–Œ        | 3/19 [00:54<03:39, 13.70s/it]loss:23.788816452026367:  21%|â–ˆâ–ˆ        | 4/19 [00:54<03:23, 13.57s/it]loss:23.370952606201172:  21%|â–ˆâ–ˆ        | 4/19 [01:07<03:23, 13.57s/it]loss:23.370952606201172:  26%|â–ˆâ–ˆâ–‹       | 5/19 [01:07<03:08, 13.45s/it]loss:24.042539596557617:  26%|â–ˆâ–ˆâ–‹       | 5/19 [01:21<03:08, 13.45s/it]loss:24.042539596557617:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [01:21<02:54, 13.40s/it]loss:23.561994552612305:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [01:34<02:54, 13.40s/it]loss:23.561994552612305:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [01:34<02:40, 13.36s/it]loss:23.561355590820312:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [01:47<02:40, 13.36s/it]loss:23.561355590820312:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [01:47<02:26, 13.31s/it]loss:23.54599952697754:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [02:01<02:26, 13.31s/it] loss:23.54599952697754:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [02:01<02:14, 13.44s/it]loss:23.5573673248291:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [02:14<02:14, 13.44s/it] loss:23.5573673248291:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [02:14<02:00, 13.43s/it]loss:23.909053802490234:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [02:28<02:00, 13.43s/it]loss:23.909053802490234:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [02:28<01:47, 13.45s/it]loss:23.553131103515625:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [02:41<01:47, 13.45s/it]loss:23.553131103515625:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [02:41<01:34, 13.46s/it]loss:24.164743423461914:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [02:55<01:34, 13.46s/it]loss:24.164743423461914:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [02:55<01:20, 13.43s/it]loss:23.422866821289062:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [03:08<01:20, 13.43s/it]loss:23.422866821289062:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [03:08<01:07, 13.48s/it]loss:24.216596603393555:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [03:22<01:07, 13.48s/it]loss:24.216596603393555:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [03:22<00:53, 13.47s/it]loss:23.691713333129883:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [03:35<00:53, 13.47s/it]loss:23.691713333129883:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [03:35<00:40, 13.51s/it]loss:23.966880798339844:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [03:49<00:40, 13.51s/it]loss:23.966880798339844:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [03:49<00:27, 13.55s/it]loss:23.759458541870117:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [04:02<00:27, 13.55s/it]loss:23.759458541870117:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [04:02<00:13, 13.55s/it]loss:23.743276596069336:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [04:16<00:13, 13.55s/it]loss:23.743276596069336: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [04:16<00:00, 13.47s/it]loss:23.743276596069336: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [04:16<00:00, 13.49s/it]
Epoch: 10 cost time: 257.4145522117615
Epoch: 10, Steps: 19 | Train Loss: 23.7197623 Vali Loss: 3.0521064 Test Loss: 39.3911209
Validation loss decreased (3.052116 --> 3.052106).  Saving model ...
Updating learning rate to 1.953125e-07
  0%|          | 0/19 [00:00<?, ?it/s]loss:23.5575008392334:   0%|          | 0/19 [00:14<?, ?it/s]loss:23.5575008392334:   5%|â–Œ         | 1/19 [00:14<04:14, 14.14s/it]loss:23.55583953857422:   5%|â–Œ         | 1/19 [00:27<04:14, 14.14s/it]loss:23.55583953857422:  11%|â–ˆ         | 2/19 [00:27<03:51, 13.62s/it]loss:23.561548233032227:  11%|â–ˆ         | 2/19 [00:40<03:51, 13.62s/it]loss:23.561548233032227:  16%|â–ˆâ–Œ        | 3/19 [00:40<03:35, 13.45s/it]loss:24.042699813842773:  16%|â–ˆâ–Œ        | 3/19 [00:54<03:35, 13.45s/it]loss:24.042699813842773:  21%|â–ˆâ–ˆ        | 4/19 [00:54<03:21, 13.46s/it]loss:24.164865493774414:  21%|â–ˆâ–ˆ        | 4/19 [01:07<03:21, 13.46s/it]loss:24.164865493774414:  26%|â–ˆâ–ˆâ–‹       | 5/19 [01:07<03:08, 13.49s/it]loss:23.42299461364746:  26%|â–ˆâ–ˆâ–‹       | 5/19 [01:21<03:08, 13.49s/it] loss:23.42299461364746:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [01:21<02:55, 13.52s/it]loss:24.216712951660156:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [01:34<02:55, 13.52s/it]loss:24.216712951660156:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [01:34<02:43, 13.60s/it]loss:23.743349075317383:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [01:48<02:43, 13.60s/it]loss:23.743349075317383:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [01:48<02:28, 13.49s/it]loss:23.90924644470215:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [02:01<02:28, 13.49s/it] loss:23.90924644470215:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [02:01<02:14, 13.46s/it]loss:23.553312301635742:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [02:15<02:14, 13.46s/it]loss:23.553312301635742:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [02:15<02:01, 13.48s/it]loss:23.56227684020996:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [02:28<02:01, 13.48s/it] loss:23.56227684020996:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [02:28<01:47, 13.47s/it]loss:23.371246337890625:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [02:42<01:47, 13.47s/it]loss:23.371246337890625:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [02:42<01:34, 13.46s/it]loss:23.69186019897461:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [02:55<01:34, 13.46s/it] loss:23.69186019897461:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [02:55<01:20, 13.49s/it]loss:23.759605407714844:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [03:09<01:20, 13.49s/it]loss:23.759605407714844:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [03:09<01:07, 13.47s/it]loss:23.532882690429688:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [03:22<01:07, 13.47s/it]loss:23.532882690429688:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [03:22<00:53, 13.47s/it]loss:23.73107147216797:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [03:35<00:53, 13.47s/it] loss:23.73107147216797:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [03:35<00:40, 13.44s/it]loss:23.54631233215332:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [03:49<00:40, 13.44s/it]loss:23.54631233215332:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [03:49<00:26, 13.39s/it]loss:23.789165496826172:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [04:02<00:26, 13.39s/it]loss:23.789165496826172:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [04:02<00:13, 13.37s/it]loss:23.967079162597656:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [04:15<00:13, 13.37s/it]loss:23.967079162597656: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [04:15<00:00, 13.39s/it]loss:23.967079162597656: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [04:16<00:00, 13.48s/it]
Epoch: 11 cost time: 257.2555947303772
Epoch: 11, Steps: 19 | Train Loss: 23.7199773 Vali Loss: 3.0521026 Test Loss: 39.3911362
Validation loss decreased (3.052106 --> 3.052103).  Saving model ...
Updating learning rate to 9.765625e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:23.55340003967285:   0%|          | 0/19 [00:14<?, ?it/s]loss:23.55340003967285:   5%|â–Œ         | 1/19 [00:14<04:16, 14.24s/it]loss:23.56171989440918:   5%|â–Œ         | 1/19 [00:27<04:16, 14.24s/it]loss:23.56171989440918:  11%|â–ˆ         | 2/19 [00:27<03:57, 13.95s/it]loss:23.731122970581055:  11%|â–ˆ         | 2/19 [00:41<03:57, 13.95s/it]loss:23.731122970581055:  16%|â–ˆâ–Œ        | 3/19 [00:41<03:38, 13.65s/it]loss:23.557695388793945:  16%|â–ˆâ–Œ        | 3/19 [00:54<03:38, 13.65s/it]loss:23.557695388793945:  21%|â–ˆâ–ˆ        | 4/19 [00:54<03:23, 13.59s/it]loss:23.371335983276367:  21%|â–ˆâ–ˆ        | 4/19 [01:08<03:23, 13.59s/it]loss:23.371335983276367:  26%|â–ˆâ–ˆâ–‹       | 5/19 [01:08<03:08, 13.48s/it]loss:23.5329532623291:  26%|â–ˆâ–ˆâ–‹       | 5/19 [01:21<03:08, 13.48s/it]  loss:23.5329532623291:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [01:21<02:54, 13.42s/it]loss:23.42315101623535:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [01:34<02:54, 13.42s/it]loss:23.42315101623535:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [01:34<02:40, 13.36s/it]loss:23.90938377380371:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [01:48<02:40, 13.36s/it]loss:23.90938377380371:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [01:48<02:27, 13.43s/it]loss:24.04285430908203:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [02:01<02:27, 13.43s/it]loss:24.04285430908203:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [02:01<02:15, 13.51s/it]loss:23.5463809967041:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [02:15<02:15, 13.51s/it] loss:23.5463809967041:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [02:15<02:00, 13.42s/it]loss:23.743499755859375:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [02:28<02:00, 13.42s/it]loss:23.743499755859375:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [02:28<01:48, 13.50s/it]loss:23.55607032775879:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [02:42<01:48, 13.50s/it] loss:23.55607032775879:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [02:42<01:34, 13.47s/it]loss:23.691978454589844:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [02:55<01:34, 13.47s/it]loss:23.691978454589844:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [02:55<01:20, 13.49s/it]loss:23.562427520751953:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [03:09<01:20, 13.49s/it]loss:23.562427520751953:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [03:09<01:07, 13.45s/it]loss:23.78924560546875:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [03:22<01:07, 13.45s/it] loss:23.78924560546875:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [03:22<00:53, 13.49s/it]loss:24.165069580078125:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [03:36<00:53, 13.49s/it]loss:24.165069580078125:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [03:36<00:40, 13.49s/it]loss:24.216899871826172:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [03:49<00:40, 13.49s/it]loss:24.216899871826172:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [03:49<00:26, 13.48s/it]loss:23.759742736816406:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [04:03<00:26, 13.48s/it]loss:23.759742736816406:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [04:03<00:13, 13.47s/it]loss:23.96717071533203:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [04:16<00:13, 13.47s/it] loss:23.96717071533203: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [04:16<00:00, 13.58s/it]loss:23.96717071533203: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [04:17<00:00, 13.53s/it]
Epoch: 12 cost time: 258.1849331855774
Epoch: 12, Steps: 19 | Train Loss: 23.7201106 Vali Loss: 3.0521002 Test Loss: 39.3911362
Validation loss decreased (3.052103 --> 3.052100).  Saving model ...
Updating learning rate to 4.8828125e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:23.7312068939209:   0%|          | 0/19 [00:14<?, ?it/s]loss:23.7312068939209:   5%|â–Œ         | 1/19 [00:14<04:15, 14.21s/it]loss:23.55610466003418:   5%|â–Œ         | 1/19 [00:28<04:15, 14.21s/it]loss:23.55610466003418:  11%|â–ˆ         | 2/19 [00:28<03:57, 14.00s/it]loss:23.7435359954834:  11%|â–ˆ         | 2/19 [00:41<03:57, 14.00s/it] loss:23.7435359954834:  16%|â–ˆâ–Œ        | 3/19 [00:41<03:40, 13.77s/it]loss:23.909440994262695:  16%|â–ˆâ–Œ        | 3/19 [00:55<03:40, 13.77s/it]loss:23.909440994262695:  21%|â–ˆâ–ˆ        | 4/19 [00:55<03:25, 13.69s/it]loss:23.562454223632812:  21%|â–ˆâ–ˆ        | 4/19 [01:08<03:25, 13.69s/it]loss:23.562454223632812:  26%|â–ˆâ–ˆâ–‹       | 5/19 [01:08<03:11, 13.64s/it]loss:23.967172622680664:  26%|â–ˆâ–ˆâ–‹       | 5/19 [01:22<03:11, 13.64s/it]loss:23.967172622680664:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [01:22<02:56, 13.61s/it]loss:23.42321014404297:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [01:35<02:56, 13.61s/it] loss:23.42321014404297:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [01:35<02:43, 13.60s/it]loss:23.561811447143555:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [01:49<02:43, 13.60s/it]loss:23.561811447143555:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [01:49<02:30, 13.65s/it]loss:23.553485870361328:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [02:03<02:30, 13.65s/it]loss:23.553485870361328:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [02:03<02:16, 13.61s/it]loss:23.759748458862305:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [02:16<02:16, 13.61s/it]loss:23.759748458862305:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [02:16<02:02, 13.62s/it]loss:23.789260864257812:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [02:30<02:02, 13.62s/it]loss:23.789260864257812:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [02:30<01:48, 13.59s/it]loss:23.557769775390625:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [02:43<01:48, 13.59s/it]loss:23.557769775390625:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [02:43<01:34, 13.55s/it]loss:23.533018112182617:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [02:57<01:34, 13.55s/it]loss:23.533018112182617:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [02:57<01:21, 13.63s/it]loss:24.216907501220703:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [03:11<01:21, 13.63s/it]loss:24.216907501220703:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [03:11<01:08, 13.66s/it]loss:23.371400833129883:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [03:25<01:08, 13.66s/it]loss:23.371400833129883:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [03:25<00:54, 13.71s/it]loss:24.165081024169922:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [03:38<00:54, 13.71s/it]loss:24.165081024169922:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [03:38<00:40, 13.66s/it]loss:23.546430587768555:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [03:52<00:40, 13.66s/it]loss:23.546430587768555:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [03:52<00:27, 13.65s/it]loss:24.042882919311523:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [04:05<00:27, 13.65s/it]loss:24.042882919311523:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [04:05<00:13, 13.66s/it]loss:23.692001342773438:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [04:19<00:13, 13.66s/it]loss:23.692001342773438: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [04:19<00:00, 13.61s/it]loss:23.692001342773438: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [04:19<00:00, 13.66s/it]
Epoch: 13 cost time: 260.69843459129333
Epoch: 13, Steps: 19 | Train Loss: 23.7201539 Vali Loss: 3.0520992 Test Loss: 39.3911362
Validation loss decreased (3.052100 --> 3.052099).  Saving model ...
Updating learning rate to 2.44140625e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:23.7435302734375:   0%|          | 0/19 [00:14<?, ?it/s]loss:23.7435302734375:   5%|â–Œ         | 1/19 [00:14<04:14, 14.15s/it]loss:24.165081024169922:   5%|â–Œ         | 1/19 [00:27<04:14, 14.15s/it]loss:24.165081024169922:  11%|â–ˆ         | 2/19 [00:27<03:54, 13.79s/it]loss:23.561811447143555:  11%|â–ˆ         | 2/19 [00:41<03:54, 13.79s/it]loss:23.561811447143555:  16%|â–ˆâ–Œ        | 3/19 [00:41<03:37, 13.61s/it]loss:23.53301429748535:  16%|â–ˆâ–Œ        | 3/19 [00:54<03:37, 13.61s/it] loss:23.53301429748535:  21%|â–ˆâ–ˆ        | 4/19 [00:54<03:24, 13.64s/it]loss:23.9671688079834:  21%|â–ˆâ–ˆ        | 4/19 [01:08<03:24, 13.64s/it] loss:23.9671688079834:  26%|â–ˆâ–ˆâ–‹       | 5/19 [01:08<03:10, 13.62s/it]loss:23.90943717956543:  26%|â–ˆâ–ˆâ–‹       | 5/19 [01:21<03:10, 13.62s/it]loss:23.90943717956543:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [01:21<02:55, 13.49s/it]loss:23.423208236694336:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [01:34<02:55, 13.49s/it]loss:23.423208236694336:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [01:34<02:40, 13.40s/it]loss:23.54642677307129:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [01:48<02:40, 13.40s/it] loss:23.54642677307129:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [01:48<02:28, 13.46s/it]loss:23.731204986572266:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [02:01<02:28, 13.46s/it]loss:23.731204986572266:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [02:01<02:14, 13.47s/it]loss:23.556102752685547:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [02:15<02:14, 13.47s/it]loss:23.556102752685547:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [02:15<02:01, 13.54s/it]loss:23.55348014831543:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [02:29<02:01, 13.54s/it] loss:23.55348014831543:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [02:29<01:48, 13.52s/it]loss:23.371397018432617:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [02:42<01:48, 13.52s/it]loss:23.371397018432617:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [02:42<01:34, 13.55s/it]loss:23.789257049560547:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [02:56<01:34, 13.55s/it]loss:23.789257049560547:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [02:56<01:21, 13.51s/it]loss:24.04287338256836:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [03:09<01:21, 13.51s/it] loss:24.04287338256836:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [03:09<01:07, 13.49s/it]loss:23.56245231628418:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [03:23<01:07, 13.49s/it]loss:23.56245231628418:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [03:23<00:54, 13.53s/it]loss:23.759746551513672:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [03:36<00:54, 13.53s/it]loss:23.759746551513672:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [03:36<00:40, 13.45s/it]loss:24.216903686523438:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [03:50<00:40, 13.45s/it]loss:24.216903686523438:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [03:50<00:26, 13.50s/it]loss:23.691999435424805:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [04:03<00:26, 13.50s/it]loss:23.691999435424805:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [04:03<00:13, 13.46s/it]loss:23.557767868041992:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [04:17<00:13, 13.46s/it]loss:23.557767868041992: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [04:17<00:00, 13.67s/it]loss:23.557767868041992: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [04:17<00:00, 13.56s/it]
Epoch: 14 cost time: 258.79126048088074
Epoch: 14, Steps: 19 | Train Loss: 23.7201507 Vali Loss: 3.0520985 Test Loss: 39.3911362
Validation loss decreased (3.052099 --> 3.052099).  Saving model ...
Updating learning rate to 1.220703125e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:23.909435272216797:   0%|          | 0/19 [00:14<?, ?it/s]loss:23.909435272216797:   5%|â–Œ         | 1/19 [00:14<04:12, 14.00s/it]loss:23.759746551513672:   5%|â–Œ         | 1/19 [00:27<04:12, 14.00s/it]loss:23.759746551513672:  11%|â–ˆ         | 2/19 [00:27<03:56, 13.91s/it]loss:23.561813354492188:  11%|â–ˆ         | 2/19 [00:41<03:56, 13.91s/it]loss:23.561813354492188:  16%|â–ˆâ–Œ        | 3/19 [00:41<03:42, 13.93s/it]loss:23.553478240966797:  16%|â–ˆâ–Œ        | 3/19 [00:55<03:42, 13.93s/it]loss:23.553478240966797:  21%|â–ˆâ–ˆ        | 4/19 [00:55<03:27, 13.86s/it]loss:23.731204986572266:  21%|â–ˆâ–ˆ        | 4/19 [01:09<03:27, 13.86s/it]loss:23.731204986572266:  26%|â–ˆâ–ˆâ–‹       | 5/19 [01:09<03:12, 13.77s/it]loss:23.9671688079834:  26%|â–ˆâ–ˆâ–‹       | 5/19 [01:22<03:12, 13.77s/it]  loss:23.9671688079834:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [01:22<02:58, 13.75s/it]loss:23.54642677307129:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [01:36<02:58, 13.75s/it]loss:23.54642677307129:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [01:36<02:44, 13.68s/it]loss:23.423206329345703:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [01:50<02:44, 13.68s/it]loss:23.423206329345703:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [01:50<02:30, 13.67s/it]loss:23.53301429748535:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [02:03<02:30, 13.67s/it] loss:23.53301429748535:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [02:03<02:16, 13.60s/it]loss:24.042871475219727:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [02:16<02:16, 13.60s/it]loss:24.042871475219727:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [02:16<02:01, 13.53s/it]loss:24.165077209472656:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [02:30<02:01, 13.53s/it]loss:24.165077209472656:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [02:30<01:48, 13.59s/it]loss:23.557767868041992:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [02:44<01:48, 13.59s/it]loss:23.557767868041992:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [02:44<01:34, 13.54s/it]loss:23.691997528076172:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [02:57<01:34, 13.54s/it]loss:23.691997528076172:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [02:57<01:20, 13.49s/it]loss:23.743526458740234:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [03:10<01:20, 13.49s/it]loss:23.743526458740234:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [03:10<01:07, 13.44s/it]loss:24.21689796447754:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [03:24<01:07, 13.44s/it] loss:24.21689796447754:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [03:24<00:54, 13.56s/it]loss:23.789255142211914:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [03:38<00:54, 13.56s/it]loss:23.789255142211914:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [03:38<00:40, 13.55s/it]loss:23.371397018432617:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [03:51<00:40, 13.55s/it]loss:23.371397018432617:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [03:51<00:26, 13.49s/it]loss:23.56245231628418:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [04:05<00:26, 13.49s/it] loss:23.56245231628418:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [04:05<00:13, 13.60s/it]loss:23.556102752685547:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [04:18<00:13, 13.60s/it]loss:23.556102752685547: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [04:18<00:00, 13.61s/it]loss:23.556102752685547: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [04:19<00:00, 13.64s/it]
Epoch: 15 cost time: 260.2881135940552
Epoch: 15, Steps: 19 | Train Loss: 23.7201495 Vali Loss: 3.0520985 Test Loss: 39.3911362
Validation loss decreased (3.052099 --> 3.052099).  Saving model ...
Updating learning rate to 6.103515625e-09
  0%|          | 0/19 [00:00<?, ?it/s]loss:24.042869567871094:   0%|          | 0/19 [00:14<?, ?it/s]loss:24.042869567871094:   5%|â–Œ         | 1/19 [00:14<04:17, 14.29s/it]loss:23.909433364868164:   5%|â–Œ         | 1/19 [00:27<04:17, 14.29s/it]loss:23.909433364868164:  11%|â–ˆ         | 2/19 [00:27<03:53, 13.76s/it]loss:23.731204986572266:  11%|â–ˆ         | 2/19 [00:41<03:53, 13.76s/it]loss:23.731204986572266:  16%|â–ˆâ–Œ        | 3/19 [00:41<03:38, 13.67s/it]loss:23.42320442199707:  16%|â–ˆâ–Œ        | 3/19 [00:54<03:38, 13.67s/it] loss:23.42320442199707:  21%|â–ˆâ–ˆ        | 4/19 [00:54<03:23, 13.54s/it]loss:23.371397018432617:  21%|â–ˆâ–ˆ        | 4/19 [01:08<03:23, 13.54s/it]loss:23.371397018432617:  26%|â–ˆâ–ˆâ–‹       | 5/19 [01:08<03:09, 13.52s/it]loss:23.69199562072754:  26%|â–ˆâ–ˆâ–‹       | 5/19 [01:21<03:09, 13.52s/it] loss:23.69199562072754:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [01:21<02:56, 13.58s/it]loss:24.165077209472656:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [01:35<02:56, 13.58s/it]loss:24.165077209472656:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [01:35<02:43, 13.61s/it]loss:23.553478240966797:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [01:49<02:43, 13.61s/it]loss:23.553478240966797:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [01:49<02:29, 13.60s/it]loss:23.759746551513672:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [02:02<02:29, 13.60s/it]loss:23.759746551513672:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [02:02<02:15, 13.53s/it]loss:23.54642677307129:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [02:15<02:15, 13.53s/it] loss:23.54642677307129:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [02:15<02:01, 13.54s/it]loss:23.557767868041992:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [02:29<02:01, 13.54s/it]loss:23.557767868041992:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [02:29<01:48, 13.61s/it]loss:23.743526458740234:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [02:43<01:48, 13.61s/it]loss:23.743526458740234:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [02:43<01:35, 13.69s/it]loss:23.556102752685547:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [02:57<01:35, 13.69s/it]loss:23.556102752685547:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [02:57<01:22, 13.69s/it]loss:23.561813354492188:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [03:10<01:22, 13.69s/it]loss:23.561813354492188:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [03:10<01:08, 13.66s/it]loss:23.53301239013672:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [03:24<01:08, 13.66s/it] loss:23.53301239013672:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [03:24<00:54, 13.67s/it]loss:23.789255142211914:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [03:38<00:54, 13.67s/it]loss:23.789255142211914:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [03:38<00:41, 13.72s/it]loss:23.56245231628418:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [03:51<00:41, 13.72s/it] loss:23.56245231628418:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [03:51<00:27, 13.66s/it]loss:24.21689796447754:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [04:05<00:27, 13.66s/it]loss:24.21689796447754:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [04:05<00:13, 13.70s/it]loss:23.9671630859375:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [04:19<00:13, 13.70s/it] loss:23.9671630859375: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [04:19<00:00, 13.58s/it]loss:23.9671630859375: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [04:19<00:00, 13.64s/it]
Epoch: 16 cost time: 260.2441773414612
Epoch: 16, Steps: 19 | Train Loss: 23.7201487 Vali Loss: 3.0520985 Test Loss: 39.3911362
Validation loss decreased (3.052099 --> 3.052099).  Saving model ...
Updating learning rate to 3.0517578125e-09
  0%|          | 0/19 [00:00<?, ?it/s]loss:23.789255142211914:   0%|          | 0/19 [00:14<?, ?it/s]loss:23.789255142211914:   5%|â–Œ         | 1/19 [00:14<04:12, 14.02s/it]loss:23.553478240966797:   5%|â–Œ         | 1/19 [00:27<04:12, 14.02s/it]loss:23.553478240966797:  11%|â–ˆ         | 2/19 [00:27<03:53, 13.74s/it]loss:23.561813354492188:  11%|â–ˆ         | 2/19 [00:40<03:53, 13.74s/it]loss:23.561813354492188:  16%|â–ˆâ–Œ        | 3/19 [00:40<03:36, 13.55s/it]loss:24.21689796447754:  16%|â–ˆâ–Œ        | 3/19 [00:54<03:36, 13.55s/it] loss:24.21689796447754:  21%|â–ˆâ–ˆ        | 4/19 [00:54<03:24, 13.63s/it]loss:23.743526458740234:  21%|â–ˆâ–ˆ        | 4/19 [01:08<03:24, 13.63s/it]loss:23.743526458740234:  26%|â–ˆâ–ˆâ–‹       | 5/19 [01:08<03:10, 13.59s/it]loss:23.731204986572266:  26%|â–ˆâ–ˆâ–‹       | 5/19 [01:21<03:10, 13.59s/it]loss:23.731204986572266:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [01:21<02:56, 13.55s/it]loss:23.557767868041992:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [01:35<02:56, 13.55s/it]loss:23.557767868041992:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [01:35<02:43, 13.58s/it]loss:23.909435272216797:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [01:48<02:43, 13.58s/it]loss:23.909435272216797:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [01:48<02:29, 13.60s/it]loss:23.75974464416504:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [02:02<02:29, 13.60s/it] loss:23.75974464416504:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [02:02<02:16, 13.66s/it]loss:23.42320442199707:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [02:16<02:16, 13.66s/it]loss:23.42320442199707:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [02:16<02:02, 13.63s/it]loss:23.371397018432617:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [02:29<02:02, 13.63s/it]loss:23.371397018432617:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [02:29<01:48, 13.57s/it]loss:23.53301239013672:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [02:43<01:48, 13.57s/it] loss:23.53301239013672:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [02:43<01:34, 13.53s/it]loss:23.56245231628418:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [02:56<01:34, 13.53s/it]loss:23.56245231628418:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [02:56<01:20, 13.48s/it]loss:24.04286766052246:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [03:10<01:20, 13.48s/it]loss:24.04286766052246:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [03:10<01:07, 13.50s/it]loss:23.9671630859375:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [03:23<01:07, 13.50s/it] loss:23.9671630859375:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [03:23<00:53, 13.46s/it]loss:23.54642677307129:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [03:37<00:53, 13.46s/it]loss:23.54642677307129:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [03:37<00:40, 13.52s/it]loss:23.69199562072754:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [03:50<00:40, 13.52s/it]loss:23.69199562072754:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [03:50<00:27, 13.52s/it]loss:24.165077209472656:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [04:03<00:27, 13.52s/it]loss:24.165077209472656:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [04:03<00:13, 13.45s/it]loss:23.556102752685547:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [04:17<00:13, 13.45s/it]loss:23.556102752685547: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [04:17<00:00, 13.50s/it]loss:23.556102752685547: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [04:17<00:00, 13.56s/it]
Epoch: 17 cost time: 258.7193546295166
Epoch: 17, Steps: 19 | Train Loss: 23.7201486 Vali Loss: 3.0520985 Test Loss: 39.3911362
Validation loss decreased (3.052099 --> 3.052099).  Saving model ...
Updating learning rate to 1.52587890625e-09
  0%|          | 0/19 [00:00<?, ?it/s]loss:24.21689796447754:   0%|          | 0/19 [00:14<?, ?it/s]loss:24.21689796447754:   5%|â–Œ         | 1/19 [00:14<04:17, 14.29s/it]loss:23.9671630859375:   5%|â–Œ         | 1/19 [00:27<04:17, 14.29s/it] loss:23.9671630859375:  11%|â–ˆ         | 2/19 [00:27<03:54, 13.79s/it]loss:23.42320442199707:  11%|â–ˆ         | 2/19 [00:41<03:54, 13.79s/it]loss:23.42320442199707:  16%|â–ˆâ–Œ        | 3/19 [00:41<03:39, 13.69s/it]loss:23.557767868041992:  16%|â–ˆâ–Œ        | 3/19 [00:54<03:39, 13.69s/it]loss:23.557767868041992:  21%|â–ˆâ–ˆ        | 4/19 [00:54<03:24, 13.64s/it]loss:23.56245231628418:  21%|â–ˆâ–ˆ        | 4/19 [01:08<03:24, 13.64s/it] loss:23.56245231628418:  26%|â–ˆâ–ˆâ–‹       | 5/19 [01:08<03:10, 13.61s/it]loss:23.53301429748535:  26%|â–ˆâ–ˆâ–‹       | 5/19 [01:21<03:10, 13.61s/it]loss:23.53301429748535:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [01:21<02:56, 13.57s/it]loss:23.54642677307129:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [01:35<02:56, 13.57s/it]loss:23.54642677307129:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [01:35<02:43, 13.62s/it]loss:23.69199562072754:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [01:49<02:43, 13.62s/it]loss:23.69199562072754:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [01:49<02:29, 13.62s/it]loss:23.731204986572266:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [02:02<02:29, 13.62s/it]loss:23.731204986572266:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [02:02<02:15, 13.50s/it]loss:24.165077209472656:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [02:16<02:15, 13.50s/it]loss:24.165077209472656:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [02:16<02:01, 13.53s/it]loss:24.042865753173828:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [02:29<02:01, 13.53s/it]loss:24.042865753173828:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [02:29<01:48, 13.50s/it]loss:23.561809539794922:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [02:43<01:48, 13.50s/it]loss:23.561809539794922:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [02:43<01:34, 13.51s/it]loss:23.7435245513916:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [02:56<01:34, 13.51s/it]  loss:23.7435245513916:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [02:56<01:20, 13.45s/it]loss:23.75974464416504:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [03:10<01:20, 13.45s/it]loss:23.75974464416504:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [03:10<01:08, 13.63s/it]loss:23.553476333618164:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [03:23<01:08, 13.63s/it]loss:23.553476333618164:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [03:23<00:54, 13.61s/it]loss:23.371397018432617:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [03:37<00:54, 13.61s/it]loss:23.371397018432617:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [03:37<00:40, 13.63s/it]loss:23.789255142211914:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [03:51<00:40, 13.63s/it]loss:23.789255142211914:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [03:51<00:27, 13.57s/it]loss:23.556102752685547:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [04:04<00:27, 13.57s/it]loss:23.556102752685547:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [04:04<00:13, 13.57s/it]loss:23.909433364868164:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [04:18<00:13, 13.57s/it]loss:23.909433364868164: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [04:18<00:00, 13.63s/it]loss:23.909433364868164: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [04:18<00:00, 13.61s/it]
Epoch: 18 cost time: 259.64437770843506
Epoch: 18, Steps: 19 | Train Loss: 23.7201481 Vali Loss: 3.0520985 Test Loss: 39.3911362
Validation loss decreased (3.052099 --> 3.052099).  Saving model ...
Updating learning rate to 7.62939453125e-10
  0%|          | 0/19 [00:00<?, ?it/s]loss:23.731204986572266:   0%|          | 0/19 [00:14<?, ?it/s]loss:23.731204986572266:   5%|â–Œ         | 1/19 [00:14<04:14, 14.16s/it]loss:23.53301239013672:   5%|â–Œ         | 1/19 [00:27<04:14, 14.16s/it] loss:23.53301239013672:  11%|â–ˆ         | 2/19 [00:27<03:56, 13.92s/it]loss:23.556100845336914:  11%|â–ˆ         | 2/19 [00:41<03:56, 13.92s/it]loss:23.556100845336914:  16%|â–ˆâ–Œ        | 3/19 [00:41<03:38, 13.64s/it]loss:23.557767868041992:  16%|â–ˆâ–Œ        | 3/19 [00:54<03:38, 13.64s/it]loss:23.557767868041992:  21%|â–ˆâ–ˆ        | 4/19 [00:54<03:23, 13.57s/it]loss:23.7435245513916:  21%|â–ˆâ–ˆ        | 4/19 [01:08<03:23, 13.57s/it]  loss:23.7435245513916:  26%|â–ˆâ–ˆâ–‹       | 5/19 [01:08<03:09, 13.54s/it]loss:23.54642677307129:  26%|â–ˆâ–ˆâ–‹       | 5/19 [01:21<03:09, 13.54s/it]loss:23.54642677307129:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [01:21<02:56, 13.59s/it]loss:23.75974464416504:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [01:35<02:56, 13.59s/it]loss:23.75974464416504:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [01:35<02:43, 13.64s/it]loss:23.69199562072754:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [01:48<02:43, 13.64s/it]loss:23.69199562072754:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [01:48<02:29, 13.55s/it]loss:23.789255142211914:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [02:02<02:29, 13.55s/it]loss:23.789255142211914:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [02:02<02:16, 13.62s/it]loss:23.371397018432617:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [02:16<02:16, 13.62s/it]loss:23.371397018432617:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [02:16<02:02, 13.64s/it]loss:24.165077209472656:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [02:29<02:02, 13.64s/it]loss:24.165077209472656:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [02:29<01:48, 13.58s/it]loss:24.21689796447754:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [02:43<01:48, 13.58s/it] loss:24.21689796447754:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [02:43<01:35, 13.62s/it]loss:23.561809539794922:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [02:56<01:35, 13.62s/it]loss:23.561809539794922:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [02:56<01:21, 13.55s/it]loss:23.42320442199707:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [03:10<01:21, 13.55s/it] loss:23.42320442199707:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [03:10<01:07, 13.53s/it]loss:23.9671630859375:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [03:24<01:07, 13.53s/it] loss:23.9671630859375:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [03:24<00:54, 13.54s/it]loss:23.553476333618164:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [03:37<00:54, 13.54s/it]loss:23.553476333618164:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [03:37<00:40, 13.61s/it]loss:24.042865753173828:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [03:51<00:40, 13.61s/it]loss:24.042865753173828:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [03:51<00:27, 13.51s/it]loss:23.909433364868164:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [04:04<00:27, 13.51s/it]loss:23.909433364868164:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [04:04<00:13, 13.44s/it]loss:23.56245231628418:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [04:18<00:13, 13.44s/it] loss:23.56245231628418: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [04:18<00:00, 13.56s/it]loss:23.56245231628418: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [04:18<00:00, 13.59s/it]
Epoch: 19 cost time: 259.3881630897522
Epoch: 19, Steps: 19 | Train Loss: 23.7201479 Vali Loss: 3.0520983 Test Loss: 39.3911362
Validation loss decreased (3.052099 --> 3.052098).  Saving model ...
Updating learning rate to 3.814697265625e-10
  0%|          | 0/19 [00:00<?, ?it/s]loss:24.165077209472656:   0%|          | 0/19 [00:14<?, ?it/s]loss:24.165077209472656:   5%|â–Œ         | 1/19 [00:14<04:15, 14.19s/it]loss:23.731204986572266:   5%|â–Œ         | 1/19 [00:27<04:15, 14.19s/it]loss:23.731204986572266:  11%|â–ˆ         | 2/19 [00:27<03:53, 13.75s/it]loss:23.42320442199707:  11%|â–ˆ         | 2/19 [00:40<03:53, 13.75s/it] loss:23.42320442199707:  16%|â–ˆâ–Œ        | 3/19 [00:40<03:36, 13.50s/it]loss:23.69199562072754:  16%|â–ˆâ–Œ        | 3/19 [00:54<03:36, 13.50s/it]loss:23.69199562072754:  21%|â–ˆâ–ˆ        | 4/19 [00:54<03:21, 13.45s/it]loss:23.56245231628418:  21%|â–ˆâ–ˆ        | 4/19 [01:07<03:21, 13.45s/it]loss:23.56245231628418:  26%|â–ˆâ–ˆâ–‹       | 5/19 [01:07<03:07, 13.39s/it]loss:23.557767868041992:  26%|â–ˆâ–ˆâ–‹       | 5/19 [01:21<03:07, 13.39s/it]loss:23.557767868041992:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [01:21<02:55, 13.49s/it]loss:23.561809539794922:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [01:34<02:55, 13.49s/it]loss:23.561809539794922:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [01:34<02:41, 13.44s/it]loss:23.743520736694336:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [01:48<02:41, 13.44s/it]loss:23.743520736694336:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [01:48<02:28, 13.49s/it]loss:23.75974464416504:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [02:01<02:28, 13.49s/it] loss:23.75974464416504:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [02:01<02:14, 13.43s/it]loss:24.042865753173828:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [02:14<02:14, 13.43s/it]loss:24.042865753173828:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [02:14<02:01, 13.45s/it]loss:23.556100845336914:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [02:28<02:01, 13.45s/it]loss:23.556100845336914:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [02:28<01:47, 13.39s/it]loss:23.909433364868164:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [02:41<01:47, 13.39s/it]loss:23.909433364868164:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [02:41<01:33, 13.40s/it]loss:23.553476333618164:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [02:54<01:33, 13.40s/it]loss:23.553476333618164:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [02:54<01:20, 13.34s/it]loss:23.53301429748535:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [03:08<01:20, 13.34s/it] loss:23.53301429748535:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [03:08<01:06, 13.35s/it]loss:23.54642677307129:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [03:21<01:06, 13.35s/it]loss:23.54642677307129:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [03:21<00:53, 13.38s/it]loss:23.9671630859375:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [03:34<00:53, 13.38s/it] loss:23.9671630859375:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [03:34<00:40, 13.38s/it]loss:23.371397018432617:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [03:48<00:40, 13.38s/it]loss:23.371397018432617:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [03:48<00:26, 13.39s/it]loss:24.21689796447754:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [04:01<00:26, 13.39s/it] loss:24.21689796447754:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [04:01<00:13, 13.39s/it]loss:23.789255142211914:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [04:15<00:13, 13.39s/it]loss:23.789255142211914: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [04:15<00:00, 13.42s/it]loss:23.789255142211914: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [04:15<00:00, 13.44s/it]
Epoch: 20 cost time: 256.5134391784668
Epoch: 20, Steps: 19 | Train Loss: 23.7201478 Vali Loss: 3.0520983 Test Loss: 39.3911362
Validation loss decreased (3.052098 --> 3.052098).  Saving model ...
Updating learning rate to 1.9073486328125e-10
>>>>>>>testing : long_term_forecast_low_0_FiLM_job_demand_region_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 4
test shape: (4, 1, 3, 16345) (4, 1, 3, 16345)
test shape: (4, 3, 16345) (4, 3, 16345)
mse:35002.984375, mae:34.24394989013672, dtw:-999
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           0                   Model:              FiLM                

[1mData Loader[0m
  Data:               job_demand_r1       Root Path:          ../../dataset/demand/
  Data Path:          r1.parquet          Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        .cache/checkpoints  

[1mForecasting Task[0m
  Seq Len:            6                   Label Len:          1                   
  Pred Len:           3                   Seasonal Patterns:  Monthly             
  Inverse:            1                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             32690               Dec In:             32690               
  C Out:              32690               d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           2                   d FF:               2048                
  Moving Avg:         25                  Factor:             1                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              learned             Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        32                  Itr:                1                   
  Train Epochs:       20                  Batch Size:         1                   
  Patience:           3                   Learning Rate:      0.0001              
  Des:                test                Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            0                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1                 

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use CPU
>>>>>>>start training : long_term_forecast_low_0_FiLM_job_demand_r1_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 19
val 1
test 4
  0%|          | 0/19 [00:00<?, ?it/s]loss:24.563016891479492:   0%|          | 0/19 [00:53<?, ?it/s]loss:24.563016891479492:   5%|â–Œ         | 1/19 [00:53<16:08, 53.80s/it]loss:24.694978713989258:   5%|â–Œ         | 1/19 [01:45<16:08, 53.80s/it]loss:24.694978713989258:  11%|â–ˆ         | 2/19 [01:45<14:52, 52.52s/it]loss:24.62242889404297:  11%|â–ˆ         | 2/19 [02:36<14:52, 52.52s/it] loss:24.62242889404297:  16%|â–ˆâ–Œ        | 3/19 [02:36<13:50, 51.89s/it]loss:24.675512313842773:  16%|â–ˆâ–Œ        | 3/19 [03:27<13:50, 51.89s/it]loss:24.675512313842773:  21%|â–ˆâ–ˆ        | 4/19 [03:27<12:50, 51.34s/it]loss:24.727184295654297:  21%|â–ˆâ–ˆ        | 4/19 [04:17<12:50, 51.34s/it]loss:24.727184295654297:  26%|â–ˆâ–ˆâ–‹       | 5/19 [04:17<11:55, 51.09s/it]loss:24.719486236572266:  26%|â–ˆâ–ˆâ–‹       | 5/19 [05:08<11:55, 51.09s/it]loss:24.719486236572266:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [05:08<11:02, 50.95s/it]loss:24.643997192382812:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [05:59<11:02, 50.95s/it]loss:24.643997192382812:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [05:59<10:10, 50.91s/it]loss:24.762624740600586:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [06:49<10:10, 50.91s/it]loss:24.762624740600586:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [06:49<09:17, 50.70s/it]loss:24.75313949584961:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [07:39<09:17, 50.70s/it] loss:24.75313949584961:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [07:39<08:24, 50.44s/it]loss:24.87856674194336:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [08:30<08:24, 50.44s/it]loss:24.87856674194336:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [08:30<07:34, 50.52s/it]loss:24.6412296295166:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [09:21<07:34, 50.52s/it] loss:24.6412296295166:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [09:21<06:45, 50.70s/it]loss:24.609952926635742:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [10:11<06:45, 50.70s/it]loss:24.609952926635742:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [10:11<05:54, 50.60s/it]loss:24.567214965820312:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [11:01<05:54, 50.60s/it]loss:24.567214965820312:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [11:01<05:02, 50.48s/it]loss:24.77587127685547:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [11:51<05:02, 50.48s/it] loss:24.77587127685547:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [11:51<04:11, 50.34s/it]loss:24.917030334472656:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [12:42<04:11, 50.34s/it]loss:24.917030334472656:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [12:42<03:22, 50.52s/it]loss:24.755863189697266:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [13:33<03:22, 50.52s/it]loss:24.755863189697266:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [13:33<02:31, 50.56s/it]loss:24.686809539794922:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [14:24<02:31, 50.56s/it]loss:24.686809539794922:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [14:24<01:41, 50.70s/it]loss:24.543264389038086:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [15:15<01:41, 50.70s/it]loss:24.543264389038086:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [15:15<00:50, 50.70s/it]loss:24.913986206054688:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [16:06<00:50, 50.70s/it]loss:24.913986206054688: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [16:06<00:00, 50.86s/it]loss:24.913986206054688: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [16:06<00:00, 50.86s/it]
Epoch: 1 cost time: 966.9102847576141
Epoch: 1, Steps: 19 | Train Loss: 24.7080083 Vali Loss: 3.8790417 Test Loss: 69.4611816
Validation loss decreased (inf --> 3.879042).  Saving model ...
Updating learning rate to 0.0001
  0%|          | 0/19 [00:00<?, ?it/s]loss:24.67954444885254:   0%|          | 0/19 [00:51<?, ?it/s]loss:24.67954444885254:   5%|â–Œ         | 1/19 [00:51<15:34, 51.92s/it]loss:24.774890899658203:   5%|â–Œ         | 1/19 [01:43<15:34, 51.92s/it]loss:24.774890899658203:  11%|â–ˆ         | 2/19 [01:43<14:36, 51.55s/it]loss:24.808326721191406:  11%|â–ˆ         | 2/19 [02:34<14:36, 51.55s/it]loss:24.808326721191406:  16%|â–ˆâ–Œ        | 3/19 [02:34<13:41, 51.32s/it]loss:24.82386016845703:  16%|â–ˆâ–Œ        | 3/19 [03:25<13:41, 51.32s/it] loss:24.82386016845703:  21%|â–ˆâ–ˆ        | 4/19 [03:25<12:48, 51.23s/it]loss:24.933349609375:  21%|â–ˆâ–ˆ        | 4/19 [04:16<12:48, 51.23s/it]  loss:24.933349609375:  26%|â–ˆâ–ˆâ–‹       | 5/19 [04:16<11:58, 51.33s/it]loss:24.66156768798828:  26%|â–ˆâ–ˆâ–‹       | 5/19 [05:07<11:58, 51.33s/it]loss:24.66156768798828:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [05:07<11:05, 51.18s/it]loss:24.66847801208496:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [05:59<11:05, 51.18s/it]loss:24.66847801208496:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [05:59<10:14, 51.23s/it]loss:24.624011993408203:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [06:50<10:14, 51.23s/it]loss:24.624011993408203:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [06:50<09:23, 51.22s/it]loss:24.949745178222656:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [07:41<09:23, 51.22s/it]loss:24.949745178222656:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [07:41<08:32, 51.26s/it]loss:24.73379135131836:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [08:32<08:32, 51.26s/it] loss:24.73379135131836:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [08:32<07:40, 51.14s/it]loss:24.968708038330078:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [09:23<07:40, 51.14s/it]loss:24.968708038330078:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [09:23<06:48, 51.04s/it]loss:24.826900482177734:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [10:13<06:48, 51.04s/it]loss:24.826900482177734:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [10:13<05:55, 50.85s/it]loss:24.73519515991211:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [11:04<05:55, 50.85s/it] loss:24.73519515991211:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [11:04<05:05, 50.90s/it]loss:24.847047805786133:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [11:55<05:05, 50.90s/it]loss:24.847047805786133:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [11:55<04:14, 50.83s/it]loss:24.798240661621094:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [12:46<04:14, 50.83s/it]loss:24.798240661621094:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [12:46<03:23, 50.91s/it]loss:24.838916778564453:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [13:37<03:23, 50.91s/it]loss:24.838916778564453:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [13:37<02:32, 50.93s/it]loss:24.83894920349121:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [14:28<02:32, 50.93s/it] loss:24.83894920349121:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [14:28<01:42, 51.00s/it]loss:24.77168083190918:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [15:19<01:42, 51.00s/it]loss:24.77168083190918:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [15:19<00:50, 50.93s/it]loss:24.622745513916016:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [16:10<00:50, 50.93s/it]loss:24.622745513916016: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [16:10<00:00, 50.95s/it]loss:24.622745513916016: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [16:10<00:00, 51.09s/it]
Epoch: 2 cost time: 972.4390604496002
Epoch: 2, Steps: 19 | Train Loss: 24.7845237 Vali Loss: 3.8764827 Test Loss: 69.6219406
Validation loss decreased (3.879042 --> 3.876483).  Saving model ...
Updating learning rate to 5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:24.723400115966797:   0%|          | 0/19 [00:52<?, ?it/s]loss:24.723400115966797:   5%|â–Œ         | 1/19 [00:52<15:40, 52.26s/it]loss:24.892452239990234:   5%|â–Œ         | 1/19 [01:43<15:40, 52.26s/it]loss:24.892452239990234:  11%|â–ˆ         | 2/19 [01:43<14:35, 51.49s/it]loss:24.848222732543945:  11%|â–ˆ         | 2/19 [02:33<14:35, 51.49s/it]loss:24.848222732543945:  16%|â–ˆâ–Œ        | 3/19 [02:33<13:37, 51.09s/it]loss:24.781431198120117:  16%|â–ˆâ–Œ        | 3/19 [03:25<13:37, 51.09s/it]loss:24.781431198120117:  21%|â–ˆâ–ˆ        | 4/19 [03:25<12:49, 51.29s/it]loss:24.634599685668945:  21%|â–ˆâ–ˆ        | 4/19 [04:17<12:49, 51.29s/it]loss:24.634599685668945:  26%|â–ˆâ–ˆâ–‹       | 5/19 [04:17<12:02, 51.61s/it]loss:25.008527755737305:  26%|â–ˆâ–ˆâ–‹       | 5/19 [05:09<12:02, 51.61s/it]loss:25.008527755737305:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [05:09<11:11, 51.69s/it]loss:25.005996704101562:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [06:01<11:11, 51.69s/it]loss:25.005996704101562:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [06:01<10:23, 51.94s/it]loss:24.776790618896484:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [06:53<10:23, 51.94s/it]loss:24.776790618896484:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [06:53<09:29, 51.80s/it]loss:24.886272430419922:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [07:45<09:29, 51.80s/it]loss:24.886272430419922:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [07:45<08:38, 51.82s/it]loss:24.73950958251953:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [08:36<08:38, 51.82s/it] loss:24.73950958251953:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [08:36<07:44, 51.63s/it]loss:24.83980941772461:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [09:27<07:44, 51.63s/it]loss:24.83980941772461:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [09:27<06:51, 51.50s/it]loss:24.879222869873047:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [10:19<06:51, 51.50s/it]loss:24.879222869873047:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [10:19<06:00, 51.45s/it]loss:24.87735939025879:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [11:10<06:00, 51.45s/it] loss:24.87735939025879:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [11:10<05:08, 51.47s/it]loss:24.904930114746094:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [12:01<05:08, 51.47s/it]loss:24.904930114746094:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [12:01<04:16, 51.31s/it]loss:24.702077865600586:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [12:52<04:16, 51.31s/it]loss:24.702077865600586:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [12:52<03:25, 51.36s/it]loss:24.81219482421875:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [13:44<03:25, 51.36s/it] loss:24.81219482421875:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [13:44<02:33, 51.33s/it]loss:25.025136947631836:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [14:35<02:33, 51.33s/it]loss:25.025136947631836:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [14:35<01:42, 51.18s/it]loss:24.798078536987305:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [15:25<01:42, 51.18s/it]loss:24.798078536987305:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [15:25<00:51, 51.07s/it]loss:24.89312171936035:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [16:16<00:51, 51.07s/it] loss:24.89312171936035: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [16:16<00:00, 51.06s/it]loss:24.89312171936035: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [16:17<00:00, 51.43s/it]
Epoch: 3 cost time: 979.0202693939209
Epoch: 3, Steps: 19 | Train Loss: 24.8436387 Vali Loss: 3.8754318 Test Loss: 69.6887817
Validation loss decreased (3.876483 --> 3.875432).  Saving model ...
Updating learning rate to 2.5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:24.917354583740234:   0%|          | 0/19 [00:52<?, ?it/s]loss:24.917354583740234:   5%|â–Œ         | 1/19 [00:52<15:43, 52.44s/it]loss:24.66567611694336:   5%|â–Œ         | 1/19 [01:42<15:43, 52.44s/it] loss:24.66567611694336:  11%|â–ˆ         | 2/19 [01:42<14:31, 51.26s/it]loss:24.714580535888672:  11%|â–ˆ         | 2/19 [02:33<14:31, 51.26s/it]loss:24.714580535888672:  16%|â–ˆâ–Œ        | 3/19 [02:33<13:36, 51.01s/it]loss:24.803647994995117:  16%|â–ˆâ–Œ        | 3/19 [03:24<13:36, 51.01s/it]loss:24.803647994995117:  21%|â–ˆâ–ˆ        | 4/19 [03:24<12:46, 51.09s/it]loss:24.86257553100586:  21%|â–ˆâ–ˆ        | 4/19 [04:16<12:46, 51.09s/it] loss:24.86257553100586:  26%|â–ˆâ–ˆâ–‹       | 5/19 [04:16<11:56, 51.20s/it]loss:24.886510848999023:  26%|â–ˆâ–ˆâ–‹       | 5/19 [05:06<11:56, 51.20s/it]loss:24.886510848999023:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [05:06<11:03, 51.06s/it]loss:24.90080451965332:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [05:58<11:03, 51.06s/it] loss:24.90080451965332:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [05:58<10:13, 51.10s/it]loss:24.7711181640625:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [06:50<10:13, 51.10s/it] loss:24.7711181640625:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [06:50<09:25, 51.39s/it]loss:24.93869972229004:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [07:41<09:25, 51.39s/it]loss:24.93869972229004:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [07:41<08:32, 51.28s/it]loss:25.041223526000977:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [08:32<08:32, 51.28s/it]loss:25.041223526000977:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [08:32<07:42, 51.36s/it]loss:24.831233978271484:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [09:23<07:42, 51.36s/it]loss:24.831233978271484:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [09:23<06:49, 51.15s/it]loss:25.043384552001953:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [10:14<06:49, 51.15s/it]loss:25.043384552001953:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [10:14<05:57, 51.08s/it]loss:24.815034866333008:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [11:05<05:57, 51.08s/it]loss:24.815034866333008:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [11:05<05:06, 51.15s/it]loss:24.774490356445312:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [11:56<05:06, 51.15s/it]loss:24.774490356445312:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [11:56<04:15, 51.17s/it]loss:25.045507431030273:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [12:48<04:15, 51.17s/it]loss:25.045507431030273:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [12:48<03:24, 51.18s/it]loss:24.923904418945312:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [13:39<03:24, 51.18s/it]loss:24.923904418945312:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [13:39<02:33, 51.11s/it]loss:24.90962791442871:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [14:29<02:33, 51.11s/it] loss:24.90962791442871:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [14:29<01:42, 51.04s/it]loss:24.832355499267578:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [15:20<01:42, 51.04s/it]loss:24.832355499267578:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [15:20<00:51, 51.04s/it]loss:24.91397476196289:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [16:11<00:51, 51.04s/it] loss:24.91397476196289: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [16:11<00:00, 50.91s/it]loss:24.91397476196289: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [16:11<00:00, 51.15s/it]
Epoch: 4 cost time: 974.0529398918152
Epoch: 4, Steps: 19 | Train Loss: 24.8732476 Vali Loss: 3.8751173 Test Loss: 69.7239532
Validation loss decreased (3.875432 --> 3.875117).  Saving model ...
Updating learning rate to 1.25e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:24.93697738647461:   0%|          | 0/19 [00:52<?, ?it/s]loss:24.93697738647461:   5%|â–Œ         | 1/19 [00:52<15:44, 52.47s/it]loss:24.78143310546875:   5%|â–Œ         | 1/19 [01:43<15:44, 52.47s/it]loss:24.78143310546875:  11%|â–ˆ         | 2/19 [01:43<14:36, 51.54s/it]loss:24.913949966430664:  11%|â–ˆ         | 2/19 [02:34<14:36, 51.54s/it]loss:24.913949966430664:  16%|â–ˆâ–Œ        | 3/19 [02:34<13:42, 51.41s/it]loss:24.824295043945312:  16%|â–ˆâ–Œ        | 3/19 [03:25<13:42, 51.41s/it]loss:24.824295043945312:  21%|â–ˆâ–ˆ        | 4/19 [03:25<12:48, 51.26s/it]loss:24.902469635009766:  21%|â–ˆâ–ˆ        | 4/19 [04:17<12:48, 51.26s/it]loss:24.902469635009766:  26%|â–ˆâ–ˆâ–‹       | 5/19 [04:17<12:01, 51.54s/it]loss:24.837139129638672:  26%|â–ˆâ–ˆâ–‹       | 5/19 [05:10<12:01, 51.54s/it]loss:24.837139129638672:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [05:10<11:13, 51.84s/it]loss:25.054513931274414:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [06:01<11:13, 51.84s/it]loss:25.054513931274414:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [06:01<10:20, 51.71s/it]loss:24.88178062438965:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [06:53<10:20, 51.71s/it] loss:24.88178062438965:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [06:53<09:29, 51.78s/it]loss:24.736549377441406:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [07:45<09:29, 51.78s/it]loss:24.736549377441406:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [07:45<08:37, 51.70s/it]loss:24.955163955688477:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [08:37<08:37, 51.70s/it]loss:24.955163955688477:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [08:37<07:46, 51.81s/it]loss:24.920347213745117:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [09:28<07:46, 51.81s/it]loss:24.920347213745117:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [09:28<06:53, 51.69s/it]loss:24.846874237060547:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [10:20<06:53, 51.69s/it]loss:24.846874237060547:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [10:20<06:02, 51.82s/it]loss:24.690170288085938:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [11:12<06:02, 51.82s/it]loss:24.690170288085938:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [11:12<05:10, 51.71s/it]loss:24.791061401367188:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [12:03<05:10, 51.71s/it]loss:24.791061401367188:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [12:03<04:18, 51.76s/it]loss:25.05740737915039:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [12:54<04:18, 51.76s/it] loss:25.05740737915039:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [12:54<03:25, 51.44s/it]loss:24.935779571533203:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [13:45<03:25, 51.44s/it]loss:24.935779571533203:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [13:45<02:34, 51.34s/it]loss:24.92169189453125:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [14:36<02:34, 51.34s/it] loss:24.92169189453125:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [14:36<01:42, 51.31s/it]loss:24.82830047607422:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [15:27<01:42, 51.31s/it]loss:24.82830047607422:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [15:27<00:51, 51.14s/it]loss:25.060012817382812:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [16:18<00:51, 51.14s/it]loss:25.060012817382812: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [16:18<00:00, 51.00s/it]loss:25.060012817382812: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [16:18<00:00, 51.51s/it]
Epoch: 5 cost time: 980.8387138843536
Epoch: 5, Steps: 19 | Train Loss: 24.8882062 Vali Loss: 3.8749349 Test Loss: 69.7371674
Validation loss decreased (3.875117 --> 3.874935).  Saving model ...
Updating learning rate to 6.25e-06
  0%|          | 0/19 [00:00<?, ?it/s]loss:24.8328914642334:   0%|          | 0/19 [00:51<?, ?it/s]loss:24.8328914642334:   5%|â–Œ         | 1/19 [00:51<15:31, 51.76s/it]loss:24.693941116333008:   5%|â–Œ         | 1/19 [01:43<15:31, 51.76s/it]loss:24.693941116333008:  11%|â–ˆ         | 2/19 [01:43<14:37, 51.62s/it]loss:24.85167694091797:  11%|â–ˆ         | 2/19 [02:34<14:37, 51.62s/it] loss:24.85167694091797:  16%|â–ˆâ–Œ        | 3/19 [02:34<13:43, 51.48s/it]loss:24.743078231811523:  16%|â–ˆâ–Œ        | 3/19 [03:25<13:43, 51.48s/it]loss:24.743078231811523:  21%|â–ˆâ–ˆ        | 4/19 [03:25<12:50, 51.38s/it]loss:24.795330047607422:  21%|â–ˆâ–ˆ        | 4/19 [04:17<12:50, 51.38s/it]loss:24.795330047607422:  26%|â–ˆâ–ˆâ–‹       | 5/19 [04:17<11:58, 51.35s/it]loss:24.911235809326172:  26%|â–ˆâ–ˆâ–‹       | 5/19 [05:08<11:58, 51.35s/it]loss:24.911235809326172:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [05:08<11:08, 51.41s/it]loss:24.948429107666016:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [05:59<11:08, 51.41s/it]loss:24.948429107666016:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [05:59<10:16, 51.38s/it]loss:24.962305068969727:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [06:51<10:16, 51.38s/it]loss:24.962305068969727:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [06:51<09:26, 51.46s/it]loss:24.890098571777344:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [07:43<09:26, 51.46s/it]loss:24.890098571777344:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [07:43<08:34, 51.45s/it]loss:24.925521850585938:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [08:34<08:34, 51.45s/it]loss:24.925521850585938:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [08:34<07:42, 51.44s/it]loss:25.063650131225586:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [09:25<07:42, 51.44s/it]loss:25.063650131225586:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [09:25<06:49, 51.24s/it]loss:25.062158584594727:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [10:15<06:49, 51.24s/it]loss:25.062158584594727:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [10:15<05:57, 51.08s/it]loss:24.832324981689453:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [11:07<05:57, 51.08s/it]loss:24.832324981689453:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [11:07<05:06, 51.12s/it]loss:24.926368713378906:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [11:58<05:06, 51.12s/it]loss:24.926368713378906:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [11:58<04:15, 51.06s/it]loss:24.848148345947266:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [12:49<04:15, 51.06s/it]loss:24.848148345947266:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [12:49<03:24, 51.10s/it]loss:24.794994354248047:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [13:40<03:24, 51.10s/it]loss:24.794994354248047:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [13:40<02:33, 51.18s/it]loss:25.064584732055664:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [14:32<02:33, 51.18s/it]loss:25.064584732055664:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [14:32<01:42, 51.28s/it]loss:24.942115783691406:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [15:23<01:42, 51.28s/it]loss:24.942115783691406:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [15:23<00:51, 51.36s/it]loss:24.929759979248047:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [16:14<00:51, 51.36s/it]loss:24.929759979248047: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [16:14<00:00, 51.24s/it]loss:24.929759979248047: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [16:14<00:00, 51.31s/it]
Epoch: 6 cost time: 977.1060740947723
Epoch: 6, Steps: 19 | Train Loss: 24.8957165 Vali Loss: 3.8748479 Test Loss: 69.7467651
Validation loss decreased (3.874935 --> 3.874848).  Saving model ...
Updating learning rate to 3.125e-06
  0%|          | 0/19 [00:00<?, ?it/s]loss:24.849443435668945:   0%|          | 0/19 [00:51<?, ?it/s]loss:24.849443435668945:   5%|â–Œ         | 1/19 [00:51<15:33, 51.87s/it]loss:24.747379302978516:   5%|â–Œ         | 1/19 [01:43<15:33, 51.87s/it]loss:24.747379302978516:  11%|â–ˆ         | 2/19 [01:43<14:36, 51.57s/it]loss:24.834321975708008:  11%|â–ˆ         | 2/19 [02:34<14:36, 51.57s/it]loss:24.834321975708008:  16%|â–ˆâ–Œ        | 3/19 [02:34<13:44, 51.55s/it]loss:24.942974090576172:  16%|â–ˆâ–Œ        | 3/19 [03:26<13:44, 51.55s/it]loss:24.942974090576172:  21%|â–ˆâ–ˆ        | 4/19 [03:26<12:53, 51.57s/it]loss:24.95232391357422:  21%|â–ˆâ–ˆ        | 4/19 [04:18<12:53, 51.57s/it] loss:24.95232391357422:  26%|â–ˆâ–ˆâ–‹       | 5/19 [04:18<12:05, 51.79s/it]loss:24.893619537353516:  26%|â–ˆâ–ˆâ–‹       | 5/19 [05:10<12:05, 51.79s/it]loss:24.893619537353516:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [05:10<11:13, 51.79s/it]loss:24.929019927978516:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [06:02<11:13, 51.79s/it]loss:24.929019927978516:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [06:02<10:23, 51.92s/it]loss:24.966413497924805:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [06:54<10:23, 51.92s/it]loss:24.966413497924805:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [06:54<09:31, 51.92s/it]loss:25.06637191772461:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [07:46<09:31, 51.92s/it] loss:25.06637191772461:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [07:46<08:40, 52.05s/it]loss:25.06708335876465:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [08:38<08:40, 52.05s/it]loss:25.06708335876465:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [08:38<07:48, 52.06s/it]loss:24.929088592529297:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [09:30<07:48, 52.06s/it]loss:24.929088592529297:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [09:30<06:55, 51.89s/it]loss:24.916065216064453:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [10:23<06:55, 51.89s/it]loss:24.916065216064453:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [10:23<06:05, 52.18s/it]loss:24.7000675201416:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [11:15<06:05, 52.18s/it]  loss:24.7000675201416:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [11:15<05:12, 52.07s/it]loss:25.06542205810547:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [12:06<05:12, 52.07s/it]loss:25.06542205810547:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [12:06<04:19, 51.95s/it]loss:24.839946746826172:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [12:58<04:19, 51.95s/it]loss:24.839946746826172:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [12:58<03:27, 51.97s/it]loss:24.80135726928711:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [13:51<03:27, 51.97s/it] loss:24.80135726928711:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [13:51<02:36, 52.10s/it]loss:24.798185348510742:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [14:43<02:36, 52.10s/it]loss:24.798185348510742:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [14:43<01:44, 52.10s/it]loss:24.932275772094727:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [15:34<01:44, 52.10s/it]loss:24.932275772094727:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [15:34<00:51, 51.76s/it]loss:24.858675003051758:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [16:24<00:51, 51.76s/it]loss:24.858675003051758: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [16:24<00:00, 51.41s/it]loss:24.858675003051758: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [16:25<00:00, 51.84s/it]
Epoch: 7 cost time: 986.8542146682739
Epoch: 7, Steps: 19 | Train Loss: 24.8994755 Vali Loss: 3.8747923 Test Loss: 69.7507477
Validation loss decreased (3.874848 --> 3.874792).  Saving model ...
Updating learning rate to 1.5625e-06
  0%|          | 0/19 [00:00<?, ?it/s]loss:24.84062385559082:   0%|          | 0/19 [00:52<?, ?it/s]loss:24.84062385559082:   5%|â–Œ         | 1/19 [00:52<15:39, 52.18s/it]loss:24.85887336730957:   5%|â–Œ         | 1/19 [01:44<15:39, 52.18s/it]loss:24.85887336730957:  11%|â–ˆ         | 2/19 [01:44<14:44, 52.03s/it]loss:25.06847381591797:  11%|â–ˆ         | 2/19 [02:35<14:44, 52.03s/it]loss:25.06847381591797:  16%|â–ˆâ–Œ        | 3/19 [02:35<13:49, 51.87s/it]loss:25.06627655029297:  16%|â–ˆâ–Œ        | 3/19 [03:27<13:49, 51.87s/it]loss:25.06627655029297:  21%|â–ˆâ–ˆ        | 4/19 [03:27<12:58, 51.89s/it]loss:24.94523811340332:  21%|â–ˆâ–ˆ        | 4/19 [04:19<12:58, 51.89s/it]loss:24.94523811340332:  26%|â–ˆâ–ˆâ–‹       | 5/19 [04:19<12:04, 51.74s/it]loss:24.917362213134766:  26%|â–ˆâ–ˆâ–‹       | 5/19 [05:10<12:04, 51.74s/it]loss:24.917362213134766:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [05:10<11:12, 51.70s/it]loss:25.06814193725586:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [06:02<11:12, 51.70s/it] loss:25.06814193725586:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [06:02<10:20, 51.73s/it]loss:24.701398849487305:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [06:54<10:20, 51.73s/it]loss:24.701398849487305:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [06:54<09:29, 51.75s/it]loss:24.933059692382812:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [07:46<09:29, 51.75s/it]loss:24.933059692382812:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [07:46<08:39, 51.91s/it]loss:24.837026596069336:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [08:39<08:39, 51.91s/it]loss:24.837026596069336:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [08:39<07:48, 52.07s/it]loss:24.85259437561035:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [09:31<07:48, 52.07s/it] loss:24.85259437561035:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [09:31<06:56, 52.06s/it]loss:24.931516647338867:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [10:24<06:56, 52.06s/it]loss:24.931516647338867:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [10:24<06:06, 52.32s/it]loss:24.79938507080078:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [11:16<06:06, 52.32s/it] loss:24.79938507080078:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [11:16<05:13, 52.24s/it]loss:24.89630126953125:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [12:08<05:13, 52.24s/it]loss:24.89630126953125:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [12:08<04:21, 52.21s/it]loss:24.93105697631836:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [13:00<04:21, 52.21s/it]loss:24.93105697631836:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [13:00<03:28, 52.12s/it]loss:24.968994140625:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [13:52<03:28, 52.12s/it]  loss:24.968994140625:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [13:52<02:36, 52.06s/it]loss:24.750789642333984:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [14:45<02:36, 52.06s/it]loss:24.750789642333984:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [14:45<01:44, 52.45s/it]loss:24.80303192138672:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [15:37<01:44, 52.45s/it] loss:24.80303192138672:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [15:37<00:52, 52.47s/it]loss:24.95545196533203:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [16:30<00:52, 52.47s/it]loss:24.95545196533203: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [16:30<00:00, 52.65s/it]loss:24.95545196533203: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [16:31<00:00, 52.17s/it]
Epoch: 8 cost time: 993.4483706951141
Epoch: 8, Steps: 19 | Train Loss: 24.9013472 Vali Loss: 3.8747692 Test Loss: 69.7530975
Validation loss decreased (3.874792 --> 3.874769).  Saving model ...
Updating learning rate to 7.8125e-07
  0%|          | 0/19 [00:00<?, ?it/s]loss:24.860076904296875:   0%|          | 0/19 [00:54<?, ?it/s]loss:24.860076904296875:   5%|â–Œ         | 1/19 [00:54<16:15, 54.17s/it]loss:24.8967227935791:   5%|â–Œ         | 1/19 [01:47<16:15, 54.17s/it]  loss:24.8967227935791:  11%|â–ˆ         | 2/19 [01:47<15:14, 53.77s/it]loss:24.918285369873047:  11%|â–ˆ         | 2/19 [02:40<15:14, 53.77s/it]loss:24.918285369873047:  16%|â–ˆâ–Œ        | 3/19 [02:40<14:12, 53.27s/it]loss:24.933874130249023:  16%|â–ˆâ–Œ        | 3/19 [03:33<14:12, 53.27s/it]loss:24.933874130249023:  21%|â–ˆâ–ˆ        | 4/19 [03:33<13:19, 53.28s/it]loss:24.842029571533203:  21%|â–ˆâ–ˆ        | 4/19 [04:26<13:19, 53.28s/it]loss:24.842029571533203:  26%|â–ˆâ–ˆâ–‹       | 5/19 [04:26<12:22, 53.02s/it]loss:25.0697021484375:  26%|â–ˆâ–ˆâ–‹       | 5/19 [05:18<12:22, 53.02s/it]  loss:25.0697021484375:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [05:18<11:27, 52.85s/it]loss:24.80335235595703:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [06:11<11:27, 52.85s/it]loss:24.80335235595703:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [06:11<10:32, 52.75s/it]loss:24.931564331054688:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [07:03<10:32, 52.75s/it]loss:24.931564331054688:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [07:03<09:38, 52.63s/it]loss:24.932302474975586:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [07:56<09:38, 52.63s/it]loss:24.932302474975586:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [07:56<08:46, 52.61s/it]loss:25.06743621826172:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [08:49<08:46, 52.61s/it] loss:25.06743621826172:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [08:49<07:55, 52.80s/it]loss:24.83795928955078:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [09:42<07:55, 52.80s/it]loss:24.83795928955078:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [09:42<07:02, 52.79s/it]loss:24.7513370513916:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [10:34<07:02, 52.79s/it] loss:24.7513370513916:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [10:34<06:08, 52.69s/it]loss:25.069353103637695:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [11:27<06:08, 52.69s/it]loss:25.069353103637695:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [11:27<05:15, 52.59s/it]loss:24.969684600830078:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [12:19<05:15, 52.59s/it]loss:24.969684600830078:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [12:19<04:23, 52.64s/it]loss:24.70260238647461:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [13:12<04:23, 52.64s/it] loss:24.70260238647461:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [13:12<03:30, 52.60s/it]loss:24.94668197631836:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [14:04<03:30, 52.60s/it]loss:24.94668197631836:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [14:04<02:37, 52.52s/it]loss:24.800386428833008:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [14:56<02:37, 52.52s/it]loss:24.800386428833008:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [14:56<01:44, 52.36s/it]loss:24.853742599487305:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [15:49<01:44, 52.36s/it]loss:24.853742599487305:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [15:49<00:52, 52.45s/it]loss:24.956092834472656:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [16:41<00:52, 52.45s/it]loss:24.956092834472656: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [16:41<00:00, 52.53s/it]loss:24.956092834472656: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [16:42<00:00, 52.75s/it]
Epoch: 9 cost time: 1004.080785036087
Epoch: 9, Steps: 19 | Train Loss: 24.9022730 Vali Loss: 3.8747604 Test Loss: 69.7541504
Validation loss decreased (3.874769 --> 3.874760).  Saving model ...
Updating learning rate to 3.90625e-07
  0%|          | 0/19 [00:00<?, ?it/s]loss:24.853805541992188:   0%|          | 0/19 [00:53<?, ?it/s]loss:24.853805541992188:   5%|â–Œ         | 1/19 [00:53<16:01, 53.40s/it]loss:24.93270492553711:   5%|â–Œ         | 1/19 [01:45<16:01, 53.40s/it] loss:24.93270492553711:  11%|â–ˆ         | 2/19 [01:45<14:52, 52.49s/it]loss:24.80382537841797:  11%|â–ˆ         | 2/19 [02:37<14:52, 52.49s/it]loss:24.80382537841797:  16%|â–ˆâ–Œ        | 3/19 [02:37<13:54, 52.16s/it]loss:24.94683837890625:  16%|â–ˆâ–Œ        | 3/19 [03:29<13:54, 52.16s/it]loss:24.94683837890625:  21%|â–ˆâ–ˆ        | 4/19 [03:29<13:05, 52.38s/it]loss:24.70281982421875:  21%|â–ˆâ–ˆ        | 4/19 [04:21<13:05, 52.38s/it]loss:24.70281982421875:  26%|â–ˆâ–ˆâ–‹       | 5/19 [04:21<12:12, 52.29s/it]loss:25.067794799804688:  26%|â–ˆâ–ˆâ–‹       | 5/19 [05:14<12:12, 52.29s/it]loss:25.067794799804688:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [05:14<11:19, 52.25s/it]loss:24.86079978942871:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [06:06<11:19, 52.25s/it] loss:24.86079978942871:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [06:06<10:28, 52.39s/it]loss:24.8426456451416:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [06:59<10:28, 52.39s/it] loss:24.8426456451416:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [06:59<09:36, 52.43s/it]loss:24.800594329833984:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [07:51<09:36, 52.43s/it]loss:24.800594329833984:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [07:51<08:42, 52.30s/it]loss:24.89743995666504:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [08:43<08:42, 52.30s/it] loss:24.89743995666504:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [08:43<07:50, 52.28s/it]loss:24.97003746032715:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [09:36<07:50, 52.28s/it]loss:24.97003746032715:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [09:36<06:59, 52.41s/it]loss:24.838409423828125:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [10:28<06:59, 52.41s/it]loss:24.838409423828125:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [10:28<06:06, 52.32s/it]loss:25.06975746154785:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [11:20<06:06, 52.32s/it] loss:25.06975746154785:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [11:20<05:13, 52.33s/it]loss:24.75179672241211:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [12:12<05:13, 52.33s/it]loss:24.75179672241211:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [12:12<04:21, 52.31s/it]loss:25.07036018371582:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [13:05<04:21, 52.31s/it]loss:25.07036018371582:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [13:05<03:28, 52.24s/it]loss:24.932161331176758:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [13:57<03:28, 52.24s/it]loss:24.932161331176758:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [13:57<02:36, 52.19s/it]loss:24.956363677978516:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [14:49<02:36, 52.19s/it]loss:24.956363677978516:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [14:49<01:44, 52.25s/it]loss:24.934656143188477:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [15:41<01:44, 52.25s/it]loss:24.934656143188477:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [15:41<00:52, 52.20s/it]loss:24.919078826904297:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [16:33<00:52, 52.20s/it]loss:24.919078826904297: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [16:33<00:00, 52.14s/it]loss:24.919078826904297: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [16:33<00:00, 52.31s/it]
Epoch: 10 cost time: 995.805172920227
Epoch: 10, Steps: 19 | Train Loss: 24.9027310 Vali Loss: 3.8747535 Test Loss: 69.7545700
Validation loss decreased (3.874760 --> 3.874753).  Saving model ...
Updating learning rate to 1.953125e-07
  0%|          | 0/19 [00:00<?, ?it/s]loss:24.897586822509766:   0%|          | 0/19 [00:53<?, ?it/s]loss:24.897586822509766:   5%|â–Œ         | 1/19 [00:53<15:54, 53.06s/it]loss:24.804100036621094:   5%|â–Œ         | 1/19 [01:44<15:54, 53.06s/it]loss:24.804100036621094:  11%|â–ˆ         | 2/19 [01:44<14:47, 52.19s/it]loss:24.842859268188477:  11%|â–ˆ         | 2/19 [02:36<14:47, 52.19s/it]loss:24.842859268188477:  16%|â–ˆâ–Œ        | 3/19 [02:36<13:54, 52.18s/it]loss:25.068002700805664:  16%|â–ˆâ–Œ        | 3/19 [03:29<13:54, 52.18s/it]loss:25.068002700805664:  21%|â–ˆâ–ˆ        | 4/19 [03:29<13:03, 52.23s/it]loss:25.069896697998047:  21%|â–ˆâ–ˆ        | 4/19 [04:21<13:03, 52.23s/it]loss:25.069896697998047:  26%|â–ˆâ–ˆâ–‹       | 5/19 [04:21<12:10, 52.15s/it]loss:24.751937866210938:  26%|â–ˆâ–ˆâ–‹       | 5/19 [05:14<12:10, 52.15s/it]loss:24.751937866210938:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [05:14<11:22, 52.52s/it]loss:25.070491790771484:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [06:07<11:22, 52.52s/it]loss:25.070491790771484:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [06:07<10:31, 52.60s/it]loss:24.919153213500977:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [06:59<10:31, 52.60s/it]loss:24.919153213500977:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [06:59<09:37, 52.48s/it]loss:24.970256805419922:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [07:52<09:37, 52.48s/it]loss:24.970256805419922:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [07:52<08:46, 52.62s/it]loss:24.83861541748047:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [08:44<08:46, 52.62s/it] loss:24.83861541748047:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [08:44<07:52, 52.53s/it]loss:24.861103057861328:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [09:36<07:52, 52.53s/it]loss:24.861103057861328:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [09:36<06:59, 52.48s/it]loss:24.703147888183594:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [10:29<06:59, 52.48s/it]loss:24.703147888183594:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [10:29<06:08, 52.59s/it]loss:24.93233299255371:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [11:22<06:08, 52.59s/it] loss:24.93233299255371:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [11:22<05:14, 52.48s/it]loss:24.934816360473633:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [12:14<05:14, 52.48s/it]loss:24.934816360473633:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [12:14<04:21, 52.40s/it]loss:24.85423469543457:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [13:06<04:21, 52.40s/it] loss:24.85423469543457:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [13:06<03:29, 52.32s/it]loss:24.933137893676758:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [13:59<03:29, 52.32s/it]loss:24.933137893676758:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [13:59<02:37, 52.49s/it]loss:24.800931930541992:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [14:51<02:37, 52.49s/it]loss:24.800931930541992:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [14:51<01:44, 52.32s/it]loss:24.94724464416504:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [15:43<01:44, 52.32s/it] loss:24.94724464416504:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [15:43<00:52, 52.32s/it]loss:24.956586837768555:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [16:36<00:52, 52.32s/it]loss:24.956586837768555: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [16:36<00:00, 52.38s/it]loss:24.956586837768555: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [16:36<00:00, 52.44s/it]
Epoch: 11 cost time: 998.319007396698
Epoch: 11, Steps: 19 | Train Loss: 24.9029704 Vali Loss: 3.8747516 Test Loss: 69.7549133
Validation loss decreased (3.874753 --> 3.874752).  Saving model ...
Updating learning rate to 9.765625e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:24.838712692260742:   0%|          | 0/19 [00:53<?, ?it/s]loss:24.838712692260742:   5%|â–Œ         | 1/19 [00:53<16:02, 53.48s/it]loss:24.84303855895996:   5%|â–Œ         | 1/19 [01:45<16:02, 53.48s/it] loss:24.84303855895996:  11%|â–ˆ         | 2/19 [01:45<14:57, 52.78s/it]loss:24.93318748474121:  11%|â–ˆ         | 2/19 [02:38<14:57, 52.78s/it]loss:24.93318748474121:  16%|â–ˆâ–Œ        | 3/19 [02:38<14:02, 52.65s/it]loss:24.897796630859375:  16%|â–ˆâ–Œ        | 3/19 [03:30<14:02, 52.65s/it]loss:24.897796630859375:  21%|â–ˆâ–ˆ        | 4/19 [03:30<13:10, 52.67s/it]loss:24.703250885009766:  21%|â–ˆâ–ˆ        | 4/19 [04:23<13:10, 52.67s/it]loss:24.703250885009766:  26%|â–ˆâ–ˆâ–‹       | 5/19 [04:23<12:15, 52.51s/it]loss:24.854310989379883:  26%|â–ˆâ–ˆâ–‹       | 5/19 [05:16<12:15, 52.51s/it]loss:24.854310989379883:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [05:16<11:24, 52.69s/it]loss:24.75210952758789:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [06:08<11:24, 52.69s/it] loss:24.75210952758789:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [06:08<10:28, 52.41s/it]loss:24.970407485961914:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [07:00<10:28, 52.41s/it]loss:24.970407485961914:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [07:00<09:37, 52.53s/it]loss:25.068187713623047:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [07:53<09:37, 52.53s/it]loss:25.068187713623047:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [07:53<08:46, 52.63s/it]loss:24.801008224487305:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [08:46<08:46, 52.63s/it]loss:24.801008224487305:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [08:46<07:53, 52.65s/it]loss:24.919322967529297:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [09:39<07:53, 52.65s/it]loss:24.919322967529297:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [09:39<07:02, 52.78s/it]loss:24.804344177246094:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [10:32<07:02, 52.78s/it]loss:24.804344177246094:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [10:32<06:08, 52.70s/it]loss:24.93246078491211:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [11:24<06:08, 52.70s/it] loss:24.93246078491211:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [11:24<05:16, 52.78s/it]loss:24.861263275146484:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [12:17<05:16, 52.78s/it]loss:24.861263275146484:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [12:17<04:23, 52.68s/it]loss:24.94733428955078:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [13:10<04:23, 52.68s/it] loss:24.94733428955078:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [13:10<03:31, 52.86s/it]loss:25.07012367248535:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [14:03<03:31, 52.86s/it]loss:25.07012367248535:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [14:03<02:38, 52.89s/it]loss:25.07069969177246:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [14:56<02:38, 52.89s/it]loss:25.07069969177246:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [14:56<01:45, 52.84s/it]loss:24.934965133666992:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [15:49<01:45, 52.84s/it]loss:24.934965133666992:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [15:49<00:52, 52.80s/it]loss:24.956689834594727:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [16:41<00:52, 52.80s/it]loss:24.956689834594727: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [16:41<00:00, 52.73s/it]loss:24.956689834594727: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [16:41<00:00, 52.73s/it]
Epoch: 12 cost time: 1003.9389374256134
Epoch: 12, Steps: 19 | Train Loss: 24.9031165 Vali Loss: 3.8747499 Test Loss: 69.7550201
Validation loss decreased (3.874752 --> 3.874750).  Saving model ...
Updating learning rate to 4.8828125e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:24.933277130126953:   0%|          | 0/19 [00:53<?, ?it/s]loss:24.933277130126953:   5%|â–Œ         | 1/19 [00:53<16:07, 53.77s/it]loss:24.80438804626465:   5%|â–Œ         | 1/19 [01:46<16:07, 53.77s/it] loss:24.80438804626465:  11%|â–ˆ         | 2/19 [01:46<15:00, 52.99s/it]loss:24.919361114501953:  11%|â–ˆ         | 2/19 [02:38<15:00, 52.99s/it]loss:24.919361114501953:  16%|â–ˆâ–Œ        | 3/19 [02:38<14:05, 52.86s/it]loss:24.97046661376953:  16%|â–ˆâ–Œ        | 3/19 [03:31<14:05, 52.86s/it] loss:24.97046661376953:  21%|â–ˆâ–ˆ        | 4/19 [03:31<13:13, 52.88s/it]loss:24.86129379272461:  21%|â–ˆâ–ˆ        | 4/19 [04:25<13:13, 52.88s/it]loss:24.86129379272461:  26%|â–ˆâ–ˆâ–‹       | 5/19 [04:25<12:23, 53.09s/it]loss:24.956693649291992:  26%|â–ˆâ–ˆâ–‹       | 5/19 [05:19<12:23, 53.09s/it]loss:24.956693649291992:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [05:19<11:35, 53.51s/it]loss:24.752174377441406:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [06:12<11:35, 53.51s/it]loss:24.752174377441406:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [06:12<10:41, 53.45s/it]loss:24.8431339263916:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [07:05<10:41, 53.45s/it]  loss:24.8431339263916:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [07:05<09:45, 53.22s/it]loss:24.838804244995117:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [07:59<09:45, 53.22s/it]loss:24.838804244995117:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [07:59<08:52, 53.27s/it]loss:24.934974670410156:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [08:51<08:52, 53.27s/it]loss:24.934974670410156:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [08:51<07:56, 52.92s/it]loss:24.947357177734375:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [09:43<07:56, 52.92s/it]loss:24.947357177734375:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [09:43<07:02, 52.87s/it]loss:24.897876739501953:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [10:37<07:02, 52.87s/it]loss:24.897876739501953:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [10:37<06:10, 52.95s/it]loss:24.85437774658203:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [11:29<06:10, 52.95s/it] loss:24.85437774658203:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [11:29<05:17, 52.84s/it]loss:25.07071304321289:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [12:22<05:17, 52.84s/it]loss:25.07071304321289:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [12:22<04:24, 52.81s/it]loss:24.703319549560547:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [13:15<04:24, 52.81s/it]loss:24.703319549560547:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [13:15<03:31, 52.76s/it]loss:25.07013702392578:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [14:07<03:31, 52.76s/it] loss:25.07013702392578:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [14:07<02:37, 52.59s/it]loss:24.80105972290039:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [14:59<02:37, 52.59s/it]loss:24.80105972290039:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [14:59<01:44, 52.48s/it]loss:25.0682315826416:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [15:51<01:44, 52.48s/it] loss:25.0682315826416:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [15:51<00:52, 52.47s/it]loss:24.932491302490234:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [16:43<00:52, 52.47s/it]loss:24.932491302490234: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [16:43<00:00, 52.30s/it]loss:24.932491302490234: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [16:44<00:00, 52.85s/it]
Epoch: 13 cost time: 1006.0165584087372
Epoch: 13, Steps: 19 | Train Loss: 24.9031648 Vali Loss: 3.8747492 Test Loss: 69.7550735
Validation loss decreased (3.874750 --> 3.874749).  Saving model ...
Updating learning rate to 2.44140625e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:24.91935920715332:   0%|          | 0/19 [00:53<?, ?it/s]loss:24.91935920715332:   5%|â–Œ         | 1/19 [00:53<15:59, 53.32s/it]loss:25.07013702392578:   5%|â–Œ         | 1/19 [01:45<15:59, 53.32s/it]loss:25.07013702392578:  11%|â–ˆ         | 2/19 [01:45<14:59, 52.89s/it]loss:24.8431339263916:  11%|â–ˆ         | 2/19 [02:37<14:59, 52.89s/it] loss:24.8431339263916:  16%|â–ˆâ–Œ        | 3/19 [02:37<14:00, 52.51s/it]loss:24.85437774658203:  16%|â–ˆâ–Œ        | 3/19 [03:30<14:00, 52.51s/it]loss:24.85437774658203:  21%|â–ˆâ–ˆ        | 4/19 [03:30<13:06, 52.43s/it]loss:24.95669174194336:  21%|â–ˆâ–ˆ        | 4/19 [04:23<13:06, 52.43s/it]loss:24.95669174194336:  26%|â–ˆâ–ˆâ–‹       | 5/19 [04:23<12:16, 52.57s/it]loss:24.9704647064209:  26%|â–ˆâ–ˆâ–‹       | 5/19 [05:16<12:16, 52.57s/it] loss:24.9704647064209:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [05:16<11:26, 52.83s/it]loss:24.752172470092773:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [06:09<11:26, 52.83s/it]loss:24.752172470092773:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [06:09<10:33, 52.79s/it]loss:24.80105972290039:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [07:02<10:33, 52.79s/it] loss:24.80105972290039:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [07:02<09:41, 52.82s/it]loss:24.93327522277832:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [07:55<09:41, 52.82s/it]loss:24.93327522277832:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [07:55<08:49, 52.93s/it]loss:24.80438232421875:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [08:47<08:49, 52.93s/it]loss:24.80438232421875:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [08:47<07:53, 52.64s/it]loss:24.83880043029785:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [09:39<07:53, 52.64s/it]loss:24.83880043029785:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [09:39<06:59, 52.45s/it]loss:24.703317642211914:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [10:31<06:59, 52.45s/it]loss:24.703317642211914:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [10:31<06:06, 52.42s/it]loss:24.947351455688477:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [11:24<06:06, 52.42s/it]loss:24.947351455688477:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [11:24<05:14, 52.45s/it]loss:25.068225860595703:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [12:16<05:14, 52.45s/it]loss:25.068225860595703:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [12:16<04:22, 52.50s/it]loss:24.86129379272461:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [13:08<04:22, 52.50s/it] loss:24.86129379272461:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [13:08<03:29, 52.38s/it]loss:24.934972763061523:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [14:01<03:29, 52.38s/it]loss:24.934972763061523:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [14:01<02:37, 52.37s/it]loss:25.070711135864258:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [14:53<02:37, 52.37s/it]loss:25.070711135864258:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [14:53<01:44, 52.27s/it]loss:24.93248748779297:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [15:44<01:44, 52.27s/it] loss:24.93248748779297:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [15:44<00:51, 51.96s/it]loss:24.897871017456055:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [16:36<00:51, 51.96s/it]loss:24.897871017456055: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [16:36<00:00, 52.03s/it]loss:24.897871017456055: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [16:36<00:00, 52.47s/it]
Epoch: 14 cost time: 998.8243763446808
Epoch: 14, Steps: 19 | Train Loss: 24.9031624 Vali Loss: 3.8747489 Test Loss: 69.7551117
Validation loss decreased (3.874749 --> 3.874749).  Saving model ...
Updating learning rate to 1.220703125e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:24.9704647064209:   0%|          | 0/19 [00:53<?, ?it/s]loss:24.9704647064209:   5%|â–Œ         | 1/19 [00:53<15:59, 53.30s/it]loss:24.934972763061523:   5%|â–Œ         | 1/19 [01:45<15:59, 53.30s/it]loss:24.934972763061523:  11%|â–ˆ         | 2/19 [01:45<14:55, 52.65s/it]loss:24.843130111694336:  11%|â–ˆ         | 2/19 [02:38<14:55, 52.65s/it]loss:24.843130111694336:  16%|â–ˆâ–Œ        | 3/19 [02:38<14:02, 52.66s/it]loss:24.83879852294922:  16%|â–ˆâ–Œ        | 3/19 [03:32<14:02, 52.66s/it] loss:24.83879852294922:  21%|â–ˆâ–ˆ        | 4/19 [03:32<13:17, 53.15s/it]loss:24.93327522277832:  21%|â–ˆâ–ˆ        | 4/19 [04:26<13:17, 53.15s/it]loss:24.93327522277832:  26%|â–ˆâ–ˆâ–‹       | 5/19 [04:26<12:32, 53.77s/it]loss:24.956689834594727:  26%|â–ˆâ–ˆâ–‹       | 5/19 [05:21<12:32, 53.77s/it]loss:24.956689834594727:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [05:21<11:40, 53.87s/it]loss:24.80105972290039:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [06:15<11:40, 53.87s/it] loss:24.80105972290039:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [06:15<10:49, 54.14s/it]loss:24.75217056274414:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [07:10<10:49, 54.14s/it]loss:24.75217056274414:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [07:10<09:58, 54.38s/it]loss:24.85437774658203:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [08:05<09:58, 54.38s/it]loss:24.85437774658203:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [08:05<09:05, 54.56s/it]loss:25.06822395324707:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [09:00<09:05, 54.56s/it]loss:25.06822395324707:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [09:00<08:11, 54.56s/it]loss:25.07013511657715:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [09:55<08:11, 54.56s/it]loss:25.07013511657715:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [09:55<07:18, 54.80s/it]loss:24.897871017456055:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [10:49<07:18, 54.80s/it]loss:24.897871017456055:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [10:49<06:22, 54.67s/it]loss:24.932485580444336:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [11:44<06:22, 54.67s/it]loss:24.932485580444336:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [11:44<05:27, 54.59s/it]loss:24.919357299804688:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [12:38<05:27, 54.59s/it]loss:24.919357299804688:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [12:38<04:31, 54.38s/it]loss:25.070709228515625:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [13:32<04:31, 54.38s/it]loss:25.070709228515625:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [13:32<03:37, 54.28s/it]loss:24.947351455688477:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [14:25<03:37, 54.28s/it]loss:24.947351455688477:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [14:25<02:42, 54.11s/it]loss:24.703317642211914:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [15:20<02:42, 54.11s/it]loss:24.703317642211914:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [15:20<01:48, 54.13s/it]loss:24.861291885375977:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [16:14<01:48, 54.13s/it]loss:24.861291885375977:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [16:14<00:54, 54.30s/it]loss:24.80438232421875:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [17:08<00:54, 54.30s/it] loss:24.80438232421875: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [17:08<00:00, 54.07s/it]loss:24.80438232421875: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [17:08<00:00, 54.14s/it]
Epoch: 15 cost time: 1030.7032194137573
Epoch: 15, Steps: 19 | Train Loss: 24.9031613 Vali Loss: 3.8747489 Test Loss: 69.7551270
Validation loss decreased (3.874749 --> 3.874749).  Saving model ...
Updating learning rate to 6.103515625e-09
  0%|          | 0/19 [00:00<?, ?it/s]loss:25.06822395324707:   0%|          | 0/19 [00:55<?, ?it/s]loss:25.06822395324707:   5%|â–Œ         | 1/19 [00:55<16:32, 55.14s/it]loss:24.9704647064209:   5%|â–Œ         | 1/19 [01:48<16:32, 55.14s/it] loss:24.9704647064209:  11%|â–ˆ         | 2/19 [01:48<15:22, 54.29s/it]loss:24.93327522277832:  11%|â–ˆ         | 2/19 [02:42<15:22, 54.29s/it]loss:24.93327522277832:  16%|â–ˆâ–Œ        | 3/19 [02:42<14:21, 53.83s/it]loss:24.75217056274414:  16%|â–ˆâ–Œ        | 3/19 [03:36<14:21, 53.83s/it]loss:24.75217056274414:  21%|â–ˆâ–ˆ        | 4/19 [03:36<13:28, 53.88s/it]loss:24.703317642211914:  21%|â–ˆâ–ˆ        | 4/19 [04:30<13:28, 53.88s/it]loss:24.703317642211914:  26%|â–ˆâ–ˆâ–‹       | 5/19 [04:30<12:35, 53.99s/it]loss:24.932485580444336:  26%|â–ˆâ–ˆâ–‹       | 5/19 [05:24<12:35, 53.99s/it]loss:24.932485580444336:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [05:24<11:43, 54.15s/it]loss:25.07013511657715:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [06:18<11:43, 54.15s/it] loss:25.07013511657715:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [06:18<10:48, 54.03s/it]loss:24.838796615600586:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [07:12<10:48, 54.03s/it]loss:24.838796615600586:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [07:12<09:54, 54.09s/it]loss:24.934972763061523:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [08:06<09:54, 54.09s/it]loss:24.934972763061523:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [08:06<09:01, 54.12s/it]loss:24.80105972290039:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [09:01<09:01, 54.12s/it] loss:24.80105972290039:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [09:01<08:07, 54.13s/it]loss:24.897871017456055:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [09:55<08:07, 54.13s/it]loss:24.897871017456055:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [09:55<07:12, 54.08s/it]loss:24.919357299804688:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [10:49<07:12, 54.08s/it]loss:24.919357299804688:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [10:49<06:18, 54.14s/it]loss:24.80438232421875:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [11:43<06:18, 54.14s/it] loss:24.80438232421875:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [11:43<05:25, 54.17s/it]loss:24.843130111694336:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [12:37<05:25, 54.17s/it]loss:24.843130111694336:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [12:37<04:30, 54.07s/it]loss:24.85437774658203:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [13:30<04:30, 54.07s/it] loss:24.85437774658203:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [13:30<03:35, 53.84s/it]loss:24.947351455688477:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [14:24<03:35, 53.84s/it]loss:24.947351455688477:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [14:24<02:41, 53.75s/it]loss:24.861291885375977:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [15:17<02:41, 53.75s/it]loss:24.861291885375977:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [15:17<01:47, 53.74s/it]loss:25.070709228515625:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [16:11<01:47, 53.74s/it]loss:25.070709228515625:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [16:11<00:53, 53.81s/it]loss:24.956689834594727:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [17:05<00:53, 53.81s/it]loss:24.956689834594727: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [17:05<00:00, 53.72s/it]loss:24.956689834594727: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [17:05<00:00, 53.99s/it]
Epoch: 16 cost time: 1027.734590768814
Epoch: 16, Steps: 19 | Train Loss: 24.9031612 Vali Loss: 3.8747489 Test Loss: 69.7551346
Validation loss decreased (3.874749 --> 3.874749).  Saving model ...
Updating learning rate to 3.0517578125e-09
  0%|          | 0/19 [00:00<?, ?it/s]loss:24.947351455688477:   0%|          | 0/19 [00:54<?, ?it/s]loss:24.947351455688477:   5%|â–Œ         | 1/19 [00:54<16:25, 54.73s/it]loss:24.838796615600586:   5%|â–Œ         | 1/19 [01:48<16:25, 54.73s/it]loss:24.838796615600586:  11%|â–ˆ         | 2/19 [01:48<15:16, 53.91s/it]loss:24.843130111694336:  11%|â–ˆ         | 2/19 [02:41<15:16, 53.91s/it]loss:24.843130111694336:  16%|â–ˆâ–Œ        | 3/19 [02:41<14:16, 53.52s/it]loss:25.070709228515625:  16%|â–ˆâ–Œ        | 3/19 [03:34<14:16, 53.52s/it]loss:25.070709228515625:  21%|â–ˆâ–ˆ        | 4/19 [03:34<13:21, 53.41s/it]loss:24.919355392456055:  21%|â–ˆâ–ˆ        | 4/19 [04:28<13:21, 53.41s/it]loss:24.919355392456055:  26%|â–ˆâ–ˆâ–‹       | 5/19 [04:28<12:31, 53.66s/it]loss:24.933273315429688:  26%|â–ˆâ–ˆâ–‹       | 5/19 [05:22<12:31, 53.66s/it]loss:24.933273315429688:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [05:22<11:40, 53.87s/it]loss:24.897871017456055:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [06:16<11:40, 53.87s/it]loss:24.897871017456055:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [06:16<10:46, 53.88s/it]loss:24.9704647064209:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [07:10<10:46, 53.88s/it]  loss:24.9704647064209:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [07:10<09:54, 54.01s/it]loss:24.934972763061523:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [08:05<09:54, 54.01s/it]loss:24.934972763061523:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [08:05<09:01, 54.17s/it]loss:24.75217056274414:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [09:00<09:01, 54.17s/it] loss:24.75217056274414:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [09:00<08:09, 54.40s/it]loss:24.703317642211914:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [09:54<08:09, 54.40s/it]loss:24.703317642211914:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [09:54<07:15, 54.47s/it]loss:24.85437774658203:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [10:49<07:15, 54.47s/it] loss:24.85437774658203:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [10:49<06:21, 54.47s/it]loss:24.861291885375977:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [11:44<06:21, 54.47s/it]loss:24.861291885375977:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [11:44<05:27, 54.57s/it]loss:25.06822395324707:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [12:38<05:27, 54.57s/it] loss:25.06822395324707:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [12:38<04:32, 54.54s/it]loss:24.956689834594727:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [13:33<04:32, 54.54s/it]loss:24.956689834594727:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [13:33<03:38, 54.50s/it]loss:24.80105972290039:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [14:27<03:38, 54.50s/it] loss:24.80105972290039:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [14:27<02:43, 54.47s/it]loss:24.932485580444336:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [15:21<02:43, 54.47s/it]loss:24.932485580444336:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [15:21<01:48, 54.40s/it]loss:25.07013511657715:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [16:15<01:48, 54.40s/it] loss:25.07013511657715:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [16:15<00:54, 54.28s/it]loss:24.80438232421875:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [17:10<00:54, 54.28s/it]loss:24.80438232421875: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [17:10<00:00, 54.32s/it]loss:24.80438232421875: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [17:10<00:00, 54.23s/it]
Epoch: 17 cost time: 1032.2379505634308
Epoch: 17, Steps: 19 | Train Loss: 24.9031610 Vali Loss: 3.8747489 Test Loss: 69.7551422
Validation loss decreased (3.874749 --> 3.874749).  Saving model ...
Updating learning rate to 1.52587890625e-09
  0%|          | 0/19 [00:00<?, ?it/s]loss:25.070709228515625:   0%|          | 0/19 [00:54<?, ?it/s]loss:25.070709228515625:   5%|â–Œ         | 1/19 [00:54<16:27, 54.86s/it]loss:24.956689834594727:   5%|â–Œ         | 1/19 [01:49<16:27, 54.86s/it]loss:24.956689834594727:  11%|â–ˆ         | 2/19 [01:49<15:29, 54.66s/it]loss:24.75217056274414:  11%|â–ˆ         | 2/19 [02:43<15:29, 54.66s/it] loss:24.75217056274414:  16%|â–ˆâ–Œ        | 3/19 [02:43<14:28, 54.30s/it]loss:24.897869110107422:  16%|â–ˆâ–Œ        | 3/19 [03:37<14:28, 54.30s/it]loss:24.897869110107422:  21%|â–ˆâ–ˆ        | 4/19 [03:37<13:34, 54.31s/it]loss:24.861291885375977:  21%|â–ˆâ–ˆ        | 4/19 [04:31<13:34, 54.31s/it]loss:24.861291885375977:  26%|â–ˆâ–ˆâ–‹       | 5/19 [04:31<12:37, 54.10s/it]loss:24.85437774658203:  26%|â–ˆâ–ˆâ–‹       | 5/19 [05:25<12:37, 54.10s/it] loss:24.85437774658203:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [05:25<11:45, 54.26s/it]loss:24.80105972290039:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [06:20<11:45, 54.26s/it]loss:24.80105972290039:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [06:20<10:52, 54.33s/it]loss:24.932485580444336:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [07:14<10:52, 54.33s/it]loss:24.932485580444336:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [07:14<09:57, 54.34s/it]loss:24.933273315429688:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [08:09<09:57, 54.34s/it]loss:24.933273315429688:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [08:09<09:03, 54.33s/it]loss:25.07013511657715:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [09:03<09:03, 54.33s/it] loss:25.07013511657715:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [09:03<08:08, 54.32s/it]loss:25.068222045898438:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [09:57<08:08, 54.32s/it]loss:25.068222045898438:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [09:57<07:13, 54.22s/it]loss:24.843130111694336:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [10:51<07:13, 54.22s/it]loss:24.843130111694336:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [10:51<06:18, 54.10s/it]loss:24.919357299804688:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [11:44<06:18, 54.10s/it]loss:24.919357299804688:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [11:44<05:23, 53.98s/it]loss:24.934972763061523:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [12:38<05:23, 53.98s/it]loss:24.934972763061523:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [12:38<04:29, 53.83s/it]loss:24.838796615600586:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [13:32<04:29, 53.83s/it]loss:24.838796615600586:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [13:32<03:35, 53.81s/it]loss:24.703317642211914:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [14:25<03:35, 53.81s/it]loss:24.703317642211914:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [14:25<02:41, 53.79s/it]loss:24.947351455688477:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [15:19<02:41, 53.79s/it]loss:24.947351455688477:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [15:19<01:47, 53.77s/it]loss:24.80438232421875:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [16:12<01:47, 53.77s/it] loss:24.80438232421875:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [16:12<00:53, 53.64s/it]loss:24.9704647064209:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [17:06<00:53, 53.64s/it] loss:24.9704647064209: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [17:06<00:00, 53.74s/it]loss:24.9704647064209: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [17:07<00:00, 54.06s/it]
Epoch: 18 cost time: 1029.0950019359589
Epoch: 18, Steps: 19 | Train Loss: 24.9031609 Vali Loss: 3.8747489 Test Loss: 69.7551422
Validation loss decreased (3.874749 --> 3.874749).  Saving model ...
Updating learning rate to 7.62939453125e-10
  0%|          | 0/19 [00:00<?, ?it/s]loss:24.933273315429688:   0%|          | 0/19 [00:54<?, ?it/s]loss:24.933273315429688:   5%|â–Œ         | 1/19 [00:54<16:22, 54.57s/it]loss:24.85437774658203:   5%|â–Œ         | 1/19 [01:48<16:22, 54.57s/it] loss:24.85437774658203:  11%|â–ˆ         | 2/19 [01:48<15:17, 54.00s/it]loss:24.80438232421875:  11%|â–ˆ         | 2/19 [02:41<15:17, 54.00s/it]loss:24.80438232421875:  16%|â–ˆâ–Œ        | 3/19 [02:41<14:21, 53.84s/it]loss:24.897871017456055:  16%|â–ˆâ–Œ        | 3/19 [03:36<14:21, 53.84s/it]loss:24.897871017456055:  21%|â–ˆâ–ˆ        | 4/19 [03:36<13:30, 54.06s/it]loss:24.919355392456055:  21%|â–ˆâ–ˆ        | 4/19 [04:30<13:30, 54.06s/it]loss:24.919355392456055:  26%|â–ˆâ–ˆâ–‹       | 5/19 [04:30<12:40, 54.29s/it]loss:24.80105972290039:  26%|â–ˆâ–ˆâ–‹       | 5/19 [05:25<12:40, 54.29s/it] loss:24.80105972290039:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [05:25<11:48, 54.46s/it]loss:24.934972763061523:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [06:20<11:48, 54.46s/it]loss:24.934972763061523:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [06:20<10:53, 54.50s/it]loss:24.932485580444336:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [07:14<10:53, 54.50s/it]loss:24.932485580444336:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [07:14<09:58, 54.42s/it]loss:24.947351455688477:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [08:08<09:58, 54.42s/it]loss:24.947351455688477:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [08:08<09:01, 54.12s/it]loss:24.703317642211914:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [09:02<09:01, 54.12s/it]loss:24.703317642211914:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [09:02<08:08, 54.27s/it]loss:25.07013511657715:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [09:57<08:08, 54.27s/it] loss:25.07013511657715:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [09:57<07:15, 54.42s/it]loss:25.070709228515625:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [10:51<07:15, 54.42s/it]loss:25.070709228515625:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [10:51<06:21, 54.45s/it]loss:24.843130111694336:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [11:46<06:21, 54.45s/it]loss:24.843130111694336:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [11:46<05:27, 54.51s/it]loss:24.75217056274414:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [12:40<05:27, 54.51s/it] loss:24.75217056274414:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [12:40<04:31, 54.34s/it]loss:24.956689834594727:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [13:34<04:31, 54.34s/it]loss:24.956689834594727:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [13:34<03:37, 54.26s/it]loss:24.838796615600586:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [14:28<03:37, 54.26s/it]loss:24.838796615600586:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [14:28<02:42, 54.21s/it]loss:25.068222045898438:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [15:22<02:42, 54.21s/it]loss:25.068222045898438:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [15:22<01:48, 54.17s/it]loss:24.970462799072266:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [16:17<01:48, 54.17s/it]loss:24.970462799072266:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [16:17<00:54, 54.24s/it]loss:24.861291885375977:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [17:11<00:54, 54.24s/it]loss:24.861291885375977: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [17:11<00:00, 54.33s/it]loss:24.861291885375977: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [17:11<00:00, 54.31s/it]
Epoch: 19 cost time: 1033.9324328899384
Epoch: 19, Steps: 19 | Train Loss: 24.9031608 Vali Loss: 3.8747489 Test Loss: 69.7551422
Validation loss decreased (3.874749 --> 3.874749).  Saving model ...
Updating learning rate to 3.814697265625e-10
  0%|          | 0/19 [00:00<?, ?it/s]loss:25.07013511657715:   0%|          | 0/19 [00:54<?, ?it/s]loss:25.07013511657715:   5%|â–Œ         | 1/19 [00:54<16:29, 54.99s/it]loss:24.933273315429688:   5%|â–Œ         | 1/19 [01:49<16:29, 54.99s/it]loss:24.933273315429688:  11%|â–ˆ         | 2/19 [01:49<15:32, 54.86s/it]loss:24.75217056274414:  11%|â–ˆ         | 2/19 [02:44<15:32, 54.86s/it] loss:24.75217056274414:  16%|â–ˆâ–Œ        | 3/19 [02:44<14:39, 54.96s/it]loss:24.932485580444336:  16%|â–ˆâ–Œ        | 3/19 [03:39<14:39, 54.96s/it]loss:24.932485580444336:  21%|â–ˆâ–ˆ        | 4/19 [03:39<13:40, 54.67s/it]loss:24.861291885375977:  21%|â–ˆâ–ˆ        | 4/19 [04:33<13:40, 54.67s/it]loss:24.861291885375977:  26%|â–ˆâ–ˆâ–‹       | 5/19 [04:33<12:43, 54.57s/it]loss:24.897871017456055:  26%|â–ˆâ–ˆâ–‹       | 5/19 [05:27<12:43, 54.57s/it]loss:24.897871017456055:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [05:27<11:46, 54.34s/it]loss:24.843130111694336:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [06:21<11:46, 54.34s/it]loss:24.843130111694336:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [06:21<10:52, 54.38s/it]loss:24.919355392456055:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [07:16<10:52, 54.38s/it]loss:24.919355392456055:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [07:16<09:58, 54.36s/it]loss:24.934972763061523:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [08:10<09:58, 54.36s/it]loss:24.934972763061523:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [08:10<09:02, 54.23s/it]loss:25.068222045898438:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [09:04<09:02, 54.23s/it]loss:25.068222045898438:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [09:04<08:07, 54.16s/it]loss:24.80438232421875:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [09:58<08:07, 54.16s/it] loss:24.80438232421875:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [09:58<07:12, 54.12s/it]loss:24.970462799072266:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [10:51<07:12, 54.12s/it]loss:24.970462799072266:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [10:51<06:17, 53.96s/it]loss:24.838796615600586:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [11:45<06:17, 53.96s/it]loss:24.838796615600586:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [11:45<05:23, 54.00s/it]loss:24.85437774658203:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [12:39<05:23, 54.00s/it] loss:24.85437774658203:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [12:39<04:29, 53.93s/it]loss:24.80105972290039:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [13:33<04:29, 53.93s/it]loss:24.80105972290039:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [13:33<03:35, 53.88s/it]loss:24.956689834594727:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [14:27<03:35, 53.88s/it]loss:24.956689834594727:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [14:27<02:41, 53.88s/it]loss:24.703317642211914:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [15:21<02:41, 53.88s/it]loss:24.703317642211914:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [15:21<01:47, 53.96s/it]loss:25.070709228515625:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [16:15<01:47, 53.96s/it]loss:25.070709228515625:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [16:15<00:53, 53.88s/it]loss:24.947351455688477:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [17:08<00:53, 53.88s/it]loss:24.947351455688477: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [17:08<00:00, 53.74s/it]loss:24.947351455688477: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [17:08<00:00, 54.14s/it]
Epoch: 20 cost time: 1030.5093059539795
Epoch: 20, Steps: 19 | Train Loss: 24.9031608 Vali Loss: 3.8747489 Test Loss: 69.7551422
Validation loss decreased (3.874749 --> 3.874749).  Saving model ...
Updating learning rate to 1.9073486328125e-10
>>>>>>>testing : long_term_forecast_low_0_FiLM_job_demand_r1_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 4
test shape: (4, 1, 3, 32690) (4, 1, 3, 32690)
test shape: (4, 3, 32690) (4, 3, 32690)
mse:43120.43359375, mae:19.16588020324707, dtw:-999
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           0                   Model:              FiLM                

[1mData Loader[0m
  Data:               job_demand_r2       Root Path:          ../../dataset/demand/
  Data Path:          r2.parquet          Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        .cache/checkpoints  

[1mForecasting Task[0m
  Seq Len:            6                   Label Len:          1                   
  Pred Len:           3                   Seasonal Patterns:  Monthly             
  Inverse:            1                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             121420              Dec In:             121420              
  C Out:              121420              d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           2                   d FF:               2048                
  Moving Avg:         25                  Factor:             1                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              learned             Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        32                  Itr:                1                   
  Train Epochs:       20                  Batch Size:         1                   
  Patience:           3                   Learning Rate:      0.0001              
  Des:                test                Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            0                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1                 

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use CPU
>>>>>>>start training : long_term_forecast_low_0_FiLM_job_demand_r2_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 19
val 1
test 4
  0%|          | 0/19 [00:00<?, ?it/s]Killed
