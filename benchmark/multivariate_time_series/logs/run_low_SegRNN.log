True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           0                   Model:              SegRNN              

[1mData Loader[0m
  Data:               job_demand_region   Root Path:          ../../dataset/demand/
  Data Path:          region.parquet      Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        .cache/checkpoints  

[1mForecasting Task[0m
  Seq Len:            6                   Label Len:          1                   
  Pred Len:           3                   Seasonal Patterns:  Monthly             
  Inverse:            1                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             16345               Dec In:             16345               
  C Out:              16345               d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           2                   d FF:               2048                
  Moving Avg:         25                  Factor:             1                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              learned             Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        32                  Itr:                1                   
  Train Epochs:       20                  Batch Size:         1                   
  Patience:           3                   Learning Rate:      0.0001              
  Des:                test                Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            0                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1                 

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use CPU
>>>>>>>start training : long_term_forecast_low_0_SegRNN_job_demand_region_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 19
val 1
test 4
  0%|          | 0/19 [00:00<?, ?it/s]loss:23.821590423583984:   0%|          | 0/19 [00:18<?, ?it/s]loss:23.821590423583984:   5%|â–Œ         | 1/19 [00:18<05:41, 18.99s/it]loss:23.69146156311035:   5%|â–Œ         | 1/19 [00:38<05:41, 18.99s/it] loss:23.69146156311035:  11%|â–ˆ         | 2/19 [00:38<05:25, 19.14s/it]loss:23.751766204833984:  11%|â–ˆ         | 2/19 [00:57<05:25, 19.14s/it]loss:23.751766204833984:  16%|â–ˆâ–Œ        | 3/19 [00:57<05:05, 19.07s/it]loss:23.375110626220703:  16%|â–ˆâ–Œ        | 3/19 [01:16<05:05, 19.07s/it]loss:23.375110626220703:  21%|â–ˆâ–ˆ        | 4/19 [01:16<04:47, 19.17s/it]loss:23.71453857421875:  21%|â–ˆâ–ˆ        | 4/19 [01:36<04:47, 19.17s/it] loss:23.71453857421875:  26%|â–ˆâ–ˆâ–‹       | 5/19 [01:36<04:29, 19.28s/it]loss:23.67985725402832:  26%|â–ˆâ–ˆâ–‹       | 5/19 [01:53<04:29, 19.28s/it]loss:23.67985725402832:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [01:53<04:04, 18.83s/it]loss:23.32722282409668:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [02:12<04:04, 18.83s/it]loss:23.32722282409668:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [02:12<03:43, 18.62s/it]loss:24.350425720214844:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [02:30<03:43, 18.62s/it]loss:24.350425720214844:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [02:30<03:22, 18.45s/it]loss:24.007356643676758:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [02:49<03:22, 18.45s/it]loss:24.007356643676758:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [02:49<03:08, 18.80s/it]loss:23.515727996826172:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [03:07<03:08, 18.80s/it]loss:23.515727996826172:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [03:07<02:46, 18.51s/it]loss:23.600820541381836:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [03:26<02:46, 18.51s/it]loss:23.600820541381836:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [03:26<02:28, 18.58s/it]loss:23.10255241394043:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [03:44<02:28, 18.58s/it] loss:23.10255241394043:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [03:44<02:08, 18.41s/it]loss:23.075912475585938:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [04:02<02:08, 18.41s/it]loss:23.075912475585938:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [04:02<01:49, 18.23s/it]loss:23.013938903808594:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [04:20<01:49, 18.23s/it]loss:23.013938903808594:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [04:20<01:30, 18.18s/it]loss:23.00852394104004:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [04:38<01:30, 18.18s/it] loss:23.00852394104004:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [04:38<01:12, 18.10s/it]loss:23.259536743164062:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [04:56<01:12, 18.10s/it]loss:23.259536743164062:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [04:56<00:54, 18.05s/it]loss:23.292205810546875:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [05:13<00:54, 18.05s/it]loss:23.292205810546875:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [05:13<00:35, 17.77s/it]loss:23.290088653564453:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [05:31<00:35, 17.77s/it]loss:23.290088653564453:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [05:31<00:17, 17.81s/it]loss:23.805782318115234:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [05:49<00:17, 17.81s/it]loss:23.805782318115234: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [05:49<00:00, 17.91s/it]loss:23.805782318115234: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [05:49<00:00, 18.39s/it]
Epoch: 1 cost time: 350.4246554374695
Epoch: 1, Steps: 19 | Train Loss: 23.5097063 Vali Loss: 3.0587039 Test Loss: 36.7391853
Validation loss decreased (inf --> 3.058704).  Saving model ...
Updating learning rate to 0.0001
  0%|          | 0/19 [00:00<?, ?it/s]loss:23.157554626464844:   0%|          | 0/19 [00:19<?, ?it/s]loss:23.157554626464844:   5%|â–Œ         | 1/19 [00:19<05:50, 19.45s/it]loss:23.21921730041504:   5%|â–Œ         | 1/19 [00:38<05:50, 19.45s/it] loss:23.21921730041504:  11%|â–ˆ         | 2/19 [00:38<05:25, 19.14s/it]loss:23.395648956298828:  11%|â–ˆ         | 2/19 [00:57<05:25, 19.14s/it]loss:23.395648956298828:  16%|â–ˆâ–Œ        | 3/19 [00:57<05:04, 19.06s/it]loss:22.907188415527344:  16%|â–ˆâ–Œ        | 3/19 [01:15<05:04, 19.06s/it]loss:22.907188415527344:  21%|â–ˆâ–ˆ        | 4/19 [01:15<04:41, 18.78s/it]loss:23.646142959594727:  21%|â–ˆâ–ˆ        | 4/19 [01:35<04:41, 18.78s/it]loss:23.646142959594727:  26%|â–ˆâ–ˆâ–‹       | 5/19 [01:35<04:25, 18.98s/it]loss:23.218765258789062:  26%|â–ˆâ–ˆâ–‹       | 5/19 [01:53<04:25, 18.98s/it]loss:23.218765258789062:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [01:53<04:04, 18.84s/it]loss:23.23366928100586:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [02:13<04:04, 18.84s/it] loss:23.23366928100586:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [02:13<03:51, 19.32s/it]loss:23.229007720947266:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [02:33<03:51, 19.32s/it]loss:23.229007720947266:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [02:33<03:34, 19.49s/it]loss:22.96785545349121:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [02:51<03:34, 19.49s/it] loss:22.96785545349121:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [02:51<03:10, 19.04s/it]loss:23.23320960998535:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [03:11<03:10, 19.04s/it]loss:23.23320960998535:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [03:11<02:53, 19.25s/it]loss:23.159914016723633:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [03:31<02:53, 19.25s/it]loss:23.159914016723633:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [03:31<02:35, 19.39s/it]loss:23.603069305419922:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [03:49<02:35, 19.39s/it]loss:23.603069305419922:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [03:49<02:14, 19.17s/it]loss:22.90395164489746:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [04:09<02:14, 19.17s/it] loss:22.90395164489746:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [04:09<01:56, 19.34s/it]loss:23.29558563232422:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [04:27<01:56, 19.34s/it]loss:23.29558563232422:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [04:27<01:35, 19.04s/it]loss:23.202486038208008:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [04:45<01:35, 19.04s/it]loss:23.202486038208008:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [04:45<01:14, 18.71s/it]loss:22.997100830078125:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [05:03<01:14, 18.71s/it]loss:22.997100830078125:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [05:03<00:55, 18.49s/it]loss:23.273056030273438:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [05:23<00:55, 18.49s/it]loss:23.273056030273438:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [05:23<00:37, 18.89s/it]loss:23.153135299682617:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [05:41<00:37, 18.89s/it]loss:23.153135299682617:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [05:41<00:18, 18.66s/it]loss:23.068639755249023:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [06:00<00:18, 18.66s/it]loss:23.068639755249023: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [06:00<00:00, 18.78s/it]loss:23.068639755249023: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [06:01<00:00, 19.01s/it]
Epoch: 2 cost time: 363.4020884037018
Epoch: 2, Steps: 19 | Train Loss: 23.2034315 Vali Loss: 3.0173273 Test Loss: 36.4822273
Validation loss decreased (3.058704 --> 3.017327).  Saving model ...
Updating learning rate to 5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:23.255857467651367:   0%|          | 0/19 [00:19<?, ?it/s]loss:23.255857467651367:   5%|â–Œ         | 1/19 [00:19<05:55, 19.76s/it]loss:22.952190399169922:   5%|â–Œ         | 1/19 [00:40<05:55, 19.76s/it]loss:22.952190399169922:  11%|â–ˆ         | 2/19 [00:40<05:46, 20.37s/it]loss:23.227882385253906:  11%|â–ˆ         | 2/19 [00:59<05:46, 20.37s/it]loss:23.227882385253906:  16%|â–ˆâ–Œ        | 3/19 [00:59<05:14, 19.64s/it]loss:23.143882751464844:  16%|â–ˆâ–Œ        | 3/19 [01:18<05:14, 19.64s/it]loss:23.143882751464844:  21%|â–ˆâ–ˆ        | 4/19 [01:18<04:54, 19.64s/it]loss:23.19477081298828:  21%|â–ˆâ–ˆ        | 4/19 [01:39<04:54, 19.64s/it] loss:23.19477081298828:  26%|â–ˆâ–ˆâ–‹       | 5/19 [01:39<04:39, 19.95s/it]loss:23.169416427612305:  26%|â–ˆâ–ˆâ–‹       | 5/19 [01:57<04:39, 19.95s/it]loss:23.169416427612305:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [01:57<04:12, 19.41s/it]loss:23.154516220092773:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [02:16<04:12, 19.41s/it]loss:23.154516220092773:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [02:16<03:50, 19.18s/it]loss:23.296144485473633:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [02:37<03:50, 19.18s/it]loss:23.296144485473633:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [02:37<03:35, 19.62s/it]loss:23.034114837646484:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [02:57<03:35, 19.62s/it]loss:23.034114837646484:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [02:57<03:18, 19.81s/it]loss:23.14638900756836:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [03:17<03:18, 19.81s/it] loss:23.14638900756836:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [03:17<02:59, 19.92s/it]loss:23.307275772094727:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [03:37<02:59, 19.92s/it]loss:23.307275772094727:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [03:37<02:40, 20.01s/it]loss:23.359155654907227:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [03:58<02:40, 20.01s/it]loss:23.359155654907227:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [03:58<02:21, 20.26s/it]loss:23.15667724609375:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [04:18<02:21, 20.26s/it] loss:23.15667724609375:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [04:18<02:00, 20.12s/it]loss:23.575801849365234:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [04:37<02:00, 20.12s/it]loss:23.575801849365234:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [04:37<01:39, 19.91s/it]loss:23.313671112060547:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [04:58<01:39, 19.91s/it]loss:23.313671112060547:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [04:58<01:20, 20.08s/it]loss:23.285282135009766:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [05:17<01:20, 20.08s/it]loss:23.285282135009766:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [05:17<00:59, 19.86s/it]loss:23.05811309814453:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [05:35<00:59, 19.86s/it] loss:23.05811309814453:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [05:35<00:38, 19.32s/it]loss:23.47664451599121:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [05:55<00:38, 19.32s/it]loss:23.47664451599121:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [05:55<00:19, 19.34s/it]loss:23.357818603515625:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [06:15<00:19, 19.34s/it]loss:23.357818603515625: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [06:15<00:00, 19.60s/it]loss:23.357818603515625: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [06:15<00:00, 19.76s/it]
Epoch: 3 cost time: 378.5753936767578
Epoch: 3, Steps: 19 | Train Loss: 23.2350318 Vali Loss: 3.0397782 Test Loss: 36.4761238
EarlyStopping counter: 1 out of 3
Updating learning rate to 2.5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:23.211376190185547:   0%|          | 0/19 [00:16<?, ?it/s]loss:23.211376190185547:   5%|â–Œ         | 1/19 [00:16<05:01, 16.78s/it]loss:23.17650604248047:   5%|â–Œ         | 1/19 [00:36<05:01, 16.78s/it] loss:23.17650604248047:  11%|â–ˆ         | 2/19 [00:36<05:14, 18.48s/it]loss:23.025606155395508:  11%|â–ˆ         | 2/19 [00:55<05:14, 18.48s/it]loss:23.025606155395508:  16%|â–ˆâ–Œ        | 3/19 [00:55<05:03, 18.95s/it]loss:23.16830062866211:  16%|â–ˆâ–Œ        | 3/19 [01:16<05:03, 18.95s/it] loss:23.16830062866211:  21%|â–ˆâ–ˆ        | 4/19 [01:16<04:53, 19.54s/it]loss:23.358888626098633:  21%|â–ˆâ–ˆ        | 4/19 [01:36<04:53, 19.54s/it]loss:23.358888626098633:  26%|â–ˆâ–ˆâ–‹       | 5/19 [01:36<04:35, 19.65s/it]loss:22.969099044799805:  26%|â–ˆâ–ˆâ–‹       | 5/19 [01:54<04:35, 19.65s/it]loss:22.969099044799805:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [01:54<04:10, 19.24s/it]loss:23.596078872680664:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [02:14<04:10, 19.24s/it]loss:23.596078872680664:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [02:14<03:51, 19.32s/it]loss:23.324039459228516:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [02:34<03:51, 19.32s/it]loss:23.324039459228516:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [02:34<03:35, 19.55s/it]loss:23.239402770996094:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [02:53<03:35, 19.55s/it]loss:23.239402770996094:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [02:53<03:15, 19.60s/it]loss:23.346088409423828:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [03:13<03:15, 19.60s/it]loss:23.346088409423828:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [03:13<02:56, 19.63s/it]loss:23.524768829345703:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [03:33<02:56, 19.63s/it]loss:23.524768829345703:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [03:33<02:36, 19.62s/it]loss:23.445220947265625:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [03:52<02:36, 19.62s/it]loss:23.445220947265625:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [03:52<02:17, 19.65s/it]loss:23.271106719970703:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [04:12<02:17, 19.65s/it]loss:23.271106719970703:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [04:12<01:56, 19.47s/it]loss:23.014272689819336:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [04:32<01:56, 19.47s/it]loss:23.014272689819336:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [04:32<01:38, 19.74s/it]loss:22.967790603637695:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [04:52<01:38, 19.74s/it]loss:22.967790603637695:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [04:52<01:19, 19.82s/it]loss:23.348308563232422:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [05:12<01:19, 19.82s/it]loss:23.348308563232422:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [05:12<00:59, 19.91s/it]loss:23.25168228149414:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [05:32<00:59, 19.91s/it] loss:23.25168228149414:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [05:32<00:39, 19.91s/it]loss:23.223228454589844:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [05:52<00:39, 19.91s/it]loss:23.223228454589844:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [05:52<00:19, 19.93s/it]loss:23.02047348022461:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [06:12<00:19, 19.93s/it] loss:23.02047348022461: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [06:12<00:00, 20.07s/it]loss:23.02047348022461: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [06:13<00:00, 19.63s/it]
Epoch: 4 cost time: 376.32591485977173
Epoch: 4, Steps: 19 | Train Loss: 23.2359073 Vali Loss: 3.0552883 Test Loss: 36.4845886
EarlyStopping counter: 2 out of 3
Updating learning rate to 1.25e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:23.221384048461914:   0%|          | 0/19 [00:20<?, ?it/s]loss:23.221384048461914:   5%|â–Œ         | 1/19 [00:20<06:06, 20.34s/it]loss:23.335493087768555:   5%|â–Œ         | 1/19 [00:40<06:06, 20.34s/it]loss:23.335493087768555:  11%|â–ˆ         | 2/19 [00:40<05:42, 20.16s/it]loss:23.426677703857422:  11%|â–ˆ         | 2/19 [01:00<05:42, 20.16s/it]loss:23.426677703857422:  16%|â–ˆâ–Œ        | 3/19 [01:00<05:21, 20.10s/it]loss:23.191631317138672:  16%|â–ˆâ–Œ        | 3/19 [01:19<05:21, 20.10s/it]loss:23.191631317138672:  21%|â–ˆâ–ˆ        | 4/19 [01:19<04:57, 19.83s/it]loss:23.202577590942383:  21%|â–ˆâ–ˆ        | 4/19 [01:39<04:57, 19.83s/it]loss:23.202577590942383:  26%|â–ˆâ–ˆâ–‹       | 5/19 [01:39<04:37, 19.85s/it]loss:23.305313110351562:  26%|â–ˆâ–ˆâ–‹       | 5/19 [01:59<04:37, 19.85s/it]loss:23.305313110351562:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [01:59<04:16, 19.76s/it]loss:22.966602325439453:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [02:19<04:16, 19.76s/it]loss:22.966602325439453:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [02:19<03:57, 19.83s/it]loss:22.984289169311523:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [02:39<03:57, 19.83s/it]loss:22.984289169311523:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [02:39<03:39, 19.97s/it]loss:23.339597702026367:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [02:59<03:39, 19.97s/it]loss:23.339597702026367:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [02:59<03:19, 19.91s/it]loss:23.263822555541992:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [03:18<03:19, 19.91s/it]loss:23.263822555541992:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [03:18<02:58, 19.82s/it]loss:23.243408203125:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [03:38<02:58, 19.82s/it]   loss:23.243408203125:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [03:38<02:38, 19.85s/it]loss:23.589466094970703:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [03:58<02:38, 19.85s/it]loss:23.589466094970703:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [03:58<02:19, 19.90s/it]loss:23.381120681762695:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [04:18<02:19, 19.90s/it]loss:23.381120681762695:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [04:18<01:59, 19.84s/it]loss:23.241931915283203:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [04:37<01:59, 19.84s/it]loss:23.241931915283203:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [04:37<01:38, 19.70s/it]loss:23.006145477294922:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [04:57<01:38, 19.70s/it]loss:23.006145477294922:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [04:57<01:18, 19.69s/it]loss:23.240093231201172:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [05:17<01:18, 19.69s/it]loss:23.240093231201172:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [05:17<00:59, 19.72s/it]loss:23.516462326049805:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [05:37<00:59, 19.72s/it]loss:23.516462326049805:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [05:37<00:39, 19.77s/it]loss:23.001920700073242:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [05:56<00:39, 19.77s/it]loss:23.001920700073242:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [05:56<00:19, 19.71s/it]loss:23.03452491760254:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [06:16<00:19, 19.71s/it] loss:23.03452491760254: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [06:16<00:00, 19.76s/it]loss:23.03452491760254: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [06:16<00:00, 19.84s/it]
Epoch: 5 cost time: 380.0134370326996
Epoch: 5, Steps: 19 | Train Loss: 23.2364454 Vali Loss: 3.0314374 Test Loss: 36.4787254
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : long_term_forecast_low_0_SegRNN_job_demand_region_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 4
test shape: (4, 1, 3, 16345) (4, 1, 3, 16345)
test shape: (4, 3, 16345) (4, 3, 16345)
mse:43585.16015625, mae:34.69598388671875, dtw:-999
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           0                   Model:              SegRNN              

[1mData Loader[0m
  Data:               job_demand_r1       Root Path:          ../../dataset/demand/
  Data Path:          r1.parquet          Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        .cache/checkpoints  

[1mForecasting Task[0m
  Seq Len:            6                   Label Len:          1                   
  Pred Len:           3                   Seasonal Patterns:  Monthly             
  Inverse:            1                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             32690               Dec In:             32690               
  C Out:              32690               d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           2                   d FF:               2048                
  Moving Avg:         25                  Factor:             1                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              learned             Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        32                  Itr:                1                   
  Train Epochs:       20                  Batch Size:         1                   
  Patience:           3                   Learning Rate:      0.0001              
  Des:                test                Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            0                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1                 

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use CPU
>>>>>>>start training : long_term_forecast_low_0_SegRNN_job_demand_r1_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 19
val 1
test 4
  0%|          | 0/19 [00:00<?, ?it/s]loss:25.085525512695312:   0%|          | 0/19 [01:22<?, ?it/s]loss:25.085525512695312:   5%|â–Œ         | 1/19 [01:22<24:52, 82.89s/it]loss:24.75473403930664:   5%|â–Œ         | 1/19 [02:45<24:52, 82.89s/it] loss:24.75473403930664:  11%|â–ˆ         | 2/19 [02:45<23:28, 82.86s/it]loss:24.54873275756836:  11%|â–ˆ         | 2/19 [04:05<23:28, 82.86s/it]loss:24.54873275756836:  16%|â–ˆâ–Œ        | 3/19 [04:05<21:40, 81.27s/it]loss:24.801799774169922:  16%|â–ˆâ–Œ        | 3/19 [05:31<21:40, 81.27s/it]loss:24.801799774169922:  21%|â–ˆâ–ˆ        | 4/19 [05:31<20:51, 83.43s/it]loss:24.600078582763672:  21%|â–ˆâ–ˆ        | 4/19 [06:53<20:51, 83.43s/it]loss:24.600078582763672:  26%|â–ˆâ–ˆâ–‹       | 5/19 [06:53<19:17, 82.71s/it]loss:24.739200592041016:  26%|â–ˆâ–ˆâ–‹       | 5/19 [08:14<19:17, 82.71s/it]loss:24.739200592041016:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [08:14<17:50, 82.33s/it]loss:24.54163360595703:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [09:35<17:50, 82.33s/it] loss:24.54163360595703:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [09:35<16:22, 81.90s/it]loss:24.559398651123047:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [10:55<16:22, 81.90s/it]loss:24.559398651123047:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [10:55<14:54, 81.32s/it]loss:25.13646697998047:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [12:17<14:54, 81.32s/it] loss:25.13646697998047:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [12:17<13:32, 81.27s/it]loss:24.68844985961914:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [13:39<13:32, 81.27s/it]loss:24.68844985961914:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [13:39<12:13, 81.49s/it]loss:24.401533126831055:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [15:00<12:13, 81.49s/it]loss:24.401533126831055:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [15:00<10:50, 81.35s/it]loss:24.643526077270508:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [16:18<10:50, 81.35s/it]loss:24.643526077270508:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [16:18<09:22, 80.40s/it]loss:24.598039627075195:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [17:39<09:22, 80.40s/it]loss:24.598039627075195:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [17:39<08:02, 80.48s/it]loss:24.66358757019043:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [18:56<08:02, 80.48s/it] loss:24.66358757019043:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [18:56<06:38, 79.65s/it]loss:24.57290267944336:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [20:18<06:38, 79.65s/it]loss:24.57290267944336:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [20:18<05:20, 80.24s/it]loss:24.360517501831055:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [21:38<05:20, 80.24s/it]loss:24.360517501831055:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [21:38<04:00, 80.19s/it]loss:24.578636169433594:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [22:59<04:00, 80.19s/it]loss:24.578636169433594:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [22:59<02:40, 80.38s/it]loss:24.695743560791016:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [24:19<02:40, 80.38s/it]loss:24.695743560791016:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [24:19<01:20, 80.32s/it]loss:24.756681442260742:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [25:42<01:20, 80.32s/it]loss:24.756681442260742: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [25:42<00:00, 81.13s/it]loss:24.756681442260742: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [25:42<00:00, 81.19s/it]
Epoch: 1 cost time: 1543.572444677353
Epoch: 1, Steps: 19 | Train Loss: 24.6698520 Vali Loss: 3.8562214 Test Loss: 79.5173264
Validation loss decreased (inf --> 3.856221).  Saving model ...
Updating learning rate to 0.0001
  0%|          | 0/19 [00:00<?, ?it/s]loss:24.587812423706055:   0%|          | 0/19 [01:20<?, ?it/s]loss:24.587812423706055:   5%|â–Œ         | 1/19 [01:20<24:04, 80.23s/it]loss:24.348718643188477:   5%|â–Œ         | 1/19 [02:42<24:04, 80.23s/it]loss:24.348718643188477:  11%|â–ˆ         | 2/19 [02:42<23:05, 81.48s/it]loss:24.442646026611328:  11%|â–ˆ         | 2/19 [04:00<23:05, 81.48s/it]loss:24.442646026611328:  16%|â–ˆâ–Œ        | 3/19 [04:00<21:18, 79.92s/it]loss:24.358863830566406:  16%|â–ˆâ–Œ        | 3/19 [05:20<21:18, 79.92s/it]loss:24.358863830566406:  21%|â–ˆâ–ˆ        | 4/19 [05:20<20:01, 80.07s/it]loss:24.425336837768555:  21%|â–ˆâ–ˆ        | 4/19 [06:45<20:01, 80.07s/it]loss:24.425336837768555:  26%|â–ˆâ–ˆâ–‹       | 5/19 [06:45<19:03, 81.69s/it]loss:24.591182708740234:  26%|â–ˆâ–ˆâ–‹       | 5/19 [08:07<19:03, 81.69s/it]loss:24.591182708740234:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [08:07<17:43, 81.78s/it]loss:24.318740844726562:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [09:27<17:43, 81.78s/it]loss:24.318740844726562:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [09:27<16:15, 81.28s/it]loss:24.580060958862305:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [10:48<16:15, 81.28s/it]loss:24.580060958862305:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [10:48<14:51, 81.06s/it]loss:24.45501136779785:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [12:07<14:51, 81.06s/it] loss:24.45501136779785:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [12:07<13:23, 80.33s/it]loss:24.341045379638672:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [13:29<13:23, 80.33s/it]loss:24.341045379638672:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [13:29<12:08, 80.99s/it]loss:24.34258270263672:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [14:53<12:08, 80.99s/it] loss:24.34258270263672:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [14:53<10:55, 81.93s/it]loss:24.42243194580078:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [16:17<10:55, 81.93s/it]loss:24.42243194580078:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [16:17<09:37, 82.55s/it]loss:24.483905792236328:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [17:41<09:37, 82.55s/it]loss:24.483905792236328:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [17:41<08:18, 83.07s/it]loss:24.448793411254883:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [19:06<08:18, 83.07s/it]loss:24.448793411254883:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [19:06<06:57, 83.58s/it]loss:24.30263328552246:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [20:28<06:57, 83.58s/it] loss:24.30263328552246:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [20:28<05:32, 83.21s/it]loss:24.453672409057617:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [21:48<05:32, 83.21s/it]loss:24.453672409057617:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [21:48<04:06, 82.03s/it]loss:24.241437911987305:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [23:09<04:06, 82.03s/it]loss:24.241437911987305:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [23:09<02:43, 81.74s/it]loss:24.40224838256836:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [24:31<02:43, 81.74s/it] loss:24.40224838256836:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [24:31<01:21, 81.88s/it]loss:24.499156951904297:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [25:58<01:21, 81.88s/it]loss:24.499156951904297: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [25:58<00:00, 83.30s/it]loss:24.499156951904297: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [25:58<00:00, 82.01s/it]
Epoch: 2 cost time: 1559.8097839355469
Epoch: 2, Steps: 19 | Train Loss: 24.4234885 Vali Loss: 3.9031928 Test Loss: 79.3208466
EarlyStopping counter: 1 out of 3
Updating learning rate to 5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:24.449058532714844:   0%|          | 0/19 [01:22<?, ?it/s]loss:24.449058532714844:   5%|â–Œ         | 1/19 [01:22<24:50, 82.83s/it]loss:24.335397720336914:   5%|â–Œ         | 1/19 [02:45<24:50, 82.83s/it]loss:24.335397720336914:  11%|â–ˆ         | 2/19 [02:45<23:28, 82.83s/it]loss:24.49459457397461:  11%|â–ˆ         | 2/19 [04:10<23:28, 82.83s/it] loss:24.49459457397461:  16%|â–ˆâ–Œ        | 3/19 [04:10<22:16, 83.53s/it]loss:24.55002212524414:  16%|â–ˆâ–Œ        | 3/19 [05:30<22:16, 83.53s/it]loss:24.55002212524414:  21%|â–ˆâ–ˆ        | 4/19 [05:30<20:32, 82.14s/it]loss:24.31024932861328:  21%|â–ˆâ–ˆ        | 4/19 [06:51<20:32, 82.14s/it]loss:24.31024932861328:  26%|â–ˆâ–ˆâ–‹       | 5/19 [06:51<19:05, 81.85s/it]loss:24.226896286010742:  26%|â–ˆâ–ˆâ–‹       | 5/19 [08:10<19:05, 81.85s/it]loss:24.226896286010742:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [08:10<17:33, 81.05s/it]loss:24.317092895507812:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [09:34<17:33, 81.05s/it]loss:24.317092895507812:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [09:34<16:22, 81.86s/it]loss:24.32242202758789:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [10:59<16:22, 81.86s/it] loss:24.32242202758789:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [10:59<15:12, 82.97s/it]loss:24.333480834960938:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [12:21<15:12, 82.97s/it]loss:24.333480834960938:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [12:21<13:44, 82.44s/it]loss:24.359121322631836:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [13:44<13:44, 82.44s/it]loss:24.359121322631836:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [13:44<12:23, 82.67s/it]loss:24.315624237060547:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [15:06<12:23, 82.67s/it]loss:24.315624237060547:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [15:06<11:01, 82.65s/it]loss:24.331607818603516:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [16:26<11:01, 82.65s/it]loss:24.331607818603516:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [16:26<09:31, 81.69s/it]loss:24.510393142700195:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [17:46<09:31, 81.69s/it]loss:24.510393142700195:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [17:46<08:06, 81.13s/it]loss:24.41790199279785:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [19:05<08:06, 81.13s/it] loss:24.41790199279785:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [19:05<06:42, 80.54s/it]loss:24.394062042236328:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [20:28<06:42, 80.54s/it]loss:24.394062042236328:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [20:28<05:25, 81.31s/it]loss:24.59125518798828:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [21:47<05:25, 81.31s/it] loss:24.59125518798828:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [21:47<04:01, 80.53s/it]loss:24.510698318481445:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [23:09<04:01, 80.53s/it]loss:24.510698318481445:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [23:09<02:42, 81.00s/it]loss:24.697662353515625:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [24:44<02:42, 81.00s/it]loss:24.697662353515625:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [24:44<01:25, 85.34s/it]loss:24.6127986907959:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [26:10<01:25, 85.34s/it]  loss:24.6127986907959: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [26:10<00:00, 85.47s/it]loss:24.6127986907959: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [26:10<00:00, 82.66s/it]
Epoch: 3 cost time: 1571.9495491981506
Epoch: 3, Steps: 19 | Train Loss: 24.4252810 Vali Loss: 3.8615620 Test Loss: 79.3159332
EarlyStopping counter: 2 out of 3
Updating learning rate to 2.5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:24.56403923034668:   0%|          | 0/19 [01:23<?, ?it/s]loss:24.56403923034668:   5%|â–Œ         | 1/19 [01:23<24:58, 83.24s/it]loss:24.307254791259766:   5%|â–Œ         | 1/19 [03:02<24:58, 83.24s/it]loss:24.307254791259766:  11%|â–ˆ         | 2/19 [03:02<26:12, 92.49s/it]loss:24.34967803955078:  11%|â–ˆ         | 2/19 [04:32<26:12, 92.49s/it] loss:24.34967803955078:  16%|â–ˆâ–Œ        | 3/19 [04:32<24:25, 91.62s/it]loss:24.402381896972656:  16%|â–ˆâ–Œ        | 3/19 [05:58<24:25, 91.62s/it]loss:24.402381896972656:  21%|â–ˆâ–ˆ        | 4/19 [05:58<22:17, 89.20s/it]loss:24.374711990356445:  21%|â–ˆâ–ˆ        | 4/19 [07:20<22:17, 89.20s/it]loss:24.374711990356445:  26%|â–ˆâ–ˆâ–‹       | 5/19 [07:20<20:13, 86.68s/it]loss:24.351634979248047:  26%|â–ˆâ–ˆâ–‹       | 5/19 [08:41<20:13, 86.68s/it]loss:24.351634979248047:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [08:41<18:20, 84.69s/it]loss:24.482086181640625:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [10:03<18:20, 84.69s/it]loss:24.482086181640625:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [10:03<16:48, 84.01s/it]loss:24.489360809326172:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [11:23<16:48, 84.01s/it]loss:24.489360809326172:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [11:23<15:09, 82.70s/it]loss:24.542062759399414:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [12:46<15:09, 82.70s/it]loss:24.542062759399414:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [12:46<13:47, 82.75s/it]loss:24.28937530517578:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [14:10<13:47, 82.75s/it] loss:24.28937530517578:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [14:10<12:27, 83.07s/it]loss:24.37050437927246:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [15:32<12:27, 83.07s/it]loss:24.37050437927246:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [15:32<11:01, 82.63s/it]loss:24.427576065063477:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [16:53<11:01, 82.63s/it]loss:24.427576065063477:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [16:53<09:36, 82.35s/it]loss:24.403350830078125:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [18:14<09:36, 82.35s/it]loss:24.403350830078125:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [18:14<08:10, 81.73s/it]loss:24.469898223876953:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [19:37<08:10, 81.73s/it]loss:24.469898223876953:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [19:37<06:51, 82.32s/it]loss:24.554410934448242:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [20:59<06:51, 82.32s/it]loss:24.554410934448242:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [20:59<05:28, 82.12s/it]loss:24.339576721191406:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [22:20<05:28, 82.12s/it]loss:24.339576721191406:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [22:20<04:05, 81.84s/it]loss:24.399656295776367:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [23:44<04:05, 81.84s/it]loss:24.399656295776367:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [23:44<02:45, 82.57s/it]loss:24.54039764404297:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [25:06<02:45, 82.57s/it] loss:24.54039764404297:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [25:06<01:22, 82.24s/it]loss:24.664854049682617:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [26:26<01:22, 82.24s/it]loss:24.664854049682617: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [26:26<00:00, 81.62s/it]loss:24.664854049682617: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [26:26<00:00, 83.51s/it]
Epoch: 4 cost time: 1588.3462505340576
Epoch: 4, Steps: 19 | Train Loss: 24.4380427 Vali Loss: 3.8311939 Test Loss: 79.3126678
Validation loss decreased (3.856221 --> 3.831194).  Saving model ...
Updating learning rate to 1.25e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:24.550052642822266:   0%|          | 0/19 [01:20<?, ?it/s]loss:24.550052642822266:   5%|â–Œ         | 1/19 [01:20<24:10, 80.60s/it]loss:24.284854888916016:   5%|â–Œ         | 1/19 [02:39<24:10, 80.60s/it]loss:24.284854888916016:  11%|â–ˆ         | 2/19 [02:39<22:35, 79.75s/it]loss:24.36797523498535:  11%|â–ˆ         | 2/19 [03:58<22:35, 79.75s/it] loss:24.36797523498535:  16%|â–ˆâ–Œ        | 3/19 [03:58<21:06, 79.16s/it]loss:24.40328598022461:  16%|â–ˆâ–Œ        | 3/19 [05:24<21:06, 79.16s/it]loss:24.40328598022461:  21%|â–ˆâ–ˆ        | 4/19 [05:24<20:26, 81.80s/it]loss:24.412960052490234:  21%|â–ˆâ–ˆ        | 4/19 [06:43<20:26, 81.80s/it]loss:24.412960052490234:  26%|â–ˆâ–ˆâ–‹       | 5/19 [06:43<18:55, 81.12s/it]loss:24.4993953704834:  26%|â–ˆâ–ˆâ–‹       | 5/19 [08:04<18:55, 81.12s/it]  loss:24.4993953704834:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [08:04<17:33, 81.01s/it]loss:24.55193519592285:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [09:24<17:33, 81.01s/it]loss:24.55193519592285:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [09:24<16:07, 80.63s/it]loss:24.539371490478516:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [10:44<16:07, 80.63s/it]loss:24.539371490478516:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [10:44<14:45, 80.47s/it]loss:24.602224349975586:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [12:11<14:45, 80.47s/it]loss:24.602224349975586:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [12:11<13:44, 82.42s/it]loss:24.47250747680664:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [13:32<13:44, 82.42s/it] loss:24.47250747680664:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [13:32<12:18, 82.09s/it]loss:24.37423324584961:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [14:52<12:18, 82.09s/it]loss:24.37423324584961:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [14:52<10:51, 81.40s/it]loss:24.481382369995117:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [16:15<10:51, 81.40s/it]loss:24.481382369995117:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [16:15<09:32, 81.72s/it]loss:24.344850540161133:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [17:36<09:32, 81.72s/it]loss:24.344850540161133:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [17:36<08:10, 81.78s/it]loss:24.3319034576416:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [19:01<08:10, 81.78s/it]  loss:24.3319034576416:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [19:01<06:53, 82.71s/it]loss:24.435178756713867:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [20:23<06:53, 82.71s/it]loss:24.435178756713867:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [20:23<05:29, 82.39s/it]loss:24.337461471557617:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [21:43<05:29, 82.39s/it]loss:24.337461471557617:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [21:43<04:04, 81.61s/it]loss:24.671621322631836:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [23:03<04:04, 81.61s/it]loss:24.671621322631836:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [23:03<02:42, 81.21s/it]loss:24.349180221557617:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [24:22<02:42, 81.21s/it]loss:24.349180221557617:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [24:22<01:20, 80.65s/it]loss:24.417959213256836:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [25:43<01:20, 80.65s/it]loss:24.417959213256836: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [25:43<00:00, 80.49s/it]loss:24.417959213256836: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [25:43<00:00, 81.22s/it]
Epoch: 5 cost time: 1544.710648059845
Epoch: 5, Steps: 19 | Train Loss: 24.4435965 Vali Loss: 3.8342841 Test Loss: 79.3093491
EarlyStopping counter: 1 out of 3
Updating learning rate to 6.25e-06
  0%|          | 0/19 [00:00<?, ?it/s]loss:24.36397933959961:   0%|          | 0/19 [01:20<?, ?it/s]loss:24.36397933959961:   5%|â–Œ         | 1/19 [01:20<24:12, 80.67s/it]loss:24.351348876953125:   5%|â–Œ         | 1/19 [02:42<24:12, 80.67s/it]loss:24.351348876953125:  11%|â–ˆ         | 2/19 [02:42<23:06, 81.57s/it]loss:24.560651779174805:  11%|â–ˆ         | 2/19 [04:04<23:06, 81.57s/it]loss:24.560651779174805:  16%|â–ˆâ–Œ        | 3/19 [04:04<21:48, 81.79s/it]loss:24.510454177856445:  16%|â–ˆâ–Œ        | 3/19 [05:25<21:48, 81.79s/it]loss:24.510454177856445:  21%|â–ˆâ–ˆ        | 4/19 [05:25<20:18, 81.25s/it]loss:24.562274932861328:  21%|â–ˆâ–ˆ        | 4/19 [06:47<20:18, 81.25s/it]loss:24.562274932861328:  26%|â–ˆâ–ˆâ–‹       | 5/19 [06:47<19:02, 81.57s/it]loss:24.418315887451172:  26%|â–ˆâ–ˆâ–‹       | 5/19 [08:07<19:02, 81.57s/it]loss:24.418315887451172:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [08:07<17:32, 81.00s/it]loss:24.617841720581055:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [09:29<17:32, 81.00s/it]loss:24.617841720581055:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [09:29<16:16, 81.40s/it]loss:24.337825775146484:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [10:51<16:16, 81.40s/it]loss:24.337825775146484:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [10:51<14:56, 81.52s/it]loss:24.331188201904297:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [12:14<14:56, 81.52s/it]loss:24.331188201904297:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [12:14<13:40, 82.07s/it]loss:24.414613723754883:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [13:37<13:40, 82.07s/it]loss:24.414613723754883:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [13:37<12:21, 82.35s/it]loss:24.673925399780273:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [14:59<12:21, 82.35s/it]loss:24.673925399780273:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [14:59<10:57, 82.16s/it]loss:24.546035766601562:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [16:21<10:57, 82.16s/it]loss:24.546035766601562:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [16:21<09:35, 82.17s/it]loss:24.342456817626953:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [17:43<09:35, 82.17s/it]loss:24.342456817626953:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [17:43<08:11, 81.96s/it]loss:24.28963279724121:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [19:04<08:11, 81.96s/it] loss:24.28963279724121:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [19:04<06:49, 81.95s/it]loss:24.481508255004883:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [20:26<06:49, 81.95s/it]loss:24.481508255004883:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [20:26<05:27, 81.85s/it]loss:24.368452072143555:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [21:48<05:27, 81.85s/it]loss:24.368452072143555:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [21:48<04:05, 81.75s/it]loss:24.4398250579834:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [23:09<04:05, 81.75s/it]  loss:24.4398250579834:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [23:09<02:43, 81.65s/it]loss:24.480323791503906:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [24:30<02:43, 81.65s/it]loss:24.480323791503906:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [24:30<01:21, 81.52s/it]loss:24.421857833862305:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [25:50<01:21, 81.52s/it]loss:24.421857833862305: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [25:50<00:00, 81.00s/it]loss:24.421857833862305: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [25:50<00:00, 81.61s/it]
Epoch: 6 cost time: 1552.1062455177307
Epoch: 6, Steps: 19 | Train Loss: 24.4480270 Vali Loss: 3.8355031 Test Loss: 79.3075714
EarlyStopping counter: 2 out of 3
Updating learning rate to 3.125e-06
  0%|          | 0/19 [00:00<?, ?it/s]loss:24.416528701782227:   0%|          | 0/19 [01:20<?, ?it/s]loss:24.416528701782227:   5%|â–Œ         | 1/19 [01:20<24:13, 80.73s/it]loss:24.340167999267578:   5%|â–Œ         | 1/19 [02:40<24:13, 80.73s/it]loss:24.340167999267578:  11%|â–ˆ         | 2/19 [02:40<22:38, 79.91s/it]loss:24.34192657470703:  11%|â–ˆ         | 2/19 [03:59<22:38, 79.91s/it] loss:24.34192657470703:  16%|â–ˆâ–Œ        | 3/19 [03:59<21:17, 79.85s/it]loss:24.56403160095215:  16%|â–ˆâ–Œ        | 3/19 [05:19<21:17, 79.85s/it]loss:24.56403160095215:  21%|â–ˆâ–ˆ        | 4/19 [05:19<19:58, 79.91s/it]loss:24.369272232055664:  21%|â–ˆâ–ˆ        | 4/19 [06:40<19:58, 79.91s/it]loss:24.369272232055664:  26%|â–ˆâ–ˆâ–‹       | 5/19 [06:40<18:44, 80.35s/it]loss:24.61996078491211:  26%|â–ˆâ–ˆâ–‹       | 5/19 [08:02<18:44, 80.35s/it] loss:24.61996078491211:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [08:02<17:29, 80.72s/it]loss:24.287677764892578:  32%|â–ˆâ–ˆâ–ˆâ–      | 6/19 [09:22<17:29, 80.72s/it]loss:24.287677764892578:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [09:22<16:06, 80.58s/it]loss:24.515277862548828:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 7/19 [10:43<16:06, 80.58s/it]loss:24.515277862548828:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [10:43<14:45, 80.50s/it]loss:24.48259735107422:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/19 [12:03<14:45, 80.50s/it] loss:24.48259735107422:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [12:03<13:24, 80.41s/it]loss:24.56925392150879:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 9/19 [13:24<13:24, 80.41s/it]loss:24.56925392150879:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [13:24<12:06, 80.69s/it]loss:24.334972381591797:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 10/19 [14:44<12:06, 80.69s/it]loss:24.334972381591797:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [14:44<10:43, 80.42s/it]loss:24.550100326538086:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 11/19 [16:04<10:43, 80.42s/it]loss:24.550100326538086:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [16:04<09:21, 80.23s/it]loss:24.35359001159668:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 12/19 [17:26<09:21, 80.23s/it] loss:24.35359001159668:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [17:26<08:04, 80.72s/it]loss:24.36615753173828:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 13/19 [18:49<08:04, 80.72s/it]loss:24.36615753173828:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [18:49<06:47, 81.50s/it]loss:24.67908477783203:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 14/19 [20:12<06:47, 81.50s/it]loss:24.67908477783203:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [20:12<05:28, 82.11s/it]loss:24.421707153320312:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 15/19 [21:32<05:28, 82.11s/it]loss:24.421707153320312:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [21:32<04:04, 81.39s/it]loss:24.442129135131836:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 16/19 [22:53<04:04, 81.39s/it]loss:24.442129135131836:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [22:53<02:42, 81.29s/it]loss:24.421546936035156:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 17/19 [24:14<02:42, 81.29s/it]loss:24.421546936035156:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [24:14<01:21, 81.30s/it]loss:24.483610153198242:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 18/19 [25:35<01:21, 81.30s/it]loss:24.483610153198242: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [25:35<00:00, 81.21s/it]loss:24.483610153198242: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [25:36<00:00, 80.85s/it]
Epoch: 7 cost time: 1537.7331268787384
Epoch: 7, Steps: 19 | Train Loss: 24.4505049 Vali Loss: 3.8354292 Test Loss: 79.3067245
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : long_term_forecast_low_0_SegRNN_job_demand_r1_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 4
test shape: (4, 1, 3, 32690) (4, 1, 3, 32690)
test shape: (4, 3, 32690) (4, 3, 32690)
mse:52451.88671875, mae:19.456722259521484, dtw:-999
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           0                   Model:              SegRNN              

[1mData Loader[0m
  Data:               job_demand_r2       Root Path:          ../../dataset/demand/
  Data Path:          r2.parquet          Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        .cache/checkpoints  

[1mForecasting Task[0m
  Seq Len:            6                   Label Len:          1                   
  Pred Len:           3                   Seasonal Patterns:  Monthly             
  Inverse:            1                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             121420              Dec In:             121420              
  C Out:              121420              d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           2                   d FF:               2048                
  Moving Avg:         25                  Factor:             1                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              learned             Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        32                  Itr:                1                   
  Train Epochs:       20                  Batch Size:         1                   
  Patience:           3                   Learning Rate:      0.0001              
  Des:                test                Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            0                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1                 

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use CPU
>>>>>>>start training : long_term_forecast_low_0_SegRNN_job_demand_r2_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 19
val 1
test 4
  0%|          | 0/19 [00:00<?, ?it/s]Killed
