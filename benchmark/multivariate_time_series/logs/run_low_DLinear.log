True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           0                   Model:              DLinear             

[1mData Loader[0m
  Data:               job_demand_region   Root Path:          ../../dataset/demand/
  Data Path:          region.parquet      Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        .cache/checkpoints  

[1mForecasting Task[0m
  Seq Len:            6                   Label Len:          1                   
  Pred Len:           3                   Seasonal Patterns:  Monthly             
  Inverse:            1                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             16345               Dec In:             16345               
  C Out:              16345               d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           2                   d FF:               2048                
  Moving Avg:         25                  Factor:             1                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              learned             Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        32                  Itr:                1                   
  Train Epochs:       20                  Batch Size:         1                   
  Patience:           3                   Learning Rate:      0.0001              
  Des:                test                Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            0                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1                 

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use CPU
>>>>>>>start training : long_term_forecast_low_0_DLinear_job_demand_region_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 19
val 1
test 4
  0%|          | 0/19 [00:00<?, ?it/s]loss:23.190120697021484:   0%|          | 0/19 [00:18<?, ?it/s]loss:23.190120697021484:   5%|▌         | 1/19 [00:18<05:33, 18.51s/it]loss:23.38861083984375:   5%|▌         | 1/19 [00:36<05:33, 18.51s/it] loss:23.38861083984375:  11%|█         | 2/19 [00:36<05:10, 18.29s/it]loss:23.564298629760742:  11%|█         | 2/19 [00:54<05:10, 18.29s/it]loss:23.564298629760742:  16%|█▌        | 3/19 [00:54<04:50, 18.13s/it]loss:23.198856353759766:  16%|█▌        | 3/19 [01:12<04:50, 18.13s/it]loss:23.198856353759766:  21%|██        | 4/19 [01:12<04:32, 18.17s/it]loss:23.144092559814453:  21%|██        | 4/19 [01:31<04:32, 18.17s/it]loss:23.144092559814453:  26%|██▋       | 5/19 [01:31<04:16, 18.32s/it]loss:23.126449584960938:  26%|██▋       | 5/19 [01:50<04:16, 18.32s/it]loss:23.126449584960938:  32%|███▏      | 6/19 [01:50<04:01, 18.57s/it]loss:23.54275131225586:  32%|███▏      | 6/19 [02:09<04:01, 18.57s/it] loss:23.54275131225586:  37%|███▋      | 7/19 [02:09<03:43, 18.60s/it]loss:23.11471939086914:  37%|███▋      | 7/19 [02:27<03:43, 18.60s/it]loss:23.11471939086914:  42%|████▏     | 8/19 [02:27<03:24, 18.58s/it]loss:22.914337158203125:  42%|████▏     | 8/19 [02:46<03:24, 18.58s/it]loss:22.914337158203125:  47%|████▋     | 9/19 [02:46<03:05, 18.58s/it]loss:23.391740798950195:  47%|████▋     | 9/19 [03:05<03:05, 18.58s/it]loss:23.391740798950195:  53%|█████▎    | 10/19 [03:05<02:49, 18.87s/it]loss:23.04037094116211:  53%|█████▎    | 10/19 [03:23<02:49, 18.87s/it] loss:23.04037094116211:  58%|█████▊    | 11/19 [03:23<02:28, 18.53s/it]loss:23.297710418701172:  58%|█████▊    | 11/19 [03:41<02:28, 18.53s/it]loss:23.297710418701172:  63%|██████▎   | 12/19 [03:41<02:09, 18.50s/it]loss:22.990543365478516:  63%|██████▎   | 12/19 [04:00<02:09, 18.50s/it]loss:22.990543365478516:  68%|██████▊   | 13/19 [04:00<01:50, 18.42s/it]loss:23.20827293395996:  68%|██████▊   | 13/19 [04:19<01:50, 18.42s/it] loss:23.20827293395996:  74%|███████▎  | 14/19 [04:19<01:33, 18.65s/it]loss:23.196033477783203:  74%|███████▎  | 14/19 [04:38<01:33, 18.65s/it]loss:23.196033477783203:  79%|███████▉  | 15/19 [04:38<01:14, 18.72s/it]loss:23.384368896484375:  79%|███████▉  | 15/19 [04:57<01:14, 18.72s/it]loss:23.384368896484375:  84%|████████▍ | 16/19 [04:57<00:56, 18.75s/it]loss:22.980396270751953:  84%|████████▍ | 16/19 [05:15<00:56, 18.75s/it]loss:22.980396270751953:  89%|████████▉ | 17/19 [05:15<00:37, 18.78s/it]loss:23.76693344116211:  89%|████████▉ | 17/19 [05:34<00:37, 18.78s/it] loss:23.76693344116211:  95%|█████████▍| 18/19 [05:34<00:18, 18.74s/it]loss:23.36455726623535:  95%|█████████▍| 18/19 [05:52<00:18, 18.74s/it]loss:23.36455726623535: 100%|██████████| 19/19 [05:52<00:00, 18.58s/it]loss:23.36455726623535: 100%|██████████| 19/19 [05:52<00:00, 18.57s/it]
Epoch: 1 cost time: 353.50101613998413
Epoch: 1, Steps: 19 | Train Loss: 23.2529034 Vali Loss: 3.2129569 Test Loss: 42.3905602
Validation loss decreased (inf --> 3.212957).  Saving model ...
Updating learning rate to 0.0001
  0%|          | 0/19 [00:00<?, ?it/s]loss:23.457996368408203:   0%|          | 0/19 [00:17<?, ?it/s]loss:23.457996368408203:   5%|▌         | 1/19 [00:17<05:19, 17.76s/it]loss:23.020870208740234:   5%|▌         | 1/19 [00:35<05:19, 17.76s/it]loss:23.020870208740234:  11%|█         | 2/19 [00:35<05:05, 17.95s/it]loss:23.209579467773438:  11%|█         | 2/19 [00:54<05:05, 17.95s/it]loss:23.209579467773438:  16%|█▌        | 3/19 [00:54<04:49, 18.09s/it]loss:23.272945404052734:  16%|█▌        | 3/19 [01:11<04:49, 18.09s/it]loss:23.272945404052734:  21%|██        | 4/19 [01:11<04:30, 18.01s/it]loss:23.230587005615234:  21%|██        | 4/19 [01:30<04:30, 18.01s/it]loss:23.230587005615234:  26%|██▋       | 5/19 [01:30<04:13, 18.14s/it]loss:23.177120208740234:  26%|██▋       | 5/19 [01:48<04:13, 18.14s/it]loss:23.177120208740234:  32%|███▏      | 6/19 [01:48<03:53, 17.98s/it]loss:23.35182762145996:  32%|███▏      | 6/19 [02:05<03:53, 17.98s/it] loss:23.35182762145996:  37%|███▋      | 7/19 [02:05<03:35, 17.94s/it]loss:23.206832885742188:  37%|███▋      | 7/19 [02:23<03:35, 17.94s/it]loss:23.206832885742188:  42%|████▏     | 8/19 [02:23<03:17, 17.92s/it]loss:22.986852645874023:  42%|████▏     | 8/19 [02:42<03:17, 17.92s/it]loss:22.986852645874023:  47%|████▋     | 9/19 [02:42<03:00, 18.05s/it]loss:23.463134765625:  47%|████▋     | 9/19 [03:00<03:00, 18.05s/it]   loss:23.463134765625:  53%|█████▎    | 10/19 [03:00<02:42, 18.01s/it]loss:23.029529571533203:  53%|█████▎    | 10/19 [03:19<02:42, 18.01s/it]loss:23.029529571533203:  58%|█████▊    | 11/19 [03:19<02:26, 18.31s/it]loss:23.30646514892578:  58%|█████▊    | 11/19 [03:36<02:26, 18.31s/it] loss:23.30646514892578:  63%|██████▎   | 12/19 [03:36<02:07, 18.20s/it]loss:23.413618087768555:  63%|██████▎   | 12/19 [03:55<02:07, 18.20s/it]loss:23.413618087768555:  68%|██████▊   | 13/19 [03:55<01:50, 18.36s/it]loss:23.631452560424805:  68%|██████▊   | 13/19 [04:14<01:50, 18.36s/it]loss:23.631452560424805:  74%|███████▎  | 14/19 [04:14<01:32, 18.49s/it]loss:23.82666778564453:  74%|███████▎  | 14/19 [04:32<01:32, 18.49s/it] loss:23.82666778564453:  79%|███████▉  | 15/19 [04:32<01:12, 18.25s/it]loss:23.132478713989258:  79%|███████▉  | 15/19 [04:50<01:12, 18.25s/it]loss:23.132478713989258:  84%|████████▍ | 16/19 [04:50<00:54, 18.22s/it]loss:23.46131134033203:  84%|████████▍ | 16/19 [05:08<00:54, 18.22s/it] loss:23.46131134033203:  89%|████████▉ | 17/19 [05:08<00:36, 18.14s/it]loss:23.29676055908203:  89%|████████▉ | 17/19 [05:25<00:36, 18.14s/it]loss:23.29676055908203:  95%|█████████▍| 18/19 [05:25<00:17, 17.92s/it]loss:23.69952964782715:  95%|█████████▍| 18/19 [05:43<00:17, 17.92s/it]loss:23.69952964782715: 100%|██████████| 19/19 [05:43<00:00, 18.03s/it]loss:23.69952964782715: 100%|██████████| 19/19 [05:44<00:00, 18.11s/it]
Epoch: 2 cost time: 344.5898606777191
Epoch: 2, Steps: 19 | Train Loss: 23.3250295 Vali Loss: 3.2097430 Test Loss: 42.4435501
Validation loss decreased (3.212957 --> 3.209743).  Saving model ...
Updating learning rate to 5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:23.063932418823242:   0%|          | 0/19 [00:18<?, ?it/s]loss:23.063932418823242:   5%|▌         | 1/19 [00:18<05:28, 18.24s/it]loss:23.277721405029297:   5%|▌         | 1/19 [00:35<05:28, 18.24s/it]loss:23.277721405029297:  11%|█         | 2/19 [00:35<05:01, 17.74s/it]loss:23.535186767578125:  11%|█         | 2/19 [00:53<05:01, 17.74s/it]loss:23.535186767578125:  16%|█▌        | 3/19 [00:53<04:46, 17.93s/it]loss:23.657520294189453:  16%|█▌        | 3/19 [01:11<04:46, 17.93s/it]loss:23.657520294189453:  21%|██        | 4/19 [01:11<04:26, 17.75s/it]loss:23.2611083984375:  21%|██        | 4/19 [01:29<04:26, 17.75s/it]  loss:23.2611083984375:  26%|██▋       | 5/19 [01:29<04:09, 17.84s/it]loss:23.03903579711914:  26%|██▋       | 5/19 [01:47<04:09, 17.84s/it]loss:23.03903579711914:  32%|███▏      | 6/19 [01:47<03:51, 17.82s/it]loss:23.240060806274414:  32%|███▏      | 6/19 [02:05<03:51, 17.82s/it]loss:23.240060806274414:  37%|███▋      | 7/19 [02:05<03:37, 18.10s/it]loss:23.349246978759766:  37%|███▋      | 7/19 [02:23<03:37, 18.10s/it]loss:23.349246978759766:  42%|████▏     | 8/19 [02:23<03:19, 18.11s/it]loss:23.32032012939453:  42%|████▏     | 8/19 [02:43<03:19, 18.11s/it] loss:23.32032012939453:  47%|████▋     | 9/19 [02:43<03:05, 18.58s/it]loss:23.165815353393555:  47%|████▋     | 9/19 [03:00<03:05, 18.58s/it]loss:23.165815353393555:  53%|█████▎    | 10/19 [03:00<02:44, 18.24s/it]loss:23.357666015625:  53%|█████▎    | 10/19 [03:18<02:44, 18.24s/it]   loss:23.357666015625:  58%|█████▊    | 11/19 [03:18<02:24, 18.08s/it]loss:23.423917770385742:  58%|█████▊    | 11/19 [03:37<02:24, 18.08s/it]loss:23.423917770385742:  63%|██████▎   | 12/19 [03:37<02:07, 18.22s/it]loss:23.868322372436523:  63%|██████▎   | 12/19 [03:55<02:07, 18.22s/it]loss:23.868322372436523:  68%|██████▊   | 13/19 [03:55<01:48, 18.14s/it]loss:23.4984130859375:  68%|██████▊   | 13/19 [04:12<01:48, 18.14s/it]  loss:23.4984130859375:  74%|███████▎  | 14/19 [04:12<01:30, 18.01s/it]loss:23.116592407226562:  74%|███████▎  | 14/19 [04:30<01:30, 18.01s/it]loss:23.116592407226562:  79%|███████▉  | 15/19 [04:30<01:11, 17.85s/it]loss:23.317129135131836:  79%|███████▉  | 15/19 [04:48<01:11, 17.85s/it]loss:23.317129135131836:  84%|████████▍ | 16/19 [04:48<00:53, 17.86s/it]loss:23.734878540039062:  84%|████████▍ | 16/19 [05:06<00:53, 17.86s/it]loss:23.734878540039062:  89%|████████▉ | 17/19 [05:06<00:36, 18.01s/it]loss:23.47296905517578:  89%|████████▉ | 17/19 [05:25<00:36, 18.01s/it] loss:23.47296905517578:  95%|█████████▍| 18/19 [05:25<00:18, 18.15s/it]loss:23.53571891784668:  95%|█████████▍| 18/19 [05:44<00:18, 18.15s/it]loss:23.53571891784668: 100%|██████████| 19/19 [05:44<00:00, 18.48s/it]loss:23.53571891784668: 100%|██████████| 19/19 [05:44<00:00, 18.12s/it]
Epoch: 3 cost time: 344.9533874988556
Epoch: 3, Steps: 19 | Train Loss: 23.3808187 Vali Loss: 3.2081721 Test Loss: 42.4679642
Validation loss decreased (3.209743 --> 3.208172).  Saving model ...
Updating learning rate to 2.5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:23.740806579589844:   0%|          | 0/19 [00:19<?, ?it/s]loss:23.740806579589844:   5%|▌         | 1/19 [00:19<05:50, 19.49s/it]loss:23.4779109954834:   5%|▌         | 1/19 [00:38<05:50, 19.49s/it]  loss:23.4779109954834:  11%|█         | 2/19 [00:38<05:23, 19.02s/it]loss:23.539628982543945:  11%|█         | 2/19 [00:57<05:23, 19.02s/it]loss:23.539628982543945:  16%|█▌        | 3/19 [00:57<05:06, 19.13s/it]loss:23.129426956176758:  16%|█▌        | 3/19 [01:16<05:06, 19.13s/it]loss:23.129426956176758:  21%|██        | 4/19 [01:16<04:44, 19.00s/it]loss:23.07021713256836:  21%|██        | 4/19 [01:35<04:44, 19.00s/it] loss:23.07021713256836:  26%|██▋       | 5/19 [01:35<04:28, 19.19s/it]loss:23.330116271972656:  26%|██▋       | 5/19 [01:54<04:28, 19.19s/it]loss:23.330116271972656:  32%|███▏      | 6/19 [01:54<04:08, 19.14s/it]loss:23.106338500976562:  32%|███▏      | 6/19 [02:13<04:08, 19.14s/it]loss:23.106338500976562:  37%|███▋      | 7/19 [02:13<03:48, 19.01s/it]loss:23.888574600219727:  37%|███▋      | 7/19 [02:34<03:48, 19.01s/it]loss:23.888574600219727:  42%|████▏     | 8/19 [02:34<03:35, 19.59s/it]loss:23.518247604370117:  42%|████▏     | 8/19 [02:53<03:35, 19.59s/it]loss:23.518247604370117:  47%|████▋     | 9/19 [02:53<03:15, 19.56s/it]loss:23.2728328704834:  47%|████▋     | 9/19 [03:13<03:15, 19.56s/it]  loss:23.2728328704834:  53%|█████▎    | 10/19 [03:13<02:55, 19.50s/it]loss:23.382863998413086:  53%|█████▎    | 10/19 [03:31<02:55, 19.50s/it]loss:23.382863998413086:  58%|█████▊    | 11/19 [03:31<02:32, 19.06s/it]loss:23.324214935302734:  58%|█████▊    | 11/19 [03:50<02:32, 19.06s/it]loss:23.324214935302734:  63%|██████▎   | 12/19 [03:50<02:13, 19.02s/it]loss:23.3021240234375:  63%|██████▎   | 12/19 [04:09<02:13, 19.02s/it]  loss:23.3021240234375:  68%|██████▊   | 13/19 [04:09<01:53, 18.98s/it]loss:23.581104278564453:  68%|██████▊   | 13/19 [04:28<01:53, 18.98s/it]loss:23.581104278564453:  74%|███████▎  | 14/19 [04:28<01:35, 19.05s/it]loss:23.697614669799805:  74%|███████▎  | 14/19 [04:47<01:35, 19.05s/it]loss:23.697614669799805:  79%|███████▉  | 15/19 [04:47<01:16, 19.06s/it]loss:23.200225830078125:  79%|███████▉  | 15/19 [05:06<01:16, 19.06s/it]loss:23.200225830078125:  84%|████████▍ | 16/19 [05:06<00:57, 19.16s/it]loss:23.357501983642578:  84%|████████▍ | 16/19 [05:25<00:57, 19.16s/it]loss:23.357501983642578:  89%|████████▉ | 17/19 [05:25<00:37, 18.97s/it]loss:23.456647872924805:  89%|████████▉ | 17/19 [05:44<00:37, 18.97s/it]loss:23.456647872924805:  95%|█████████▍| 18/19 [05:44<00:19, 19.02s/it]loss:23.393592834472656:  95%|█████████▍| 18/19 [06:03<00:19, 19.02s/it]loss:23.393592834472656: 100%|██████████| 19/19 [06:03<00:00, 18.91s/it]loss:23.393592834472656: 100%|██████████| 19/19 [06:03<00:00, 19.11s/it]
Epoch: 4 cost time: 363.78455328941345
Epoch: 4, Steps: 19 | Train Loss: 23.4089469 Vali Loss: 3.2074625 Test Loss: 42.4851761
Validation loss decreased (3.208172 --> 3.207463).  Saving model ...
Updating learning rate to 1.25e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:23.49525260925293:   0%|          | 0/19 [00:18<?, ?it/s]loss:23.49525260925293:   5%|▌         | 1/19 [00:18<05:34, 18.57s/it]loss:23.360881805419922:   5%|▌         | 1/19 [00:37<05:34, 18.57s/it]loss:23.360881805419922:  11%|█         | 2/19 [00:37<05:14, 18.50s/it]loss:23.14584732055664:  11%|█         | 2/19 [00:56<05:14, 18.50s/it] loss:23.14584732055664:  16%|█▌        | 3/19 [00:56<05:04, 19.04s/it]loss:23.393177032470703:  16%|█▌        | 3/19 [01:15<05:04, 19.04s/it]loss:23.393177032470703:  21%|██        | 4/19 [01:15<04:44, 18.97s/it]loss:23.310821533203125:  21%|██        | 4/19 [01:34<04:44, 18.97s/it]loss:23.310821533203125:  26%|██▋       | 5/19 [01:34<04:25, 18.98s/it]loss:23.76167869567871:  26%|██▋       | 5/19 [01:52<04:25, 18.98s/it] loss:23.76167869567871:  32%|███▏      | 6/19 [01:52<04:03, 18.70s/it]loss:23.558597564697266:  32%|███▏      | 6/19 [02:11<04:03, 18.70s/it]loss:23.558597564697266:  37%|███▋      | 7/19 [02:11<03:44, 18.69s/it]loss:23.28537368774414:  37%|███▋      | 7/19 [02:30<03:44, 18.69s/it] loss:23.28537368774414:  42%|████▏     | 8/19 [02:30<03:26, 18.78s/it]loss:23.207921981811523:  42%|████▏     | 8/19 [02:49<03:26, 18.78s/it]loss:23.207921981811523:  47%|████▋     | 9/19 [02:49<03:07, 18.80s/it]loss:23.39892578125:  47%|████▋     | 9/19 [03:07<03:07, 18.80s/it]    loss:23.39892578125:  53%|█████▎    | 10/19 [03:07<02:48, 18.78s/it]loss:23.904632568359375:  53%|█████▎    | 10/19 [03:26<02:48, 18.78s/it]loss:23.904632568359375:  58%|█████▊    | 11/19 [03:26<02:29, 18.66s/it]loss:23.592235565185547:  58%|█████▊    | 11/19 [03:44<02:29, 18.66s/it]loss:23.592235565185547:  63%|██████▎   | 12/19 [03:44<02:10, 18.66s/it]loss:23.70712661743164:  63%|██████▎   | 12/19 [04:03<02:10, 18.66s/it] loss:23.70712661743164:  68%|██████▊   | 13/19 [04:03<01:52, 18.73s/it]loss:23.35000991821289:  68%|██████▊   | 13/19 [04:21<01:52, 18.73s/it]loss:23.35000991821289:  74%|███████▎  | 14/19 [04:21<01:32, 18.51s/it]loss:23.338993072509766:  74%|███████▎  | 14/19 [04:40<01:32, 18.51s/it]loss:23.338993072509766:  79%|███████▉  | 15/19 [04:40<01:13, 18.46s/it]loss:23.46598243713379:  79%|███████▉  | 15/19 [04:58<01:13, 18.46s/it] loss:23.46598243713379:  84%|████████▍ | 16/19 [04:58<00:55, 18.55s/it]loss:23.126535415649414:  84%|████████▍ | 16/19 [05:17<00:55, 18.55s/it]loss:23.126535415649414:  89%|████████▉ | 17/19 [05:17<00:37, 18.65s/it]loss:23.093141555786133:  89%|████████▉ | 17/19 [05:36<00:37, 18.65s/it]loss:23.093141555786133:  95%|█████████▍| 18/19 [05:36<00:18, 18.77s/it]loss:23.537782669067383:  95%|█████████▍| 18/19 [05:55<00:18, 18.77s/it]loss:23.537782669067383: 100%|██████████| 19/19 [05:55<00:00, 18.86s/it]loss:23.537782669067383: 100%|██████████| 19/19 [05:56<00:00, 18.74s/it]
Epoch: 5 cost time: 356.66552567481995
Epoch: 5, Steps: 19 | Train Loss: 23.4228904 Vali Loss: 3.2070727 Test Loss: 42.4912529
Validation loss decreased (3.207463 --> 3.207073).  Saving model ...
Updating learning rate to 6.25e-06
  0%|          | 0/19 [00:00<?, ?it/s]loss:23.53825569152832:   0%|          | 0/19 [00:19<?, ?it/s]loss:23.53825569152832:   5%|▌         | 1/19 [00:19<05:44, 19.15s/it]loss:23.596397399902344:   5%|▌         | 1/19 [00:37<05:44, 19.15s/it]loss:23.596397399902344:  11%|█         | 2/19 [00:37<05:20, 18.86s/it]loss:23.769052505493164:  11%|█         | 2/19 [00:57<05:20, 18.86s/it]loss:23.769052505493164:  16%|█▌        | 3/19 [00:57<05:04, 19.06s/it]loss:23.710851669311523:  16%|█▌        | 3/19 [01:15<05:04, 19.06s/it]loss:23.710851669311523:  21%|██        | 4/19 [01:15<04:41, 18.76s/it]loss:23.353918075561523:  21%|██        | 4/19 [01:33<04:41, 18.76s/it]loss:23.353918075561523:  26%|██▋       | 5/19 [01:33<04:21, 18.68s/it]loss:23.342689514160156:  26%|██▋       | 5/19 [01:51<04:21, 18.68s/it]loss:23.342689514160156:  32%|███▏      | 6/19 [01:51<03:59, 18.46s/it]loss:23.469409942626953:  32%|███▏      | 6/19 [02:10<03:59, 18.46s/it]loss:23.469409942626953:  37%|███▋      | 7/19 [02:10<03:41, 18.46s/it]loss:23.09581756591797:  37%|███▋      | 7/19 [02:29<03:41, 18.46s/it] loss:23.09581756591797:  42%|████▏     | 8/19 [02:29<03:23, 18.50s/it]loss:23.4030704498291:  42%|████▏     | 8/19 [02:47<03:23, 18.50s/it] loss:23.4030704498291:  47%|████▋     | 9/19 [02:47<03:04, 18.43s/it]loss:23.320377349853516:  47%|████▋     | 9/19 [03:05<03:04, 18.43s/it]loss:23.320377349853516:  53%|█████▎    | 10/19 [03:05<02:44, 18.29s/it]loss:23.506778717041016:  53%|█████▎    | 10/19 [03:24<02:44, 18.29s/it]loss:23.506778717041016:  58%|█████▊    | 11/19 [03:24<02:28, 18.58s/it]loss:23.567516326904297:  58%|█████▊    | 11/19 [03:42<02:28, 18.58s/it]loss:23.567516326904297:  63%|██████▎   | 12/19 [03:42<02:09, 18.55s/it]loss:23.406898498535156:  63%|██████▎   | 12/19 [04:00<02:09, 18.55s/it]loss:23.406898498535156:  68%|██████▊   | 13/19 [04:00<01:49, 18.31s/it]loss:23.91206932067871:  68%|██████▊   | 13/19 [04:19<01:49, 18.31s/it] loss:23.91206932067871:  74%|███████▎  | 14/19 [04:19<01:31, 18.37s/it]loss:23.1574649810791:  74%|███████▎  | 14/19 [04:37<01:31, 18.37s/it] loss:23.1574649810791:  79%|███████▉  | 15/19 [04:37<01:13, 18.26s/it]loss:23.217029571533203:  79%|███████▉  | 15/19 [04:55<01:13, 18.26s/it]loss:23.217029571533203:  84%|████████▍ | 16/19 [04:55<00:54, 18.27s/it]loss:23.373565673828125:  84%|████████▍ | 16/19 [05:14<00:54, 18.27s/it]loss:23.373565673828125:  89%|████████▉ | 17/19 [05:14<00:36, 18.41s/it]loss:23.132055282592773:  89%|████████▉ | 17/19 [05:32<00:36, 18.41s/it]loss:23.132055282592773:  95%|█████████▍| 18/19 [05:32<00:18, 18.38s/it]loss:23.295251846313477:  95%|█████████▍| 18/19 [05:51<00:18, 18.38s/it]loss:23.295251846313477: 100%|██████████| 19/19 [05:51<00:00, 18.55s/it]loss:23.295251846313477: 100%|██████████| 19/19 [05:51<00:00, 18.51s/it]
Epoch: 6 cost time: 352.3423216342926
Epoch: 6, Steps: 19 | Train Loss: 23.4299195 Vali Loss: 3.2068632 Test Loss: 42.4944077
Validation loss decreased (3.207073 --> 3.206863).  Saving model ...
Updating learning rate to 3.125e-06
  0%|          | 0/19 [00:00<?, ?it/s]loss:23.600786209106445:   0%|          | 0/19 [00:18<?, ?it/s]loss:23.600786209106445:   5%|▌         | 1/19 [00:18<05:31, 18.44s/it]loss:23.50904083251953:   5%|▌         | 1/19 [00:36<05:31, 18.44s/it] loss:23.50904083251953:  11%|█         | 2/19 [00:36<05:12, 18.41s/it]loss:23.346338272094727:  11%|█         | 2/19 [00:55<05:12, 18.41s/it]loss:23.346338272094727:  16%|█▌        | 3/19 [00:55<04:55, 18.48s/it]loss:23.408958435058594:  16%|█▌        | 3/19 [01:14<04:55, 18.48s/it]loss:23.408958435058594:  21%|██        | 4/19 [01:14<04:39, 18.66s/it]loss:23.132978439331055:  21%|██        | 4/19 [01:34<04:39, 18.66s/it]loss:23.132978439331055:  26%|██▋       | 5/19 [01:34<04:27, 19.08s/it]loss:23.09928321838379:  26%|██▋       | 5/19 [01:53<04:27, 19.08s/it] loss:23.09928321838379:  32%|███▏      | 6/19 [01:53<04:07, 19.05s/it]loss:23.32349395751953:  32%|███▏      | 6/19 [02:12<04:07, 19.05s/it]loss:23.32349395751953:  37%|███▋      | 7/19 [02:12<03:49, 19.13s/it]loss:23.218780517578125:  37%|███▋      | 7/19 [02:32<03:49, 19.13s/it]loss:23.218780517578125:  42%|████▏     | 8/19 [02:32<03:32, 19.29s/it]loss:23.358470916748047:  42%|████▏     | 8/19 [02:52<03:32, 19.29s/it]loss:23.358470916748047:  47%|████▋     | 9/19 [02:52<03:16, 19.62s/it]loss:23.5439395904541:  47%|████▋     | 9/19 [03:11<03:16, 19.62s/it]  loss:23.5439395904541:  53%|█████▎    | 10/19 [03:11<02:55, 19.48s/it]loss:23.715373992919922:  53%|█████▎    | 10/19 [03:30<02:55, 19.48s/it]loss:23.715373992919922:  58%|█████▊    | 11/19 [03:30<02:34, 19.27s/it]loss:23.375534057617188:  58%|█████▊    | 11/19 [03:49<02:34, 19.27s/it]loss:23.375534057617188:  63%|██████▎   | 12/19 [03:49<02:14, 19.18s/it]loss:23.160024642944336:  63%|██████▎   | 12/19 [04:08<02:14, 19.18s/it]loss:23.160024642944336:  68%|██████▊   | 13/19 [04:08<01:54, 19.07s/it]loss:23.914945602416992:  68%|██████▊   | 13/19 [04:27<01:54, 19.07s/it]loss:23.914945602416992:  74%|███████▎  | 14/19 [04:27<01:36, 19.24s/it]loss:23.774852752685547:  74%|███████▎  | 14/19 [04:46<01:36, 19.24s/it]loss:23.774852752685547:  79%|███████▉  | 15/19 [04:46<01:16, 19.19s/it]loss:23.29712677001953:  79%|███████▉  | 15/19 [05:06<01:16, 19.19s/it] loss:23.29712677001953:  84%|████████▍ | 16/19 [05:06<00:58, 19.34s/it]loss:23.40764617919922:  84%|████████▍ | 16/19 [05:25<00:58, 19.34s/it]loss:23.40764617919922:  89%|████████▉ | 17/19 [05:25<00:38, 19.21s/it]loss:23.571378707885742:  89%|████████▉ | 17/19 [05:45<00:38, 19.21s/it]loss:23.571378707885742:  95%|█████████▍| 18/19 [05:45<00:19, 19.40s/it]loss:23.474716186523438:  95%|█████████▍| 18/19 [06:04<00:19, 19.40s/it]loss:23.474716186523438: 100%|██████████| 19/19 [06:04<00:00, 19.47s/it]loss:23.474716186523438: 100%|██████████| 19/19 [06:04<00:00, 19.21s/it]
Epoch: 7 cost time: 365.6202824115753
Epoch: 7, Steps: 19 | Train Loss: 23.4333510 Vali Loss: 3.2067747 Test Loss: 42.4959488
Validation loss decreased (3.206863 --> 3.206775).  Saving model ...
Updating learning rate to 1.5625e-06
  0%|          | 0/19 [00:00<?, ?it/s]loss:23.408018112182617:   0%|          | 0/19 [00:18<?, ?it/s]loss:23.408018112182617:   5%|▌         | 1/19 [00:18<05:41, 18.95s/it]loss:23.915714263916016:   5%|▌         | 1/19 [00:37<05:41, 18.95s/it]loss:23.915714263916016:  11%|█         | 2/19 [00:37<05:19, 18.77s/it]loss:23.410968780517578:  11%|█         | 2/19 [00:56<05:19, 18.77s/it]loss:23.410968780517578:  16%|█▌        | 3/19 [00:56<05:02, 18.93s/it]loss:23.325218200683594:  16%|█▌        | 3/19 [01:16<05:02, 18.93s/it]loss:23.325218200683594:  21%|██        | 4/19 [01:16<04:51, 19.41s/it]loss:23.716550827026367:  21%|██        | 4/19 [01:36<04:51, 19.41s/it]loss:23.716550827026367:  26%|██▋       | 5/19 [01:36<04:32, 19.49s/it]loss:23.220504760742188:  26%|██▋       | 5/19 [01:55<04:32, 19.49s/it]loss:23.220504760742188:  32%|███▏      | 6/19 [01:55<04:12, 19.40s/it]loss:23.161231994628906:  32%|███▏      | 6/19 [02:14<04:12, 19.40s/it]loss:23.161231994628906:  37%|███▋      | 7/19 [02:14<03:51, 19.32s/it]loss:23.1351318359375:  37%|███▋      | 7/19 [02:33<03:51, 19.32s/it]  loss:23.1351318359375:  42%|████▏     | 8/19 [02:33<03:30, 19.14s/it]loss:23.775970458984375:  42%|████▏     | 8/19 [02:52<03:30, 19.14s/it]loss:23.775970458984375:  47%|████▋     | 9/19 [02:52<03:11, 19.11s/it]loss:23.572172164916992:  47%|████▋     | 9/19 [03:12<03:11, 19.11s/it]loss:23.572172164916992:  53%|█████▎    | 10/19 [03:12<02:53, 19.30s/it]loss:23.603635787963867:  53%|█████▎    | 10/19 [03:31<02:53, 19.30s/it]loss:23.603635787963867:  58%|█████▊    | 11/19 [03:31<02:33, 19.18s/it]loss:23.47552490234375:  58%|█████▊    | 11/19 [03:51<02:33, 19.18s/it] loss:23.47552490234375:  63%|██████▎   | 12/19 [03:51<02:15, 19.34s/it]loss:23.10166358947754:  63%|██████▎   | 12/19 [04:10<02:15, 19.34s/it]loss:23.10166358947754:  68%|██████▊   | 13/19 [04:10<01:55, 19.33s/it]loss:23.511911392211914:  68%|██████▊   | 13/19 [04:29<01:55, 19.33s/it]loss:23.511911392211914:  74%|███████▎  | 14/19 [04:29<01:36, 19.35s/it]loss:23.546001434326172:  74%|███████▎  | 14/19 [04:48<01:36, 19.35s/it]loss:23.546001434326172:  79%|███████▉  | 15/19 [04:48<01:16, 19.19s/it]loss:23.298484802246094:  79%|███████▉  | 15/19 [05:08<01:16, 19.19s/it]loss:23.298484802246094:  84%|████████▍ | 16/19 [05:08<00:58, 19.41s/it]loss:23.377479553222656:  84%|████████▍ | 16/19 [05:28<00:58, 19.41s/it]loss:23.377479553222656:  89%|████████▉ | 17/19 [05:28<00:39, 19.66s/it]loss:23.360816955566406:  89%|████████▉ | 17/19 [05:48<00:39, 19.66s/it]loss:23.360816955566406:  95%|█████████▍| 18/19 [05:48<00:19, 19.77s/it]loss:23.34947967529297:  95%|█████████▍| 18/19 [06:07<00:19, 19.77s/it] loss:23.34947967529297: 100%|██████████| 19/19 [06:07<00:00, 19.61s/it]loss:23.34947967529297: 100%|██████████| 19/19 [06:08<00:00, 19.37s/it]
Epoch: 8 cost time: 368.7411880493164
Epoch: 8, Steps: 19 | Train Loss: 23.4350779 Vali Loss: 3.2067239 Test Loss: 42.4968338
Validation loss decreased (3.206775 --> 3.206724).  Saving model ...
Updating learning rate to 7.8125e-07
  0%|          | 0/19 [00:00<?, ?it/s]loss:23.47602081298828:   0%|          | 0/19 [00:19<?, ?it/s]loss:23.47602081298828:   5%|▌         | 1/19 [00:19<05:49, 19.44s/it]loss:23.412059783935547:   5%|▌         | 1/19 [00:38<05:49, 19.44s/it]loss:23.412059783935547:  11%|█         | 2/19 [00:38<05:29, 19.41s/it]loss:23.221420288085938:  11%|█         | 2/19 [00:58<05:29, 19.41s/it]loss:23.221420288085938:  16%|█▌        | 3/19 [00:58<05:09, 19.31s/it]loss:23.37775421142578:  16%|█▌        | 3/19 [01:17<05:09, 19.31s/it] loss:23.37775421142578:  21%|██        | 4/19 [01:17<04:51, 19.42s/it]loss:23.51238250732422:  21%|██        | 4/19 [01:36<04:51, 19.42s/it]loss:23.51238250732422:  26%|██▋       | 5/19 [01:36<04:28, 19.20s/it]loss:23.16216278076172:  26%|██▋       | 5/19 [01:55<04:28, 19.20s/it]loss:23.16216278076172:  32%|███▏      | 6/19 [01:55<04:09, 19.18s/it]loss:23.29888343811035:  32%|███▏      | 6/19 [02:14<04:09, 19.18s/it]loss:23.29888343811035:  37%|███▋      | 7/19 [02:14<03:49, 19.17s/it]loss:23.9169864654541:  37%|███▋      | 7/19 [02:34<03:49, 19.17s/it] loss:23.9169864654541:  42%|████▏     | 8/19 [02:34<03:32, 19.29s/it]loss:23.572988510131836:  42%|████▏     | 8/19 [02:53<03:32, 19.29s/it]loss:23.572988510131836:  47%|████▋     | 9/19 [02:53<03:12, 19.20s/it]loss:23.32645606994629:  47%|████▋     | 9/19 [03:12<03:12, 19.20s/it] loss:23.32645606994629:  53%|█████▎    | 10/19 [03:12<02:52, 19.16s/it]loss:23.361221313476562:  53%|█████▎    | 10/19 [03:31<02:52, 19.16s/it]loss:23.361221313476562:  58%|█████▊    | 11/19 [03:31<02:33, 19.24s/it]loss:23.776954650878906:  58%|█████▊    | 11/19 [03:51<02:33, 19.24s/it]loss:23.776954650878906:  63%|██████▎   | 12/19 [03:51<02:15, 19.37s/it]loss:23.717681884765625:  63%|██████▎   | 12/19 [04:10<02:15, 19.37s/it]loss:23.717681884765625:  68%|██████▊   | 13/19 [04:10<01:56, 19.33s/it]loss:23.604562759399414:  68%|██████▊   | 13/19 [04:30<01:56, 19.33s/it]loss:23.604562759399414:  74%|███████▎  | 14/19 [04:30<01:37, 19.42s/it]loss:23.102506637573242:  74%|███████▎  | 14/19 [04:49<01:37, 19.42s/it]loss:23.102506637573242:  79%|███████▉  | 15/19 [04:49<01:17, 19.32s/it]loss:23.349990844726562:  79%|███████▉  | 15/19 [05:08<01:17, 19.32s/it]loss:23.349990844726562:  84%|████████▍ | 16/19 [05:08<00:57, 19.16s/it]loss:23.546781539916992:  84%|████████▍ | 16/19 [05:27<00:57, 19.16s/it]loss:23.546781539916992:  89%|████████▉ | 17/19 [05:27<00:38, 19.22s/it]loss:23.136363983154297:  89%|████████▉ | 17/19 [05:46<00:38, 19.22s/it]loss:23.136363983154297:  95%|█████████▍| 18/19 [05:46<00:19, 19.14s/it]loss:23.409740447998047:  95%|█████████▍| 18/19 [06:05<00:19, 19.14s/it]loss:23.409740447998047: 100%|██████████| 19/19 [06:05<00:00, 19.15s/it]loss:23.409740447998047: 100%|██████████| 19/19 [06:05<00:00, 19.25s/it]
Epoch: 9 cost time: 366.3703525066376
Epoch: 9, Steps: 19 | Train Loss: 23.4359431 Vali Loss: 3.2067003 Test Loss: 42.4972610
Validation loss decreased (3.206724 --> 3.206700).  Saving model ...
Updating learning rate to 3.90625e-07
  0%|          | 0/19 [00:00<?, ?it/s]loss:23.326763153076172:   0%|          | 0/19 [00:19<?, ?it/s]loss:23.326763153076172:   5%|▌         | 1/19 [00:19<05:44, 19.15s/it]loss:23.36151695251465:   5%|▌         | 1/19 [00:38<05:44, 19.15s/it] loss:23.36151695251465:  11%|█         | 2/19 [00:38<05:24, 19.09s/it]loss:23.717899322509766:  11%|█         | 2/19 [00:57<05:24, 19.09s/it]loss:23.717899322509766:  16%|█▌        | 3/19 [00:57<05:03, 18.99s/it]loss:23.35015106201172:  16%|█▌        | 3/19 [01:16<05:03, 18.99s/it] loss:23.35015106201172:  21%|██        | 4/19 [01:16<04:50, 19.35s/it]loss:23.57337188720703:  21%|██        | 4/19 [01:36<04:50, 19.35s/it]loss:23.57337188720703:  26%|██▋       | 5/19 [01:36<04:32, 19.44s/it]loss:23.378299713134766:  26%|██▋       | 5/19 [01:55<04:32, 19.44s/it]loss:23.378299713134766:  32%|███▏      | 6/19 [01:55<04:11, 19.33s/it]loss:23.409854888916016:  32%|███▏      | 6/19 [02:14<04:11, 19.33s/it]loss:23.409854888916016:  37%|███▋      | 7/19 [02:14<03:50, 19.20s/it]loss:23.917434692382812:  37%|███▋      | 7/19 [02:34<03:50, 19.20s/it]loss:23.917434692382812:  42%|████▏     | 8/19 [02:34<03:32, 19.32s/it]loss:23.54698371887207:  42%|████▏     | 8/19 [02:53<03:32, 19.32s/it] loss:23.54698371887207:  47%|████▋     | 9/19 [02:53<03:12, 19.23s/it]loss:23.222057342529297:  47%|████▋     | 9/19 [03:12<03:12, 19.23s/it]loss:23.222057342529297:  53%|█████▎    | 10/19 [03:12<02:53, 19.25s/it]loss:23.412742614746094:  53%|█████▎    | 10/19 [03:31<02:53, 19.25s/it]loss:23.412742614746094:  58%|█████▊    | 11/19 [03:31<02:34, 19.30s/it]loss:23.604902267456055:  58%|█████▊    | 11/19 [03:52<02:34, 19.30s/it]loss:23.604902267456055:  63%|██████▎   | 12/19 [03:52<02:17, 19.70s/it]loss:23.512989044189453:  63%|██████▎   | 12/19 [04:11<02:17, 19.70s/it]loss:23.512989044189453:  68%|██████▊   | 13/19 [04:11<01:56, 19.49s/it]loss:23.47677230834961:  68%|██████▊   | 13/19 [04:30<01:56, 19.49s/it] loss:23.47677230834961:  74%|███████▎  | 14/19 [04:30<01:36, 19.36s/it]loss:23.777402877807617:  74%|███████▎  | 14/19 [04:50<01:36, 19.36s/it]loss:23.777402877807617:  79%|███████▉  | 15/19 [04:50<01:18, 19.56s/it]loss:23.102863311767578:  79%|███████▉  | 15/19 [05:09<01:18, 19.56s/it]loss:23.102863311767578:  84%|████████▍ | 16/19 [05:09<00:57, 19.30s/it]loss:23.136642456054688:  84%|████████▍ | 16/19 [05:28<00:57, 19.30s/it]loss:23.136642456054688:  89%|████████▉ | 17/19 [05:28<00:38, 19.17s/it]loss:23.162822723388672:  89%|████████▉ | 17/19 [05:47<00:38, 19.17s/it]loss:23.162822723388672:  95%|█████████▍| 18/19 [05:47<00:19, 19.08s/it]loss:23.299503326416016:  95%|█████████▍| 18/19 [06:06<00:19, 19.08s/it]loss:23.299503326416016: 100%|██████████| 19/19 [06:06<00:00, 19.13s/it]loss:23.299503326416016: 100%|██████████| 19/19 [06:06<00:00, 19.28s/it]
Epoch: 10 cost time: 366.9462959766388
Epoch: 10, Steps: 19 | Train Loss: 23.4363670 Vali Loss: 3.2066884 Test Loss: 42.4974670
Validation loss decreased (3.206700 --> 3.206688).  Saving model ...
Updating learning rate to 1.953125e-07
  0%|          | 0/19 [00:00<?, ?it/s]loss:23.51308822631836:   0%|          | 0/19 [00:18<?, ?it/s]loss:23.51308822631836:   5%|▌         | 1/19 [00:18<05:33, 18.54s/it]loss:23.718124389648438:   5%|▌         | 1/19 [00:37<05:33, 18.54s/it]loss:23.718124389648438:  11%|█         | 2/19 [00:37<05:16, 18.59s/it]loss:23.476877212524414:  11%|█         | 2/19 [00:55<05:16, 18.59s/it]loss:23.476877212524414:  16%|█▌        | 3/19 [00:55<04:56, 18.50s/it]loss:23.327062606811523:  16%|█▌        | 3/19 [01:13<04:56, 18.50s/it]loss:23.327062606811523:  21%|██        | 4/19 [01:13<04:35, 18.35s/it]loss:23.222240447998047:  21%|██        | 4/19 [01:32<04:35, 18.35s/it]loss:23.222240447998047:  26%|██▋       | 5/19 [01:32<04:21, 18.69s/it]loss:23.361814498901367:  26%|██▋       | 5/19 [01:50<04:21, 18.69s/it]loss:23.361814498901367:  32%|███▏      | 6/19 [01:50<03:59, 18.44s/it]loss:23.547197341918945:  32%|███▏      | 6/19 [02:10<03:59, 18.44s/it]loss:23.547197341918945:  37%|███▋      | 7/19 [02:10<03:45, 18.82s/it]loss:23.299579620361328:  37%|███▋      | 7/19 [02:29<03:45, 18.82s/it]loss:23.299579620361328:  42%|████▏     | 8/19 [02:29<03:27, 18.91s/it]loss:23.777551651000977:  42%|████▏     | 8/19 [02:48<03:27, 18.91s/it]loss:23.777551651000977:  47%|████▋     | 9/19 [02:48<03:07, 18.77s/it]loss:23.573665618896484:  47%|████▋     | 9/19 [03:06<03:07, 18.77s/it]loss:23.573665618896484:  53%|█████▎    | 10/19 [03:06<02:47, 18.65s/it]loss:23.136777877807617:  53%|█████▎    | 10/19 [03:25<02:47, 18.65s/it]loss:23.136777877807617:  58%|█████▊    | 11/19 [03:25<02:31, 18.91s/it]loss:23.91770362854004:  58%|█████▊    | 11/19 [03:45<02:31, 18.91s/it] loss:23.91770362854004:  63%|██████▎   | 12/19 [03:45<02:13, 19.10s/it]loss:23.350492477416992:  63%|██████▎   | 12/19 [04:05<02:13, 19.10s/it]loss:23.350492477416992:  68%|██████▊   | 13/19 [04:05<01:55, 19.23s/it]loss:23.378623962402344:  68%|██████▊   | 13/19 [04:23<01:55, 19.23s/it]loss:23.378623962402344:  74%|███████▎  | 14/19 [04:23<01:35, 19.06s/it]loss:23.410179138183594:  74%|███████▎  | 14/19 [04:41<01:35, 19.06s/it]loss:23.410179138183594:  79%|███████▉  | 15/19 [04:41<01:15, 18.83s/it]loss:23.413021087646484:  79%|███████▉  | 15/19 [04:59<01:15, 18.83s/it]loss:23.413021087646484:  84%|████████▍ | 16/19 [04:59<00:55, 18.58s/it]loss:23.16299819946289:  84%|████████▍ | 16/19 [05:19<00:55, 18.58s/it] loss:23.16299819946289:  89%|████████▉ | 17/19 [05:19<00:37, 18.80s/it]loss:23.605178833007812:  89%|████████▉ | 17/19 [05:37<00:37, 18.80s/it]loss:23.605178833007812:  95%|█████████▍| 18/19 [05:37<00:18, 18.64s/it]loss:23.10309410095215:  95%|█████████▍| 18/19 [05:56<00:18, 18.64s/it] loss:23.10309410095215: 100%|██████████| 19/19 [05:56<00:00, 18.72s/it]loss:23.10309410095215: 100%|██████████| 19/19 [05:56<00:00, 18.76s/it]
Epoch: 11 cost time: 357.2022180557251
Epoch: 11, Steps: 19 | Train Loss: 23.4365932 Vali Loss: 3.2066824 Test Loss: 42.4975739
Validation loss decreased (3.206688 --> 3.206682).  Saving model ...
Updating learning rate to 9.765625e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:23.29969024658203:   0%|          | 0/19 [00:18<?, ?it/s]loss:23.29969024658203:   5%|▌         | 1/19 [00:18<05:24, 18.05s/it]loss:23.41306495666504:   5%|▌         | 1/19 [00:36<05:24, 18.05s/it]loss:23.41306495666504:  11%|█         | 2/19 [00:36<05:15, 18.55s/it]loss:23.103113174438477:  11%|█         | 2/19 [00:56<05:15, 18.55s/it]loss:23.103113174438477:  16%|█▌        | 3/19 [00:56<05:03, 18.99s/it]loss:23.71829605102539:  16%|█▌        | 3/19 [01:15<05:03, 18.99s/it] loss:23.71829605102539:  21%|██        | 4/19 [01:15<04:44, 18.97s/it]loss:23.77767562866211:  21%|██        | 4/19 [01:34<04:44, 18.97s/it]loss:23.77767562866211:  26%|██▋       | 5/19 [01:34<04:24, 18.93s/it]loss:23.37870216369629:  26%|██▋       | 5/19 [01:53<04:24, 18.93s/it]loss:23.37870216369629:  32%|███▏      | 6/19 [01:53<04:05, 18.91s/it]loss:23.477069854736328:  32%|███▏      | 6/19 [02:11<04:05, 18.91s/it]loss:23.477069854736328:  37%|███▋      | 7/19 [02:11<03:44, 18.74s/it]loss:23.410259246826172:  37%|███▋      | 7/19 [02:30<03:44, 18.74s/it]loss:23.410259246826172:  42%|████▏     | 8/19 [02:30<03:26, 18.77s/it]loss:23.5133056640625:  42%|████▏     | 8/19 [02:49<03:26, 18.77s/it]  loss:23.5133056640625:  47%|████▋     | 9/19 [02:49<03:08, 18.82s/it]loss:23.605243682861328:  47%|████▋     | 9/19 [03:08<03:08, 18.82s/it]loss:23.605243682861328:  53%|█████▎    | 10/19 [03:08<02:50, 18.93s/it]loss:23.13690757751465:  53%|█████▎    | 10/19 [03:26<02:50, 18.93s/it] loss:23.13690757751465:  58%|█████▊    | 11/19 [03:26<02:29, 18.69s/it]loss:23.1630802154541:  58%|█████▊    | 11/19 [03:45<02:29, 18.69s/it] loss:23.1630802154541:  63%|██████▎   | 12/19 [03:45<02:10, 18.65s/it]loss:23.91783332824707:  63%|██████▎   | 12/19 [04:03<02:10, 18.65s/it]loss:23.91783332824707:  68%|██████▊   | 13/19 [04:03<01:51, 18.53s/it]loss:23.573822021484375:  68%|██████▊   | 13/19 [04:21<01:51, 18.53s/it]loss:23.573822021484375:  74%|███████▎  | 14/19 [04:21<01:32, 18.48s/it]loss:23.32727813720703:  74%|███████▎  | 14/19 [04:39<01:32, 18.48s/it] loss:23.32727813720703:  79%|███████▉  | 15/19 [04:39<01:13, 18.39s/it]loss:23.350637435913086:  79%|███████▉  | 15/19 [04:58<01:13, 18.39s/it]loss:23.350637435913086:  84%|████████▍ | 16/19 [04:58<00:55, 18.57s/it]loss:23.547399520874023:  84%|████████▍ | 16/19 [05:17<00:55, 18.57s/it]loss:23.547399520874023:  89%|████████▉ | 17/19 [05:17<00:37, 18.63s/it]loss:23.362028121948242:  89%|████████▉ | 17/19 [05:36<00:37, 18.63s/it]loss:23.362028121948242:  95%|█████████▍| 18/19 [05:36<00:18, 18.53s/it]loss:23.22246551513672:  95%|█████████▍| 18/19 [05:55<00:18, 18.53s/it] loss:23.22246551513672: 100%|██████████| 19/19 [05:55<00:00, 18.77s/it]loss:23.22246551513672: 100%|██████████| 19/19 [05:55<00:00, 18.70s/it]
Epoch: 12 cost time: 355.97736859321594
Epoch: 12, Steps: 19 | Train Loss: 23.4367301 Vali Loss: 3.2066789 Test Loss: 42.4976273
Validation loss decreased (3.206682 --> 3.206679).  Saving model ...
Updating learning rate to 4.8828125e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:23.327302932739258:   0%|          | 0/19 [00:19<?, ?it/s]loss:23.327302932739258:   5%|▌         | 1/19 [00:19<05:46, 19.27s/it]loss:23.917869567871094:   5%|▌         | 1/19 [00:38<05:46, 19.27s/it]loss:23.917869567871094:  11%|█         | 2/19 [00:38<05:23, 19.01s/it]loss:23.37877082824707:  11%|█         | 2/19 [00:56<05:23, 19.01s/it] loss:23.37877082824707:  16%|█▌        | 3/19 [00:56<04:58, 18.68s/it]loss:23.163114547729492:  16%|█▌        | 3/19 [01:14<04:58, 18.68s/it]loss:23.163114547729492:  21%|██        | 4/19 [01:14<04:36, 18.41s/it]loss:23.410316467285156:  21%|██        | 4/19 [01:33<04:36, 18.41s/it]loss:23.410316467285156:  26%|██▋       | 5/19 [01:33<04:19, 18.56s/it]loss:23.362037658691406:  26%|██▋       | 5/19 [01:52<04:19, 18.56s/it]loss:23.362037658691406:  32%|███▏      | 6/19 [01:52<04:04, 18.83s/it]loss:23.136951446533203:  32%|███▏      | 6/19 [02:12<04:04, 18.83s/it]loss:23.136951446533203:  37%|███▋      | 7/19 [02:12<03:48, 19.06s/it]loss:23.299776077270508:  37%|███▋      | 7/19 [02:30<03:48, 19.06s/it]loss:23.299776077270508:  42%|████▏     | 8/19 [02:30<03:26, 18.77s/it]loss:23.5738468170166:  42%|████▏     | 8/19 [02:48<03:26, 18.77s/it]  loss:23.5738468170166:  47%|████▋     | 9/19 [02:48<03:06, 18.63s/it]loss:23.777746200561523:  47%|████▋     | 9/19 [03:07<03:06, 18.63s/it]loss:23.777746200561523:  53%|█████▎    | 10/19 [03:07<02:47, 18.66s/it]loss:23.413148880004883:  53%|█████▎    | 10/19 [03:26<02:47, 18.66s/it]loss:23.413148880004883:  58%|█████▊    | 11/19 [03:26<02:30, 18.85s/it]loss:23.547412872314453:  58%|█████▊    | 11/19 [03:45<02:30, 18.85s/it]loss:23.547412872314453:  63%|██████▎   | 12/19 [03:45<02:11, 18.79s/it]loss:23.35065460205078:  63%|██████▎   | 12/19 [04:03<02:11, 18.79s/it] loss:23.35065460205078:  68%|██████▊   | 13/19 [04:03<01:52, 18.74s/it]loss:23.103191375732422:  68%|██████▊   | 13/19 [04:22<01:52, 18.74s/it]loss:23.103191375732422:  74%|███████▎  | 14/19 [04:22<01:33, 18.72s/it]loss:23.605287551879883:  74%|███████▎  | 14/19 [04:40<01:33, 18.72s/it]loss:23.605287551879883:  79%|███████▉  | 15/19 [04:40<01:14, 18.59s/it]loss:23.71835708618164:  79%|███████▉  | 15/19 [04:59<01:14, 18.59s/it] loss:23.71835708618164:  84%|████████▍ | 16/19 [04:59<00:55, 18.59s/it]loss:23.222469329833984:  84%|████████▍ | 16/19 [05:17<00:55, 18.59s/it]loss:23.222469329833984:  89%|████████▉ | 17/19 [05:17<00:37, 18.54s/it]loss:23.477130889892578:  89%|████████▉ | 17/19 [05:36<00:37, 18.54s/it]loss:23.477130889892578:  95%|█████████▍| 18/19 [05:36<00:18, 18.45s/it]loss:23.513355255126953:  95%|█████████▍| 18/19 [05:55<00:18, 18.45s/it]loss:23.513355255126953: 100%|██████████| 19/19 [05:55<00:00, 18.64s/it]loss:23.513355255126953: 100%|██████████| 19/19 [05:55<00:00, 18.69s/it]
Epoch: 13 cost time: 355.8485221862793
Epoch: 13, Steps: 19 | Train Loss: 23.4367758 Vali Loss: 3.2066777 Test Loss: 42.4976578
Validation loss decreased (3.206679 --> 3.206678).  Saving model ...
Updating learning rate to 2.44140625e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:23.410314559936523:   0%|          | 0/19 [00:19<?, ?it/s]loss:23.410314559936523:   5%|▌         | 1/19 [00:19<05:50, 19.45s/it]loss:23.718355178833008:   5%|▌         | 1/19 [00:38<05:50, 19.45s/it]loss:23.718355178833008:  11%|█         | 2/19 [00:38<05:21, 18.94s/it]loss:23.917865753173828:  11%|█         | 2/19 [00:57<05:21, 18.94s/it]loss:23.917865753173828:  16%|█▌        | 3/19 [00:57<05:06, 19.14s/it]loss:23.299774169921875:  16%|█▌        | 3/19 [01:16<05:06, 19.14s/it]loss:23.299774169921875:  21%|██        | 4/19 [01:16<04:44, 18.97s/it]loss:23.10318946838379:  21%|██        | 4/19 [01:34<04:44, 18.97s/it] loss:23.10318946838379:  26%|██▋       | 5/19 [01:34<04:23, 18.82s/it]loss:23.222469329833984:  26%|██▋       | 5/19 [01:53<04:23, 18.82s/it]loss:23.222469329833984:  32%|███▏      | 6/19 [01:53<04:06, 18.94s/it]loss:23.513355255126953:  32%|███▏      | 6/19 [02:12<04:06, 18.94s/it]loss:23.513355255126953:  37%|███▋      | 7/19 [02:12<03:46, 18.89s/it]loss:23.378765106201172:  37%|███▋      | 7/19 [02:30<03:46, 18.89s/it]loss:23.378765106201172:  42%|████▏     | 8/19 [02:30<03:24, 18.58s/it]loss:23.362035751342773:  42%|████▏     | 8/19 [02:49<03:24, 18.58s/it]loss:23.362035751342773:  47%|████▋     | 9/19 [02:49<03:06, 18.62s/it]loss:23.136943817138672:  47%|████▋     | 9/19 [03:08<03:06, 18.62s/it]loss:23.136943817138672:  53%|█████▎    | 10/19 [03:08<02:48, 18.77s/it]loss:23.777742385864258:  53%|█████▎    | 10/19 [03:27<02:48, 18.77s/it]loss:23.777742385864258:  58%|█████▊    | 11/19 [03:27<02:30, 18.76s/it]loss:23.54741096496582:  58%|█████▊    | 11/19 [03:45<02:30, 18.76s/it] loss:23.54741096496582:  63%|██████▎   | 12/19 [03:45<02:11, 18.77s/it]loss:23.35065269470215:  63%|██████▎   | 12/19 [04:04<02:11, 18.77s/it]loss:23.35065269470215:  68%|██████▊   | 13/19 [04:04<01:53, 18.87s/it]loss:23.163110733032227:  68%|██████▊   | 13/19 [04:23<01:53, 18.87s/it]loss:23.163110733032227:  74%|███████▎  | 14/19 [04:23<01:34, 18.82s/it]loss:23.477128982543945:  74%|███████▎  | 14/19 [04:41<01:34, 18.82s/it]loss:23.477128982543945:  79%|███████▉  | 15/19 [04:41<01:14, 18.64s/it]loss:23.41314697265625:  79%|███████▉  | 15/19 [05:00<01:14, 18.64s/it] loss:23.41314697265625:  84%|████████▍ | 16/19 [05:00<00:55, 18.60s/it]loss:23.327299118041992:  84%|████████▍ | 16/19 [05:18<00:55, 18.60s/it]loss:23.327299118041992:  89%|████████▉ | 17/19 [05:18<00:37, 18.53s/it]loss:23.573843002319336:  89%|████████▉ | 17/19 [05:37<00:37, 18.53s/it]loss:23.573843002319336:  95%|█████████▍| 18/19 [05:37<00:18, 18.57s/it]loss:23.60528564453125:  95%|█████████▍| 18/19 [05:56<00:18, 18.57s/it] loss:23.60528564453125: 100%|██████████| 19/19 [05:56<00:00, 18.68s/it]loss:23.60528564453125: 100%|██████████| 19/19 [05:56<00:00, 18.76s/it]
Epoch: 14 cost time: 357.09248208999634
Epoch: 14, Steps: 19 | Train Loss: 23.4367731 Vali Loss: 3.2066770 Test Loss: 42.4976730
Validation loss decreased (3.206678 --> 3.206677).  Saving model ...
Updating learning rate to 1.220703125e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:23.299772262573242:   0%|          | 0/19 [00:18<?, ?it/s]loss:23.299772262573242:   5%|▌         | 1/19 [00:18<05:27, 18.20s/it]loss:23.718353271484375:   5%|▌         | 1/19 [00:37<05:27, 18.20s/it]loss:23.718353271484375:  11%|█         | 2/19 [00:37<05:17, 18.66s/it]loss:23.60528564453125:  11%|█         | 2/19 [00:55<05:17, 18.66s/it] loss:23.60528564453125:  16%|█▌        | 3/19 [00:55<04:59, 18.72s/it]loss:23.573843002319336:  16%|█▌        | 3/19 [01:14<04:59, 18.72s/it]loss:23.573843002319336:  21%|██        | 4/19 [01:14<04:39, 18.61s/it]loss:23.136943817138672:  21%|██        | 4/19 [01:33<04:39, 18.61s/it]loss:23.136943817138672:  26%|██▋       | 5/19 [01:33<04:21, 18.71s/it]loss:23.327299118041992:  26%|██▋       | 5/19 [01:51<04:21, 18.71s/it]loss:23.327299118041992:  32%|███▏      | 6/19 [01:51<04:01, 18.56s/it]loss:23.777742385864258:  32%|███▏      | 6/19 [02:09<04:01, 18.56s/it]loss:23.777742385864258:  37%|███▋      | 7/19 [02:09<03:42, 18.51s/it]loss:23.41314697265625:  37%|███▋      | 7/19 [02:28<03:42, 18.51s/it] loss:23.41314697265625:  42%|████▏     | 8/19 [02:28<03:22, 18.42s/it]loss:23.513349533081055:  42%|████▏     | 8/19 [02:46<03:22, 18.42s/it]loss:23.513349533081055:  47%|████▋     | 9/19 [02:46<03:03, 18.38s/it]loss:23.36203384399414:  47%|████▋     | 9/19 [03:05<03:03, 18.38s/it] loss:23.36203384399414:  53%|█████▎    | 10/19 [03:05<02:47, 18.58s/it]loss:23.103187561035156:  53%|█████▎    | 10/19 [03:24<02:47, 18.58s/it]loss:23.103187561035156:  58%|█████▊    | 11/19 [03:24<02:28, 18.55s/it]loss:23.547407150268555:  58%|█████▊    | 11/19 [03:42<02:28, 18.55s/it]loss:23.547407150268555:  63%|██████▎   | 12/19 [03:42<02:09, 18.54s/it]loss:23.917858123779297:  63%|██████▎   | 12/19 [04:01<02:09, 18.54s/it]loss:23.917858123779297:  68%|██████▊   | 13/19 [04:01<01:51, 18.60s/it]loss:23.477127075195312:  68%|██████▊   | 13/19 [04:20<01:51, 18.60s/it]loss:23.477127075195312:  74%|███████▎  | 14/19 [04:20<01:33, 18.67s/it]loss:23.37876319885254:  74%|███████▎  | 14/19 [04:39<01:33, 18.67s/it] loss:23.37876319885254:  79%|███████▉  | 15/19 [04:39<01:15, 18.87s/it]loss:23.163110733032227:  79%|███████▉  | 15/19 [04:58<01:15, 18.87s/it]loss:23.163110733032227:  84%|████████▍ | 16/19 [04:58<00:57, 19.06s/it]loss:23.41031265258789:  84%|████████▍ | 16/19 [05:17<00:57, 19.06s/it] loss:23.41031265258789:  89%|████████▉ | 17/19 [05:17<00:37, 18.95s/it]loss:23.350650787353516:  89%|████████▉ | 17/19 [05:36<00:37, 18.95s/it]loss:23.350650787353516:  95%|█████████▍| 18/19 [05:36<00:18, 18.96s/it]loss:23.22246551513672:  95%|█████████▍| 18/19 [05:54<00:18, 18.96s/it] loss:23.22246551513672: 100%|██████████| 19/19 [05:54<00:00, 18.78s/it]loss:23.22246551513672: 100%|██████████| 19/19 [05:55<00:00, 18.68s/it]
Epoch: 15 cost time: 355.6715302467346
Epoch: 15, Steps: 19 | Train Loss: 23.4367712 Vali Loss: 3.2066770 Test Loss: 42.4976883
Validation loss decreased (3.206677 --> 3.206677).  Saving model ...
Updating learning rate to 6.103515625e-09
  0%|          | 0/19 [00:00<?, ?it/s]loss:23.136943817138672:   0%|          | 0/19 [00:19<?, ?it/s]loss:23.136943817138672:   5%|▌         | 1/19 [00:19<05:42, 19.02s/it]loss:23.718351364135742:   5%|▌         | 1/19 [00:37<05:42, 19.02s/it]loss:23.718351364135742:  11%|█         | 2/19 [00:37<05:20, 18.85s/it]loss:23.477127075195312:  11%|█         | 2/19 [00:56<05:20, 18.85s/it]loss:23.477127075195312:  16%|█▌        | 3/19 [00:56<04:59, 18.75s/it]loss:23.547405242919922:  16%|█▌        | 3/19 [01:14<04:59, 18.75s/it]loss:23.547405242919922:  21%|██        | 4/19 [01:14<04:40, 18.68s/it]loss:23.35064697265625:  21%|██        | 4/19 [01:33<04:40, 18.68s/it] loss:23.35064697265625:  26%|██▋       | 5/19 [01:33<04:19, 18.52s/it]loss:23.36203384399414:  26%|██▋       | 5/19 [01:51<04:19, 18.52s/it]loss:23.36203384399414:  32%|███▏      | 6/19 [01:51<03:59, 18.44s/it]loss:23.327299118041992:  32%|███▏      | 6/19 [02:10<03:59, 18.44s/it]loss:23.327299118041992:  37%|███▋      | 7/19 [02:10<03:42, 18.56s/it]loss:23.513347625732422:  37%|███▋      | 7/19 [02:29<03:42, 18.56s/it]loss:23.513347625732422:  42%|████▏     | 8/19 [02:29<03:26, 18.81s/it]loss:23.41031265258789:  42%|████▏     | 8/19 [02:49<03:26, 18.81s/it] loss:23.41031265258789:  47%|████▋     | 9/19 [02:49<03:11, 19.12s/it]loss:23.777742385864258:  47%|████▋     | 9/19 [03:08<03:11, 19.12s/it]loss:23.777742385864258:  53%|█████▎    | 10/19 [03:08<02:51, 19.01s/it]loss:23.37876319885254:  53%|█████▎    | 10/19 [03:27<02:51, 19.01s/it] loss:23.37876319885254:  58%|█████▊    | 11/19 [03:27<02:33, 19.23s/it]loss:23.60528564453125:  58%|█████▊    | 11/19 [03:46<02:33, 19.23s/it]loss:23.60528564453125:  63%|██████▎   | 12/19 [03:46<02:13, 19.05s/it]loss:23.41314697265625:  63%|██████▎   | 12/19 [04:05<02:13, 19.05s/it]loss:23.41314697265625:  68%|██████▊   | 13/19 [04:05<01:54, 19.12s/it]loss:23.573841094970703:  68%|██████▊   | 13/19 [04:24<01:54, 19.12s/it]loss:23.573841094970703:  74%|███████▎  | 14/19 [04:24<01:35, 19.10s/it]loss:23.22246551513672:  74%|███████▎  | 14/19 [04:43<01:35, 19.10s/it] loss:23.22246551513672:  79%|███████▉  | 15/19 [04:43<01:15, 18.87s/it]loss:23.103187561035156:  79%|███████▉  | 15/19 [05:02<01:15, 18.87s/it]loss:23.103187561035156:  84%|████████▍ | 16/19 [05:02<00:57, 19.14s/it]loss:23.163108825683594:  84%|████████▍ | 16/19 [05:22<00:57, 19.14s/it]loss:23.163108825683594:  89%|████████▉ | 17/19 [05:22<00:38, 19.20s/it]loss:23.299772262573242:  89%|████████▉ | 17/19 [05:41<00:38, 19.20s/it]loss:23.299772262573242:  95%|█████████▍| 18/19 [05:41<00:19, 19.06s/it]loss:23.917858123779297:  95%|█████████▍| 18/19 [06:00<00:19, 19.06s/it]loss:23.917858123779297: 100%|██████████| 19/19 [06:00<00:00, 19.09s/it]loss:23.917858123779297: 100%|██████████| 19/19 [06:00<00:00, 18.96s/it]
Epoch: 16 cost time: 360.89443469047546
Epoch: 16, Steps: 19 | Train Loss: 23.4367705 Vali Loss: 3.2066770 Test Loss: 42.4976883
Validation loss decreased (3.206677 --> 3.206677).  Saving model ...
Updating learning rate to 3.0517578125e-09
  0%|          | 0/19 [00:00<?, ?it/s]loss:23.299772262573242:   0%|          | 0/19 [00:18<?, ?it/s]loss:23.299772262573242:   5%|▌         | 1/19 [00:18<05:40, 18.89s/it]loss:23.917858123779297:   5%|▌         | 1/19 [00:37<05:40, 18.89s/it]loss:23.917858123779297:  11%|█         | 2/19 [00:37<05:21, 18.90s/it]loss:23.41031265258789:  11%|█         | 2/19 [00:56<05:21, 18.90s/it] loss:23.41031265258789:  16%|█▌        | 3/19 [00:56<05:03, 18.97s/it]loss:23.718351364135742:  16%|█▌        | 3/19 [01:16<05:03, 18.97s/it]loss:23.718351364135742:  21%|██        | 4/19 [01:16<04:46, 19.08s/it]loss:23.777742385864258:  21%|██        | 4/19 [01:34<04:46, 19.08s/it]loss:23.777742385864258:  26%|██▋       | 5/19 [01:34<04:24, 18.87s/it]loss:23.60528564453125:  26%|██▋       | 5/19 [01:54<04:24, 18.87s/it] loss:23.60528564453125:  32%|███▏      | 6/19 [01:54<04:09, 19.16s/it]loss:23.136943817138672:  32%|███▏      | 6/19 [02:13<04:09, 19.16s/it]loss:23.136943817138672:  37%|███▋      | 7/19 [02:13<03:49, 19.15s/it]loss:23.573841094970703:  37%|███▋      | 7/19 [02:32<03:49, 19.15s/it]loss:23.573841094970703:  42%|████▏     | 8/19 [02:32<03:29, 19.07s/it]loss:23.477127075195312:  42%|████▏     | 8/19 [02:50<03:29, 19.07s/it]loss:23.477127075195312:  47%|████▋     | 9/19 [02:50<03:09, 18.91s/it]loss:23.37876319885254:  47%|████▋     | 9/19 [03:09<03:09, 18.91s/it] loss:23.37876319885254:  53%|█████▎    | 10/19 [03:09<02:50, 18.95s/it]loss:23.103187561035156:  53%|█████▎    | 10/19 [03:29<02:50, 18.95s/it]loss:23.103187561035156:  58%|█████▊    | 11/19 [03:29<02:32, 19.07s/it]loss:23.513347625732422:  58%|█████▊    | 11/19 [03:48<02:32, 19.07s/it]loss:23.513347625732422:  63%|██████▎   | 12/19 [03:48<02:14, 19.18s/it]loss:23.35064697265625:  63%|██████▎   | 12/19 [04:07<02:14, 19.18s/it] loss:23.35064697265625:  68%|██████▊   | 13/19 [04:07<01:54, 19.03s/it]loss:23.327299118041992:  68%|██████▊   | 13/19 [04:26<01:54, 19.03s/it]loss:23.327299118041992:  74%|███████▎  | 14/19 [04:26<01:34, 18.92s/it]loss:23.41314697265625:  74%|███████▎  | 14/19 [04:45<01:34, 18.92s/it] loss:23.41314697265625:  79%|███████▉  | 15/19 [04:45<01:16, 19.06s/it]loss:23.22246551513672:  79%|███████▉  | 15/19 [05:04<01:16, 19.06s/it]loss:23.22246551513672:  84%|████████▍ | 16/19 [05:04<00:57, 19.09s/it]loss:23.547405242919922:  84%|████████▍ | 16/19 [05:23<00:57, 19.09s/it]loss:23.547405242919922:  89%|████████▉ | 17/19 [05:23<00:38, 19.05s/it]loss:23.163110733032227:  89%|████████▉ | 17/19 [05:42<00:38, 19.05s/it]loss:23.163110733032227:  95%|█████████▍| 18/19 [05:42<00:19, 19.09s/it]loss:23.36203384399414:  95%|█████████▍| 18/19 [06:02<00:19, 19.09s/it] loss:23.36203384399414: 100%|██████████| 19/19 [06:02<00:00, 19.35s/it]loss:23.36203384399414: 100%|██████████| 19/19 [06:02<00:00, 19.09s/it]
Epoch: 17 cost time: 363.4249801635742
Epoch: 17, Steps: 19 | Train Loss: 23.4367706 Vali Loss: 3.2066770 Test Loss: 42.4976883
Validation loss decreased (3.206677 --> 3.206677).  Saving model ...
Updating learning rate to 1.52587890625e-09
  0%|          | 0/19 [00:00<?, ?it/s]loss:23.573841094970703:   0%|          | 0/19 [00:19<?, ?it/s]loss:23.573841094970703:   5%|▌         | 1/19 [00:19<05:49, 19.41s/it]loss:23.41314697265625:   5%|▌         | 1/19 [00:38<05:49, 19.41s/it] loss:23.41314697265625:  11%|█         | 2/19 [00:38<05:27, 19.28s/it]loss:23.513347625732422:  11%|█         | 2/19 [00:57<05:27, 19.28s/it]loss:23.513347625732422:  16%|█▌        | 3/19 [00:57<05:08, 19.30s/it]loss:23.103187561035156:  16%|█▌        | 3/19 [01:17<05:08, 19.30s/it]loss:23.103187561035156:  21%|██        | 4/19 [01:17<04:50, 19.35s/it]loss:23.299772262573242:  21%|██        | 4/19 [01:37<04:50, 19.35s/it]loss:23.299772262573242:  26%|██▋       | 5/19 [01:37<04:33, 19.54s/it]loss:23.917858123779297:  26%|██▋       | 5/19 [01:56<04:33, 19.54s/it]loss:23.917858123779297:  32%|███▏      | 6/19 [01:56<04:13, 19.51s/it]loss:23.327299118041992:  32%|███▏      | 6/19 [02:15<04:13, 19.51s/it]loss:23.327299118041992:  37%|███▋      | 7/19 [02:15<03:50, 19.23s/it]loss:23.547405242919922:  37%|███▋      | 7/19 [02:34<03:50, 19.23s/it]loss:23.547405242919922:  42%|████▏     | 8/19 [02:34<03:31, 19.24s/it]loss:23.35064697265625:  42%|████▏     | 8/19 [02:54<03:31, 19.24s/it] loss:23.35064697265625:  47%|████▋     | 9/19 [02:54<03:13, 19.32s/it]loss:23.477127075195312:  47%|████▋     | 9/19 [03:14<03:13, 19.32s/it]loss:23.477127075195312:  53%|█████▎    | 10/19 [03:14<02:56, 19.63s/it]loss:23.41031265258789:  53%|█████▎    | 10/19 [03:34<02:56, 19.63s/it] loss:23.41031265258789:  58%|█████▊    | 11/19 [03:34<02:37, 19.67s/it]loss:23.163108825683594:  58%|█████▊    | 11/19 [03:54<02:37, 19.67s/it]loss:23.163108825683594:  63%|██████▎   | 12/19 [03:54<02:18, 19.73s/it]loss:23.37876319885254:  63%|██████▎   | 12/19 [04:12<02:18, 19.73s/it] loss:23.37876319885254:  68%|██████▊   | 13/19 [04:12<01:56, 19.48s/it]loss:23.60528564453125:  68%|██████▊   | 13/19 [04:31<01:56, 19.48s/it]loss:23.60528564453125:  74%|███████▎  | 14/19 [04:31<01:36, 19.28s/it]loss:23.36203384399414:  74%|███████▎  | 14/19 [04:51<01:36, 19.28s/it]loss:23.36203384399414:  79%|███████▉  | 15/19 [04:51<01:17, 19.50s/it]loss:23.136943817138672:  79%|███████▉  | 15/19 [05:11<01:17, 19.50s/it]loss:23.136943817138672:  84%|████████▍ | 16/19 [05:11<00:58, 19.43s/it]loss:23.777742385864258:  84%|████████▍ | 16/19 [05:30<00:58, 19.43s/it]loss:23.777742385864258:  89%|████████▉ | 17/19 [05:30<00:39, 19.55s/it]loss:23.718351364135742:  89%|████████▉ | 17/19 [05:50<00:39, 19.55s/it]loss:23.718351364135742:  95%|█████████▍| 18/19 [05:50<00:19, 19.47s/it]loss:23.22246551513672:  95%|█████████▍| 18/19 [06:09<00:19, 19.47s/it] loss:23.22246551513672: 100%|██████████| 19/19 [06:09<00:00, 19.34s/it]loss:23.22246551513672: 100%|██████████| 19/19 [06:09<00:00, 19.43s/it]
Epoch: 18 cost time: 369.8631775379181
Epoch: 18, Steps: 19 | Train Loss: 23.4367705 Vali Loss: 3.2066770 Test Loss: 42.4976883
Validation loss decreased (3.206677 --> 3.206677).  Saving model ...
Updating learning rate to 7.62939453125e-10
  0%|          | 0/19 [00:00<?, ?it/s]loss:23.917858123779297:   0%|          | 0/19 [00:19<?, ?it/s]loss:23.917858123779297:   5%|▌         | 1/19 [00:19<05:47, 19.32s/it]loss:23.327299118041992:   5%|▌         | 1/19 [00:38<05:47, 19.32s/it]loss:23.327299118041992:  11%|█         | 2/19 [00:38<05:29, 19.40s/it]loss:23.103187561035156:  11%|█         | 2/19 [00:57<05:29, 19.40s/it]loss:23.103187561035156:  16%|█▌        | 3/19 [00:57<05:07, 19.24s/it]loss:23.299772262573242:  16%|█▌        | 3/19 [01:16<05:07, 19.24s/it]loss:23.299772262573242:  21%|██        | 4/19 [01:16<04:47, 19.17s/it]loss:23.22246551513672:  21%|██        | 4/19 [01:36<04:47, 19.17s/it] loss:23.22246551513672:  26%|██▋       | 5/19 [01:36<04:32, 19.47s/it]loss:23.477127075195312:  26%|██▋       | 5/19 [01:57<04:32, 19.47s/it]loss:23.477127075195312:  32%|███▏      | 6/19 [01:57<04:17, 19.78s/it]loss:23.37876319885254:  32%|███▏      | 6/19 [02:16<04:17, 19.78s/it] loss:23.37876319885254:  37%|███▋      | 7/19 [02:16<03:53, 19.47s/it]loss:23.718351364135742:  37%|███▋      | 7/19 [02:35<03:53, 19.47s/it]loss:23.718351364135742:  42%|████▏     | 8/19 [02:35<03:33, 19.42s/it]loss:23.136943817138672:  42%|████▏     | 8/19 [02:54<03:33, 19.42s/it]loss:23.136943817138672:  47%|████▋     | 9/19 [02:54<03:14, 19.46s/it]loss:23.513347625732422:  47%|████▋     | 9/19 [03:14<03:14, 19.46s/it]loss:23.513347625732422:  53%|█████▎    | 10/19 [03:14<02:56, 19.63s/it]loss:23.547405242919922:  53%|█████▎    | 10/19 [03:34<02:56, 19.63s/it]loss:23.547405242919922:  58%|█████▊    | 11/19 [03:34<02:37, 19.66s/it]loss:23.41031265258789:  58%|█████▊    | 11/19 [03:54<02:37, 19.66s/it] loss:23.41031265258789:  63%|██████▎   | 12/19 [03:54<02:17, 19.66s/it]loss:23.777742385864258:  63%|██████▎   | 12/19 [04:14<02:17, 19.66s/it]loss:23.777742385864258:  68%|██████▊   | 13/19 [04:14<01:58, 19.73s/it]loss:23.35064697265625:  68%|██████▊   | 13/19 [04:33<01:58, 19.73s/it] loss:23.35064697265625:  74%|███████▎  | 14/19 [04:33<01:37, 19.52s/it]loss:23.60528564453125:  74%|███████▎  | 14/19 [04:53<01:37, 19.52s/it]loss:23.60528564453125:  79%|███████▉  | 15/19 [04:53<01:18, 19.61s/it]loss:23.163108825683594:  79%|███████▉  | 15/19 [05:12<01:18, 19.61s/it]loss:23.163108825683594:  84%|████████▍ | 16/19 [05:12<00:58, 19.52s/it]loss:23.36203384399414:  84%|████████▍ | 16/19 [05:31<00:58, 19.52s/it] loss:23.36203384399414:  89%|████████▉ | 17/19 [05:31<00:38, 19.47s/it]loss:23.41314697265625:  89%|████████▉ | 17/19 [05:51<00:38, 19.47s/it]loss:23.41314697265625:  95%|█████████▍| 18/19 [05:51<00:19, 19.54s/it]loss:23.573841094970703:  95%|█████████▍| 18/19 [06:11<00:19, 19.54s/it]loss:23.573841094970703: 100%|██████████| 19/19 [06:11<00:00, 19.60s/it]loss:23.573841094970703: 100%|██████████| 19/19 [06:11<00:00, 19.54s/it]
Epoch: 19 cost time: 371.92804884910583
Epoch: 19, Steps: 19 | Train Loss: 23.4367705 Vali Loss: 3.2066770 Test Loss: 42.4976883
Validation loss decreased (3.206677 --> 3.206677).  Saving model ...
Updating learning rate to 3.814697265625e-10
  0%|          | 0/19 [00:00<?, ?it/s]loss:23.547405242919922:   0%|          | 0/19 [00:19<?, ?it/s]loss:23.547405242919922:   5%|▌         | 1/19 [00:19<05:52, 19.60s/it]loss:23.60528564453125:   5%|▌         | 1/19 [00:38<05:52, 19.60s/it] loss:23.60528564453125:  11%|█         | 2/19 [00:38<05:25, 19.15s/it]loss:23.299772262573242:  11%|█         | 2/19 [00:57<05:25, 19.15s/it]loss:23.299772262573242:  16%|█▌        | 3/19 [00:57<05:05, 19.12s/it]loss:23.573841094970703:  16%|█▌        | 3/19 [01:17<05:05, 19.12s/it]loss:23.573841094970703:  21%|██        | 4/19 [01:17<04:50, 19.34s/it]loss:23.163108825683594:  21%|██        | 4/19 [01:35<04:50, 19.34s/it]loss:23.163108825683594:  26%|██▋       | 5/19 [01:35<04:28, 19.15s/it]loss:23.22246551513672:  26%|██▋       | 5/19 [01:55<04:28, 19.15s/it] loss:23.22246551513672:  32%|███▏      | 6/19 [01:55<04:10, 19.28s/it]loss:23.718351364135742:  32%|███▏      | 6/19 [02:15<04:10, 19.28s/it]loss:23.718351364135742:  37%|███▋      | 7/19 [02:15<03:52, 19.39s/it]loss:23.917858123779297:  37%|███▋      | 7/19 [02:33<03:52, 19.39s/it]loss:23.917858123779297:  42%|████▏     | 8/19 [02:33<03:31, 19.20s/it]loss:23.136943817138672:  42%|████▏     | 8/19 [02:53<03:31, 19.20s/it]loss:23.136943817138672:  47%|████▋     | 9/19 [02:53<03:13, 19.31s/it]loss:23.36203384399414:  47%|████▋     | 9/19 [03:12<03:13, 19.31s/it] loss:23.36203384399414:  53%|█████▎    | 10/19 [03:12<02:52, 19.18s/it]loss:23.777742385864258:  53%|█████▎    | 10/19 [03:31<02:52, 19.18s/it]loss:23.777742385864258:  58%|█████▊    | 11/19 [03:31<02:33, 19.23s/it]loss:23.477127075195312:  58%|█████▊    | 11/19 [03:49<02:33, 19.23s/it]loss:23.477127075195312:  63%|██████▎   | 12/19 [03:49<02:12, 18.93s/it]loss:23.103187561035156:  63%|██████▎   | 12/19 [04:09<02:12, 18.93s/it]loss:23.103187561035156:  68%|██████▊   | 13/19 [04:09<01:54, 19.03s/it]loss:23.35064697265625:  68%|██████▊   | 13/19 [04:27<01:54, 19.03s/it] loss:23.35064697265625:  74%|███████▎  | 14/19 [04:27<01:34, 18.92s/it]loss:23.37876319885254:  74%|███████▎  | 14/19 [04:49<01:34, 18.92s/it]loss:23.37876319885254:  79%|███████▉  | 15/19 [04:49<01:18, 19.74s/it]loss:23.41314697265625:  79%|███████▉  | 15/19 [05:09<01:18, 19.74s/it]loss:23.41314697265625:  84%|████████▍ | 16/19 [05:09<00:59, 19.72s/it]loss:23.327299118041992:  84%|████████▍ | 16/19 [05:28<00:59, 19.72s/it]loss:23.327299118041992:  89%|████████▉ | 17/19 [05:28<00:39, 19.62s/it]loss:23.513347625732422:  89%|████████▉ | 17/19 [05:47<00:39, 19.62s/it]loss:23.513347625732422:  95%|█████████▍| 18/19 [05:47<00:19, 19.34s/it]loss:23.41031265258789:  95%|█████████▍| 18/19 [06:06<00:19, 19.34s/it] loss:23.41031265258789: 100%|██████████| 19/19 [06:06<00:00, 19.39s/it]loss:23.41031265258789: 100%|██████████| 19/19 [06:06<00:00, 19.31s/it]
Epoch: 20 cost time: 367.44920802116394
Epoch: 20, Steps: 19 | Train Loss: 23.4367705 Vali Loss: 3.2066770 Test Loss: 42.4976883
Validation loss decreased (3.206677 --> 3.206677).  Saving model ...
Updating learning rate to 1.9073486328125e-10
>>>>>>>testing : long_term_forecast_low_0_DLinear_job_demand_region_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 4
test shape: (4, 1, 3, 16345) (4, 1, 3, 16345)
test shape: (4, 3, 16345) (4, 3, 16345)
mse:51490.22265625, mae:35.050777435302734, dtw:-999
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           0                   Model:              DLinear             

[1mData Loader[0m
  Data:               job_demand_r1       Root Path:          ../../dataset/demand/
  Data Path:          r1.parquet          Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        .cache/checkpoints  

[1mForecasting Task[0m
  Seq Len:            6                   Label Len:          1                   
  Pred Len:           3                   Seasonal Patterns:  Monthly             
  Inverse:            1                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             32690               Dec In:             32690               
  C Out:              32690               d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           2                   d FF:               2048                
  Moving Avg:         25                  Factor:             1                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              learned             Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        32                  Itr:                1                   
  Train Epochs:       20                  Batch Size:         1                   
  Patience:           3                   Learning Rate:      0.0001              
  Des:                test                Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            0                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1                 

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use CPU
>>>>>>>start training : long_term_forecast_low_0_DLinear_job_demand_r1_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 19
val 1
test 4
  0%|          | 0/19 [00:00<?, ?it/s]loss:24.226362228393555:   0%|          | 0/19 [01:14<?, ?it/s]loss:24.226362228393555:   5%|▌         | 1/19 [01:14<22:15, 74.22s/it]loss:24.42880630493164:   5%|▌         | 1/19 [02:24<22:15, 74.22s/it] loss:24.42880630493164:  11%|█         | 2/19 [02:24<20:17, 71.61s/it]loss:24.578750610351562:  11%|█         | 2/19 [03:37<20:17, 71.61s/it]loss:24.578750610351562:  16%|█▌        | 3/19 [03:37<19:22, 72.63s/it]loss:24.43031120300293:  16%|█▌        | 3/19 [04:50<19:22, 72.63s/it] loss:24.43031120300293:  21%|██        | 4/19 [04:50<18:10, 72.68s/it]loss:24.23719596862793:  21%|██        | 4/19 [06:02<18:10, 72.68s/it]loss:24.23719596862793:  26%|██▋       | 5/19 [06:02<16:52, 72.30s/it]loss:24.319927215576172:  26%|██▋       | 5/19 [07:12<16:52, 72.30s/it]loss:24.319927215576172:  32%|███▏      | 6/19 [07:12<15:30, 71.57s/it]loss:24.647546768188477:  32%|███▏      | 6/19 [08:23<15:30, 71.57s/it]loss:24.647546768188477:  37%|███▋      | 7/19 [08:23<14:17, 71.47s/it]loss:24.35173797607422:  37%|███▋      | 7/19 [09:34<14:17, 71.47s/it] loss:24.35173797607422:  42%|████▏     | 8/19 [09:34<13:03, 71.23s/it]loss:24.20153045654297:  42%|████▏     | 8/19 [10:46<13:03, 71.23s/it]loss:24.20153045654297:  47%|████▋     | 9/19 [10:46<11:54, 71.46s/it]loss:24.52758026123047:  47%|████▋     | 9/19 [11:59<11:54, 71.46s/it]loss:24.52758026123047:  53%|█████▎    | 10/19 [11:59<10:48, 72.07s/it]loss:24.35738182067871:  53%|█████▎    | 10/19 [13:14<10:48, 72.07s/it]loss:24.35738182067871:  58%|█████▊    | 11/19 [13:14<09:43, 72.96s/it]loss:24.42972183227539:  58%|█████▊    | 11/19 [14:30<09:43, 72.96s/it]loss:24.42972183227539:  63%|██████▎   | 12/19 [14:30<08:37, 73.94s/it]loss:24.36419677734375:  63%|██████▎   | 12/19 [15:44<08:37, 73.94s/it]loss:24.36419677734375:  68%|██████▊   | 13/19 [15:44<07:23, 73.93s/it]loss:24.326404571533203:  68%|██████▊   | 13/19 [16:58<07:23, 73.93s/it]loss:24.326404571533203:  74%|███████▎  | 14/19 [16:58<06:09, 73.84s/it]loss:24.377634048461914:  74%|███████▎  | 14/19 [18:09<06:09, 73.84s/it]loss:24.377634048461914:  79%|███████▉  | 15/19 [18:09<04:52, 73.14s/it]loss:24.56690216064453:  79%|███████▉  | 15/19 [19:24<04:52, 73.14s/it] loss:24.56690216064453:  84%|████████▍ | 16/19 [19:24<03:40, 73.49s/it]loss:24.325929641723633:  84%|████████▍ | 16/19 [20:41<03:40, 73.49s/it]loss:24.325929641723633:  89%|████████▉ | 17/19 [20:41<02:29, 74.63s/it]loss:24.74164581298828:  89%|████████▉ | 17/19 [21:56<02:29, 74.63s/it] loss:24.74164581298828:  95%|█████████▍| 18/19 [21:56<01:14, 74.63s/it]loss:24.601146697998047:  95%|█████████▍| 18/19 [23:14<01:14, 74.63s/it]loss:24.601146697998047: 100%|██████████| 19/19 [23:14<00:00, 75.63s/it]loss:24.601146697998047: 100%|██████████| 19/19 [23:14<00:00, 73.38s/it]
Epoch: 1 cost time: 1394.9801638126373
Epoch: 1, Steps: 19 | Train Loss: 24.4231954 Vali Loss: 3.9349673 Test Loss: 69.5881958
Validation loss decreased (inf --> 3.934967).  Saving model ...
Updating learning rate to 0.0001
  0%|          | 0/19 [00:00<?, ?it/s]loss:24.505226135253906:   0%|          | 0/19 [01:14<?, ?it/s]loss:24.505226135253906:   5%|▌         | 1/19 [01:14<22:24, 74.70s/it]loss:24.397682189941406:   5%|▌         | 1/19 [02:32<22:24, 74.70s/it]loss:24.397682189941406:  11%|█         | 2/19 [02:32<21:38, 76.41s/it]loss:24.310226440429688:  11%|█         | 2/19 [03:47<21:38, 76.41s/it]loss:24.310226440429688:  16%|█▌        | 3/19 [03:47<20:13, 75.86s/it]loss:24.511287689208984:  16%|█▌        | 3/19 [05:07<20:13, 75.86s/it]loss:24.511287689208984:  21%|██        | 4/19 [05:07<19:23, 77.57s/it]loss:24.416061401367188:  21%|██        | 4/19 [06:21<19:23, 77.57s/it]loss:24.416061401367188:  26%|██▋       | 5/19 [06:21<17:44, 76.07s/it]loss:24.42180061340332:  26%|██▋       | 5/19 [07:28<17:44, 76.07s/it] loss:24.42180061340332:  32%|███▏      | 6/19 [07:28<15:52, 73.26s/it]loss:24.48950958251953:  32%|███▏      | 6/19 [08:35<15:52, 73.26s/it]loss:24.48950958251953:  37%|███▋      | 7/19 [08:35<14:13, 71.11s/it]loss:24.408828735351562:  37%|███▋      | 7/19 [09:40<14:13, 71.11s/it]loss:24.408828735351562:  42%|████▏     | 8/19 [09:40<12:39, 69.08s/it]loss:24.281818389892578:  42%|████▏     | 8/19 [10:47<12:39, 69.08s/it]loss:24.281818389892578:  47%|████▋     | 9/19 [10:47<11:25, 68.52s/it]loss:24.607131958007812:  47%|████▋     | 9/19 [11:55<11:25, 68.52s/it]loss:24.607131958007812:  53%|█████▎    | 10/19 [11:55<10:14, 68.32s/it]loss:24.380168914794922:  53%|█████▎    | 10/19 [13:05<10:14, 68.32s/it]loss:24.380168914794922:  58%|█████▊    | 11/19 [13:05<09:11, 68.93s/it]loss:24.35565757751465:  58%|█████▊    | 11/19 [14:11<09:11, 68.93s/it] loss:24.35565757751465:  63%|██████▎   | 12/19 [14:11<07:54, 67.81s/it]loss:24.655385971069336:  63%|██████▎   | 12/19 [15:17<07:54, 67.81s/it]loss:24.655385971069336:  68%|██████▊   | 13/19 [15:17<06:44, 67.38s/it]loss:24.750350952148438:  68%|██████▊   | 13/19 [16:23<06:44, 67.38s/it]loss:24.750350952148438:  74%|███████▎  | 14/19 [16:23<05:35, 67.05s/it]loss:24.808155059814453:  74%|███████▎  | 14/19 [17:34<05:35, 67.05s/it]loss:24.808155059814453:  79%|███████▉  | 15/19 [17:34<04:32, 68.12s/it]loss:24.458484649658203:  79%|███████▉  | 15/19 [18:40<04:32, 68.12s/it]loss:24.458484649658203:  84%|████████▍ | 16/19 [18:40<03:22, 67.43s/it]loss:24.651294708251953:  84%|████████▍ | 16/19 [19:46<03:22, 67.43s/it]loss:24.651294708251953:  89%|████████▉ | 17/19 [19:46<02:14, 67.04s/it]loss:24.424787521362305:  89%|████████▉ | 17/19 [21:00<02:14, 67.04s/it]loss:24.424787521362305:  95%|█████████▍| 18/19 [21:00<01:09, 69.25s/it]loss:24.72784423828125:  95%|█████████▍| 18/19 [22:11<01:09, 69.25s/it] loss:24.72784423828125: 100%|██████████| 19/19 [22:11<00:00, 69.59s/it]loss:24.72784423828125: 100%|██████████| 19/19 [22:11<00:00, 70.06s/it]
Epoch: 2 cost time: 1331.7992613315582
Epoch: 2, Steps: 19 | Train Loss: 24.5032475 Vali Loss: 3.9315646 Test Loss: 69.6374588
Validation loss decreased (3.934967 --> 3.931565).  Saving model ...
Updating learning rate to 5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:24.417938232421875:   0%|          | 0/19 [01:11<?, ?it/s]loss:24.417938232421875:   5%|▌         | 1/19 [01:11<21:32, 71.79s/it]loss:24.385711669921875:   5%|▌         | 1/19 [02:23<21:32, 71.79s/it]loss:24.385711669921875:  11%|█         | 2/19 [02:23<20:17, 71.60s/it]loss:24.590232849121094:  11%|█         | 2/19 [03:39<20:17, 71.60s/it]loss:24.590232849121094:  16%|█▌        | 3/19 [03:39<19:39, 73.73s/it]loss:24.780439376831055:  16%|█▌        | 3/19 [04:50<19:39, 73.73s/it]loss:24.780439376831055:  21%|██        | 4/19 [04:50<18:11, 72.75s/it]loss:24.468345642089844:  21%|██        | 4/19 [06:03<18:11, 72.75s/it]loss:24.468345642089844:  26%|██▋       | 5/19 [06:03<16:57, 72.67s/it]loss:24.339115142822266:  26%|██▋       | 5/19 [07:16<16:57, 72.67s/it]loss:24.339115142822266:  32%|███▏      | 6/19 [07:16<15:45, 72.71s/it]loss:24.491941452026367:  32%|███▏      | 6/19 [08:26<15:45, 72.71s/it]loss:24.491941452026367:  37%|███▋      | 7/19 [08:26<14:24, 72.08s/it]loss:24.594341278076172:  37%|███▋      | 7/19 [09:41<14:24, 72.08s/it]loss:24.594341278076172:  42%|████▏     | 8/19 [09:41<13:20, 72.81s/it]loss:24.450666427612305:  42%|████▏     | 8/19 [10:57<13:20, 72.81s/it]loss:24.450666427612305:  47%|████▋     | 9/19 [10:57<12:18, 73.87s/it]loss:24.49468231201172:  47%|████▋     | 9/19 [12:08<12:18, 73.87s/it] loss:24.49468231201172:  53%|█████▎    | 10/19 [12:08<10:57, 73.08s/it]loss:24.412092208862305:  53%|█████▎    | 10/19 [13:19<10:57, 73.08s/it]loss:24.412092208862305:  58%|█████▊    | 11/19 [13:19<09:38, 72.30s/it]loss:24.568405151367188:  58%|█████▊    | 11/19 [14:32<09:38, 72.30s/it]loss:24.568405151367188:  63%|██████▎   | 12/19 [14:32<08:28, 72.58s/it]loss:24.85419273376465:  63%|██████▎   | 12/19 [15:44<08:28, 72.58s/it] loss:24.85419273376465:  68%|██████▊   | 13/19 [15:44<07:14, 72.45s/it]loss:24.691564559936523:  68%|██████▊   | 13/19 [16:57<07:14, 72.45s/it]loss:24.691564559936523:  74%|███████▎  | 14/19 [16:57<06:03, 72.61s/it]loss:24.502365112304688:  74%|███████▎  | 14/19 [18:08<06:03, 72.61s/it]loss:24.502365112304688:  79%|███████▉  | 15/19 [18:08<04:48, 72.16s/it]loss:24.511611938476562:  79%|███████▉  | 15/19 [19:21<04:48, 72.16s/it]loss:24.511611938476562:  84%|████████▍ | 16/19 [19:21<03:37, 72.40s/it]loss:24.766313552856445:  84%|████████▍ | 16/19 [20:37<03:37, 72.40s/it]loss:24.766313552856445:  89%|████████▉ | 17/19 [20:37<02:26, 73.48s/it]loss:24.720508575439453:  89%|████████▉ | 17/19 [21:49<02:26, 73.48s/it]loss:24.720508575439453:  95%|█████████▍| 18/19 [21:49<01:13, 73.12s/it]loss:24.687108993530273:  95%|█████████▍| 18/19 [23:02<01:13, 73.12s/it]loss:24.687108993530273: 100%|██████████| 19/19 [23:02<00:00, 73.02s/it]loss:24.687108993530273: 100%|██████████| 19/19 [23:03<00:00, 72.83s/it]
Epoch: 3 cost time: 1384.3847486972809
Epoch: 3, Steps: 19 | Train Loss: 24.5646093 Vali Loss: 3.9299037 Test Loss: 69.6602020
Validation loss decreased (3.931565 --> 3.929904).  Saving model ...
Updating learning rate to 2.5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:24.772811889648438:   0%|          | 0/19 [01:11<?, ?it/s]loss:24.772811889648438:   5%|▌         | 1/19 [01:11<21:20, 71.17s/it]loss:24.72590446472168:   5%|▌         | 1/19 [02:25<21:20, 71.17s/it] loss:24.72590446472168:  11%|█         | 2/19 [02:25<20:41, 73.06s/it]loss:24.691438674926758:  11%|█         | 2/19 [03:37<20:41, 73.06s/it]loss:24.691438674926758:  16%|█▌        | 3/19 [03:37<19:17, 72.37s/it]loss:24.516311645507812:  16%|█▌        | 3/19 [04:49<19:17, 72.37s/it]loss:24.516311645507812:  21%|██        | 4/19 [04:49<18:07, 72.47s/it]loss:24.3731689453125:  21%|██        | 4/19 [06:02<18:07, 72.47s/it]  loss:24.3731689453125:  26%|██▋       | 5/19 [06:02<16:56, 72.59s/it]loss:24.52584457397461:  26%|██▋       | 5/19 [07:16<16:56, 72.59s/it]loss:24.52584457397461:  32%|███▏      | 6/19 [07:16<15:49, 73.01s/it]loss:24.464183807373047:  32%|███▏      | 6/19 [08:30<15:49, 73.01s/it]loss:24.464183807373047:  37%|███▋      | 7/19 [08:30<14:38, 73.24s/it]loss:24.876522064208984:  37%|███▋      | 7/19 [09:44<14:38, 73.24s/it]loss:24.876522064208984:  42%|████▏     | 8/19 [09:44<13:29, 73.63s/it]loss:24.713134765625:  42%|████▏     | 8/19 [10:58<13:29, 73.63s/it]   loss:24.713134765625:  47%|████▋     | 9/19 [10:58<12:16, 73.64s/it]loss:24.528303146362305:  47%|████▋     | 9/19 [12:12<12:16, 73.64s/it]loss:24.528303146362305:  53%|█████▎    | 10/19 [12:12<11:03, 73.73s/it]loss:24.630828857421875:  53%|█████▎    | 10/19 [13:29<11:03, 73.73s/it]loss:24.630828857421875:  58%|█████▊    | 11/19 [13:29<09:59, 74.98s/it]loss:24.436752319335938:  58%|█████▊    | 11/19 [14:48<09:59, 74.98s/it]loss:24.436752319335938:  63%|██████▎   | 12/19 [14:48<08:51, 75.95s/it]loss:24.51320457458496:  63%|██████▎   | 12/19 [16:01<08:51, 75.95s/it] loss:24.51320457458496:  68%|██████▊   | 13/19 [16:01<07:31, 75.22s/it]loss:24.640445709228516:  68%|██████▊   | 13/19 [17:11<07:31, 75.22s/it]loss:24.640445709228516:  74%|███████▎  | 14/19 [17:11<06:08, 73.67s/it]loss:24.826446533203125:  74%|███████▎  | 14/19 [18:24<06:08, 73.67s/it]loss:24.826446533203125:  79%|███████▉  | 15/19 [18:24<04:53, 73.44s/it]loss:24.53209114074707:  79%|███████▉  | 15/19 [19:35<04:53, 73.44s/it] loss:24.53209114074707:  84%|████████▍ | 16/19 [19:35<03:37, 72.57s/it]loss:24.491683959960938:  84%|████████▍ | 16/19 [20:45<03:37, 72.57s/it]loss:24.491683959960938:  89%|████████▉ | 17/19 [20:45<02:23, 71.80s/it]loss:24.604135513305664:  89%|████████▉ | 17/19 [21:54<02:23, 71.80s/it]loss:24.604135513305664:  95%|█████████▍| 18/19 [21:54<01:11, 71.07s/it]loss:24.45155143737793:  95%|█████████▍| 18/19 [23:04<01:11, 71.07s/it] loss:24.45155143737793: 100%|██████████| 19/19 [23:04<00:00, 70.80s/it]loss:24.45155143737793: 100%|██████████| 19/19 [23:04<00:00, 72.88s/it]
Epoch: 4 cost time: 1385.4699311256409
Epoch: 4, Steps: 19 | Train Loss: 24.5955139 Vali Loss: 3.9291120 Test Loss: 69.6768341
Validation loss decreased (3.929904 --> 3.929112).  Saving model ...
Updating learning rate to 1.25e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:24.745006561279297:   0%|          | 0/19 [01:08<?, ?it/s]loss:24.745006561279297:   5%|▌         | 1/19 [01:08<20:28, 68.26s/it]loss:24.495397567749023:   5%|▌         | 1/19 [02:17<20:28, 68.26s/it]loss:24.495397567749023:  11%|█         | 2/19 [02:17<19:27, 68.70s/it]loss:24.534284591674805:  11%|█         | 2/19 [03:25<19:27, 68.70s/it]loss:24.534284591674805:  16%|█▌        | 3/19 [03:25<18:14, 68.38s/it]loss:24.642019271850586:  16%|█▌        | 3/19 [04:35<18:14, 68.38s/it]loss:24.642019271850586:  21%|██        | 4/19 [04:35<17:17, 69.18s/it]loss:24.522727966308594:  21%|██        | 4/19 [05:49<17:17, 69.18s/it]loss:24.522727966308594:  26%|██▋       | 5/19 [05:49<16:32, 70.92s/it]loss:24.795875549316406:  26%|██▋       | 5/19 [07:01<16:32, 70.92s/it]loss:24.795875549316406:  32%|███▏      | 6/19 [07:01<15:27, 71.34s/it]loss:24.712535858154297:  32%|███▏      | 6/19 [08:15<15:27, 71.34s/it]loss:24.712535858154297:  37%|███▋      | 7/19 [08:15<14:23, 72.00s/it]loss:24.542245864868164:  37%|███▋      | 7/19 [09:35<14:23, 72.00s/it]loss:24.542245864868164:  42%|████▏     | 8/19 [09:35<13:39, 74.54s/it]loss:24.54047393798828:  42%|████▏     | 8/19 [10:49<13:39, 74.54s/it] loss:24.54047393798828:  47%|████▋     | 9/19 [10:49<12:24, 74.48s/it]loss:24.457433700561523:  47%|████▋     | 9/19 [12:03<12:24, 74.48s/it]loss:24.457433700561523:  53%|█████▎    | 10/19 [12:03<11:07, 74.17s/it]loss:24.894309997558594:  53%|█████▎    | 10/19 [13:17<11:07, 74.17s/it]loss:24.894309997558594:  58%|█████▊    | 11/19 [13:17<09:55, 74.38s/it]loss:24.652616500854492:  58%|█████▊    | 11/19 [14:33<09:55, 74.38s/it]loss:24.652616500854492:  63%|██████▎   | 12/19 [14:33<08:43, 74.82s/it]loss:24.83734703063965:  63%|██████▎   | 12/19 [15:49<08:43, 74.82s/it] loss:24.83734703063965:  68%|██████▊   | 13/19 [15:49<07:31, 75.20s/it]loss:24.547744750976562:  68%|██████▊   | 13/19 [17:03<07:31, 75.20s/it]loss:24.547744750976562:  74%|███████▎  | 14/19 [17:03<06:14, 74.87s/it]loss:24.45294761657715:  74%|███████▎  | 14/19 [18:17<06:14, 74.87s/it] loss:24.45294761657715:  79%|███████▉  | 15/19 [18:17<04:58, 74.50s/it]loss:24.614242553710938:  79%|███████▉  | 15/19 [19:30<04:58, 74.50s/it]loss:24.614242553710938:  84%|████████▍ | 16/19 [19:30<03:42, 74.06s/it]loss:24.486225128173828:  84%|████████▍ | 16/19 [20:50<03:42, 74.06s/it]loss:24.486225128173828:  89%|████████▉ | 17/19 [20:50<02:31, 75.74s/it]loss:24.398204803466797:  89%|████████▉ | 17/19 [22:07<02:31, 75.74s/it]loss:24.398204803466797:  95%|█████████▍| 18/19 [22:07<01:16, 76.17s/it]loss:24.734312057495117:  95%|█████████▍| 18/19 [23:25<01:16, 76.17s/it]loss:24.734312057495117: 100%|██████████| 19/19 [23:25<00:00, 76.62s/it]loss:24.734312057495117: 100%|██████████| 19/19 [23:25<00:00, 73.95s/it]
Epoch: 5 cost time: 1405.7400164604187
Epoch: 5, Steps: 19 | Train Loss: 24.6108395 Vali Loss: 3.9287038 Test Loss: 69.6820908
Validation loss decreased (3.929112 --> 3.928704).  Saving model ...
Updating learning rate to 6.25e-06
  0%|          | 0/19 [00:00<?, ?it/s]loss:24.734834671020508:   0%|          | 0/19 [01:16<?, ?it/s]loss:24.734834671020508:   5%|▌         | 1/19 [01:16<22:52, 76.23s/it]loss:24.6571102142334:   5%|▌         | 1/19 [02:30<22:52, 76.23s/it]  loss:24.6571102142334:  11%|█         | 2/19 [02:30<21:12, 74.84s/it]loss:24.803863525390625:  11%|█         | 2/19 [03:46<21:12, 74.84s/it]loss:24.803863525390625:  16%|█▌        | 3/19 [03:46<20:05, 75.37s/it]loss:24.841554641723633:  16%|█▌        | 3/19 [05:00<20:05, 75.37s/it]loss:24.841554641723633:  21%|██        | 4/19 [05:00<18:46, 75.12s/it]loss:24.551984786987305:  21%|██        | 4/19 [06:17<18:46, 75.12s/it]loss:24.551984786987305:  26%|██▋       | 5/19 [06:17<17:41, 75.84s/it]loss:24.45696449279785:  26%|██▋       | 5/19 [07:37<17:41, 75.84s/it] loss:24.45696449279785:  32%|███▏      | 6/19 [07:37<16:41, 77.03s/it]loss:24.617961883544922:  32%|███▏      | 6/19 [08:56<16:41, 77.03s/it]loss:24.617961883544922:  37%|███▋      | 7/19 [08:56<15:33, 77.76s/it]loss:24.40111541748047:  37%|███▋      | 7/19 [10:10<15:33, 77.76s/it] loss:24.40111541748047:  42%|████▏     | 8/19 [10:10<14:02, 76.61s/it]loss:24.65264892578125:  42%|████▏     | 8/19 [11:27<14:02, 76.61s/it]loss:24.65264892578125:  47%|████▋     | 9/19 [11:27<12:47, 76.73s/it]loss:24.533065795898438:  47%|████▋     | 9/19 [12:46<12:47, 76.73s/it]loss:24.533065795898438:  53%|█████▎    | 10/19 [12:46<11:37, 77.45s/it]loss:24.757537841796875:  53%|█████▎    | 10/19 [14:03<11:37, 77.45s/it]loss:24.757537841796875:  58%|█████▊    | 11/19 [14:03<10:17, 77.16s/it]loss:24.722251892089844:  58%|█████▊    | 11/19 [15:19<10:17, 77.16s/it]loss:24.722251892089844:  63%|██████▎   | 12/19 [15:19<08:58, 76.94s/it]loss:24.46608543395996:  63%|██████▎   | 12/19 [16:37<08:58, 76.94s/it] loss:24.46608543395996:  68%|██████▊   | 13/19 [16:37<07:43, 77.31s/it]loss:24.902400970458984:  68%|██████▊   | 13/19 [17:54<07:43, 77.31s/it]loss:24.902400970458984:  74%|███████▎  | 14/19 [17:54<06:26, 77.24s/it]loss:24.546842575073242:  74%|███████▎  | 14/19 [19:15<06:26, 77.24s/it]loss:24.546842575073242:  79%|███████▉  | 15/19 [19:15<05:13, 78.26s/it]loss:24.55025863647461:  79%|███████▉  | 15/19 [20:35<05:13, 78.26s/it] loss:24.55025863647461:  84%|████████▍ | 16/19 [20:35<03:56, 78.82s/it]loss:24.509279251098633:  84%|████████▍ | 16/19 [21:53<03:56, 78.82s/it]loss:24.509279251098633:  89%|████████▉ | 17/19 [21:53<02:37, 78.54s/it]loss:24.49221420288086:  89%|████████▉ | 17/19 [23:11<02:37, 78.54s/it] loss:24.49221420288086:  95%|█████████▍| 18/19 [23:11<01:18, 78.26s/it]loss:24.553091049194336:  95%|█████████▍| 18/19 [24:26<01:18, 78.26s/it]loss:24.553091049194336: 100%|██████████| 19/19 [24:26<00:00, 77.50s/it]loss:24.553091049194336: 100%|██████████| 19/19 [24:26<00:00, 77.21s/it]
Epoch: 6 cost time: 1467.6600079536438
Epoch: 6, Steps: 19 | Train Loss: 24.6184772 Vali Loss: 3.9284937 Test Loss: 69.6852036
Validation loss decreased (3.928704 --> 3.928494).  Saving model ...
Updating learning rate to 3.125e-06
  0%|          | 0/19 [00:00<?, ?it/s]loss:24.66188621520996:   0%|          | 0/19 [01:17<?, ?it/s]loss:24.66188621520996:   5%|▌         | 1/19 [01:17<23:19, 77.73s/it]loss:24.76001739501953:   5%|▌         | 1/19 [02:37<23:19, 77.73s/it]loss:24.76001739501953:  11%|█         | 2/19 [02:37<22:18, 78.72s/it]loss:24.460983276367188:  11%|█         | 2/19 [03:55<22:18, 78.72s/it]loss:24.460983276367188:  16%|█▌        | 3/19 [03:55<20:53, 78.33s/it]loss:24.468358993530273:  16%|█▌        | 3/19 [05:11<20:53, 78.33s/it]loss:24.468358993530273:  21%|██        | 4/19 [05:11<19:22, 77.49s/it]loss:24.493227005004883:  21%|██        | 4/19 [06:30<19:22, 77.49s/it]loss:24.493227005004883:  26%|██▋       | 5/19 [06:30<18:14, 78.17s/it]loss:24.404911041259766:  26%|██▋       | 5/19 [07:47<18:14, 78.17s/it]loss:24.404911041259766:  32%|███▏      | 6/19 [07:47<16:52, 77.89s/it]loss:24.536479949951172:  32%|███▏      | 6/19 [09:06<16:52, 77.89s/it]loss:24.536479949951172:  37%|███▋      | 7/19 [09:06<15:36, 78.04s/it]loss:24.55217742919922:  37%|███▋      | 7/19 [10:29<15:36, 78.04s/it] loss:24.55217742919922:  42%|████▏     | 8/19 [10:29<14:37, 79.78s/it]loss:24.55698013305664:  42%|████▏     | 8/19 [11:48<14:37, 79.78s/it]loss:24.55698013305664:  47%|████▋     | 9/19 [11:48<13:14, 79.45s/it]loss:24.74099349975586:  47%|████▋     | 9/19 [13:11<13:14, 79.45s/it]loss:24.74099349975586:  53%|█████▎    | 10/19 [13:11<12:05, 80.56s/it]loss:24.84671974182129:  53%|█████▎    | 10/19 [14:31<12:05, 80.56s/it]loss:24.84671974182129:  58%|█████▊    | 11/19 [14:31<10:42, 80.29s/it]loss:24.511457443237305:  58%|█████▊    | 11/19 [15:54<10:42, 80.29s/it]loss:24.511457443237305:  63%|██████▎   | 12/19 [15:54<09:29, 81.32s/it]loss:24.549636840820312:  63%|██████▎   | 12/19 [17:17<09:29, 81.32s/it]loss:24.549636840820312:  68%|██████▊   | 13/19 [17:17<08:10, 81.83s/it]loss:24.90557861328125:  68%|██████▊   | 13/19 [18:42<08:10, 81.83s/it] loss:24.90557861328125:  74%|███████▎  | 14/19 [18:42<06:53, 82.61s/it]loss:24.810192108154297:  74%|███████▎  | 14/19 [20:06<06:53, 82.61s/it]loss:24.810192108154297:  79%|███████▉  | 15/19 [20:06<05:32, 83.07s/it]loss:24.555194854736328:  79%|███████▉  | 15/19 [21:26<05:32, 83.07s/it]loss:24.555194854736328:  84%|████████▍ | 16/19 [21:26<04:06, 82.17s/it]loss:24.657621383666992:  84%|████████▍ | 16/19 [22:51<04:06, 82.17s/it]loss:24.657621383666992:  89%|████████▉ | 17/19 [22:51<02:45, 82.98s/it]loss:24.72650718688965:  89%|████████▉ | 17/19 [24:10<02:45, 82.98s/it] loss:24.72650718688965:  95%|█████████▍| 18/19 [24:10<01:21, 81.85s/it]loss:24.62374496459961:  95%|█████████▍| 18/19 [25:29<01:21, 81.85s/it]loss:24.62374496459961: 100%|██████████| 19/19 [25:29<00:00, 80.97s/it]loss:24.62374496459961: 100%|██████████| 19/19 [25:29<00:00, 80.51s/it]
Epoch: 7 cost time: 1530.2697939872742
Epoch: 7, Steps: 19 | Train Loss: 24.6222457 Vali Loss: 3.9283962 Test Loss: 69.6865997
Validation loss decreased (3.928494 --> 3.928396).  Saving model ...
Updating learning rate to 1.5625e-06
  0%|          | 0/19 [00:00<?, ?it/s]loss:24.65802574157715:   0%|          | 0/19 [01:19<?, ?it/s]loss:24.65802574157715:   5%|▌         | 1/19 [01:19<23:57, 79.84s/it]loss:24.906431198120117:   5%|▌         | 1/19 [02:43<23:57, 79.84s/it]loss:24.906431198120117:  11%|█         | 2/19 [02:43<23:17, 82.20s/it]loss:24.470592498779297:  11%|█         | 2/19 [04:06<23:17, 82.20s/it]loss:24.470592498779297:  16%|█▌        | 3/19 [04:06<21:56, 82.26s/it]loss:24.53836441040039:  16%|█▌        | 3/19 [05:26<21:56, 82.26s/it] loss:24.53836441040039:  21%|██        | 4/19 [05:26<20:25, 81.72s/it]loss:24.84808349609375:  21%|██        | 4/19 [06:48<20:25, 81.72s/it]loss:24.84808349609375:  26%|██▋       | 5/19 [06:48<19:04, 81.78s/it]loss:24.554059982299805:  26%|██▋       | 5/19 [08:10<19:04, 81.78s/it]loss:24.554059982299805:  32%|███▏      | 6/19 [08:10<17:43, 81.84s/it]loss:24.55095863342285:  32%|███▏      | 6/19 [09:31<17:43, 81.84s/it] loss:24.55095863342285:  37%|███▋      | 7/19 [09:31<16:18, 81.54s/it]loss:24.495595932006836:  37%|███▋      | 7/19 [10:54<16:18, 81.54s/it]loss:24.495595932006836:  42%|████▏     | 8/19 [10:54<14:59, 81.81s/it]loss:24.811403274536133:  42%|████▏     | 8/19 [12:13<14:59, 81.81s/it]loss:24.811403274536133:  47%|████▋     | 9/19 [12:13<13:31, 81.20s/it]loss:24.727373123168945:  47%|████▋     | 9/19 [13:35<13:31, 81.20s/it]loss:24.727373123168945:  53%|█████▎    | 10/19 [13:35<12:12, 81.34s/it]loss:24.66501235961914:  53%|█████▎    | 10/19 [14:56<12:12, 81.34s/it] loss:24.66501235961914:  58%|█████▊    | 11/19 [14:56<10:50, 81.35s/it]loss:24.624622344970703:  58%|█████▊    | 11/19 [16:16<10:50, 81.35s/it]loss:24.624622344970703:  63%|██████▎   | 12/19 [16:16<09:26, 80.93s/it]loss:24.407514572143555:  63%|██████▎   | 12/19 [17:38<09:26, 80.93s/it]loss:24.407514572143555:  68%|██████▊   | 13/19 [17:38<08:06, 81.07s/it]loss:24.763166427612305:  68%|██████▊   | 13/19 [18:59<08:06, 81.07s/it]loss:24.763166427612305:  74%|███████▎  | 14/19 [18:59<06:45, 81.19s/it]loss:24.74323272705078:  74%|███████▎  | 14/19 [20:20<06:45, 81.19s/it] loss:24.74323272705078:  79%|███████▉  | 15/19 [20:20<05:24, 81.11s/it]loss:24.556690216064453:  79%|███████▉  | 15/19 [21:42<05:24, 81.11s/it]loss:24.556690216064453:  84%|████████▍ | 16/19 [21:42<04:03, 81.33s/it]loss:24.513607025146484:  84%|████████▍ | 16/19 [23:03<04:03, 81.33s/it]loss:24.513607025146484:  89%|████████▉ | 17/19 [23:03<02:42, 81.22s/it]loss:24.559558868408203:  89%|████████▉ | 17/19 [24:24<02:42, 81.22s/it]loss:24.559558868408203:  95%|█████████▍| 18/19 [24:24<01:21, 81.16s/it]loss:24.464433670043945:  95%|█████████▍| 18/19 [25:46<01:21, 81.16s/it]loss:24.464433670043945: 100%|██████████| 19/19 [25:46<00:00, 81.38s/it]loss:24.464433670043945: 100%|██████████| 19/19 [25:46<00:00, 81.39s/it]
Epoch: 8 cost time: 1547.1543531417847
Epoch: 8, Steps: 19 | Train Loss: 24.6241435 Vali Loss: 3.9283431 Test Loss: 69.6874084
Validation loss decreased (3.928396 --> 3.928343).  Saving model ...
Updating learning rate to 7.8125e-07
  0%|          | 0/19 [00:00<?, ?it/s]loss:24.62516212463379:   0%|          | 0/19 [01:18<?, ?it/s]loss:24.62516212463379:   5%|▌         | 1/19 [01:18<23:34, 78.58s/it]loss:24.47178077697754:   5%|▌         | 1/19 [02:35<23:34, 78.58s/it]loss:24.47178077697754:  11%|█         | 2/19 [02:35<22:02, 77.77s/it]loss:24.5550537109375:  11%|█         | 2/19 [03:56<22:02, 77.77s/it] loss:24.5550537109375:  16%|█▌        | 3/19 [03:56<21:03, 79.00s/it]loss:24.513898849487305:  16%|█▌        | 3/19 [05:19<21:03, 79.00s/it]loss:24.513898849487305:  21%|██        | 4/19 [05:19<20:08, 80.55s/it]loss:24.763681411743164:  21%|██        | 4/19 [06:40<20:08, 80.55s/it]loss:24.763681411743164:  26%|██▋       | 5/19 [06:40<18:51, 80.82s/it]loss:24.551965713500977:  26%|██▋       | 5/19 [07:58<18:51, 80.82s/it]loss:24.551965713500977:  32%|███▏      | 6/19 [07:58<17:17, 79.80s/it]loss:24.5571231842041:  32%|███▏      | 6/19 [09:21<17:17, 79.80s/it]  loss:24.5571231842041:  37%|███▋      | 7/19 [09:21<16:11, 80.94s/it]loss:24.90782356262207:  37%|███▋      | 7/19 [10:40<16:11, 80.94s/it]loss:24.90782356262207:  42%|████▏     | 8/19 [10:40<14:44, 80.38s/it]loss:24.728273391723633:  42%|████▏     | 8/19 [11:59<14:44, 80.38s/it]loss:24.728273391723633:  47%|████▋     | 9/19 [11:59<13:20, 80.02s/it]loss:24.539714813232422:  47%|████▋     | 9/19 [13:18<13:20, 80.02s/it]loss:24.539714813232422:  53%|█████▎    | 10/19 [13:18<11:56, 79.58s/it]loss:24.560007095336914:  53%|█████▎    | 10/19 [14:38<11:56, 79.58s/it]loss:24.560007095336914:  58%|█████▊    | 11/19 [14:38<10:37, 79.71s/it]loss:24.812482833862305:  58%|█████▊    | 11/19 [16:02<10:37, 79.71s/it]loss:24.812482833862305:  63%|██████▎   | 12/19 [16:02<09:27, 81.02s/it]loss:24.8493709564209:  63%|██████▎   | 12/19 [17:22<09:27, 81.02s/it]  loss:24.8493709564209:  68%|██████▊   | 13/19 [17:22<08:04, 80.68s/it]loss:24.66602325439453:  68%|██████▊   | 13/19 [18:43<08:04, 80.68s/it]loss:24.66602325439453:  74%|███████▎  | 14/19 [18:43<06:44, 80.88s/it]loss:24.408432006835938:  74%|███████▎  | 14/19 [20:03<06:44, 80.88s/it]loss:24.408432006835938:  79%|███████▉  | 15/19 [20:03<05:21, 80.41s/it]loss:24.464996337890625:  79%|███████▉  | 15/19 [21:22<05:21, 80.41s/it]loss:24.464996337890625:  84%|████████▍ | 16/19 [21:22<04:00, 80.18s/it]loss:24.744081497192383:  84%|████████▍ | 16/19 [22:46<04:00, 80.18s/it]loss:24.744081497192383:  89%|████████▉ | 17/19 [22:46<02:42, 81.18s/it]loss:24.496923446655273:  89%|████████▉ | 17/19 [24:05<02:42, 81.18s/it]loss:24.496923446655273:  95%|█████████▍| 18/19 [24:05<01:20, 80.73s/it]loss:24.65987777709961:  95%|█████████▍| 18/19 [25:25<01:20, 80.73s/it] loss:24.65987777709961: 100%|██████████| 19/19 [25:25<00:00, 80.42s/it]loss:24.65987777709961: 100%|██████████| 19/19 [25:25<00:00, 80.30s/it]
Epoch: 9 cost time: 1526.3699779510498
Epoch: 9, Steps: 19 | Train Loss: 24.6250880 Vali Loss: 3.9283178 Test Loss: 69.6877975
Validation loss decreased (3.928343 --> 3.928318).  Saving model ...
Updating learning rate to 3.90625e-07
  0%|          | 0/19 [00:00<?, ?it/s]loss:24.540037155151367:   0%|          | 0/19 [01:16<?, ?it/s]loss:24.540037155151367:   5%|▌         | 1/19 [01:16<22:57, 76.55s/it]loss:24.560325622558594:   5%|▌         | 1/19 [02:27<22:57, 76.55s/it]loss:24.560325622558594:  11%|█         | 2/19 [02:27<20:47, 73.41s/it]loss:24.84961700439453:  11%|█         | 2/19 [03:36<20:47, 73.41s/it] loss:24.84961700439453:  16%|█▌        | 3/19 [03:36<18:57, 71.12s/it]loss:24.465166091918945:  16%|█▌        | 3/19 [04:41<18:57, 71.12s/it]loss:24.465166091918945:  21%|██        | 4/19 [04:41<17:12, 68.85s/it]loss:24.72869110107422:  21%|██        | 4/19 [05:58<17:12, 68.85s/it] loss:24.72869110107422:  26%|██▋       | 5/19 [05:58<16:46, 71.87s/it]loss:24.514497756958008:  26%|██▋       | 5/19 [07:14<16:46, 71.87s/it]loss:24.514497756958008:  32%|███▏      | 6/19 [07:14<15:53, 73.34s/it]loss:24.65999984741211:  32%|███▏      | 6/19 [08:35<15:53, 73.34s/it] loss:24.65999984741211:  37%|███▋      | 7/19 [08:35<15:09, 75.79s/it]loss:24.90831756591797:  37%|███▋      | 7/19 [09:50<15:09, 75.79s/it]loss:24.90831756591797:  42%|████▏     | 8/19 [09:50<13:49, 75.40s/it]loss:24.744293212890625:  42%|████▏     | 8/19 [11:08<13:49, 75.40s/it]loss:24.744293212890625:  47%|████▋     | 9/19 [11:08<12:41, 76.14s/it]loss:24.555734634399414:  47%|████▋     | 9/19 [12:27<12:41, 76.14s/it]loss:24.555734634399414:  53%|█████▎    | 10/19 [12:27<11:35, 77.28s/it]loss:24.472524642944336:  53%|█████▎    | 10/19 [13:46<11:35, 77.28s/it]loss:24.472524642944336:  58%|█████▊    | 11/19 [13:46<10:21, 77.67s/it]loss:24.66638946533203:  58%|█████▊    | 11/19 [15:04<10:21, 77.67s/it] loss:24.66638946533203:  63%|██████▎   | 12/19 [15:04<09:04, 77.76s/it]loss:24.764339447021484:  63%|██████▎   | 12/19 [16:26<09:04, 77.76s/it]loss:24.764339447021484:  68%|██████▊   | 13/19 [16:26<07:54, 79.10s/it]loss:24.6259708404541:  68%|██████▊   | 13/19 [17:47<07:54, 79.10s/it]  loss:24.6259708404541:  74%|███████▎  | 14/19 [17:47<06:38, 79.72s/it]loss:24.812965393066406:  74%|███████▎  | 14/19 [19:02<06:38, 79.72s/it]loss:24.812965393066406:  79%|███████▉  | 15/19 [19:02<05:12, 78.12s/it]loss:24.408815383911133:  79%|███████▉  | 15/19 [20:15<05:12, 78.12s/it]loss:24.408815383911133:  84%|████████▍ | 16/19 [20:15<03:49, 76.64s/it]loss:24.497222900390625:  84%|████████▍ | 16/19 [21:30<03:49, 76.64s/it]loss:24.497222900390625:  89%|████████▉ | 17/19 [21:30<02:32, 76.15s/it]loss:24.55266761779785:  89%|████████▉ | 17/19 [22:52<02:32, 76.15s/it] loss:24.55266761779785:  95%|█████████▍| 18/19 [22:52<01:17, 77.94s/it]loss:24.55780792236328:  95%|█████████▍| 18/19 [24:12<01:17, 77.94s/it]loss:24.55780792236328: 100%|██████████| 19/19 [24:12<00:00, 78.66s/it]loss:24.55780792236328: 100%|██████████| 19/19 [24:12<00:00, 76.47s/it]
Epoch: 10 cost time: 1453.6282222270966
Epoch: 10, Steps: 19 | Train Loss: 24.6255465 Vali Loss: 3.9283054 Test Loss: 69.6879959
Validation loss decreased (3.928318 --> 3.928305).  Saving model ...
Updating learning rate to 1.953125e-07
  0%|          | 0/19 [00:00<?, ?it/s]loss:24.764446258544922:   0%|          | 0/19 [01:14<?, ?it/s]loss:24.764446258544922:   5%|▌         | 1/19 [01:14<22:29, 74.98s/it]loss:24.849868774414062:   5%|▌         | 1/19 [02:30<22:29, 74.98s/it]loss:24.849868774414062:  11%|█         | 2/19 [02:30<21:19, 75.24s/it]loss:24.62608528137207:  11%|█         | 2/19 [03:46<21:19, 75.24s/it] loss:24.62608528137207:  16%|█▌        | 3/19 [03:46<20:10, 75.65s/it]loss:24.54036521911621:  16%|█▌        | 3/19 [05:01<20:10, 75.65s/it]loss:24.54036521911621:  21%|██        | 4/19 [05:01<18:53, 75.57s/it]loss:24.55592918395996:  21%|██        | 4/19 [06:16<18:53, 75.57s/it]loss:24.55592918395996:  26%|██▋       | 5/19 [06:16<17:30, 75.04s/it]loss:24.560649871826172:  26%|██▋       | 5/19 [07:30<17:30, 75.04s/it]loss:24.560649871826172:  32%|███▏      | 6/19 [07:30<16:13, 74.90s/it]loss:24.744522094726562:  32%|███▏      | 6/19 [08:45<16:13, 74.90s/it]loss:24.744522094726562:  37%|███▋      | 7/19 [08:45<15:00, 75.02s/it]loss:24.55789566040039:  37%|███▋      | 7/19 [10:04<15:00, 75.02s/it] loss:24.55789566040039:  42%|████▏     | 8/19 [10:04<13:57, 76.16s/it]loss:24.81312370300293:  42%|████▏     | 8/19 [11:25<13:57, 76.16s/it]loss:24.81312370300293:  47%|████▋     | 9/19 [11:25<12:55, 77.57s/it]loss:24.729013442993164:  47%|████▋     | 9/19 [12:45<12:55, 77.57s/it]loss:24.729013442993164:  53%|█████▎    | 10/19 [12:45<11:45, 78.37s/it]loss:24.497371673583984:  53%|█████▎    | 10/19 [14:03<11:45, 78.37s/it]loss:24.497371673583984:  58%|█████▊    | 11/19 [14:03<10:27, 78.43s/it]loss:24.908611297607422:  58%|█████▊    | 11/19 [15:19<10:27, 78.43s/it]loss:24.908611297607422:  63%|██████▎   | 12/19 [15:19<09:03, 77.64s/it]loss:24.465543746948242:  63%|██████▎   | 12/19 [16:38<09:03, 77.64s/it]loss:24.465543746948242:  68%|██████▊   | 13/19 [16:38<07:48, 78.10s/it]loss:24.514850616455078:  68%|██████▊   | 13/19 [17:59<07:48, 78.10s/it]loss:24.514850616455078:  74%|███████▎  | 14/19 [17:59<06:34, 78.86s/it]loss:24.66034507751465:  74%|███████▎  | 14/19 [19:17<06:34, 78.86s/it] loss:24.66034507751465:  79%|███████▉  | 15/19 [19:17<05:14, 78.64s/it]loss:24.472824096679688:  79%|███████▉  | 15/19 [20:36<05:14, 78.64s/it]loss:24.472824096679688:  84%|████████▍ | 16/19 [20:36<03:56, 78.81s/it]loss:24.552865982055664:  84%|████████▍ | 16/19 [21:52<03:56, 78.81s/it]loss:24.552865982055664:  89%|████████▉ | 17/19 [21:52<02:35, 77.93s/it]loss:24.66668701171875:  89%|████████▉ | 17/19 [23:08<02:35, 77.93s/it] loss:24.66668701171875:  95%|█████████▍| 18/19 [23:08<01:17, 77.21s/it]loss:24.4090633392334:  95%|█████████▍| 18/19 [24:29<01:17, 77.21s/it] loss:24.4090633392334: 100%|██████████| 19/19 [24:29<00:00, 78.29s/it]loss:24.4090633392334: 100%|██████████| 19/19 [24:29<00:00, 77.32s/it]
Epoch: 11 cost time: 1469.826334953308
Epoch: 11, Steps: 19 | Train Loss: 24.6257928 Vali Loss: 3.9282990 Test Loss: 69.6880951
Validation loss decreased (3.928305 --> 3.928299).  Saving model ...
Updating learning rate to 9.765625e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:24.558013916015625:   0%|          | 0/19 [01:20<?, ?it/s]loss:24.558013916015625:   5%|▌         | 1/19 [01:20<24:16, 80.93s/it]loss:24.472871780395508:   5%|▌         | 1/19 [02:38<24:16, 80.93s/it]loss:24.472871780395508:  11%|█         | 2/19 [02:38<22:24, 79.11s/it]loss:24.409086227416992:  11%|█         | 2/19 [03:59<22:24, 79.11s/it]loss:24.409086227416992:  16%|█▌        | 3/19 [03:59<21:19, 79.97s/it]loss:24.85005760192871:  16%|█▌        | 3/19 [05:20<21:19, 79.97s/it] loss:24.85005760192871:  21%|██        | 4/19 [05:20<20:01, 80.12s/it]loss:24.81325912475586:  21%|██        | 4/19 [06:36<20:01, 80.12s/it]loss:24.81325912475586:  26%|██▋       | 5/19 [06:36<18:21, 78.69s/it]loss:24.51494026184082:  26%|██▋       | 5/19 [07:57<18:21, 78.69s/it]loss:24.51494026184082:  32%|███▏      | 6/19 [07:57<17:13, 79.52s/it]loss:24.62629508972168:  32%|███▏      | 6/19 [09:16<17:13, 79.52s/it]loss:24.62629508972168:  37%|███▋      | 7/19 [09:16<15:52, 79.36s/it]loss:24.660430908203125:  37%|███▋      | 7/19 [10:34<15:52, 79.36s/it]loss:24.660430908203125:  42%|████▏     | 8/19 [10:34<14:29, 79.06s/it]loss:24.764680862426758:  42%|████▏     | 8/19 [11:54<14:29, 79.06s/it]loss:24.764680862426758:  47%|████▋     | 9/19 [11:54<13:11, 79.17s/it]loss:24.66675567626953:  47%|████▋     | 9/19 [13:11<13:11, 79.17s/it] loss:24.66675567626953:  53%|█████▎    | 10/19 [13:11<11:48, 78.71s/it]loss:24.497516632080078:  53%|█████▎    | 10/19 [14:30<11:48, 78.71s/it]loss:24.497516632080078:  58%|█████▊    | 11/19 [14:30<10:30, 78.78s/it]loss:24.552949905395508:  58%|█████▊    | 11/19 [15:49<10:30, 78.78s/it]loss:24.552949905395508:  63%|██████▎   | 12/19 [15:49<09:10, 78.71s/it]loss:24.908754348754883:  63%|██████▎   | 12/19 [17:08<09:10, 78.71s/it]loss:24.908754348754883:  68%|██████▊   | 13/19 [17:08<07:52, 78.83s/it]loss:24.72918128967285:  68%|██████▊   | 13/19 [18:25<07:52, 78.83s/it] loss:24.72918128967285:  74%|███████▎  | 14/19 [18:25<06:31, 78.38s/it]loss:24.540597915649414:  74%|███████▎  | 14/19 [19:45<06:31, 78.38s/it]loss:24.540597915649414:  79%|███████▉  | 15/19 [19:45<05:15, 78.77s/it]loss:24.465694427490234:  79%|███████▉  | 15/19 [21:05<05:15, 78.77s/it]loss:24.465694427490234:  84%|████████▍ | 16/19 [21:05<03:57, 79.14s/it]loss:24.744741439819336:  84%|████████▍ | 16/19 [22:22<03:57, 79.14s/it]loss:24.744741439819336:  89%|████████▉ | 17/19 [22:22<02:36, 78.37s/it]loss:24.560884475708008:  89%|████████▉ | 17/19 [23:43<02:36, 78.37s/it]loss:24.560884475708008:  95%|█████████▍| 18/19 [23:43<01:19, 79.17s/it]loss:24.556177139282227:  95%|█████████▍| 18/19 [25:01<01:19, 79.17s/it]loss:24.556177139282227: 100%|██████████| 19/19 [25:01<00:00, 79.05s/it]loss:24.556177139282227: 100%|██████████| 19/19 [25:01<00:00, 79.05s/it]
Epoch: 12 cost time: 1502.6302700042725
Epoch: 12, Steps: 19 | Train Loss: 24.6259415 Vali Loss: 3.9282954 Test Loss: 69.6881485
Validation loss decreased (3.928299 --> 3.928295).  Saving model ...
Updating learning rate to 4.8828125e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:24.540624618530273:   0%|          | 0/19 [01:18<?, ?it/s]loss:24.540624618530273:   5%|▌         | 1/19 [01:18<23:37, 78.76s/it]loss:24.90878677368164:   5%|▌         | 1/19 [02:34<23:37, 78.76s/it] loss:24.90878677368164:  11%|█         | 2/19 [02:34<21:52, 77.21s/it]loss:24.515012741088867:  11%|█         | 2/19 [03:57<21:52, 77.21s/it]loss:24.515012741088867:  16%|█▌        | 3/19 [03:57<21:11, 79.48s/it]loss:24.55299186706543:  16%|█▌        | 3/19 [05:15<21:11, 79.48s/it] loss:24.55299186706543:  21%|██        | 4/19 [05:15<19:45, 79.06s/it]loss:24.66049575805664:  21%|██        | 4/19 [06:35<19:45, 79.06s/it]loss:24.66049575805664:  26%|██▋       | 5/19 [06:35<18:32, 79.50s/it]loss:24.560897827148438:  26%|██▋       | 5/19 [07:53<18:32, 79.50s/it]loss:24.560897827148438:  32%|███▏      | 6/19 [07:53<17:05, 78.89s/it]loss:24.49756622314453:  32%|███▏      | 6/19 [09:13<17:05, 78.89s/it] loss:24.49756622314453:  37%|███▋      | 7/19 [09:13<15:50, 79.17s/it]loss:24.55811309814453:  37%|███▋      | 7/19 [10:32<15:50, 79.17s/it]loss:24.55811309814453:  42%|████▏     | 8/19 [10:32<14:31, 79.22s/it]loss:24.729211807250977:  42%|████▏     | 8/19 [11:51<14:31, 79.22s/it]loss:24.729211807250977:  47%|████▋     | 9/19 [11:51<13:11, 79.20s/it]loss:24.81334114074707:  47%|████▋     | 9/19 [13:11<13:11, 79.20s/it] loss:24.81334114074707:  53%|█████▎    | 10/19 [13:11<11:53, 79.31s/it]loss:24.472963333129883:  53%|█████▎    | 10/19 [14:29<11:53, 79.31s/it]loss:24.472963333129883:  58%|█████▊    | 11/19 [14:29<10:31, 78.94s/it]loss:24.744752883911133:  58%|█████▊    | 11/19 [15:45<10:31, 78.94s/it]loss:24.744752883911133:  63%|██████▎   | 12/19 [15:45<09:06, 78.02s/it]loss:24.465713500976562:  63%|██████▎   | 12/19 [17:05<09:06, 78.02s/it]loss:24.465713500976562:  68%|██████▊   | 13/19 [17:05<07:52, 78.72s/it]loss:24.409168243408203:  68%|██████▊   | 13/19 [18:24<07:52, 78.72s/it]loss:24.409168243408203:  74%|███████▎  | 14/19 [18:24<06:33, 78.73s/it]loss:24.666805267333984:  74%|███████▎  | 14/19 [19:44<06:33, 78.73s/it]loss:24.666805267333984:  79%|███████▉  | 15/19 [19:44<05:16, 79.10s/it]loss:24.850130081176758:  79%|███████▉  | 15/19 [21:02<05:16, 79.10s/it]loss:24.850130081176758:  84%|████████▍ | 16/19 [21:02<03:56, 78.86s/it]loss:24.556180953979492:  84%|████████▍ | 16/19 [22:22<03:56, 78.86s/it]loss:24.556180953979492:  89%|████████▉ | 17/19 [22:22<02:38, 79.31s/it]loss:24.626361846923828:  89%|████████▉ | 17/19 [23:43<02:38, 79.31s/it]loss:24.626361846923828:  95%|█████████▍| 18/19 [23:43<01:19, 79.57s/it]loss:24.76473617553711:  95%|█████████▍| 18/19 [25:02<01:19, 79.57s/it] loss:24.76473617553711: 100%|██████████| 19/19 [25:02<00:00, 79.46s/it]loss:24.76473617553711: 100%|██████████| 19/19 [25:02<00:00, 79.07s/it]
Epoch: 13 cost time: 1502.9669501781464
Epoch: 13, Steps: 19 | Train Loss: 24.6259923 Vali Loss: 3.9282942 Test Loss: 69.6881714
Validation loss decreased (3.928295 --> 3.928294).  Saving model ...
Updating learning rate to 2.44140625e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:24.660493850708008:   0%|          | 0/19 [01:19<?, ?it/s]loss:24.660493850708008:   5%|▌         | 1/19 [01:19<23:55, 79.73s/it]loss:24.850128173828125:   5%|▌         | 1/19 [02:37<23:55, 79.73s/it]loss:24.850128173828125:  11%|█         | 2/19 [02:37<22:18, 78.75s/it]loss:24.908784866333008:  11%|█         | 2/19 [03:58<22:18, 78.75s/it]loss:24.908784866333008:  16%|█▌        | 3/19 [03:58<21:10, 79.42s/it]loss:24.55810546875:  16%|█▌        | 3/19 [05:16<21:10, 79.42s/it]    loss:24.55810546875:  21%|██        | 4/19 [05:16<19:48, 79.24s/it]loss:24.40916633605957:  21%|██        | 4/19 [06:35<19:48, 79.24s/it]loss:24.40916633605957:  26%|██▋       | 5/19 [06:35<18:27, 79.08s/it]loss:24.556180953979492:  26%|██▋       | 5/19 [07:54<18:27, 79.08s/it]loss:24.556180953979492:  32%|███▏      | 6/19 [07:54<17:08, 79.11s/it]loss:24.76473617553711:  32%|███▏      | 6/19 [09:10<17:08, 79.11s/it] loss:24.76473617553711:  37%|███▋      | 7/19 [09:10<15:36, 78.04s/it]loss:24.51500701904297:  37%|███▋      | 7/19 [10:29<15:36, 78.04s/it]loss:24.51500701904297:  42%|████▏     | 8/19 [10:29<14:22, 78.37s/it]loss:24.560894012451172:  42%|████▏     | 8/19 [11:50<14:22, 78.37s/it]loss:24.560894012451172:  47%|████▋     | 9/19 [11:50<13:09, 78.98s/it]loss:24.49755859375:  47%|████▋     | 9/19 [13:08<13:09, 78.98s/it]    loss:24.49755859375:  53%|█████▎    | 10/19 [13:08<11:49, 78.80s/it]loss:24.813337326049805:  53%|█████▎    | 10/19 [14:26<11:49, 78.80s/it]loss:24.813337326049805:  58%|█████▊    | 11/19 [14:26<10:29, 78.67s/it]loss:24.7447509765625:  58%|█████▊    | 11/19 [15:47<10:29, 78.67s/it]  loss:24.7447509765625:  63%|██████▎   | 12/19 [15:47<09:14, 79.23s/it]loss:24.465713500976562:  63%|██████▎   | 12/19 [17:07<09:14, 79.23s/it]loss:24.465713500976562:  68%|██████▊   | 13/19 [17:07<07:57, 79.61s/it]loss:24.552988052368164:  68%|██████▊   | 13/19 [18:28<07:57, 79.61s/it]loss:24.552988052368164:  74%|███████▎  | 14/19 [18:28<06:39, 79.84s/it]loss:24.626361846923828:  74%|███████▎  | 14/19 [19:47<06:39, 79.84s/it]loss:24.626361846923828:  79%|███████▉  | 15/19 [19:47<05:18, 79.70s/it]loss:24.47296142578125:  79%|███████▉  | 15/19 [21:05<05:18, 79.70s/it] loss:24.47296142578125:  84%|████████▍ | 16/19 [21:05<03:57, 79.13s/it]loss:24.54062271118164:  84%|████████▍ | 16/19 [22:21<03:57, 79.13s/it]loss:24.54062271118164:  89%|████████▉ | 17/19 [22:21<02:36, 78.13s/it]loss:24.729206085205078:  89%|████████▉ | 17/19 [23:40<02:36, 78.13s/it]loss:24.729206085205078:  95%|█████████▍| 18/19 [23:40<01:18, 78.60s/it]loss:24.66680335998535:  95%|█████████▍| 18/19 [25:02<01:18, 78.60s/it] loss:24.66680335998535: 100%|██████████| 19/19 [25:02<00:00, 79.43s/it]loss:24.66680335998535: 100%|██████████| 19/19 [25:02<00:00, 79.07s/it]
Epoch: 14 cost time: 1502.99094414711
Epoch: 14, Steps: 19 | Train Loss: 24.6259895 Vali Loss: 3.9282932 Test Loss: 69.6881866
Validation loss decreased (3.928294 --> 3.928293).  Saving model ...
Updating learning rate to 1.220703125e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:24.55810546875:   0%|          | 0/19 [01:19<?, ?it/s]loss:24.55810546875:   5%|▌         | 1/19 [01:19<23:47, 79.29s/it]loss:24.850126266479492:   5%|▌         | 1/19 [02:36<23:47, 79.29s/it]loss:24.850126266479492:  11%|█         | 2/19 [02:36<22:02, 77.80s/it]loss:24.66680335998535:  11%|█         | 2/19 [03:57<22:02, 77.80s/it] loss:24.66680335998535:  16%|█▌        | 3/19 [03:57<21:12, 79.55s/it]loss:24.729206085205078:  16%|█▌        | 3/19 [05:22<21:12, 79.55s/it]loss:24.729206085205078:  21%|██        | 4/19 [05:22<20:21, 81.46s/it]loss:24.49755859375:  21%|██        | 4/19 [06:41<20:21, 81.46s/it]    loss:24.49755859375:  26%|██▋       | 5/19 [06:41<18:47, 80.56s/it]loss:24.54062271118164:  26%|██▋       | 5/19 [08:03<18:47, 80.56s/it]loss:24.54062271118164:  32%|███▏      | 6/19 [08:03<17:37, 81.34s/it]loss:24.813335418701172:  32%|███▏      | 6/19 [09:22<17:37, 81.34s/it]loss:24.813335418701172:  37%|███▋      | 7/19 [09:22<16:07, 80.60s/it]loss:24.47296142578125:  37%|███▋      | 7/19 [10:43<16:07, 80.60s/it] loss:24.47296142578125:  42%|████▏     | 8/19 [10:43<14:48, 80.73s/it]loss:24.764734268188477:  42%|████▏     | 8/19 [12:04<14:48, 80.73s/it]loss:24.764734268188477:  47%|████▋     | 9/19 [12:04<13:27, 80.72s/it]loss:24.56089210510254:  47%|████▋     | 9/19 [13:25<13:27, 80.72s/it] loss:24.56089210510254:  53%|█████▎    | 10/19 [13:25<12:06, 80.73s/it]loss:24.409164428710938:  53%|█████▎    | 10/19 [14:46<12:06, 80.73s/it]loss:24.409164428710938:  58%|█████▊    | 11/19 [14:46<10:47, 80.98s/it]loss:24.7447509765625:  58%|█████▊    | 11/19 [16:09<10:47, 80.98s/it]  loss:24.7447509765625:  63%|██████▎   | 12/19 [16:09<09:30, 81.46s/it]loss:24.908782958984375:  63%|██████▎   | 12/19 [17:31<09:30, 81.46s/it]loss:24.908782958984375:  68%|██████▊   | 13/19 [17:31<08:08, 81.48s/it]loss:24.626359939575195:  68%|██████▊   | 13/19 [18:51<08:08, 81.48s/it]loss:24.626359939575195:  74%|███████▎  | 14/19 [18:51<06:46, 81.24s/it]loss:24.51500701904297:  74%|███████▎  | 14/19 [20:12<06:46, 81.24s/it] loss:24.51500701904297:  79%|███████▉  | 15/19 [20:12<05:24, 81.12s/it]loss:24.552988052368164:  79%|███████▉  | 15/19 [21:32<05:24, 81.12s/it]loss:24.552988052368164:  84%|████████▍ | 16/19 [21:32<04:02, 80.89s/it]loss:24.660490036010742:  84%|████████▍ | 16/19 [22:54<04:02, 80.89s/it]loss:24.660490036010742:  89%|████████▉ | 17/19 [22:54<02:42, 81.13s/it]loss:24.46571159362793:  89%|████████▉ | 17/19 [24:15<02:42, 81.13s/it] loss:24.46571159362793:  95%|█████████▍| 18/19 [24:15<01:21, 81.15s/it]loss:24.55617904663086:  95%|█████████▍| 18/19 [25:34<01:21, 81.15s/it]loss:24.55617904663086: 100%|██████████| 19/19 [25:34<00:00, 80.53s/it]loss:24.55617904663086: 100%|██████████| 19/19 [25:34<00:00, 80.79s/it]
Epoch: 15 cost time: 1535.6408200263977
Epoch: 15, Steps: 19 | Train Loss: 24.6259884 Vali Loss: 3.9282932 Test Loss: 69.6882019
Validation loss decreased (3.928293 --> 3.928293).  Saving model ...
Updating learning rate to 6.103515625e-09
  0%|          | 0/19 [00:00<?, ?it/s]loss:24.497554779052734:   0%|          | 0/19 [01:22<?, ?it/s]loss:24.497554779052734:   5%|▌         | 1/19 [01:22<24:44, 82.46s/it]loss:24.850126266479492:   5%|▌         | 1/19 [02:39<24:44, 82.46s/it]loss:24.850126266479492:  11%|█         | 2/19 [02:39<22:29, 79.40s/it]loss:24.626359939575195:  11%|█         | 2/19 [04:02<22:29, 79.40s/it]loss:24.626359939575195:  16%|█▌        | 3/19 [04:02<21:36, 81.00s/it]loss:24.7447509765625:  16%|█▌        | 3/19 [05:22<21:36, 81.00s/it]  loss:24.7447509765625:  21%|██        | 4/19 [05:22<20:09, 80.67s/it]loss:24.46571159362793:  21%|██        | 4/19 [06:39<20:09, 80.67s/it]loss:24.46571159362793:  26%|██▋       | 5/19 [06:39<18:31, 79.42s/it]loss:24.56089210510254:  26%|██▋       | 5/19 [08:00<18:31, 79.42s/it]loss:24.56089210510254:  32%|███▏      | 6/19 [08:00<17:15, 79.67s/it]loss:24.540620803833008:  32%|███▏      | 6/19 [09:19<17:15, 79.67s/it]loss:24.540620803833008:  37%|███▋      | 7/19 [09:19<15:55, 79.63s/it]loss:24.764734268188477:  37%|███▋      | 7/19 [10:40<15:55, 79.63s/it]loss:24.764734268188477:  42%|████▏     | 8/19 [10:40<14:40, 80.04s/it]loss:24.660490036010742:  42%|████▏     | 8/19 [12:02<14:40, 80.04s/it]loss:24.660490036010742:  47%|████▋     | 9/19 [12:02<13:25, 80.56s/it]loss:24.813335418701172:  47%|████▋     | 9/19 [13:21<13:25, 80.56s/it]loss:24.813335418701172:  53%|█████▎    | 10/19 [13:21<12:02, 80.26s/it]loss:24.51500701904297:  53%|█████▎    | 10/19 [14:42<12:02, 80.26s/it] loss:24.51500701904297:  58%|█████▊    | 11/19 [14:42<10:42, 80.34s/it]loss:24.66680335998535:  58%|█████▊    | 11/19 [16:05<10:42, 80.34s/it]loss:24.66680335998535:  63%|██████▎   | 12/19 [16:05<09:27, 81.13s/it]loss:24.47296142578125:  63%|██████▎   | 12/19 [17:27<09:27, 81.13s/it]loss:24.47296142578125:  68%|██████▊   | 13/19 [17:27<08:08, 81.40s/it]loss:24.729206085205078:  68%|██████▊   | 13/19 [18:51<08:08, 81.40s/it]loss:24.729206085205078:  74%|███████▎  | 14/19 [18:51<06:50, 82.16s/it]loss:24.55617904663086:  74%|███████▎  | 14/19 [20:12<06:50, 82.16s/it] loss:24.55617904663086:  79%|███████▉  | 15/19 [20:12<05:27, 81.85s/it]loss:24.409164428710938:  79%|███████▉  | 15/19 [21:35<05:27, 81.85s/it]loss:24.409164428710938:  84%|████████▍ | 16/19 [21:35<04:06, 82.16s/it]loss:24.552988052368164:  84%|████████▍ | 16/19 [22:55<04:06, 82.16s/it]loss:24.552988052368164:  89%|████████▉ | 17/19 [22:55<02:43, 81.66s/it]loss:24.558103561401367:  89%|████████▉ | 17/19 [24:17<02:43, 81.66s/it]loss:24.558103561401367:  95%|█████████▍| 18/19 [24:17<01:21, 81.61s/it]loss:24.908782958984375:  95%|█████████▍| 18/19 [25:35<01:21, 81.61s/it]loss:24.908782958984375: 100%|██████████| 19/19 [25:35<00:00, 80.70s/it]loss:24.908782958984375: 100%|██████████| 19/19 [25:35<00:00, 80.84s/it]
Epoch: 16 cost time: 1536.5691957473755
Epoch: 16, Steps: 19 | Train Loss: 24.6259880 Vali Loss: 3.9282932 Test Loss: 69.6882019
Validation loss decreased (3.928293 --> 3.928293).  Saving model ...
Updating learning rate to 3.0517578125e-09
  0%|          | 0/19 [00:00<?, ?it/s]loss:24.558103561401367:   0%|          | 0/19 [01:19<?, ?it/s]loss:24.558103561401367:   5%|▌         | 1/19 [01:19<23:47, 79.30s/it]loss:24.908782958984375:   5%|▌         | 1/19 [02:39<23:47, 79.30s/it]loss:24.908782958984375:  11%|█         | 2/19 [02:39<22:39, 79.97s/it]loss:24.660490036010742:  11%|█         | 2/19 [04:01<22:39, 79.97s/it]loss:24.660490036010742:  16%|█▌        | 3/19 [04:01<21:30, 80.68s/it]loss:24.850126266479492:  16%|█▌        | 3/19 [05:21<21:30, 80.68s/it]loss:24.850126266479492:  21%|██        | 4/19 [05:21<20:09, 80.65s/it]loss:24.813335418701172:  21%|██        | 4/19 [06:44<20:09, 80.65s/it]loss:24.813335418701172:  26%|██▋       | 5/19 [06:44<19:00, 81.48s/it]loss:24.66680335998535:  26%|██▋       | 5/19 [08:02<19:00, 81.48s/it] loss:24.66680335998535:  32%|███▏      | 6/19 [08:02<17:21, 80.12s/it]loss:24.497554779052734:  32%|███▏      | 6/19 [09:24<17:21, 80.12s/it]loss:24.497554779052734:  37%|███▋      | 7/19 [09:24<16:09, 80.76s/it]loss:24.729206085205078:  37%|███▋      | 7/19 [10:46<16:09, 80.76s/it]loss:24.729206085205078:  42%|████▏     | 8/19 [10:46<14:52, 81.13s/it]loss:24.626359939575195:  42%|████▏     | 8/19 [12:08<14:52, 81.13s/it]loss:24.626359939575195:  47%|████▋     | 9/19 [12:08<13:34, 81.48s/it]loss:24.51500701904297:  47%|████▋     | 9/19 [13:29<13:34, 81.48s/it] loss:24.51500701904297:  53%|█████▎    | 10/19 [13:29<12:11, 81.23s/it]loss:24.409164428710938:  53%|█████▎    | 10/19 [14:49<12:11, 81.23s/it]loss:24.409164428710938:  58%|█████▊    | 11/19 [14:49<10:48, 81.03s/it]loss:24.764734268188477:  58%|█████▊    | 11/19 [16:12<10:48, 81.03s/it]loss:24.764734268188477:  63%|██████▎   | 12/19 [16:12<09:30, 81.56s/it]loss:24.46571159362793:  63%|██████▎   | 12/19 [17:34<09:30, 81.56s/it] loss:24.46571159362793:  68%|██████▊   | 13/19 [17:34<08:09, 81.59s/it]loss:24.540620803833008:  68%|██████▊   | 13/19 [18:55<08:09, 81.59s/it]loss:24.540620803833008:  74%|███████▎  | 14/19 [18:55<06:47, 81.53s/it]loss:24.47296142578125:  74%|███████▎  | 14/19 [20:13<06:47, 81.53s/it] loss:24.47296142578125:  79%|███████▉  | 15/19 [20:13<05:21, 80.45s/it]loss:24.55617904663086:  79%|███████▉  | 15/19 [21:36<05:21, 80.45s/it]loss:24.55617904663086:  84%|████████▍ | 16/19 [21:36<04:04, 81.34s/it]loss:24.7447509765625:  84%|████████▍ | 16/19 [22:59<04:04, 81.34s/it] loss:24.7447509765625:  89%|████████▉ | 17/19 [22:59<02:43, 81.79s/it]loss:24.552988052368164:  89%|████████▉ | 17/19 [24:22<02:43, 81.79s/it]loss:24.552988052368164:  95%|█████████▍| 18/19 [24:22<01:22, 82.11s/it]loss:24.56089210510254:  95%|█████████▍| 18/19 [25:44<01:22, 82.11s/it] loss:24.56089210510254: 100%|██████████| 19/19 [25:44<00:00, 81.91s/it]loss:24.56089210510254: 100%|██████████| 19/19 [25:44<00:00, 81.27s/it]
Epoch: 17 cost time: 1544.7963602542877
Epoch: 17, Steps: 19 | Train Loss: 24.6259880 Vali Loss: 3.9282932 Test Loss: 69.6882019
Validation loss decreased (3.928293 --> 3.928293).  Saving model ...
Updating learning rate to 1.52587890625e-09
  0%|          | 0/19 [00:00<?, ?it/s]loss:24.729206085205078:   0%|          | 0/19 [01:19<?, ?it/s]loss:24.729206085205078:   5%|▌         | 1/19 [01:19<23:51, 79.50s/it]loss:24.47296142578125:   5%|▌         | 1/19 [02:40<23:51, 79.50s/it] loss:24.47296142578125:  11%|█         | 2/19 [02:40<22:42, 80.18s/it]loss:24.764734268188477:  11%|█         | 2/19 [04:02<22:42, 80.18s/it]loss:24.764734268188477:  16%|█▌        | 3/19 [04:02<21:40, 81.28s/it]loss:24.409164428710938:  16%|█▌        | 3/19 [05:26<21:40, 81.28s/it]loss:24.409164428710938:  21%|██        | 4/19 [05:26<20:32, 82.16s/it]loss:24.558103561401367:  21%|██        | 4/19 [06:48<20:32, 82.16s/it]loss:24.558103561401367:  26%|██▋       | 5/19 [06:48<19:08, 82.03s/it]loss:24.908782958984375:  26%|██▋       | 5/19 [08:10<19:08, 82.03s/it]loss:24.908782958984375:  32%|███▏      | 6/19 [08:10<17:46, 82.01s/it]loss:24.540620803833008:  32%|███▏      | 6/19 [09:32<17:46, 82.01s/it]loss:24.540620803833008:  37%|███▋      | 7/19 [09:32<16:27, 82.26s/it]loss:24.7447509765625:  37%|███▋      | 7/19 [10:54<16:27, 82.26s/it]  loss:24.7447509765625:  42%|████▏     | 8/19 [10:54<15:01, 81.99s/it]loss:24.46571159362793:  42%|████▏     | 8/19 [12:17<15:01, 81.99s/it]loss:24.46571159362793:  47%|████▋     | 9/19 [12:17<13:42, 82.28s/it]loss:24.626359939575195:  47%|████▋     | 9/19 [13:37<13:42, 82.28s/it]loss:24.626359939575195:  53%|█████▎    | 10/19 [13:37<12:15, 81.75s/it]loss:24.660490036010742:  53%|█████▎    | 10/19 [15:00<12:15, 81.75s/it]loss:24.660490036010742:  58%|█████▊    | 11/19 [15:00<10:57, 82.15s/it]loss:24.552988052368164:  58%|█████▊    | 11/19 [16:21<10:57, 82.15s/it]loss:24.552988052368164:  63%|██████▎   | 12/19 [16:21<09:32, 81.74s/it]loss:24.51500701904297:  63%|██████▎   | 12/19 [17:41<09:32, 81.74s/it] loss:24.51500701904297:  68%|██████▊   | 13/19 [17:41<08:07, 81.19s/it]loss:24.66680335998535:  68%|██████▊   | 13/19 [19:02<08:07, 81.19s/it]loss:24.66680335998535:  74%|███████▎  | 14/19 [19:02<06:45, 81.04s/it]loss:24.56089210510254:  74%|███████▎  | 14/19 [20:25<06:45, 81.04s/it]loss:24.56089210510254:  79%|███████▉  | 15/19 [20:25<05:26, 81.69s/it]loss:24.49755859375:  79%|███████▉  | 15/19 [21:45<05:26, 81.69s/it]   loss:24.49755859375:  84%|████████▍ | 16/19 [21:45<04:03, 81.09s/it]loss:24.813335418701172:  84%|████████▍ | 16/19 [23:07<04:03, 81.09s/it]loss:24.813335418701172:  89%|████████▉ | 17/19 [23:07<02:42, 81.36s/it]loss:24.850126266479492:  89%|████████▉ | 17/19 [24:31<02:42, 81.36s/it]loss:24.850126266479492:  95%|█████████▍| 18/19 [24:31<01:22, 82.19s/it]loss:24.55617904663086:  95%|█████████▍| 18/19 [25:52<01:22, 82.19s/it] loss:24.55617904663086: 100%|██████████| 19/19 [25:52<00:00, 81.79s/it]loss:24.55617904663086: 100%|██████████| 19/19 [25:52<00:00, 81.69s/it]
Epoch: 18 cost time: 1552.7112531661987
Epoch: 18, Steps: 19 | Train Loss: 24.6259882 Vali Loss: 3.9282932 Test Loss: 69.6882019
Validation loss decreased (3.928293 --> 3.928293).  Saving model ...
Updating learning rate to 7.62939453125e-10
  0%|          | 0/19 [00:00<?, ?it/s]loss:24.908782958984375:   0%|          | 0/19 [01:18<?, ?it/s]loss:24.908782958984375:   5%|▌         | 1/19 [01:18<23:41, 78.98s/it]loss:24.540620803833008:   5%|▌         | 1/19 [02:40<23:41, 78.98s/it]loss:24.540620803833008:  11%|█         | 2/19 [02:40<22:43, 80.22s/it]loss:24.409164428710938:  11%|█         | 2/19 [04:02<22:43, 80.22s/it]loss:24.409164428710938:  16%|█▌        | 3/19 [04:02<21:42, 81.39s/it]loss:24.558103561401367:  16%|█▌        | 3/19 [05:26<21:42, 81.39s/it]loss:24.558103561401367:  21%|██        | 4/19 [05:26<20:31, 82.11s/it]loss:24.55617904663086:  21%|██        | 4/19 [06:47<20:31, 82.11s/it] loss:24.55617904663086:  26%|██▋       | 5/19 [06:47<19:08, 82.02s/it]loss:24.626359939575195:  26%|██▋       | 5/19 [08:07<19:08, 82.02s/it]loss:24.626359939575195:  32%|███▏      | 6/19 [08:07<17:36, 81.25s/it]loss:24.51500701904297:  32%|███▏      | 6/19 [09:28<17:36, 81.25s/it] loss:24.51500701904297:  37%|███▋      | 7/19 [09:28<16:15, 81.27s/it]loss:24.850126266479492:  37%|███▋      | 7/19 [10:51<16:15, 81.27s/it]loss:24.850126266479492:  42%|████▏     | 8/19 [10:51<14:57, 81.61s/it]loss:24.49755859375:  42%|████▏     | 8/19 [12:14<14:57, 81.61s/it]    loss:24.49755859375:  47%|████▋     | 9/19 [12:14<13:41, 82.15s/it]loss:24.764734268188477:  47%|████▋     | 9/19 [13:32<13:41, 82.15s/it]loss:24.764734268188477:  53%|█████▎    | 10/19 [13:32<12:08, 80.95s/it]loss:24.7447509765625:  53%|█████▎    | 10/19 [14:53<12:08, 80.95s/it]  loss:24.7447509765625:  58%|█████▊    | 11/19 [14:53<10:47, 80.94s/it]loss:24.660490036010742:  58%|█████▊    | 11/19 [16:12<10:47, 80.94s/it]loss:24.660490036010742:  63%|██████▎   | 12/19 [16:12<09:21, 80.22s/it]loss:24.813335418701172:  63%|██████▎   | 12/19 [17:35<09:21, 80.22s/it]loss:24.813335418701172:  68%|██████▊   | 13/19 [17:35<08:06, 81.03s/it]loss:24.46571159362793:  68%|██████▊   | 13/19 [18:53<08:06, 81.03s/it] loss:24.46571159362793:  74%|███████▎  | 14/19 [18:53<06:40, 80.13s/it]loss:24.66680335998535:  74%|███████▎  | 14/19 [20:16<06:40, 80.13s/it]loss:24.66680335998535:  79%|███████▉  | 15/19 [20:16<05:24, 81.10s/it]loss:24.552988052368164:  79%|███████▉  | 15/19 [21:38<05:24, 81.10s/it]loss:24.552988052368164:  84%|████████▍ | 16/19 [21:38<04:04, 81.43s/it]loss:24.56089210510254:  84%|████████▍ | 16/19 [23:02<04:04, 81.43s/it] loss:24.56089210510254:  89%|████████▉ | 17/19 [23:02<02:43, 81.98s/it]loss:24.47296142578125:  89%|████████▉ | 17/19 [24:23<02:43, 81.98s/it]loss:24.47296142578125:  95%|█████████▍| 18/19 [24:23<01:21, 81.89s/it]loss:24.729206085205078:  95%|█████████▍| 18/19 [25:46<01:21, 81.89s/it]loss:24.729206085205078: 100%|██████████| 19/19 [25:46<00:00, 82.14s/it]loss:24.729206085205078: 100%|██████████| 19/19 [25:46<00:00, 81.40s/it]
Epoch: 19 cost time: 1547.287427663803
Epoch: 19, Steps: 19 | Train Loss: 24.6259882 Vali Loss: 3.9282932 Test Loss: 69.6882019
Validation loss decreased (3.928293 --> 3.928293).  Saving model ...
Updating learning rate to 3.814697265625e-10
  0%|          | 0/19 [00:00<?, ?it/s]loss:24.7447509765625:   0%|          | 0/19 [01:22<?, ?it/s]loss:24.7447509765625:   5%|▌         | 1/19 [01:22<24:39, 82.21s/it]loss:24.66680335998535:   5%|▌         | 1/19 [02:45<24:39, 82.21s/it]loss:24.66680335998535:  11%|█         | 2/19 [02:45<23:23, 82.58s/it]loss:24.558103561401367:  11%|█         | 2/19 [04:04<23:23, 82.58s/it]loss:24.558103561401367:  16%|█▌        | 3/19 [04:04<21:40, 81.26s/it]loss:24.729206085205078:  16%|█▌        | 3/19 [05:26<21:40, 81.26s/it]loss:24.729206085205078:  21%|██        | 4/19 [05:26<20:20, 81.39s/it]loss:24.552988052368164:  21%|██        | 4/19 [06:50<20:20, 81.39s/it]loss:24.552988052368164:  26%|██▋       | 5/19 [06:50<19:13, 82.37s/it]loss:24.55617904663086:  26%|██▋       | 5/19 [08:11<19:13, 82.37s/it] loss:24.55617904663086:  32%|███▏      | 6/19 [08:11<17:45, 81.93s/it]loss:24.850126266479492:  32%|███▏      | 6/19 [09:32<17:45, 81.93s/it]loss:24.850126266479492:  37%|███▋      | 7/19 [09:32<16:20, 81.74s/it]loss:24.908782958984375:  37%|███▋      | 7/19 [10:54<16:20, 81.74s/it]loss:24.908782958984375:  42%|████▏     | 8/19 [10:54<14:57, 81.62s/it]loss:24.49755859375:  42%|████▏     | 8/19 [12:16<14:57, 81.62s/it]    loss:24.49755859375:  47%|████▋     | 9/19 [12:16<13:38, 81.83s/it]loss:24.56089210510254:  47%|████▋     | 9/19 [13:37<13:38, 81.83s/it]loss:24.56089210510254:  53%|█████▎    | 10/19 [13:37<12:13, 81.50s/it]loss:24.813335418701172:  53%|█████▎    | 10/19 [14:56<12:13, 81.50s/it]loss:24.813335418701172:  58%|█████▊    | 11/19 [14:56<10:45, 80.71s/it]loss:24.626359939575195:  58%|█████▊    | 11/19 [16:18<10:45, 80.71s/it]loss:24.626359939575195:  63%|██████▎   | 12/19 [16:18<09:28, 81.23s/it]loss:24.409164428710938:  63%|██████▎   | 12/19 [17:44<09:28, 81.23s/it]loss:24.409164428710938:  68%|██████▊   | 13/19 [17:44<08:15, 82.62s/it]loss:24.46571159362793:  68%|██████▊   | 13/19 [19:06<08:15, 82.62s/it] loss:24.46571159362793:  74%|███████▎  | 14/19 [19:06<06:52, 82.43s/it]loss:24.51500701904297:  74%|███████▎  | 14/19 [20:28<06:52, 82.43s/it]loss:24.51500701904297:  79%|███████▉  | 15/19 [20:28<05:29, 82.40s/it]loss:24.47296142578125:  79%|███████▉  | 15/19 [21:52<05:29, 82.40s/it]loss:24.47296142578125:  84%|████████▍ | 16/19 [21:52<04:08, 82.90s/it]loss:24.540620803833008:  84%|████████▍ | 16/19 [23:13<04:08, 82.90s/it]loss:24.540620803833008:  89%|████████▉ | 17/19 [23:13<02:44, 82.20s/it]loss:24.764734268188477:  89%|████████▉ | 17/19 [24:36<02:44, 82.20s/it]loss:24.764734268188477:  95%|█████████▍| 18/19 [24:36<01:22, 82.39s/it]loss:24.660490036010742:  95%|█████████▍| 18/19 [25:55<01:22, 82.39s/it]loss:24.660490036010742: 100%|██████████| 19/19 [25:55<00:00, 81.39s/it]loss:24.660490036010742: 100%|██████████| 19/19 [25:55<00:00, 81.86s/it]
Epoch: 20 cost time: 1556.0063407421112
Epoch: 20, Steps: 19 | Train Loss: 24.6259882 Vali Loss: 3.9282932 Test Loss: 69.6882019
Validation loss decreased (3.928293 --> 3.928293).  Saving model ...
Updating learning rate to 1.9073486328125e-10
>>>>>>>testing : long_term_forecast_low_0_DLinear_job_demand_r1_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 4
test shape: (4, 1, 3, 32690) (4, 1, 3, 32690)
test shape: (4, 3, 32690) (4, 3, 32690)
mse:63021.69140625, mae:19.327939987182617, dtw:-999
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           0                   Model:              DLinear             

[1mData Loader[0m
  Data:               job_demand_r2       Root Path:          ../../dataset/demand/
  Data Path:          r2.parquet          Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        .cache/checkpoints  

[1mForecasting Task[0m
  Seq Len:            6                   Label Len:          1                   
  Pred Len:           3                   Seasonal Patterns:  Monthly             
  Inverse:            1                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             121420              Dec In:             121420              
  C Out:              121420              d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           2                   d FF:               2048                
  Moving Avg:         25                  Factor:             1                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              learned             Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        32                  Itr:                1                   
  Train Epochs:       20                  Batch Size:         1                   
  Patience:           3                   Learning Rate:      0.0001              
  Des:                test                Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            0                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1                 

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use CPU
>>>>>>>start training : long_term_forecast_low_0_DLinear_job_demand_r2_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 19
val 1
test 4
  0%|          | 0/19 [00:00<?, ?it/s]Killed
