True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           0                   Model:              PatchTST            

[1mData Loader[0m
  Data:               job_demand_region   Root Path:          ../../dataset/demand/
  Data Path:          region.parquet      Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        .cache/checkpoints  

[1mForecasting Task[0m
  Seq Len:            6                   Label Len:          1                   
  Pred Len:           3                   Seasonal Patterns:  Monthly             
  Inverse:            1                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             16345               Dec In:             16345               
  C Out:              16345               d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           2                   d FF:               2048                
  Moving Avg:         25                  Factor:             1                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              learned             Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        32                  Itr:                1                   
  Train Epochs:       20                  Batch Size:         1                   
  Patience:           3                   Learning Rate:      0.0001              
  Des:                test                Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            0                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1                 

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use CPU
>>>>>>>start training : long_term_forecast_low_0_PatchTST_job_demand_region_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 19
val 1
test 4
  0%|          | 0/19 [00:00<?, ?it/s]loss:23.290748596191406:   0%|          | 0/19 [00:16<?, ?it/s]loss:23.290748596191406:   5%|▌         | 1/19 [00:16<05:03, 16.87s/it]loss:24.1545467376709:   5%|▌         | 1/19 [00:33<05:03, 16.87s/it]  loss:24.1545467376709:  11%|█         | 2/19 [00:33<04:41, 16.58s/it]loss:23.15323829650879:  11%|█         | 2/19 [00:49<04:41, 16.58s/it]loss:23.15323829650879:  16%|█▌        | 3/19 [00:49<04:23, 16.47s/it]loss:23.741201400756836:  16%|█▌        | 3/19 [01:05<04:23, 16.47s/it]loss:23.741201400756836:  21%|██        | 4/19 [01:05<04:05, 16.34s/it]loss:23.429738998413086:  21%|██        | 4/19 [01:21<04:05, 16.34s/it]loss:23.429738998413086:  26%|██▋       | 5/19 [01:21<03:47, 16.23s/it]loss:23.492435455322266:  26%|██▋       | 5/19 [01:38<03:47, 16.23s/it]loss:23.492435455322266:  32%|███▏      | 6/19 [01:38<03:31, 16.30s/it]loss:23.745033264160156:  32%|███▏      | 6/19 [01:54<03:31, 16.30s/it]loss:23.745033264160156:  37%|███▋      | 7/19 [01:54<03:14, 16.23s/it]loss:23.584186553955078:  37%|███▋      | 7/19 [02:10<03:14, 16.23s/it]loss:23.584186553955078:  42%|████▏     | 8/19 [02:10<02:57, 16.15s/it]loss:23.548887252807617:  42%|████▏     | 8/19 [02:25<02:57, 16.15s/it]loss:23.548887252807617:  47%|████▋     | 9/19 [02:25<02:39, 15.94s/it]loss:23.33174705505371:  47%|████▋     | 9/19 [02:40<02:39, 15.94s/it] loss:23.33174705505371:  53%|█████▎    | 10/19 [02:40<02:20, 15.57s/it]loss:23.2659854888916:  53%|█████▎    | 10/19 [02:54<02:20, 15.57s/it] loss:23.2659854888916:  58%|█████▊    | 11/19 [02:54<02:01, 15.16s/it]loss:23.577728271484375:  58%|█████▊    | 11/19 [03:08<02:01, 15.16s/it]loss:23.577728271484375:  63%|██████▎   | 12/19 [03:08<01:43, 14.73s/it]loss:23.17023277282715:  63%|██████▎   | 12/19 [03:22<01:43, 14.73s/it] loss:23.17023277282715:  68%|██████▊   | 13/19 [03:22<01:27, 14.62s/it]loss:23.207698822021484:  68%|██████▊   | 13/19 [03:38<01:27, 14.62s/it]loss:23.207698822021484:  74%|███████▎  | 14/19 [03:38<01:13, 14.79s/it]loss:23.080766677856445:  74%|███████▎  | 14/19 [03:53<01:13, 14.79s/it]loss:23.080766677856445:  79%|███████▉  | 15/19 [03:53<01:00, 15.03s/it]loss:23.486167907714844:  79%|███████▉  | 15/19 [04:08<01:00, 15.03s/it]loss:23.486167907714844:  84%|████████▍ | 16/19 [04:08<00:44, 14.92s/it]loss:22.829133987426758:  84%|████████▍ | 16/19 [04:25<00:44, 14.92s/it]loss:22.829133987426758:  89%|████████▉ | 17/19 [04:25<00:31, 15.55s/it]loss:23.93834686279297:  89%|████████▉ | 17/19 [04:41<00:31, 15.55s/it] loss:23.93834686279297:  95%|█████████▍| 18/19 [04:41<00:15, 15.75s/it]loss:23.849191665649414:  95%|█████████▍| 18/19 [04:57<00:15, 15.75s/it]loss:23.849191665649414: 100%|██████████| 19/19 [04:57<00:00, 15.90s/it]loss:23.849191665649414: 100%|██████████| 19/19 [04:57<00:00, 15.67s/it]
Epoch: 1 cost time: 298.2834665775299
Epoch: 1, Steps: 19 | Train Loss: 23.4672114 Vali Loss: 3.3613596 Test Loss: 41.2751045
Validation loss decreased (inf --> 3.361360).  Saving model ...
Updating learning rate to 0.0001
  0%|          | 0/19 [00:00<?, ?it/s]loss:23.336551666259766:   0%|          | 0/19 [00:17<?, ?it/s]loss:23.336551666259766:   5%|▌         | 1/19 [00:17<05:08, 17.16s/it]loss:23.114877700805664:   5%|▌         | 1/19 [00:33<05:08, 17.16s/it]loss:23.114877700805664:  11%|█         | 2/19 [00:33<04:44, 16.76s/it]loss:23.23395347595215:  11%|█         | 2/19 [00:50<04:44, 16.76s/it] loss:23.23395347595215:  16%|█▌        | 3/19 [00:50<04:29, 16.86s/it]loss:23.395864486694336:  16%|█▌        | 3/19 [01:07<04:29, 16.86s/it]loss:23.395864486694336:  21%|██        | 4/19 [01:07<04:12, 16.82s/it]loss:23.51380729675293:  21%|██        | 4/19 [01:23<04:12, 16.82s/it] loss:23.51380729675293:  26%|██▋       | 5/19 [01:23<03:52, 16.62s/it]loss:23.573833465576172:  26%|██▋       | 5/19 [01:42<03:52, 16.62s/it]loss:23.573833465576172:  32%|███▏      | 6/19 [01:42<03:44, 17.26s/it]loss:23.506790161132812:  32%|███▏      | 6/19 [02:00<03:44, 17.26s/it]loss:23.506790161132812:  37%|███▋      | 7/19 [02:00<03:31, 17.63s/it]loss:23.416606903076172:  37%|███▋      | 7/19 [02:16<03:31, 17.63s/it]loss:23.416606903076172:  42%|████▏     | 8/19 [02:16<03:08, 17.09s/it]loss:23.519689559936523:  42%|████▏     | 8/19 [02:34<03:08, 17.09s/it]loss:23.519689559936523:  47%|████▋     | 9/19 [02:34<02:52, 17.30s/it]loss:23.343097686767578:  47%|████▋     | 9/19 [02:52<02:52, 17.30s/it]loss:23.343097686767578:  53%|█████▎    | 10/19 [02:52<02:38, 17.66s/it]loss:23.824583053588867:  53%|█████▎    | 10/19 [03:09<02:38, 17.66s/it]loss:23.824583053588867:  58%|█████▊    | 11/19 [03:09<02:19, 17.39s/it]loss:23.195724487304688:  58%|█████▊    | 11/19 [03:26<02:19, 17.39s/it]loss:23.195724487304688:  63%|██████▎   | 12/19 [03:26<02:01, 17.31s/it]loss:23.284297943115234:  63%|██████▎   | 12/19 [03:43<02:01, 17.31s/it]loss:23.284297943115234:  68%|██████▊   | 13/19 [03:43<01:43, 17.22s/it]loss:23.78520965576172:  68%|██████▊   | 13/19 [03:58<01:43, 17.22s/it] loss:23.78520965576172:  74%|███████▎  | 14/19 [03:58<01:22, 16.52s/it]loss:24.26890754699707:  74%|███████▎  | 14/19 [04:16<01:22, 16.52s/it]loss:24.26890754699707:  79%|███████▉  | 15/19 [04:16<01:08, 17.11s/it]loss:22.90568733215332:  79%|███████▉  | 15/19 [04:34<01:08, 17.11s/it]loss:22.90568733215332:  84%|████████▍ | 16/19 [04:34<00:51, 17.13s/it]loss:23.593351364135742:  84%|████████▍ | 16/19 [04:50<00:51, 17.13s/it]loss:23.593351364135742:  89%|████████▉ | 17/19 [04:50<00:34, 17.01s/it]loss:23.083730697631836:  89%|████████▉ | 17/19 [05:07<00:34, 17.01s/it]loss:23.083730697631836:  95%|█████████▍| 18/19 [05:07<00:16, 16.93s/it]loss:23.45494270324707:  95%|█████████▍| 18/19 [05:23<00:16, 16.93s/it] loss:23.45494270324707: 100%|██████████| 19/19 [05:23<00:00, 16.75s/it]loss:23.45494270324707: 100%|██████████| 19/19 [05:24<00:00, 17.07s/it]
Epoch: 2 cost time: 326.1185019016266
Epoch: 2, Steps: 19 | Train Loss: 23.4395530 Vali Loss: 3.2227676 Test Loss: 45.3994217
Validation loss decreased (3.361360 --> 3.222768).  Saving model ...
Updating learning rate to 5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:23.10197639465332:   0%|          | 0/19 [00:18<?, ?it/s]loss:23.10197639465332:   5%|▌         | 1/19 [00:18<05:24, 18.04s/it]loss:23.459712982177734:   5%|▌         | 1/19 [00:35<05:24, 18.04s/it]loss:23.459712982177734:  11%|█         | 2/19 [00:35<04:56, 17.42s/it]loss:23.403837203979492:  11%|█         | 2/19 [00:51<04:56, 17.42s/it]loss:23.403837203979492:  16%|█▌        | 3/19 [00:51<04:31, 16.99s/it]loss:23.127784729003906:  16%|█▌        | 3/19 [01:07<04:31, 16.99s/it]loss:23.127784729003906:  21%|██        | 4/19 [01:07<04:11, 16.77s/it]loss:23.045734405517578:  21%|██        | 4/19 [01:24<04:11, 16.77s/it]loss:23.045734405517578:  26%|██▋       | 5/19 [01:24<03:54, 16.77s/it]loss:23.289554595947266:  26%|██▋       | 5/19 [01:41<03:54, 16.77s/it]loss:23.289554595947266:  32%|███▏      | 6/19 [01:41<03:38, 16.81s/it]loss:23.78512191772461:  32%|███▏      | 6/19 [01:58<03:38, 16.81s/it] loss:23.78512191772461:  37%|███▋      | 7/19 [01:58<03:23, 16.93s/it]loss:23.756187438964844:  37%|███▋      | 7/19 [02:15<03:23, 16.93s/it]loss:23.756187438964844:  42%|████▏     | 8/19 [02:15<03:05, 16.86s/it]loss:23.128238677978516:  42%|████▏     | 8/19 [02:33<03:05, 16.86s/it]loss:23.128238677978516:  47%|████▋     | 9/19 [02:33<02:51, 17.13s/it]loss:23.610368728637695:  47%|████▋     | 9/19 [02:50<02:51, 17.13s/it]loss:23.610368728637695:  53%|█████▎    | 10/19 [02:50<02:33, 17.05s/it]loss:23.338834762573242:  53%|█████▎    | 10/19 [03:05<02:33, 17.05s/it]loss:23.338834762573242:  58%|█████▊    | 11/19 [03:05<02:12, 16.56s/it]loss:23.387500762939453:  58%|█████▊    | 11/19 [03:22<02:12, 16.56s/it]loss:23.387500762939453:  63%|██████▎   | 12/19 [03:22<01:56, 16.68s/it]loss:23.302324295043945:  63%|██████▎   | 12/19 [03:39<01:56, 16.68s/it]loss:23.302324295043945:  68%|██████▊   | 13/19 [03:39<01:40, 16.73s/it]loss:23.195573806762695:  68%|██████▊   | 13/19 [03:55<01:40, 16.73s/it]loss:23.195573806762695:  74%|███████▎  | 14/19 [03:55<01:23, 16.69s/it]loss:23.35019302368164:  74%|███████▎  | 14/19 [04:12<01:23, 16.69s/it] loss:23.35019302368164:  79%|███████▉  | 15/19 [04:12<01:07, 16.78s/it]loss:23.444408416748047:  79%|███████▉  | 15/19 [04:29<01:07, 16.78s/it]loss:23.444408416748047:  84%|████████▍ | 16/19 [04:29<00:50, 16.87s/it]loss:23.026952743530273:  84%|████████▍ | 16/19 [04:47<00:50, 16.87s/it]loss:23.026952743530273:  89%|████████▉ | 17/19 [04:47<00:34, 17.06s/it]loss:23.49302101135254:  89%|████████▉ | 17/19 [05:04<00:34, 17.06s/it] loss:23.49302101135254:  95%|█████████▍| 18/19 [05:04<00:16, 16.98s/it]loss:23.488224029541016:  95%|█████████▍| 18/19 [05:21<00:16, 16.98s/it]loss:23.488224029541016: 100%|██████████| 19/19 [05:21<00:00, 16.94s/it]loss:23.488224029541016: 100%|██████████| 19/19 [05:21<00:00, 16.92s/it]
Epoch: 3 cost time: 323.83526277542114
Epoch: 3, Steps: 19 | Train Loss: 23.3545026 Vali Loss: 3.1356175 Test Loss: 39.2458496
Validation loss decreased (3.222768 --> 3.135617).  Saving model ...
Updating learning rate to 2.5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:23.092636108398438:   0%|          | 0/19 [00:16<?, ?it/s]loss:23.092636108398438:   5%|▌         | 1/19 [00:16<05:04, 16.93s/it]loss:23.190488815307617:   5%|▌         | 1/19 [00:33<05:04, 16.93s/it]loss:23.190488815307617:  11%|█         | 2/19 [00:33<04:44, 16.72s/it]loss:23.454849243164062:  11%|█         | 2/19 [00:49<04:44, 16.72s/it]loss:23.454849243164062:  16%|█▌        | 3/19 [00:49<04:21, 16.33s/it]loss:23.03306007385254:  16%|█▌        | 3/19 [01:05<04:21, 16.33s/it] loss:23.03306007385254:  21%|██        | 4/19 [01:05<04:01, 16.11s/it]loss:23.389066696166992:  21%|██        | 4/19 [01:21<04:01, 16.11s/it]loss:23.389066696166992:  26%|██▋       | 5/19 [01:21<03:45, 16.13s/it]loss:23.403860092163086:  26%|██▋       | 5/19 [01:37<03:45, 16.13s/it]loss:23.403860092163086:  32%|███▏      | 6/19 [01:37<03:29, 16.12s/it]loss:23.261659622192383:  32%|███▏      | 6/19 [01:53<03:29, 16.12s/it]loss:23.261659622192383:  37%|███▋      | 7/19 [01:53<03:13, 16.15s/it]loss:23.103567123413086:  37%|███▋      | 7/19 [02:09<03:13, 16.15s/it]loss:23.103567123413086:  42%|████▏     | 8/19 [02:09<02:58, 16.19s/it]loss:23.299528121948242:  42%|████▏     | 8/19 [02:25<02:58, 16.19s/it]loss:23.299528121948242:  47%|████▋     | 9/19 [02:25<02:40, 16.06s/it]loss:22.993871688842773:  47%|████▋     | 9/19 [02:41<02:40, 16.06s/it]loss:22.993871688842773:  53%|█████▎    | 10/19 [02:41<02:24, 16.11s/it]loss:23.431821823120117:  53%|█████▎    | 10/19 [02:58<02:24, 16.11s/it]loss:23.431821823120117:  58%|█████▊    | 11/19 [02:58<02:09, 16.19s/it]loss:23.619617462158203:  58%|█████▊    | 11/19 [03:14<02:09, 16.19s/it]loss:23.619617462158203:  63%|██████▎   | 12/19 [03:14<01:54, 16.33s/it]loss:23.299781799316406:  63%|██████▎   | 12/19 [03:31<01:54, 16.33s/it]loss:23.299781799316406:  68%|██████▊   | 13/19 [03:31<01:38, 16.38s/it]loss:23.363597869873047:  68%|██████▊   | 13/19 [03:47<01:38, 16.38s/it]loss:23.363597869873047:  74%|███████▎  | 14/19 [03:47<01:20, 16.15s/it]loss:23.0627384185791:  74%|███████▎  | 14/19 [04:02<01:20, 16.15s/it]  loss:23.0627384185791:  79%|███████▉  | 15/19 [04:02<01:04, 16.04s/it]loss:23.877248764038086:  79%|███████▉  | 15/19 [04:19<01:04, 16.04s/it]loss:23.877248764038086:  84%|████████▍ | 16/19 [04:19<00:48, 16.15s/it]loss:23.76836395263672:  84%|████████▍ | 16/19 [04:35<00:48, 16.15s/it] loss:23.76836395263672:  89%|████████▉ | 17/19 [04:35<00:32, 16.28s/it]loss:23.349109649658203:  89%|████████▉ | 17/19 [04:52<00:32, 16.28s/it]loss:23.349109649658203:  95%|█████████▍| 18/19 [04:52<00:16, 16.30s/it]loss:23.311548233032227:  95%|█████████▍| 18/19 [05:07<00:16, 16.30s/it]loss:23.311548233032227: 100%|██████████| 19/19 [05:07<00:00, 16.01s/it]loss:23.311548233032227: 100%|██████████| 19/19 [05:07<00:00, 16.19s/it]
Epoch: 4 cost time: 309.52955865859985
Epoch: 4, Steps: 19 | Train Loss: 23.3319166 Vali Loss: 3.0824053 Test Loss: 41.7757759
Validation loss decreased (3.135617 --> 3.082405).  Saving model ...
Updating learning rate to 1.25e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:23.03495979309082:   0%|          | 0/19 [00:17<?, ?it/s]loss:23.03495979309082:   5%|▌         | 1/19 [00:17<05:18, 17.70s/it]loss:23.347511291503906:   5%|▌         | 1/19 [00:35<05:18, 17.70s/it]loss:23.347511291503906:  11%|█         | 2/19 [00:35<05:02, 17.80s/it]loss:23.32954216003418:  11%|█         | 2/19 [00:51<05:02, 17.80s/it] loss:23.32954216003418:  16%|█▌        | 3/19 [00:51<04:30, 16.88s/it]loss:23.322248458862305:  16%|█▌        | 3/19 [01:08<04:30, 16.88s/it]loss:23.322248458862305:  21%|██        | 4/19 [01:08<04:15, 17.01s/it]loss:23.66509437561035:  21%|██        | 4/19 [01:25<04:15, 17.01s/it] loss:23.66509437561035:  26%|██▋       | 5/19 [01:25<03:59, 17.10s/it]loss:23.397537231445312:  26%|██▋       | 5/19 [01:42<03:59, 17.10s/it]loss:23.397537231445312:  32%|███▏      | 6/19 [01:42<03:40, 16.94s/it]loss:23.05426788330078:  32%|███▏      | 6/19 [01:59<03:40, 16.94s/it] loss:23.05426788330078:  37%|███▋      | 7/19 [01:59<03:21, 16.83s/it]loss:23.459135055541992:  37%|███▋      | 7/19 [02:16<03:21, 16.83s/it]loss:23.459135055541992:  42%|████▏     | 8/19 [02:16<03:07, 17.07s/it]loss:23.42266082763672:  42%|████▏     | 8/19 [02:35<03:07, 17.07s/it] loss:23.42266082763672:  47%|████▋     | 9/19 [02:35<02:55, 17.56s/it]loss:23.384878158569336:  47%|████▋     | 9/19 [02:52<02:55, 17.56s/it]loss:23.384878158569336:  53%|█████▎    | 10/19 [02:52<02:37, 17.55s/it]loss:23.075963973999023:  53%|█████▎    | 10/19 [03:09<02:37, 17.55s/it]loss:23.075963973999023:  58%|█████▊    | 11/19 [03:09<02:18, 17.32s/it]loss:23.507917404174805:  58%|█████▊    | 11/19 [03:27<02:18, 17.32s/it]loss:23.507917404174805:  63%|██████▎   | 12/19 [03:27<02:01, 17.35s/it]loss:23.87934112548828:  63%|██████▎   | 12/19 [03:44<02:01, 17.35s/it] loss:23.87934112548828:  68%|██████▊   | 13/19 [03:44<01:44, 17.43s/it]loss:23.074363708496094:  68%|██████▊   | 13/19 [04:02<01:44, 17.43s/it]loss:23.074363708496094:  74%|███████▎  | 14/19 [04:02<01:27, 17.43s/it]loss:23.30762481689453:  74%|███████▎  | 14/19 [04:19<01:27, 17.43s/it] loss:23.30762481689453:  79%|███████▉  | 15/19 [04:19<01:09, 17.33s/it]loss:23.36908721923828:  79%|███████▉  | 15/19 [04:35<01:09, 17.33s/it]loss:23.36908721923828:  84%|████████▍ | 16/19 [04:35<00:51, 17.15s/it]loss:23.070146560668945:  84%|████████▍ | 16/19 [04:53<00:51, 17.15s/it]loss:23.070146560668945:  89%|████████▉ | 17/19 [04:53<00:34, 17.30s/it]loss:23.35150909423828:  89%|████████▉ | 17/19 [05:09<00:34, 17.30s/it] loss:23.35150909423828:  95%|█████████▍| 18/19 [05:09<00:16, 16.95s/it]loss:23.34459686279297:  95%|█████████▍| 18/19 [05:28<00:16, 16.95s/it]loss:23.34459686279297: 100%|██████████| 19/19 [05:28<00:00, 17.38s/it]loss:23.34459686279297: 100%|██████████| 19/19 [05:28<00:00, 17.28s/it]
Epoch: 5 cost time: 330.2275929450989
Epoch: 5, Steps: 19 | Train Loss: 23.3367572 Vali Loss: 3.0812659 Test Loss: 41.3668671
Validation loss decreased (3.082405 --> 3.081266).  Saving model ...
Updating learning rate to 6.25e-06
  0%|          | 0/19 [00:00<?, ?it/s]loss:23.23326873779297:   0%|          | 0/19 [00:18<?, ?it/s]loss:23.23326873779297:   5%|▌         | 1/19 [00:18<05:37, 18.74s/it]loss:23.507396697998047:   5%|▌         | 1/19 [00:37<05:37, 18.74s/it]loss:23.507396697998047:  11%|█         | 2/19 [00:37<05:18, 18.74s/it]loss:23.405681610107422:  11%|█         | 2/19 [00:57<05:18, 18.74s/it]loss:23.405681610107422:  16%|█▌        | 3/19 [00:57<05:06, 19.15s/it]loss:23.37837028503418:  16%|█▌        | 3/19 [01:14<05:06, 19.15s/it] loss:23.37837028503418:  21%|██        | 4/19 [01:14<04:38, 18.57s/it]loss:23.329740524291992:  21%|██        | 4/19 [01:33<04:38, 18.57s/it]loss:23.329740524291992:  26%|██▋       | 5/19 [01:33<04:21, 18.68s/it]loss:23.371129989624023:  26%|██▋       | 5/19 [01:52<04:21, 18.68s/it]loss:23.371129989624023:  32%|███▏      | 6/19 [01:52<04:04, 18.79s/it]loss:23.09375762939453:  32%|███▏      | 6/19 [02:10<04:04, 18.79s/it] loss:23.09375762939453:  37%|███▋      | 7/19 [02:10<03:42, 18.57s/it]loss:23.037904739379883:  37%|███▋      | 7/19 [02:30<03:42, 18.57s/it]loss:23.037904739379883:  42%|████▏     | 8/19 [02:30<03:27, 18.85s/it]loss:23.0791015625:  42%|████▏     | 8/19 [02:48<03:27, 18.85s/it]     loss:23.0791015625:  47%|████▋     | 9/19 [02:48<03:07, 18.78s/it]loss:23.60683250427246:  47%|████▋     | 9/19 [03:06<03:07, 18.78s/it]loss:23.60683250427246:  53%|█████▎    | 10/19 [03:06<02:47, 18.56s/it]loss:23.06606674194336:  53%|█████▎    | 10/19 [03:26<02:47, 18.56s/it]loss:23.06606674194336:  58%|█████▊    | 11/19 [03:26<02:29, 18.73s/it]loss:23.367652893066406:  58%|█████▊    | 11/19 [03:41<02:29, 18.73s/it]loss:23.367652893066406:  63%|██████▎   | 12/19 [03:41<02:03, 17.64s/it]loss:23.391408920288086:  63%|██████▎   | 12/19 [03:56<02:03, 17.64s/it]loss:23.391408920288086:  68%|██████▊   | 13/19 [03:56<01:42, 17.07s/it]loss:23.888826370239258:  68%|██████▊   | 13/19 [04:13<01:42, 17.07s/it]loss:23.888826370239258:  74%|███████▎  | 14/19 [04:13<01:23, 16.78s/it]loss:23.072757720947266:  74%|███████▎  | 14/19 [04:28<01:23, 16.78s/it]loss:23.072757720947266:  79%|███████▉  | 15/19 [04:28<01:06, 16.52s/it]loss:23.347150802612305:  79%|███████▉  | 15/19 [04:43<01:06, 16.52s/it]loss:23.347150802612305:  84%|████████▍ | 16/19 [04:43<00:47, 15.99s/it]loss:23.349828720092773:  84%|████████▍ | 16/19 [04:58<00:47, 15.99s/it]loss:23.349828720092773:  89%|████████▉ | 17/19 [04:58<00:31, 15.59s/it]loss:23.456134796142578:  89%|████████▉ | 17/19 [05:14<00:31, 15.59s/it]loss:23.456134796142578:  95%|█████████▍| 18/19 [05:14<00:15, 15.63s/it]loss:23.29552459716797:  95%|█████████▍| 18/19 [05:30<00:15, 15.63s/it] loss:23.29552459716797: 100%|██████████| 19/19 [05:30<00:00, 15.82s/it]loss:23.29552459716797: 100%|██████████| 19/19 [05:30<00:00, 17.40s/it]
Epoch: 6 cost time: 332.66334867477417
Epoch: 6, Steps: 19 | Train Loss: 23.3304493 Vali Loss: 3.0810275 Test Loss: 41.1882629
Validation loss decreased (3.081266 --> 3.081028).  Saving model ...
Updating learning rate to 3.125e-06
  0%|          | 0/19 [00:00<?, ?it/s]loss:23.082202911376953:   0%|          | 0/19 [00:15<?, ?it/s]loss:23.082202911376953:   5%|▌         | 1/19 [00:15<04:42, 15.72s/it]loss:23.34295082092285:   5%|▌         | 1/19 [00:32<04:42, 15.72s/it] loss:23.34295082092285:  11%|█         | 2/19 [00:32<04:33, 16.08s/it]loss:23.365894317626953:  11%|█         | 2/19 [00:47<04:33, 16.08s/it]loss:23.365894317626953:  16%|█▌        | 3/19 [00:47<04:12, 15.75s/it]loss:23.32047462463379:  16%|█▌        | 3/19 [01:02<04:12, 15.75s/it] loss:23.32047462463379:  21%|██        | 4/19 [01:02<03:50, 15.37s/it]loss:23.344451904296875:  21%|██        | 4/19 [01:18<03:50, 15.37s/it]loss:23.344451904296875:  26%|██▋       | 5/19 [01:18<03:37, 15.54s/it]loss:23.066513061523438:  26%|██▋       | 5/19 [01:33<03:37, 15.54s/it]loss:23.066513061523438:  32%|███▏      | 6/19 [01:33<03:22, 15.61s/it]loss:23.554000854492188:  32%|███▏      | 6/19 [01:49<03:22, 15.61s/it]loss:23.554000854492188:  37%|███▋      | 7/19 [01:49<03:08, 15.71s/it]loss:23.009267807006836:  37%|███▋      | 7/19 [02:05<03:08, 15.71s/it]loss:23.009267807006836:  42%|████▏     | 8/19 [02:05<02:52, 15.66s/it]loss:23.65777015686035:  42%|████▏     | 8/19 [02:20<02:52, 15.66s/it] loss:23.65777015686035:  47%|████▋     | 9/19 [02:20<02:36, 15.65s/it]loss:23.457815170288086:  47%|████▋     | 9/19 [02:36<02:36, 15.65s/it]loss:23.457815170288086:  53%|█████▎    | 10/19 [02:36<02:20, 15.61s/it]loss:23.288131713867188:  53%|█████▎    | 10/19 [02:51<02:20, 15.61s/it]loss:23.288131713867188:  58%|█████▊    | 11/19 [02:51<02:04, 15.57s/it]loss:23.071134567260742:  58%|█████▊    | 11/19 [03:06<02:04, 15.57s/it]loss:23.071134567260742:  63%|██████▎   | 12/19 [03:06<01:47, 15.43s/it]loss:23.893569946289062:  63%|██████▎   | 12/19 [03:22<01:47, 15.43s/it]loss:23.893569946289062:  68%|██████▊   | 13/19 [03:22<01:32, 15.40s/it]loss:23.400123596191406:  68%|██████▊   | 13/19 [03:37<01:32, 15.40s/it]loss:23.400123596191406:  74%|███████▎  | 14/19 [03:37<01:16, 15.31s/it]loss:23.422348022460938:  74%|███████▎  | 14/19 [03:52<01:16, 15.31s/it]loss:23.422348022460938:  79%|███████▉  | 15/19 [03:52<01:00, 15.22s/it]loss:23.262432098388672:  79%|███████▉  | 15/19 [04:07<01:00, 15.22s/it]loss:23.262432098388672:  84%|████████▍ | 16/19 [04:07<00:45, 15.09s/it]loss:23.068693161010742:  84%|████████▍ | 16/19 [04:22<00:45, 15.09s/it]loss:23.068693161010742:  89%|████████▉ | 17/19 [04:22<00:30, 15.15s/it]loss:23.384008407592773:  89%|████████▉ | 17/19 [04:38<00:30, 15.15s/it]loss:23.384008407592773:  95%|█████████▍| 18/19 [04:38<00:15, 15.28s/it]loss:23.336509704589844:  95%|█████████▍| 18/19 [04:54<00:15, 15.28s/it]loss:23.336509704589844: 100%|██████████| 19/19 [04:54<00:00, 15.47s/it]loss:23.336509704589844: 100%|██████████| 19/19 [04:54<00:00, 15.49s/it]
Epoch: 7 cost time: 295.8889079093933
Epoch: 7, Steps: 19 | Train Loss: 23.3330680 Vali Loss: 3.0804660 Test Loss: 41.1195831
Validation loss decreased (3.081028 --> 3.080466).  Saving model ...
Updating learning rate to 1.5625e-06
  0%|          | 0/19 [00:00<?, ?it/s]loss:23.07489585876465:   0%|          | 0/19 [00:16<?, ?it/s]loss:23.07489585876465:   5%|▌         | 1/19 [00:16<04:48, 16.01s/it]loss:23.45159149169922:   5%|▌         | 1/19 [00:31<04:48, 16.01s/it]loss:23.45159149169922:  11%|█         | 2/19 [00:31<04:22, 15.42s/it]loss:23.37632942199707:  11%|█         | 2/19 [00:45<04:22, 15.42s/it]loss:23.37632942199707:  16%|█▌        | 3/19 [00:45<04:03, 15.22s/it]loss:23.068178176879883:  16%|█▌        | 3/19 [01:01<04:03, 15.22s/it]loss:23.068178176879883:  21%|██        | 4/19 [01:01<03:48, 15.26s/it]loss:23.07196044921875:  21%|██        | 4/19 [01:16<03:48, 15.26s/it] loss:23.07196044921875:  26%|██▋       | 5/19 [01:16<03:35, 15.36s/it]loss:23.32239532470703:  26%|██▋       | 5/19 [01:32<03:35, 15.36s/it]loss:23.32239532470703:  32%|███▏      | 6/19 [01:32<03:21, 15.51s/it]loss:23.551715850830078:  32%|███▏      | 6/19 [01:48<03:21, 15.51s/it]loss:23.551715850830078:  37%|███▋      | 7/19 [01:48<03:08, 15.67s/it]loss:23.075483322143555:  37%|███▋      | 7/19 [02:04<03:08, 15.67s/it]loss:23.075483322143555:  42%|████▏     | 8/19 [02:04<02:52, 15.69s/it]loss:23.376846313476562:  42%|████▏     | 8/19 [02:20<02:52, 15.69s/it]loss:23.376846313476562:  47%|████▋     | 9/19 [02:20<02:38, 15.87s/it]loss:23.265792846679688:  47%|████▋     | 9/19 [02:36<02:38, 15.87s/it]loss:23.265792846679688:  53%|█████▎    | 10/19 [02:36<02:23, 15.90s/it]loss:23.34317398071289:  53%|█████▎    | 10/19 [02:52<02:23, 15.90s/it] loss:23.34317398071289:  58%|█████▊    | 11/19 [02:52<02:07, 15.93s/it]loss:23.32853889465332:  58%|█████▊    | 11/19 [03:08<02:07, 15.93s/it]loss:23.32853889465332:  63%|██████▎   | 12/19 [03:08<01:51, 15.87s/it]loss:23.889249801635742:  63%|██████▎   | 12/19 [03:24<01:51, 15.87s/it]loss:23.889249801635742:  68%|██████▊   | 13/19 [03:24<01:35, 15.92s/it]loss:23.35219383239746:  68%|██████▊   | 13/19 [03:40<01:35, 15.92s/it] loss:23.35219383239746:  74%|███████▎  | 14/19 [03:40<01:20, 16.07s/it]loss:23.286909103393555:  74%|███████▎  | 14/19 [03:57<01:20, 16.07s/it]loss:23.286909103393555:  79%|███████▉  | 15/19 [03:57<01:04, 16.19s/it]loss:23.383089065551758:  79%|███████▉  | 15/19 [04:13<01:04, 16.19s/it]loss:23.383089065551758:  84%|████████▍ | 16/19 [04:13<00:48, 16.14s/it]loss:23.424318313598633:  84%|████████▍ | 16/19 [04:29<00:48, 16.14s/it]loss:23.424318313598633:  89%|████████▉ | 17/19 [04:29<00:32, 16.11s/it]loss:23.655784606933594:  89%|████████▉ | 17/19 [04:44<00:32, 16.11s/it]loss:23.655784606933594:  95%|█████████▍| 18/19 [04:44<00:15, 15.87s/it]loss:23.01862335205078:  95%|█████████▍| 18/19 [05:00<00:15, 15.87s/it] loss:23.01862335205078: 100%|██████████| 19/19 [05:00<00:00, 15.75s/it]loss:23.01862335205078: 100%|██████████| 19/19 [05:00<00:00, 15.81s/it]
Epoch: 8 cost time: 302.26572251319885
Epoch: 8, Steps: 19 | Train Loss: 23.3324774 Vali Loss: 3.0771337 Test Loss: 41.0478630
Validation loss decreased (3.080466 --> 3.077134).  Saving model ...
Updating learning rate to 7.8125e-07
  0%|          | 0/19 [00:00<?, ?it/s]loss:23.068809509277344:   0%|          | 0/19 [00:16<?, ?it/s]loss:23.068809509277344:   5%|▌         | 1/19 [00:16<04:56, 16.45s/it]loss:23.385961532592773:   5%|▌         | 1/19 [00:32<04:56, 16.45s/it]loss:23.385961532592773:  11%|█         | 2/19 [00:32<04:31, 15.99s/it]loss:23.88866424560547:  11%|█         | 2/19 [00:48<04:31, 15.99s/it] loss:23.88866424560547:  16%|█▌        | 3/19 [00:48<04:16, 16.01s/it]loss:23.075328826904297:  16%|█▌        | 3/19 [01:04<04:16, 16.01s/it]loss:23.075328826904297:  21%|██        | 4/19 [01:04<04:01, 16.08s/it]loss:23.64738655090332:  21%|██        | 4/19 [01:20<04:01, 16.08s/it] loss:23.64738655090332:  26%|██▋       | 5/19 [01:20<03:45, 16.09s/it]loss:23.45138168334961:  26%|██▋       | 5/19 [01:36<03:45, 16.09s/it]loss:23.45138168334961:  32%|███▏      | 6/19 [01:36<03:28, 16.06s/it]loss:23.37677001953125:  32%|███▏      | 6/19 [01:51<03:28, 16.06s/it]loss:23.37677001953125:  37%|███▋      | 7/19 [01:51<03:10, 15.87s/it]loss:23.290542602539062:  37%|███▋      | 7/19 [02:07<03:10, 15.87s/it]loss:23.290542602539062:  42%|████▏     | 8/19 [02:07<02:53, 15.78s/it]loss:23.34431266784668:  42%|████▏     | 8/19 [02:23<02:53, 15.78s/it] loss:23.34431266784668:  47%|████▋     | 9/19 [02:23<02:38, 15.82s/it]loss:23.551448822021484:  47%|████▋     | 9/19 [02:38<02:38, 15.82s/it]loss:23.551448822021484:  53%|█████▎    | 10/19 [02:38<02:20, 15.66s/it]loss:23.374086380004883:  53%|█████▎    | 10/19 [02:54<02:20, 15.66s/it]loss:23.374086380004883:  58%|█████▊    | 11/19 [02:54<02:05, 15.71s/it]loss:23.326181411743164:  58%|█████▊    | 11/19 [03:09<02:05, 15.71s/it]loss:23.326181411743164:  63%|██████▎   | 12/19 [03:09<01:48, 15.55s/it]loss:23.07619285583496:  63%|██████▎   | 12/19 [03:25<01:48, 15.55s/it] loss:23.07619285583496:  68%|██████▊   | 13/19 [03:25<01:34, 15.69s/it]loss:23.419933319091797:  68%|██████▊   | 13/19 [03:40<01:34, 15.69s/it]loss:23.419933319091797:  74%|███████▎  | 14/19 [03:40<01:17, 15.56s/it]loss:23.33456802368164:  74%|███████▎  | 14/19 [03:56<01:17, 15.56s/it] loss:23.33456802368164:  79%|███████▉  | 15/19 [03:56<01:02, 15.59s/it]loss:23.072736740112305:  79%|███████▉  | 15/19 [04:11<01:02, 15.59s/it]loss:23.072736740112305:  84%|████████▍ | 16/19 [04:11<00:46, 15.49s/it]loss:23.265493392944336:  84%|████████▍ | 16/19 [04:27<00:46, 15.49s/it]loss:23.265493392944336:  89%|████████▉ | 17/19 [04:27<00:30, 15.41s/it]loss:23.3439998626709:  89%|████████▉ | 17/19 [04:42<00:30, 15.41s/it]  loss:23.3439998626709:  95%|█████████▍| 18/19 [04:42<00:15, 15.50s/it]loss:23.027666091918945:  95%|█████████▍| 18/19 [04:58<00:15, 15.50s/it]loss:23.027666091918945: 100%|██████████| 19/19 [04:58<00:00, 15.54s/it]loss:23.027666091918945: 100%|██████████| 19/19 [04:58<00:00, 15.72s/it]
Epoch: 9 cost time: 300.35065054893494
Epoch: 9, Steps: 19 | Train Loss: 23.3327087 Vali Loss: 3.0749133 Test Loss: 41.0223198
Validation loss decreased (3.077134 --> 3.074913).  Saving model ...
Updating learning rate to 3.90625e-07
  0%|          | 0/19 [00:00<?, ?it/s]loss:23.88385009765625:   0%|          | 0/19 [00:16<?, ?it/s]loss:23.88385009765625:   5%|▌         | 1/19 [00:16<04:58, 16.56s/it]loss:23.38326072692871:   5%|▌         | 1/19 [00:32<04:58, 16.56s/it]loss:23.38326072692871:  11%|█         | 2/19 [00:32<04:34, 16.15s/it]loss:23.291711807250977:  11%|█         | 2/19 [00:48<04:34, 16.15s/it]loss:23.291711807250977:  16%|█▌        | 3/19 [00:48<04:17, 16.11s/it]loss:23.263870239257812:  16%|█▌        | 3/19 [01:03<04:17, 16.11s/it]loss:23.263870239257812:  21%|██        | 4/19 [01:03<03:57, 15.81s/it]loss:23.07583236694336:  21%|██        | 4/19 [01:19<03:57, 15.81s/it] loss:23.07583236694336:  26%|██▋       | 5/19 [01:19<03:42, 15.89s/it]loss:23.448442459106445:  26%|██▋       | 5/19 [01:35<03:42, 15.89s/it]loss:23.448442459106445:  32%|███▏      | 6/19 [01:35<03:24, 15.75s/it]loss:23.548828125:  32%|███▏      | 6/19 [01:50<03:24, 15.75s/it]      loss:23.548828125:  37%|███▋      | 7/19 [01:50<03:06, 15.56s/it]loss:23.071041107177734:  37%|███▋      | 7/19 [02:06<03:06, 15.56s/it]loss:23.071041107177734:  42%|████▏     | 8/19 [02:06<02:51, 15.61s/it]loss:23.650514602661133:  42%|████▏     | 8/19 [02:21<02:51, 15.61s/it]loss:23.650514602661133:  47%|████▋     | 9/19 [02:21<02:35, 15.57s/it]loss:23.3271484375:  47%|████▋     | 9/19 [02:37<02:35, 15.57s/it]     loss:23.3271484375:  53%|█████▎    | 10/19 [02:37<02:21, 15.70s/it]loss:23.345199584960938:  53%|█████▎    | 10/19 [02:53<02:21, 15.70s/it]loss:23.345199584960938:  58%|█████▊    | 11/19 [02:53<02:04, 15.59s/it]loss:23.381574630737305:  58%|█████▊    | 11/19 [03:08<02:04, 15.59s/it]loss:23.381574630737305:  63%|██████▎   | 12/19 [03:08<01:49, 15.61s/it]loss:23.026752471923828:  63%|██████▎   | 12/19 [03:24<01:49, 15.61s/it]loss:23.026752471923828:  68%|██████▊   | 13/19 [03:24<01:34, 15.79s/it]loss:23.337905883789062:  68%|██████▊   | 13/19 [03:40<01:34, 15.79s/it]loss:23.337905883789062:  74%|███████▎  | 14/19 [03:40<01:18, 15.67s/it]loss:23.371870040893555:  74%|███████▎  | 14/19 [03:56<01:18, 15.67s/it]loss:23.371870040893555:  79%|███████▉  | 15/19 [03:56<01:03, 15.77s/it]loss:23.066627502441406:  79%|███████▉  | 15/19 [04:11<01:03, 15.77s/it]loss:23.066627502441406:  84%|████████▍ | 16/19 [04:11<00:46, 15.63s/it]loss:23.346906661987305:  84%|████████▍ | 16/19 [04:27<00:46, 15.63s/it]loss:23.346906661987305:  89%|████████▉ | 17/19 [04:27<00:31, 15.62s/it]loss:23.071609497070312:  89%|████████▉ | 17/19 [04:42<00:31, 15.62s/it]loss:23.071609497070312:  95%|█████████▍| 18/19 [04:42<00:15, 15.58s/it]loss:23.424251556396484:  95%|█████████▍| 18/19 [04:58<00:15, 15.58s/it]loss:23.424251556396484: 100%|██████████| 19/19 [04:58<00:00, 15.63s/it]loss:23.424251556396484: 100%|██████████| 19/19 [04:58<00:00, 15.72s/it]
Epoch: 10 cost time: 300.4606440067291
Epoch: 10, Steps: 19 | Train Loss: 23.3324841 Vali Loss: 3.0761714 Test Loss: 41.0363541
EarlyStopping counter: 1 out of 3
Updating learning rate to 1.953125e-07
  0%|          | 0/19 [00:00<?, ?it/s]loss:23.080322265625:   0%|          | 0/19 [00:16<?, ?it/s]loss:23.080322265625:   5%|▌         | 1/19 [00:16<04:56, 16.45s/it]loss:23.267757415771484:   5%|▌         | 1/19 [00:30<04:56, 16.45s/it]loss:23.267757415771484:  11%|█         | 2/19 [00:30<04:18, 15.22s/it]loss:23.649442672729492:  11%|█         | 2/19 [00:46<04:18, 15.22s/it]loss:23.649442672729492:  16%|█▌        | 3/19 [00:46<04:09, 15.57s/it]loss:23.38711929321289:  16%|█▌        | 3/19 [01:02<04:09, 15.57s/it] loss:23.38711929321289:  21%|██        | 4/19 [01:02<03:53, 15.56s/it]loss:23.342130661010742:  21%|██        | 4/19 [01:16<03:53, 15.56s/it]loss:23.342130661010742:  26%|██▋       | 5/19 [01:16<03:32, 15.19s/it]loss:23.424304962158203:  26%|██▋       | 5/19 [01:32<03:32, 15.19s/it]loss:23.424304962158203:  32%|███▏      | 6/19 [01:32<03:21, 15.47s/it]loss:23.336742401123047:  32%|███▏      | 6/19 [01:48<03:21, 15.47s/it]loss:23.336742401123047:  37%|███▋      | 7/19 [01:48<03:07, 15.62s/it]loss:23.3289794921875:  37%|███▋      | 7/19 [02:04<03:07, 15.62s/it]  loss:23.3289794921875:  42%|████▏     | 8/19 [02:04<02:53, 15.79s/it]loss:23.54828643798828:  42%|████▏     | 8/19 [02:22<02:53, 15.79s/it]loss:23.54828643798828:  47%|████▋     | 9/19 [02:22<02:43, 16.33s/it]loss:23.072391510009766:  47%|████▋     | 9/19 [02:38<02:43, 16.33s/it]loss:23.072391510009766:  53%|█████▎    | 10/19 [02:38<02:24, 16.11s/it]loss:23.06907844543457:  53%|█████▎    | 10/19 [02:54<02:24, 16.11s/it] loss:23.06907844543457:  58%|█████▊    | 11/19 [02:54<02:09, 16.13s/it]loss:23.38355255126953:  58%|█████▊    | 11/19 [03:10<02:09, 16.13s/it]loss:23.38355255126953:  63%|██████▎   | 12/19 [03:10<01:53, 16.17s/it]loss:23.029504776000977:  63%|██████▎   | 12/19 [03:26<01:53, 16.17s/it]loss:23.029504776000977:  68%|██████▊   | 13/19 [03:26<01:36, 16.07s/it]loss:23.354368209838867:  68%|██████▊   | 13/19 [03:44<01:36, 16.07s/it]loss:23.354368209838867:  74%|███████▎  | 14/19 [03:44<01:22, 16.58s/it]loss:23.376863479614258:  74%|███████▎  | 14/19 [04:01<01:22, 16.58s/it]loss:23.376863479614258:  79%|███████▉  | 15/19 [04:01<01:07, 16.82s/it]loss:23.450529098510742:  79%|███████▉  | 15/19 [04:17<01:07, 16.82s/it]loss:23.450529098510742:  84%|████████▍ | 16/19 [04:17<00:50, 16.70s/it]loss:23.887252807617188:  84%|████████▍ | 16/19 [04:34<00:50, 16.70s/it]loss:23.887252807617188:  89%|████████▉ | 17/19 [04:34<00:33, 16.66s/it]loss:23.069652557373047:  89%|████████▉ | 17/19 [04:51<00:33, 16.66s/it]loss:23.069652557373047:  95%|█████████▍| 18/19 [04:51<00:16, 16.89s/it]loss:23.29146385192871:  95%|█████████▍| 18/19 [05:07<00:16, 16.89s/it] loss:23.29146385192871: 100%|██████████| 19/19 [05:07<00:00, 16.63s/it]loss:23.29146385192871: 100%|██████████| 19/19 [05:08<00:00, 16.22s/it]
Epoch: 11 cost time: 309.9963617324829
Epoch: 11, Steps: 19 | Train Loss: 23.3341970 Vali Loss: 3.0764716 Test Loss: 41.0354919
EarlyStopping counter: 2 out of 3
Updating learning rate to 9.765625e-08
  0%|          | 0/19 [00:00<?, ?it/s]loss:23.072206497192383:   0%|          | 0/19 [00:17<?, ?it/s]loss:23.072206497192383:   5%|▌         | 1/19 [00:17<05:07, 17.07s/it]loss:23.346691131591797:   5%|▌         | 1/19 [00:32<05:07, 17.07s/it]loss:23.346691131591797:  11%|█         | 2/19 [00:32<04:38, 16.38s/it]loss:23.32668113708496:  11%|█         | 2/19 [00:48<04:38, 16.38s/it] loss:23.32668113708496:  16%|█▌        | 3/19 [00:48<04:15, 15.98s/it]loss:23.550939559936523:  16%|█▌        | 3/19 [01:04<04:15, 15.98s/it]loss:23.550939559936523:  21%|██        | 4/19 [01:04<04:00, 16.02s/it]loss:23.64472770690918:  21%|██        | 4/19 [01:20<04:00, 16.02s/it] loss:23.64472770690918:  26%|██▋       | 5/19 [01:20<03:43, 15.99s/it]loss:23.3460693359375:  26%|██▋       | 5/19 [01:35<03:43, 15.99s/it] loss:23.3460693359375:  32%|███▏      | 6/19 [01:35<03:23, 15.63s/it]loss:23.39002799987793:  32%|███▏      | 6/19 [01:51<03:23, 15.63s/it]loss:23.39002799987793:  37%|███▋      | 7/19 [01:51<03:09, 15.75s/it]loss:23.026586532592773:  37%|███▋      | 7/19 [02:05<03:09, 15.75s/it]loss:23.026586532592773:  42%|████▏     | 8/19 [02:05<02:49, 15.37s/it]loss:23.0778751373291:  42%|████▏     | 8/19 [02:20<02:49, 15.37s/it]  loss:23.0778751373291:  47%|████▋     | 9/19 [02:20<02:30, 15.08s/it]loss:23.079883575439453:  47%|████▋     | 9/19 [02:35<02:30, 15.08s/it]loss:23.079883575439453:  53%|█████▎    | 10/19 [02:35<02:15, 15.03s/it]loss:23.075834274291992:  53%|█████▎    | 10/19 [02:49<02:15, 15.03s/it]loss:23.075834274291992:  58%|█████▊    | 11/19 [02:49<01:58, 14.75s/it]loss:23.451580047607422:  58%|█████▊    | 11/19 [03:04<01:58, 14.75s/it]loss:23.451580047607422:  63%|██████▎   | 12/19 [03:04<01:42, 14.69s/it]loss:23.887256622314453:  63%|██████▎   | 12/19 [03:18<01:42, 14.69s/it]loss:23.887256622314453:  68%|██████▊   | 13/19 [03:18<01:28, 14.74s/it]loss:23.332536697387695:  68%|██████▊   | 13/19 [03:33<01:28, 14.74s/it]loss:23.332536697387695:  74%|███████▎  | 14/19 [03:33<01:12, 14.60s/it]loss:23.289947509765625:  74%|███████▎  | 14/19 [03:47<01:12, 14.60s/it]loss:23.289947509765625:  79%|███████▉  | 15/19 [03:47<00:57, 14.48s/it]loss:23.42662811279297:  79%|███████▉  | 15/19 [04:02<00:57, 14.48s/it] loss:23.42662811279297:  84%|████████▍ | 16/19 [04:02<00:44, 14.83s/it]loss:23.38251495361328:  84%|████████▍ | 16/19 [04:18<00:44, 14.83s/it]loss:23.38251495361328:  89%|████████▉ | 17/19 [04:18<00:30, 15.13s/it]loss:23.375411987304688:  89%|████████▉ | 17/19 [04:33<00:30, 15.13s/it]loss:23.375411987304688:  95%|█████████▍| 18/19 [04:33<00:14, 14.92s/it]loss:23.25908660888672:  95%|█████████▍| 18/19 [04:48<00:14, 14.92s/it] loss:23.25908660888672: 100%|██████████| 19/19 [04:48<00:00, 14.97s/it]loss:23.25908660888672: 100%|██████████| 19/19 [04:48<00:00, 15.19s/it]
Epoch: 12 cost time: 290.4990427494049
Epoch: 12, Steps: 19 | Train Loss: 23.3338150 Vali Loss: 3.0764000 Test Loss: 41.0363159
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : long_term_forecast_low_0_PatchTST_job_demand_region_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 4
test shape: (4, 1, 3, 16345) (4, 1, 3, 16345)
test shape: (4, 3, 16345) (4, 3, 16345)
mse:40348.7578125, mae:32.00470733642578, dtw:-999
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           0                   Model:              PatchTST            

[1mData Loader[0m
  Data:               job_demand_r1       Root Path:          ../../dataset/demand/
  Data Path:          r1.parquet          Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        .cache/checkpoints  

[1mForecasting Task[0m
  Seq Len:            6                   Label Len:          1                   
  Pred Len:           3                   Seasonal Patterns:  Monthly             
  Inverse:            1                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             32690               Dec In:             32690               
  C Out:              32690               d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           2                   d FF:               2048                
  Moving Avg:         25                  Factor:             1                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              learned             Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        32                  Itr:                1                   
  Train Epochs:       20                  Batch Size:         1                   
  Patience:           3                   Learning Rate:      0.0001              
  Des:                test                Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            0                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1                 

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use CPU
>>>>>>>start training : long_term_forecast_low_0_PatchTST_job_demand_r1_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 19
val 1
test 4
  0%|          | 0/19 [00:00<?, ?it/s]loss:24.472068786621094:   0%|          | 0/19 [01:04<?, ?it/s]loss:24.472068786621094:   5%|▌         | 1/19 [01:04<19:19, 64.42s/it]loss:24.684755325317383:   5%|▌         | 1/19 [02:05<19:19, 64.42s/it]loss:24.684755325317383:  11%|█         | 2/19 [02:05<17:43, 62.57s/it]loss:24.364717483520508:  11%|█         | 2/19 [03:06<17:43, 62.57s/it]loss:24.364717483520508:  16%|█▌        | 3/19 [03:06<16:25, 61.59s/it]loss:25.031116485595703:  16%|█▌        | 3/19 [04:06<16:25, 61.59s/it]loss:25.031116485595703:  21%|██        | 4/19 [04:06<15:15, 61.06s/it]loss:24.50775146484375:  21%|██        | 4/19 [05:07<15:15, 61.06s/it] loss:24.50775146484375:  26%|██▋       | 5/19 [05:07<14:13, 60.96s/it]loss:24.469623565673828:  26%|██▋       | 5/19 [06:06<14:13, 60.96s/it]loss:24.469623565673828:  32%|███▏      | 6/19 [06:06<13:06, 60.52s/it]loss:24.767959594726562:  32%|███▏      | 6/19 [07:06<13:06, 60.52s/it]loss:24.767959594726562:  37%|███▋      | 7/19 [07:06<12:04, 60.40s/it]loss:24.674692153930664:  37%|███▋      | 7/19 [08:07<12:04, 60.40s/it]loss:24.674692153930664:  42%|████▏     | 8/19 [08:07<11:04, 60.42s/it]loss:24.7087345123291:  42%|████▏     | 8/19 [09:07<11:04, 60.42s/it]  loss:24.7087345123291:  47%|████▋     | 9/19 [09:07<10:03, 60.35s/it]loss:24.565542221069336:  47%|████▋     | 9/19 [10:07<10:03, 60.35s/it]loss:24.565542221069336:  53%|█████▎    | 10/19 [10:07<09:02, 60.26s/it]loss:24.48567008972168:  53%|█████▎    | 10/19 [11:10<09:02, 60.26s/it] loss:24.48567008972168:  58%|█████▊    | 11/19 [11:10<08:08, 61.00s/it]loss:24.286657333374023:  58%|█████▊    | 11/19 [12:10<08:08, 61.00s/it]loss:24.286657333374023:  63%|██████▎   | 12/19 [12:10<07:05, 60.84s/it]loss:24.255897521972656:  63%|██████▎   | 12/19 [13:10<07:05, 60.84s/it]loss:24.255897521972656:  68%|██████▊   | 13/19 [13:10<06:02, 60.49s/it]loss:24.453039169311523:  68%|██████▊   | 13/19 [14:10<06:02, 60.49s/it]loss:24.453039169311523:  74%|███████▎  | 14/19 [14:10<05:02, 60.43s/it]loss:24.529502868652344:  74%|███████▎  | 14/19 [15:10<05:02, 60.43s/it]loss:24.529502868652344:  79%|███████▉  | 15/19 [15:10<04:01, 60.35s/it]loss:24.58782196044922:  79%|███████▉  | 15/19 [16:11<04:01, 60.35s/it] loss:24.58782196044922:  84%|████████▍ | 16/19 [16:11<03:01, 60.39s/it]loss:24.147268295288086:  84%|████████▍ | 16/19 [17:11<03:01, 60.39s/it]loss:24.147268295288086:  89%|████████▉ | 17/19 [17:11<02:00, 60.18s/it]loss:24.79347801208496:  89%|████████▉ | 17/19 [18:13<02:00, 60.18s/it] loss:24.79347801208496:  95%|█████████▍| 18/19 [18:13<01:00, 60.75s/it]loss:24.751928329467773:  95%|█████████▍| 18/19 [19:20<01:00, 60.75s/it]loss:24.751928329467773: 100%|██████████| 19/19 [19:20<00:00, 62.63s/it]loss:24.751928329467773: 100%|██████████| 19/19 [19:20<00:00, 61.07s/it]
Epoch: 1 cost time: 1160.7566614151
Epoch: 1, Steps: 19 | Train Loss: 24.5546434 Vali Loss: 3.9281757 Test Loss: 68.0261307
Validation loss decreased (inf --> 3.928176).  Saving model ...
Updating learning rate to 0.0001
  0%|          | 0/19 [00:00<?, ?it/s]loss:24.442790985107422:   0%|          | 0/19 [01:07<?, ?it/s]loss:24.442790985107422:   5%|▌         | 1/19 [01:07<20:12, 67.34s/it]loss:24.348384857177734:   5%|▌         | 1/19 [02:14<20:12, 67.34s/it]loss:24.348384857177734:  11%|█         | 2/19 [02:14<19:01, 67.14s/it]loss:24.55649185180664:  11%|█         | 2/19 [03:20<19:01, 67.14s/it] loss:24.55649185180664:  16%|█▌        | 3/19 [03:20<17:45, 66.59s/it]loss:24.59426498413086:  16%|█▌        | 3/19 [04:26<17:45, 66.59s/it]loss:24.59426498413086:  21%|██        | 4/19 [04:26<16:35, 66.37s/it]loss:24.686384201049805:  21%|██        | 4/19 [05:33<16:35, 66.37s/it]loss:24.686384201049805:  26%|██▋       | 5/19 [05:33<15:31, 66.55s/it]loss:24.540502548217773:  26%|██▋       | 5/19 [06:36<15:31, 66.55s/it]loss:24.540502548217773:  32%|███▏      | 6/19 [06:36<14:12, 65.61s/it]loss:24.471677780151367:  32%|███▏      | 6/19 [07:42<14:12, 65.61s/it]loss:24.471677780151367:  37%|███▋      | 7/19 [07:42<13:07, 65.66s/it]loss:24.489009857177734:  37%|███▋      | 7/19 [08:48<13:07, 65.66s/it]loss:24.489009857177734:  42%|████▏     | 8/19 [08:48<12:03, 65.78s/it]loss:24.31080436706543:  42%|████▏     | 8/19 [09:53<12:03, 65.78s/it] loss:24.31080436706543:  47%|████▋     | 9/19 [09:53<10:55, 65.52s/it]loss:24.397186279296875:  47%|████▋     | 9/19 [11:01<10:55, 65.52s/it]loss:24.397186279296875:  53%|█████▎    | 10/19 [11:01<09:56, 66.25s/it]loss:24.878015518188477:  53%|█████▎    | 10/19 [12:07<09:56, 66.25s/it]loss:24.878015518188477:  58%|█████▊    | 11/19 [12:07<08:49, 66.22s/it]loss:24.276042938232422:  58%|█████▊    | 11/19 [13:13<08:49, 66.22s/it]loss:24.276042938232422:  63%|██████▎   | 12/19 [13:13<07:42, 66.10s/it]loss:24.463016510009766:  63%|██████▎   | 12/19 [14:13<07:42, 66.10s/it]loss:24.463016510009766:  68%|██████▊   | 13/19 [14:13<06:24, 64.17s/it]loss:24.800830841064453:  68%|██████▊   | 13/19 [15:14<06:24, 64.17s/it]loss:24.800830841064453:  74%|███████▎  | 14/19 [15:14<05:15, 63.13s/it]loss:24.938173294067383:  74%|███████▎  | 14/19 [16:14<05:15, 63.13s/it]loss:24.938173294067383:  79%|███████▉  | 15/19 [16:14<04:09, 62.38s/it]loss:24.22867202758789:  79%|███████▉  | 15/19 [17:14<04:09, 62.38s/it] loss:24.22867202758789:  84%|████████▍ | 16/19 [17:14<03:04, 61.66s/it]loss:24.669864654541016:  84%|████████▍ | 16/19 [18:15<03:04, 61.66s/it]loss:24.669864654541016:  89%|████████▉ | 17/19 [18:15<02:02, 61.35s/it]loss:24.439105987548828:  89%|████████▉ | 17/19 [19:15<02:02, 61.35s/it]loss:24.439105987548828:  95%|█████████▍| 18/19 [19:15<01:00, 60.97s/it]loss:24.548534393310547:  95%|█████████▍| 18/19 [20:15<01:00, 60.97s/it]loss:24.548534393310547: 100%|██████████| 19/19 [20:15<00:00, 60.79s/it]loss:24.548534393310547: 100%|██████████| 19/19 [20:15<00:00, 63.99s/it]
Epoch: 2 cost time: 1216.574045419693
Epoch: 2, Steps: 19 | Train Loss: 24.5305134 Vali Loss: 3.8725078 Test Loss: 71.4908676
Validation loss decreased (3.928176 --> 3.872508).  Saving model ...
Updating learning rate to 5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:24.38114356994629:   0%|          | 0/19 [01:01<?, ?it/s]loss:24.38114356994629:   5%|▌         | 1/19 [01:01<18:20, 61.15s/it]loss:24.439483642578125:   5%|▌         | 1/19 [02:00<18:20, 61.15s/it]loss:24.439483642578125:  11%|█         | 2/19 [02:00<17:06, 60.36s/it]loss:24.58122444152832:  11%|█         | 2/19 [03:00<17:06, 60.36s/it] loss:24.58122444152832:  16%|█▌        | 3/19 [03:00<15:59, 59.95s/it]loss:24.432151794433594:  16%|█▌        | 3/19 [04:00<15:59, 59.95s/it]loss:24.432151794433594:  21%|██        | 4/19 [04:00<14:57, 59.82s/it]loss:24.376041412353516:  21%|██        | 4/19 [04:59<14:57, 59.82s/it]loss:24.376041412353516:  26%|██▋       | 5/19 [04:59<13:56, 59.75s/it]loss:24.37509536743164:  26%|██▋       | 5/19 [05:59<13:56, 59.75s/it] loss:24.37509536743164:  32%|███▏      | 6/19 [05:59<12:57, 59.81s/it]loss:24.746347427368164:  32%|███▏      | 6/19 [06:59<12:57, 59.81s/it]loss:24.746347427368164:  37%|███▋      | 7/19 [06:59<11:58, 59.88s/it]loss:24.81582260131836:  37%|███▋      | 7/19 [07:59<11:58, 59.88s/it] loss:24.81582260131836:  42%|████▏     | 8/19 [07:59<10:59, 59.96s/it]loss:24.31439208984375:  42%|████▏     | 8/19 [08:59<10:59, 59.96s/it]loss:24.31439208984375:  47%|████▋     | 9/19 [08:59<09:58, 59.85s/it]loss:24.436275482177734:  47%|████▋     | 9/19 [09:58<09:58, 59.85s/it]loss:24.436275482177734:  53%|█████▎    | 10/19 [09:58<08:56, 59.63s/it]loss:24.635971069335938:  53%|█████▎    | 10/19 [10:57<08:56, 59.63s/it]loss:24.635971069335938:  58%|█████▊    | 11/19 [10:57<07:55, 59.47s/it]loss:24.523269653320312:  58%|█████▊    | 11/19 [11:58<07:55, 59.47s/it]loss:24.523269653320312:  63%|██████▎   | 12/19 [11:58<06:58, 59.81s/it]loss:24.4703311920166:  63%|██████▎   | 12/19 [12:57<06:58, 59.81s/it]  loss:24.4703311920166:  68%|██████▊   | 13/19 [12:57<05:58, 59.75s/it]loss:24.417407989501953:  68%|██████▊   | 13/19 [13:58<05:58, 59.75s/it]loss:24.417407989501953:  74%|███████▎  | 14/19 [13:58<04:59, 59.92s/it]loss:24.526968002319336:  74%|███████▎  | 14/19 [14:58<04:59, 59.92s/it]loss:24.526968002319336:  79%|███████▉  | 15/19 [14:58<04:00, 60.16s/it]loss:24.691600799560547:  79%|███████▉  | 15/19 [15:59<04:00, 60.16s/it]loss:24.691600799560547:  84%|████████▍ | 16/19 [15:59<03:01, 60.34s/it]loss:24.444664001464844:  84%|████████▍ | 16/19 [16:59<03:01, 60.34s/it]loss:24.444664001464844:  89%|████████▉ | 17/19 [16:59<02:00, 60.16s/it]loss:24.715469360351562:  89%|████████▉ | 17/19 [17:59<02:00, 60.16s/it]loss:24.715469360351562:  95%|█████████▍| 18/19 [17:59<01:00, 60.14s/it]loss:24.61500358581543:  95%|█████████▍| 18/19 [18:59<01:00, 60.14s/it] loss:24.61500358581543: 100%|██████████| 19/19 [18:59<00:00, 60.05s/it]loss:24.61500358581543: 100%|██████████| 19/19 [18:59<00:00, 59.96s/it]
Epoch: 3 cost time: 1139.8222169876099
Epoch: 3, Steps: 19 | Train Loss: 24.5230876 Vali Loss: 3.8675668 Test Loss: 68.5317764
Validation loss decreased (3.872508 --> 3.867567).  Saving model ...
Updating learning rate to 2.5e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:24.394058227539062:   0%|          | 0/19 [01:00<?, ?it/s]loss:24.394058227539062:   5%|▌         | 1/19 [01:00<18:12, 60.71s/it]loss:24.431053161621094:   5%|▌         | 1/19 [02:01<18:12, 60.71s/it]loss:24.431053161621094:  11%|█         | 2/19 [02:01<17:14, 60.84s/it]loss:24.42291831970215:  11%|█         | 2/19 [03:02<17:14, 60.84s/it] loss:24.42291831970215:  16%|█▌        | 3/19 [03:02<16:14, 60.94s/it]loss:24.428823471069336:  16%|█▌        | 3/19 [04:04<16:14, 60.94s/it]loss:24.428823471069336:  21%|██        | 4/19 [04:04<15:16, 61.13s/it]loss:24.629369735717773:  21%|██        | 4/19 [05:05<15:16, 61.13s/it]loss:24.629369735717773:  26%|██▋       | 5/19 [05:05<14:16, 61.20s/it]loss:24.621896743774414:  26%|██▋       | 5/19 [06:07<14:16, 61.20s/it]loss:24.621896743774414:  32%|███▏      | 6/19 [06:07<13:21, 61.62s/it]loss:24.428255081176758:  32%|███▏      | 6/19 [07:08<13:21, 61.62s/it]loss:24.428255081176758:  37%|███▋      | 7/19 [07:08<12:16, 61.38s/it]loss:24.415653228759766:  37%|███▋      | 7/19 [08:08<12:16, 61.38s/it]loss:24.415653228759766:  42%|████▏     | 8/19 [08:08<11:10, 60.95s/it]loss:24.410783767700195:  42%|████▏     | 8/19 [09:08<11:10, 60.95s/it]loss:24.410783767700195:  47%|████▋     | 9/19 [09:08<10:05, 60.53s/it]loss:24.319766998291016:  47%|████▋     | 9/19 [10:08<10:05, 60.53s/it]loss:24.319766998291016:  53%|█████▎    | 10/19 [10:08<09:03, 60.43s/it]loss:24.555009841918945:  53%|█████▎    | 10/19 [11:09<09:03, 60.43s/it]loss:24.555009841918945:  58%|█████▊    | 11/19 [11:09<08:03, 60.42s/it]loss:24.66898536682129:  58%|█████▊    | 11/19 [12:09<08:03, 60.42s/it] loss:24.66898536682129:  63%|██████▎   | 12/19 [12:09<07:03, 60.47s/it]loss:24.495071411132812:  63%|██████▎   | 12/19 [13:10<07:03, 60.47s/it]loss:24.495071411132812:  68%|██████▊   | 13/19 [13:10<06:03, 60.61s/it]loss:24.651836395263672:  68%|██████▊   | 13/19 [14:11<06:03, 60.61s/it]loss:24.651836395263672:  74%|███████▎  | 14/19 [14:11<05:03, 60.61s/it]loss:24.418235778808594:  74%|███████▎  | 14/19 [15:12<05:03, 60.61s/it]loss:24.418235778808594:  79%|███████▉  | 15/19 [15:12<04:03, 60.97s/it]loss:24.862916946411133:  79%|███████▉  | 15/19 [16:14<04:03, 60.97s/it]loss:24.862916946411133:  84%|████████▍ | 16/19 [16:14<03:03, 61.05s/it]loss:24.785722732543945:  84%|████████▍ | 16/19 [17:15<03:03, 61.05s/it]loss:24.785722732543945:  89%|████████▉ | 17/19 [17:15<02:02, 61.19s/it]loss:24.526268005371094:  89%|████████▉ | 17/19 [18:16<02:02, 61.19s/it]loss:24.526268005371094:  95%|█████████▍| 18/19 [18:16<01:01, 61.08s/it]loss:24.566829681396484:  95%|█████████▍| 18/19 [19:17<01:01, 61.08s/it]loss:24.566829681396484: 100%|██████████| 19/19 [19:17<00:00, 60.98s/it]loss:24.566829681396484: 100%|██████████| 19/19 [19:17<00:00, 60.91s/it]
Epoch: 4 cost time: 1157.862447977066
Epoch: 4, Steps: 19 | Train Loss: 24.5280766 Vali Loss: 3.8680420 Test Loss: 69.8014450
EarlyStopping counter: 1 out of 3
Updating learning rate to 1.25e-05
  0%|          | 0/19 [00:00<?, ?it/s]loss:24.29977035522461:   0%|          | 0/19 [01:00<?, ?it/s]loss:24.29977035522461:   5%|▌         | 1/19 [01:00<18:16, 60.93s/it]loss:24.49532699584961:   5%|▌         | 1/19 [02:01<18:16, 60.93s/it]loss:24.49532699584961:  11%|█         | 2/19 [02:01<17:13, 60.77s/it]loss:24.49429702758789:  11%|█         | 2/19 [03:02<17:13, 60.77s/it]loss:24.49429702758789:  16%|█▌        | 3/19 [03:02<16:15, 60.94s/it]loss:24.357202529907227:  16%|█▌        | 3/19 [04:03<16:15, 60.94s/it]loss:24.357202529907227:  21%|██        | 4/19 [04:03<15:12, 60.84s/it]loss:24.73575210571289:  21%|██        | 4/19 [05:04<15:12, 60.84s/it] loss:24.73575210571289:  26%|██▋       | 5/19 [05:04<14:12, 60.90s/it]loss:24.65803337097168:  26%|██▋       | 5/19 [06:05<14:12, 60.90s/it]loss:24.65803337097168:  32%|███▏      | 6/19 [06:05<13:11, 60.86s/it]loss:24.42800521850586:  32%|███▏      | 6/19 [07:06<13:11, 60.86s/it]loss:24.42800521850586:  37%|███▋      | 7/19 [07:06<12:10, 60.87s/it]loss:24.572214126586914:  37%|███▋      | 7/19 [08:06<12:10, 60.87s/it]loss:24.572214126586914:  42%|████▏     | 8/19 [08:06<11:07, 60.72s/it]loss:24.654281616210938:  42%|████▏     | 8/19 [09:06<11:07, 60.72s/it]loss:24.654281616210938:  47%|████▋     | 9/19 [09:06<10:06, 60.64s/it]loss:24.407133102416992:  47%|████▋     | 9/19 [10:07<10:06, 60.64s/it]loss:24.407133102416992:  53%|█████▎    | 10/19 [10:07<09:05, 60.65s/it]loss:24.45397186279297:  53%|█████▎    | 10/19 [11:08<09:05, 60.65s/it] loss:24.45397186279297:  58%|█████▊    | 11/19 [11:08<08:05, 60.73s/it]loss:24.689855575561523:  58%|█████▊    | 11/19 [12:09<08:05, 60.73s/it]loss:24.689855575561523:  63%|██████▎   | 12/19 [12:09<07:05, 60.72s/it]loss:24.878915786743164:  63%|██████▎   | 12/19 [13:10<07:05, 60.72s/it]loss:24.878915786743164:  68%|██████▊   | 13/19 [13:10<06:04, 60.79s/it]loss:24.40740203857422:  68%|██████▊   | 13/19 [14:10<06:04, 60.79s/it] loss:24.40740203857422:  74%|███████▎  | 14/19 [14:10<05:03, 60.72s/it]loss:24.431468963623047:  74%|███████▎  | 14/19 [15:11<05:03, 60.72s/it]loss:24.431468963623047:  79%|███████▉  | 15/19 [15:11<04:02, 60.68s/it]loss:24.67254638671875:  79%|███████▉  | 15/19 [16:11<04:02, 60.68s/it] loss:24.67254638671875:  84%|████████▍ | 16/19 [16:11<03:01, 60.64s/it]loss:24.4220027923584:  84%|████████▍ | 16/19 [17:13<03:01, 60.64s/it] loss:24.4220027923584:  89%|████████▉ | 17/19 [17:13<02:01, 60.82s/it]loss:24.590396881103516:  89%|████████▉ | 17/19 [18:15<02:01, 60.82s/it]loss:24.590396881103516:  95%|█████████▍| 18/19 [18:15<01:01, 61.18s/it]loss:24.53216552734375:  95%|█████████▍| 18/19 [19:16<01:01, 61.18s/it] loss:24.53216552734375: 100%|██████████| 19/19 [19:16<00:00, 61.09s/it]loss:24.53216552734375: 100%|██████████| 19/19 [19:16<00:00, 60.85s/it]
Epoch: 5 cost time: 1156.5469524860382
Epoch: 5, Steps: 19 | Train Loss: 24.5358285 Vali Loss: 3.8606799 Test Loss: 69.3425903
Validation loss decreased (3.867567 --> 3.860680).  Saving model ...
Updating learning rate to 6.25e-06
  0%|          | 0/19 [00:00<?, ?it/s]loss:24.472732543945312:   0%|          | 0/19 [01:00<?, ?it/s]loss:24.472732543945312:   5%|▌         | 1/19 [01:00<18:07, 60.43s/it]loss:24.669124603271484:   5%|▌         | 1/19 [02:01<18:07, 60.43s/it]loss:24.669124603271484:  11%|█         | 2/19 [02:01<17:11, 60.69s/it]loss:24.655441284179688:  11%|█         | 2/19 [03:01<17:11, 60.69s/it]loss:24.655441284179688:  16%|█▌        | 3/19 [03:01<16:05, 60.33s/it]loss:24.392627716064453:  16%|█▌        | 3/19 [04:01<16:05, 60.33s/it]loss:24.392627716064453:  21%|██        | 4/19 [04:01<15:05, 60.38s/it]loss:24.508041381835938:  21%|██        | 4/19 [05:00<15:05, 60.38s/it]loss:24.508041381835938:  26%|██▋       | 5/19 [05:00<13:59, 59.99s/it]loss:24.664485931396484:  26%|██▋       | 5/19 [06:00<13:59, 59.99s/it]loss:24.664485931396484:  32%|███▏      | 6/19 [06:00<12:58, 59.91s/it]loss:24.43694496154785:  32%|███▏      | 6/19 [07:00<12:58, 59.91s/it] loss:24.43694496154785:  37%|███▋      | 7/19 [07:00<11:57, 59.77s/it]loss:24.329063415527344:  37%|███▋      | 7/19 [08:00<11:57, 59.77s/it]loss:24.329063415527344:  42%|████▏     | 8/19 [08:00<10:59, 59.91s/it]loss:24.407054901123047:  42%|████▏     | 8/19 [09:01<10:59, 59.91s/it]loss:24.407054901123047:  47%|████▋     | 9/19 [09:01<10:02, 60.23s/it]loss:24.720481872558594:  47%|████▋     | 9/19 [10:02<10:02, 60.23s/it]loss:24.720481872558594:  53%|█████▎    | 10/19 [10:02<09:03, 60.42s/it]loss:24.457002639770508:  53%|█████▎    | 10/19 [11:02<09:03, 60.42s/it]loss:24.457002639770508:  58%|█████▊    | 11/19 [11:02<08:02, 60.33s/it]loss:24.452531814575195:  58%|█████▊    | 11/19 [12:02<08:02, 60.33s/it]loss:24.452531814575195:  63%|██████▎   | 12/19 [12:02<07:02, 60.39s/it]loss:24.655975341796875:  63%|██████▎   | 12/19 [13:03<07:02, 60.39s/it]loss:24.655975341796875:  68%|██████▊   | 13/19 [13:03<06:03, 60.53s/it]loss:24.86713409423828:  68%|██████▊   | 13/19 [14:04<06:03, 60.53s/it] loss:24.86713409423828:  74%|███████▎  | 14/19 [14:04<05:03, 60.64s/it]loss:24.42746925354004:  74%|███████▎  | 14/19 [15:05<05:03, 60.64s/it]loss:24.42746925354004:  79%|███████▉  | 15/19 [15:05<04:03, 60.80s/it]loss:24.5407772064209:  79%|███████▉  | 15/19 [16:06<04:03, 60.80s/it] loss:24.5407772064209:  84%|████████▍ | 16/19 [16:06<03:02, 60.71s/it]loss:24.589384078979492:  84%|████████▍ | 16/19 [17:05<03:02, 60.71s/it]loss:24.589384078979492:  89%|████████▉ | 17/19 [17:05<02:00, 60.41s/it]loss:24.5761661529541:  89%|████████▉ | 17/19 [18:06<02:00, 60.41s/it]  loss:24.5761661529541:  95%|█████████▍| 18/19 [18:06<01:00, 60.42s/it]loss:24.430604934692383:  95%|█████████▍| 18/19 [19:06<01:00, 60.42s/it]loss:24.430604934692383: 100%|██████████| 19/19 [19:06<00:00, 60.37s/it]loss:24.430604934692383: 100%|██████████| 19/19 [19:06<00:00, 60.35s/it]
Epoch: 6 cost time: 1147.2266426086426
Epoch: 6, Steps: 19 | Train Loss: 24.5396339 Vali Loss: 3.8593097 Test Loss: 69.1576996
Validation loss decreased (3.860680 --> 3.859310).  Saving model ...
Updating learning rate to 3.125e-06
  0%|          | 0/19 [00:00<?, ?it/s]loss:24.433364868164062:   0%|          | 0/19 [01:00<?, ?it/s]loss:24.433364868164062:   5%|▌         | 1/19 [01:00<18:04, 60.25s/it]loss:24.37923812866211:   5%|▌         | 1/19 [02:01<18:04, 60.25s/it] loss:24.37923812866211:  11%|█         | 2/19 [02:01<17:09, 60.56s/it]loss:24.440692901611328:  11%|█         | 2/19 [03:01<17:09, 60.56s/it]loss:24.440692901611328:  16%|█▌        | 3/19 [03:01<16:07, 60.46s/it]loss:24.5073299407959:  16%|█▌        | 3/19 [04:01<16:07, 60.46s/it]  loss:24.5073299407959:  21%|██        | 4/19 [04:01<15:03, 60.22s/it]loss:24.536327362060547:  21%|██        | 4/19 [05:00<15:03, 60.22s/it]loss:24.536327362060547:  26%|██▋       | 5/19 [05:00<13:58, 59.91s/it]loss:24.423311233520508:  26%|██▋       | 5/19 [06:00<13:58, 59.91s/it]loss:24.423311233520508:  32%|███▏      | 6/19 [06:00<13:00, 60.03s/it]loss:24.692840576171875:  32%|███▏      | 6/19 [07:01<13:00, 60.03s/it]loss:24.692840576171875:  37%|███▋      | 7/19 [07:01<12:01, 60.14s/it]loss:24.31744384765625:  37%|███▋      | 7/19 [08:01<12:01, 60.14s/it] loss:24.31744384765625:  42%|████▏     | 8/19 [08:01<11:01, 60.18s/it]loss:24.748779296875:  42%|████▏     | 8/19 [09:01<11:01, 60.18s/it]  loss:24.748779296875:  47%|████▋     | 9/19 [09:01<10:01, 60.19s/it]loss:24.574697494506836:  47%|████▋     | 9/19 [10:01<10:01, 60.19s/it]loss:24.574697494506836:  53%|█████▎    | 10/19 [10:01<08:59, 59.97s/it]loss:24.426694869995117:  53%|█████▎    | 10/19 [11:01<08:59, 59.97s/it]loss:24.426694869995117:  58%|█████▊    | 11/19 [11:01<08:01, 60.14s/it]loss:24.405710220336914:  58%|█████▊    | 11/19 [12:02<08:01, 60.14s/it]loss:24.405710220336914:  63%|██████▎   | 12/19 [12:02<07:03, 60.48s/it]loss:24.876605987548828:  63%|██████▎   | 12/19 [13:03<07:03, 60.48s/it]loss:24.876605987548828:  68%|██████▊   | 13/19 [13:03<06:02, 60.37s/it]loss:24.66185188293457:  68%|██████▊   | 13/19 [14:03<06:02, 60.37s/it] loss:24.66185188293457:  74%|███████▎  | 14/19 [14:03<05:02, 60.42s/it]loss:24.672012329101562:  74%|███████▎  | 14/19 [15:03<05:02, 60.42s/it]loss:24.672012329101562:  79%|███████▉  | 15/19 [15:03<04:00, 60.24s/it]loss:24.488065719604492:  79%|███████▉  | 15/19 [16:02<04:00, 60.24s/it]loss:24.488065719604492:  84%|████████▍ | 16/19 [16:02<03:00, 60.02s/it]loss:24.462724685668945:  84%|████████▍ | 16/19 [17:02<03:00, 60.02s/it]loss:24.462724685668945:  89%|████████▉ | 17/19 [17:02<02:00, 60.00s/it]loss:24.679895401000977:  89%|████████▉ | 17/19 [18:03<02:00, 60.00s/it]loss:24.679895401000977:  95%|█████████▍| 18/19 [18:03<01:00, 60.22s/it]loss:24.58917236328125:  95%|█████████▍| 18/19 [19:04<01:00, 60.22s/it] loss:24.58917236328125: 100%|██████████| 19/19 [19:04<00:00, 60.42s/it]loss:24.58917236328125: 100%|██████████| 19/19 [19:04<00:00, 60.24s/it]
Epoch: 7 cost time: 1145.0772647857666
Epoch: 7, Steps: 19 | Train Loss: 24.5429873 Vali Loss: 3.8630075 Test Loss: 69.0953217
EarlyStopping counter: 1 out of 3
Updating learning rate to 1.5625e-06
  0%|          | 0/19 [00:00<?, ?it/s]loss:24.433921813964844:   0%|          | 0/19 [01:00<?, ?it/s]loss:24.433921813964844:   5%|▌         | 1/19 [01:00<18:01, 60.11s/it]loss:24.574764251708984:   5%|▌         | 1/19 [01:59<18:01, 60.11s/it]loss:24.574764251708984:  11%|█         | 2/19 [01:59<16:57, 59.88s/it]loss:24.67855453491211:  11%|█         | 2/19 [03:00<16:57, 59.88s/it] loss:24.67855453491211:  16%|█▌        | 3/19 [03:00<16:01, 60.10s/it]loss:24.461610794067383:  16%|█▌        | 3/19 [04:00<16:01, 60.10s/it]loss:24.461610794067383:  21%|██        | 4/19 [04:00<15:02, 60.14s/it]loss:24.40306854248047:  21%|██        | 4/19 [04:59<15:02, 60.14s/it] loss:24.40306854248047:  26%|██▋       | 5/19 [04:59<13:56, 59.78s/it]loss:24.50896644592285:  26%|██▋       | 5/19 [05:59<13:56, 59.78s/it]loss:24.50896644592285:  32%|███▏      | 6/19 [05:59<12:57, 59.77s/it]loss:24.691720962524414:  32%|███▏      | 6/19 [06:59<12:57, 59.77s/it]loss:24.691720962524414:  37%|███▋      | 7/19 [06:59<11:57, 59.83s/it]loss:24.42680549621582:  37%|███▋      | 7/19 [08:01<11:57, 59.83s/it] loss:24.42680549621582:  42%|████▏     | 8/19 [08:01<11:08, 60.75s/it]loss:24.4427490234375:  42%|████▏     | 8/19 [09:04<11:08, 60.75s/it] loss:24.4427490234375:  47%|████▋     | 9/19 [09:04<10:12, 61.29s/it]loss:24.49098014831543:  47%|████▋     | 9/19 [10:05<10:12, 61.29s/it]loss:24.49098014831543:  53%|█████▎    | 10/19 [10:05<09:10, 61.20s/it]loss:24.593788146972656:  53%|█████▎    | 10/19 [11:05<09:10, 61.20s/it]loss:24.593788146972656:  58%|█████▊    | 11/19 [11:05<08:07, 60.98s/it]loss:24.37702751159668:  58%|█████▊    | 11/19 [12:06<08:07, 60.98s/it] loss:24.37702751159668:  63%|██████▎   | 12/19 [12:06<07:05, 60.76s/it]loss:24.87552833557129:  63%|██████▎   | 12/19 [13:06<07:05, 60.76s/it]loss:24.87552833557129:  68%|██████▊   | 13/19 [13:06<06:03, 60.65s/it]loss:24.54080581665039:  68%|██████▊   | 13/19 [14:06<06:03, 60.65s/it]loss:24.54080581665039:  74%|███████▎  | 14/19 [14:06<05:02, 60.51s/it]loss:24.431047439575195:  74%|███████▎  | 14/19 [15:08<05:02, 60.51s/it]loss:24.431047439575195:  79%|███████▉  | 15/19 [15:08<04:03, 60.80s/it]loss:24.659770965576172:  79%|███████▉  | 15/19 [16:09<04:03, 60.80s/it]loss:24.659770965576172:  84%|████████▍ | 16/19 [16:09<03:02, 60.88s/it]loss:24.668684005737305:  84%|████████▍ | 16/19 [17:10<03:02, 60.88s/it]loss:24.668684005737305:  89%|████████▉ | 17/19 [17:10<02:02, 61.04s/it]loss:24.74327278137207:  89%|████████▉ | 17/19 [18:11<02:02, 61.04s/it] loss:24.74327278137207:  95%|█████████▍| 18/19 [18:11<01:01, 61.07s/it]loss:24.322023391723633:  95%|█████████▍| 18/19 [19:13<01:01, 61.07s/it]loss:24.322023391723633: 100%|██████████| 19/19 [19:13<00:00, 61.11s/it]loss:24.322023391723633: 100%|██████████| 19/19 [19:13<00:00, 60.69s/it]
Epoch: 8 cost time: 1153.5708177089691
Epoch: 8, Steps: 19 | Train Loss: 24.5434258 Vali Loss: 3.8612423 Test Loss: 69.0547409
EarlyStopping counter: 2 out of 3
Updating learning rate to 7.8125e-07
  0%|          | 0/19 [00:00<?, ?it/s]loss:24.407106399536133:   0%|          | 0/19 [01:00<?, ?it/s]loss:24.407106399536133:   5%|▌         | 1/19 [01:00<18:17, 60.96s/it]loss:24.65951919555664:   5%|▌         | 1/19 [02:01<18:17, 60.96s/it] loss:24.65951919555664:  11%|█         | 2/19 [02:01<17:13, 60.80s/it]loss:24.871488571166992:  11%|█         | 2/19 [03:02<17:13, 60.80s/it]loss:24.871488571166992:  16%|█▌        | 3/19 [03:02<16:15, 60.96s/it]loss:24.437278747558594:  16%|█▌        | 3/19 [04:03<16:15, 60.96s/it]loss:24.437278747558594:  21%|██        | 4/19 [04:03<15:11, 60.74s/it]loss:24.742107391357422:  21%|██        | 4/19 [05:04<15:11, 60.74s/it]loss:24.742107391357422:  26%|██▋       | 5/19 [05:04<14:13, 60.93s/it]loss:24.5778751373291:  26%|██▋       | 5/19 [06:05<14:13, 60.93s/it]  loss:24.5778751373291:  32%|███▏      | 6/19 [06:05<13:11, 60.91s/it]loss:24.448192596435547:  32%|███▏      | 6/19 [07:05<13:11, 60.91s/it]loss:24.448192596435547:  37%|███▋      | 7/19 [07:05<12:08, 60.71s/it]loss:24.42966651916504:  37%|███▋      | 7/19 [08:06<12:08, 60.71s/it] loss:24.42966651916504:  42%|████▏     | 8/19 [08:06<11:09, 60.82s/it]loss:24.542516708374023:  42%|████▏     | 8/19 [09:07<11:09, 60.82s/it]loss:24.542516708374023:  47%|████▋     | 9/19 [09:07<10:09, 60.96s/it]loss:24.69394302368164:  47%|████▋     | 9/19 [10:09<10:09, 60.96s/it] loss:24.69394302368164:  53%|█████▎    | 10/19 [10:09<09:08, 60.99s/it]loss:24.673908233642578:  53%|█████▎    | 10/19 [11:09<09:08, 60.99s/it]loss:24.673908233642578:  58%|█████▊    | 11/19 [11:09<08:05, 60.75s/it]loss:24.51117706298828:  58%|█████▊    | 11/19 [12:10<08:05, 60.75s/it] loss:24.51117706298828:  63%|██████▎   | 12/19 [12:10<07:05, 60.83s/it]loss:24.431486129760742:  63%|██████▎   | 12/19 [13:11<07:05, 60.83s/it]loss:24.431486129760742:  68%|██████▊   | 13/19 [13:11<06:05, 60.87s/it]loss:24.66807746887207:  68%|██████▊   | 13/19 [14:12<06:05, 60.87s/it] loss:24.66807746887207:  74%|███████▎  | 14/19 [14:12<05:04, 60.90s/it]loss:24.38430404663086:  74%|███████▎  | 14/19 [15:12<05:04, 60.90s/it]loss:24.38430404663086:  79%|███████▉  | 15/19 [15:12<04:03, 60.86s/it]loss:24.46135139465332:  79%|███████▉  | 15/19 [16:14<04:03, 60.86s/it]loss:24.46135139465332:  84%|████████▍ | 16/19 [16:14<03:02, 60.93s/it]loss:24.489896774291992:  84%|████████▍ | 16/19 [17:15<03:02, 60.93s/it]loss:24.489896774291992:  89%|████████▉ | 17/19 [17:15<02:01, 60.98s/it]loss:24.592554092407227:  89%|████████▉ | 17/19 [18:16<02:01, 60.98s/it]loss:24.592554092407227:  95%|█████████▍| 18/19 [18:16<01:00, 60.99s/it]loss:24.323957443237305:  95%|█████████▍| 18/19 [19:17<01:00, 60.99s/it]loss:24.323957443237305: 100%|██████████| 19/19 [19:17<00:00, 61.12s/it]loss:24.323957443237305: 100%|██████████| 19/19 [19:17<00:00, 60.93s/it]
Epoch: 9 cost time: 1158.0894227027893
Epoch: 9, Steps: 19 | Train Loss: 24.5445477 Vali Loss: 3.8598986 Test Loss: 69.0624084
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : long_term_forecast_low_0_PatchTST_job_demand_r1_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 4
test shape: (4, 1, 3, 32690) (4, 1, 3, 32690)
test shape: (4, 3, 32690) (4, 3, 32690)
mse:52375.94140625, mae:17.650402069091797, dtw:-999
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           0                   Model:              PatchTST            

[1mData Loader[0m
  Data:               job_demand_r2       Root Path:          ../../dataset/demand/
  Data Path:          r2.parquet          Features:           M                   
  Target:             OT                  Freq:               h                   
  Checkpoints:        .cache/checkpoints  

[1mForecasting Task[0m
  Seq Len:            6                   Label Len:          1                   
  Pred Len:           3                   Seasonal Patterns:  Monthly             
  Inverse:            1                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             121420              Dec In:             121420              
  C Out:              121420              d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           2                   d FF:               2048                
  Moving Avg:         25                  Factor:             1                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              learned             Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        32                  Itr:                1                   
  Train Epochs:       20                  Batch Size:         1                   
  Patience:           3                   Learning Rate:      0.0001              
  Des:                test                Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            0                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1                 

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use CPU
>>>>>>>start training : long_term_forecast_low_0_PatchTST_job_demand_r2_ftM_sl6_ll1_pl3_dm512_nh8_el2_dl2_df2048_expand2_dc4_fc1_eblearned_dtTrue_test_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 19
val 1
test 4
  0%|          | 0/19 [00:00<?, ?it/s]Killed
