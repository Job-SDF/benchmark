{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2856/2856 [00:00<00:00, 1146419.01it/s]\n",
      "100%|██████████| 3/3 [00:01<00:00,  2.73it/s]\n",
      "100%|██████████| 2349/2349 [00:00<00:00, 1150043.20it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00,  3.03it/s]\n",
      "100%|██████████| 2387/2387 [00:00<00:00, 1140556.35it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00,  3.05it/s]\n",
      "100%|██████████| 2433/2433 [00:00<00:00, 1075088.67it/s]\n",
      "100%|██████████| 3/3 [00:01<00:00,  2.99it/s]\n",
      "100%|██████████| 2699/2699 [00:00<00:00, 1153380.18it/s]\n",
      "100%|██████████| 3/3 [00:01<00:00,  2.95it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data_type = 'month'\n",
    "date_list = {\n",
    "    \"season\": 4,\n",
    "    \"month\": 12,\n",
    "}\n",
    "for data_name in ['company', 'r1', 'r2', 'r1-region', 'r2-region']:\n",
    "# for data_name in ['company']:\n",
    "    if not os.path.exists(f'data/{data_type}_{data_name}/task1/train'):\n",
    "        os.makedirs(f'data/{data_type}_{data_name}/task1/train')\n",
    "    if not os.path.exists(f'data/{data_type}_{data_name}/task1/eval'):\n",
    "        os.makedirs(f'data/{data_type}_{data_name}/task1/eval')\n",
    "    if not os.path.exists(f'data/{data_type}_{data_name}/task1/test'):\n",
    "        os.makedirs(f'data/{data_type}_{data_name}/task1/test')\n",
    "    if not os.path.exists(f'data/{data_type}_{data_name}/task2'):\n",
    "        os.makedirs(f'data/{data_type}_{data_name}/task2')\n",
    "\n",
    "\n",
    "    df = pd.read_csv(f'../data/{data_type}/job_count_{data_name}.csv')\n",
    "    col_index = [f\"{i}_id\" for i in data_name.split('-')]\n",
    "    for col in col_index + ['skill_id']:\n",
    "        df[col] = df[col].apply(int)\n",
    "    col_num = [df[col].nunique() for col in col_index]\n",
    "    df[data_name] = df.apply(lambda x: int(sum([x[v]*col_num[i-1] if i > 0 else x[v] for i,v in enumerate(col_index)])),axis=1)\n",
    "    df['skill_id'] = df['skill_id'] + 200000\n",
    "\n",
    "    pd.DataFrame(sorted(df.reset_index()[data_name].unique().tolist() + df.reset_index()['skill_id'].unique().tolist())).reset_index().to_csv(f'data/{data_type}_{data_name}/entities.dict', index=None, sep='\\t', header=None)\n",
    "    pd.DataFrame([0]* df.reset_index()['skill_id'].nunique()).to_csv(f'data/{data_type}_{data_name}/skill2cluster.tsv', index=None, header=None)\n",
    "    pd.DataFrame([100000]).to_csv(f'data/{data_type}_{data_name}/relations.dict', sep='\\t', header=None)\n",
    "\n",
    "    name_df = pd.DataFrame(sorted(df.reset_index()[data_name].unique().tolist() + df.reset_index()['skill_id'].unique().tolist()))\n",
    "    real_name_list = pd.read_csv(f'../../dataset/name/{data_name}_name.list')[f'{data_name}_name'].tolist()\n",
    "    skill_name_list = pd.read_csv(f'../../dataset/name/skill_name.list')['skill'].tolist()\n",
    "    name_list = name_df[0].progress_apply(lambda x: real_name_list[x] if x<200000 else skill_name_list[x-200000])\n",
    "    name_list.to_csv(f'{data_name}.list', sep='\\t', header=None, index=None)\n",
    "    os.system(f'python bert.py {data_type}_{data_name}')\n",
    "    \n",
    "\n",
    "    pre_train_data = [f\"{year}-{month:02d}\" for year in range(2021, 2023) for month in range(1, date_list[data_type] + 1)]\n",
    "    pre_df = df[[data_name] + pre_train_data + ['skill_id']]\n",
    "    pre_df = pre_df.set_index([data_name, 'skill_id'])\n",
    "    pre_df['demand'] = pre_df.sum(axis=1)\n",
    "    pre_df = pre_df[['demand']].reset_index()\n",
    "    pre_df['relation'] = 100000\n",
    "    pre_df = pre_df[pre_df['demand']>100]\n",
    "    ran_pre_df = pre_df.sample(n=len(pre_df),axis=0,random_state=42)\n",
    "\n",
    "    ran_pre_df = ran_pre_df[[data_name, 'relation', 'skill_id', 'demand']]\n",
    "    pre_train_df = ran_pre_df[:int(0.95 *len(pre_df))]\n",
    "    pre_eval_df = ran_pre_df[int(0.95 *len(pre_df)):int(0.99 *len(pre_df))]\n",
    "    pre_test_df = ran_pre_df[int(0.99 *len(pre_df)):]\n",
    "        \n",
    "    pre_train_df.to_csv(f'data/{data_type}_{data_name}/task1/train/triplet_value.tsv', index=None, sep='\\t', header=None)\n",
    "    pre_eval_df.to_csv(f'data/{data_type}_{data_name}/task1/eval/triplet_value.tsv', index=None, sep='\\t', header=None)\n",
    "    pre_test_df.to_csv(f'data/{data_type}_{data_name}/task1/test/triplet_value.tsv', index=None, sep='\\t', header=None)\n",
    "\n",
    "    pre_train_df.to_csv(f'data/{data_type}_{data_name}/task2/old_train_triplet_value.tsv', index=None, sep='\\t', header=None)\n",
    "    pre_eval_df.to_csv(f'data/{data_type}_{data_name}/task2/old_eval_triplet_value.tsv', index=None, sep='\\t', header=None)\n",
    "    pre_test_df.to_csv(f'data/{data_type}_{data_name}/task2/old_test_triplet_value.tsv', index=None, sep='\\t', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "for data_name in ['company', 'r1', 'r2', 'r1-region', 'r2-region']:\n",
    "    df = pd.read_csv(f'../data/{data_type}/job_count_{data_name}.csv')\n",
    "    col_index = [f\"{i}_id\" for i in data_name.split('-')]\n",
    "    for col in col_index + ['skill_id']:\n",
    "        df[col] = df[col].apply(int)\n",
    "    col_num = [df[col].nunique() for col in col_index]\n",
    "    df[data_name] = df.apply(lambda x: int(sum([x[v]*col_num[i-1] if i > 0 else x[v] for i,v in enumerate(col_index)])),axis=1)\n",
    "    df = df.drop(col_index, axis=1).set_index([data_name, 'skill_id'])\n",
    "    for i, col in enumerate(df.columns):\n",
    "        sub_df = df[[col]].reset_index()\n",
    "        sub_df['relation'] = 100000\n",
    "        sub_df = sub_df[[data_name, 'relation', 'skill_id', col]]\n",
    "        sub_df = sub_df[sub_df[col]>0]\n",
    "        sub_df['skill_id'] = sub_df['skill_id'] + 200000\n",
    "\n",
    "        ran_pre_df = sub_df.sample(n=len(sub_df),axis=0,random_state=42).reset_index().drop('index', axis=1)\n",
    "        \n",
    "        train_df = ran_pre_df[:int(0.95 *len(ran_pre_df))]\n",
    "        eval_df = ran_pre_df[int(0.95 *len(ran_pre_df)):]\n",
    "        if not os.path.exists(f'data/{data_type}_{data_name}/task2/{i}/train'):\n",
    "            os.makedirs(f'data/{data_type}_{data_name}/task2/{i}/train')\n",
    "        if not os.path.exists(f'data/{data_type}_{data_name}/task2/{i}/eval'):\n",
    "            os.makedirs(f'data/{data_type}_{data_name}/task2/{i}/eval')\n",
    "        train_df.to_csv(f'data/{data_type}_{data_name}/task2/{i}/train/triplet_value.tsv', index=None, sep='\\t', header=None)\n",
    "        eval_df.to_csv(f'data/{data_type}_{data_name}/task2/{i}/eval/triplet_value.tsv', index=None, sep='\\t', header=None)\n",
    "        sub_df.to_csv(f'data/{data_type}_{data_name}/task2/{i}/triplet_value.tsv', index=None, sep='\\t', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_181664/3365603392.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  diff_i['diff'] = diff_i['diff'].apply(lambda x: 3 if x > 0 else 2)\n",
      "/tmp/ipykernel_181664/3365603392.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  current_i['diff'][diff_i['index']] = diff_i['diff'].tolist()\n"
     ]
    }
   ],
   "source": [
    "data_list = ['company', 'r1', 'r2', 'r1-region', 'r2-region']\n",
    "cur_root_dir = '/individual/chenxi02/conferences/NeuIPS24/benchmark/baselines/Pre-DyGAE/data'\n",
    "import pandas as pd\n",
    "ans = {}\n",
    "for data_name in data_list:\n",
    "    ans[data_name] = []\n",
    "    for i in range(date_list[data_type]*3):\n",
    "        file_path = f'{cur_root_dir}/{data_name}/task2/{i}/triplet_value.tsv'\n",
    "        x_i = pd.read_csv(file_path, header=None, sep='\\t')\n",
    "        x_i['index'] = x_i[0].apply(str) + '-' + x_i[2].apply(str)\n",
    "        ans[data_name].append(x_i)\n",
    "\n",
    "for data_name in data_list:\n",
    "    for i in range(date_list[data_type]*3):\n",
    "        current_i = ans[data_name][i]\n",
    "        pre_i = ans[data_name][i - 1]\n",
    "        x_i = pd.merge(current_i, pre_i, how='inner', on='index')\n",
    "        current_i = current_i.set_index('index')\n",
    "        x_i['diff'] = x_i['3_y'] - x_i['3_x']\n",
    "        diff_i = x_i[['index', 'diff']]\n",
    "        diff_i['diff'] = diff_i['diff'].apply(lambda x: 3 if x > 0 else 2)\n",
    "        current_i['diff'] = 1\n",
    "        current_i['diff'][diff_i['index']] = diff_i['diff'].tolist()\n",
    "        current_i.to_csv(f'{cur_root_dir}/{data_type}_{data_name}/task2/{i}/diff_triplet_value.tsv', header=None, sep='\\t', index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
